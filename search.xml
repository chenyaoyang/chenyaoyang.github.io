<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SHA-2算法]]></title>
    <url>%2F2019%2F04%2F03%2FSHA-2%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景前面介绍了SHA-1的详细内容。因为SHA-1已经被认为是不安全的，所以又开发了SHA-2。SHA-2可分为6种不同标准：SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。其后数字表示摘要长度。 SHA-256和SHA-512是很新的散列函数，前者以定义一个word为32位，后者则定义一个word为64位。它们分别使用了不同的偏移量，或用不同的常量，然而，实际上二者结构是相同的，只在循环运行的次数上有所差异。SHA-224以及SHA-384则是前述二种散列函数的截短版，利用不同的初始值做计算。我们这里介绍SHA-512的内容，其余标准见标准文档 详细流程SHA-512的最大数据长度为2^128 - 1。它的摘要长度为512位，分块长度为1024位。SHA-512是按照SHA-1的模型而来的，而SHA-1又是仿照MD5而来的，所以他们之间有很多相似之处，对于相似地方我们只简要说明一下 填充填充为1024的倍数少128位，通用填充总是要进行的，即使已满足条件 添加长度将原始信息长度写成128位形式填充到最后 分块按1024一组进行分块 初始化链接变量一共有8个初始化变量，实际上多少个初始化变量是由最后摘要长度决定的。如MD5为128位，就是4个，SHA-1位160位，就是5个。而SHA-512是512位，就是8个，但每个是64位：12345678A = 6a09e667f3bcc908B = bb67ae8584caa73bC = 3c6ef372fe94f82bD = a54ff53a5f1d36f1E = 510e527fade682d1F = 9b05688c2b3e6c1fG = 1f83d9abfb41bd6bH = 5be0cd19137e2179 轮次操作 将初始化变量复制到abcdefgh中 将当前子块每64位一组，分16组 一共有80轮，每轮以当前块，abcdefgh和常量K[t]，常量总共有80个，这些常数的取值是前80个质数的立方根的小数部分的前64位。每轮操作如下：12345678910temp1 = h + ch(e,f,g) + sum1(e)+wt+kttemp2 = sum0(a) + maj(a,b,c)a = temp1 + temp2b = ac = bd = ce = d + temp1f = eg = fh = g 上面运算中t为轮次号，加法均是加完之后取2^64模，几个函数如下定义：1234ch(e,f,g) = (e and f) xor (not e and g)maj(a,b,c) = (a and b) xor (a and c) xor (b and c)sum1(e) = e&gt;&gt;14 xor e&gt;&gt;18 xor e&gt;&gt;41sum0(a) = a&gt;&gt;28 xor a&gt;&gt;34 xor a&gt;&gt;39 对于每轮中的w，前16轮就是分好的16组子块，后面的w如下计算1234wt = a1(w(t-2)) + w(t-7) + a0(w(t-15)) + w(t-16)a1(x) = x&gt;&gt;1 xor x&gt;&gt;8 xor x&gt;3a0(x) = x&gt;&gt;17 xor x&gt;&gt;19 xor x&gt;10 上面&gt;&gt;表示循环右移，&gt;表示右移，空出的补零 80轮之后计算出的abcdefgh分别加上原来的ABCDEFGH作为处理下一个块的输入 和MD5与SHA-1一样，处理完所有块之后，最后的ABCDEFGH拼接到一起就是摘要信息。 题图来自unsplash：https://unsplash.com/photos/OIYrmG5FNFg]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SHA-1算法]]></title>
    <url>%2F2019%2F04%2F02%2FSHA-1%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景SHA全称Secure Hash Algorithm，即安全散列算法。它是一个算法簇，包含多种算法。是FIPS所认证的安全散列算法。能计算出一个数字消息所对应到的，长度固定的字符串（又称消息摘要）的算法。且若输入的消息不同，它们对应到不同字符串的机率很高。 SHA-1于1995年发布，应用相当广泛，被认为是MD5的替代者，但是随着技术的进步SHA-1已经被认为是不安全的，特别是2017年荷兰密码学研究小组CWI和Google正式宣布攻破了SHA-1 SHA-2在2001年发布，包括SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。虽然至今尚未出现对SHA-2有效的攻击，它的算法跟SHA-1基本上仍然相似，所以理论上也有漏洞 SHA-3在2015年正式发布，SHA-3并不是要取代SHA-2，因为SHA-2当前并没有出现明显的弱点。由于对MD5出现成功的破解，以及对SHA-0和SHA-1出现理论上破解的方法，NIST感觉需要一个与之前算法不同的，可替换的加密散列算法，也就是现在的SHA-3。 SHA家族几种算法比较如下： 这里我们先来梳理SHA-1的详细过程 详细流程SHA-1和MD5设计非常类似，标准文档链接，基本步骤如下 填充和MD5一样，填充总是增加的，也就是512的倍数少64 添加长度将原始长度的64位表示添加到末尾 分块每512位一块 初始化链接变量总共有5个，其中ABCD和MD5一样，D的值位C3D2E1F0。五个值如下12345A=67452301B=efcdab89C=98badcfeD=10325476E=c3d2e1f0 处理块 将A~E赋值到a~e 将每块分为16个子块，每个子块32位 SHA共4轮，每轮20步，输入为子块，abcde，常量。整体算法和MD5类似。与MD5不同，这里的常量仅有四个值，每轮用一个，分别是：5a827999,6ed9eba1,8f1bbcdc，ca62c1d6。 每一步的逻辑如下图所示 具体来说，一次操作的数学表达式如下：1abcde=(e + P + a&lt;&lt;5 + W[] + K[]),a,b&lt;&lt;30,c,d P依然还是一个非线性操作，&lt;&lt;表示循环左移，W[]表示计算某一子块，K[]表示该轮的常量 w是将16个子块扩展为80个，前16个就是原16个子块，后面的按照下面公式计算1w[t] = (w[t-16] xor w[t-14] xor w[t-8] xor w[t-3])&lt;&lt;1 P的具体运算如下轮次 | P—|—1 | (b AND c) OR ((NOT b) AND d)2 | b xor c xor d3 | (b AND c) or (b AND d) OR (c AND d)4 | b xor c xor d 就这样对每一块执行80次后，输出的abcde就是160位的散列值。相比于MD5无规则的运算，SHA-1基本可以用公式表示整个算法 题图来自unsplash：https://unsplash.com/photos/I2UR7wEftf4]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MD5算法]]></title>
    <url>%2F2019%2F04%2F02%2FMD5%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景MD5全称Message-Digest Algorithm，就是信息摘要算法。是一种被广泛使用的密码散列函数，可以产生出一个128位的散列值，它是由美国密码学家Ron Rivest开发的，于1992年公开。最开始算法是MD，很快出现MD2，不过算法很脆弱，又改为研究MD3，不过最终研发失败。接下来又出现MD4，但仍不理想，最后研发出MD5，成为一个全世界广泛使用的算法。 如今，MD5被证实存在一系列弱点，可以被加以破解，同时也无法防止碰撞，所以已经不适合安全认证。但是，MD5算法因其普遍、稳定、快速的特点，仍广泛应用于普通数据的错误检查领域。 作为一个经典算法，这里就详细梳理一下整个流程。MD5标准文档见这里 详细步骤填充第一步是在初始消息中填充信息，使其达到一个要求的长度，即比512位的倍数少64位。如原始消息是1000位，512*3=1536,1536-64=1472，所以要填充472位。填充的内容是1个1和多个0 填充总是要进行的，即使消息长度已经比512的倍数少64位，仍要填充512位 添加长度计算源消息的长度，表示成64位填充到末尾。如果消息的长度大于2^64，则使用低64位填充，即len mod 2^64 添加完之后，整体长度为512的倍数 分块将输入以512位一组分块 初始化链接变量初始化4个32位数字，16进制表示如下1234A = 0x67452301B = 0xEFCDAB89C = 0x98BADCFED = 0x10325476 处理块前面都是初始化操作，这里开始才是算法开始 复制将4个初始化变量复制到4个变量abcd中，这四个变量组成一个128位寄存器，用于表示中间结果和最终结果 分解将每块512位分解为16个子块，每个子块32位 轮次迭代主循环有4轮，每轮有16次操作。每次操作对abcd的其中三个做一次非线性运算P，然后将所得结果加上第四个变量、一个子块和一个常数。再将所得结果向左循环移位,最后加上abcd的其中给一个，最后用该结果取代abcd其中之一。如下图所示 表示成数学表达式如下1a = b + ((a + P(b,c,d) + M[i] + t[k])&lt;&lt;&lt;s) P的每一轮操作如下： 轮次 P 1 (b AND c) OR ((NOT b) AND b) 2 (b AND d) OR (c AND (NOT d) 3 b XOR c XOR d 4 C XOR (b OR (NOTd) 关于轮次操作中abcd取哪一个，取哪一个子块以及移位多少，都没有公式推导，算法中有固定步骤，只有常量t[i] = 4294967296*abs(sin(i))的整数部分。下面我们给出每一步详细操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081首先定义P的4种运算：F( X ,Y ,Z ) = ( X &amp; Y ) | ( (~X) &amp; Z )G( X ,Y ,Z ) = ( X &amp; Z ) | ( Y &amp; (~Z) )H( X ,Y ,Z ) =X ^ Y ^ ZI( X ,Y ,Z ) =Y ^ ( X | (~Z) )再定义4个函数：FF(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + F(b,c,d) + Mj + ti) &lt;&lt; s)GG(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + G(b,c,d) + Mj + ti) &lt;&lt; s)HH(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + H(b,c,d) + Mj + ti) &lt;&lt; s)II(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + I(b,c,d) + Mj + ti) &lt;&lt; s)这4轮64步分别如下：第一轮：FF(a ,b ,c ,d ,M0 ,7 ,0xd76aa478 )FF(d ,a ,b ,c ,M1 ,12 ,0xe8c7b756 )FF(c ,d ,a ,b ,M2 ,17 ,0x242070db )FF(b ,c ,d ,a ,M3 ,22 ,0xc1bdceee )FF(a ,b ,c ,d ,M4 ,7 ,0xf57c0faf )FF(d ,a ,b ,c ,M5 ,12 ,0x4787c62a )FF(c ,d ,a ,b ,M6 ,17 ,0xa8304613 )FF(b ,c ,d ,a ,M7 ,22 ,0xfd469501)FF(a ,b ,c ,d ,M8 ,7 ,0x698098d8 )FF(d ,a ,b ,c ,M9 ,12 ,0x8b44f7af )FF(c ,d ,a ,b ,M10 ,17 ,0xffff5bb1 )FF(b ,c ,d ,a ,M11 ,22 ,0x895cd7be )FF(a ,b ,c ,d ,M12 ,7 ,0x6b901122 )FF(d ,a ,b ,c ,M13 ,12 ,0xfd987193 )FF(c ,d ,a ,b ,M14 ,17 ,0xa679438e )FF(b ,c ,d ,a ,M15 ,22 ,0x49b40821 )第二轮GG(a ,b ,c ,d ,M1 ,5 ,0xf61e2562 )GG(d ,a ,b ,c ,M6 ,9 ,0xc040b340 )GG(c ,d ,a ,b ,M11 ,14 ,0x265e5a51 )GG(b ,c ,d ,a ,M0 ,20 ,0xe9b6c7aa )GG(a ,b ,c ,d ,M5 ,5 ,0xd62f105d )GG(d ,a ,b ,c ,M10 ,9 ,0x02441453 )GG(c ,d ,a ,b ,M15 ,14 ,0xd8a1e681 )GG(b ,c ,d ,a ,M4 ,20 ,0xe7d3fbc8 )GG(a ,b ,c ,d ,M9 ,5 ,0x21e1cde6 )GG(d ,a ,b ,c ,M14 ,9 ,0xc33707d6 )GG(c ,d ,a ,b ,M3 ,14 ,0xf4d50d87 )GG(b ,c ,d ,a ,M8 ,20 ,0x455a14ed )GG(a ,b ,c ,d ,M13 ,5 ,0xa9e3e905 )GG(d ,a ,b ,c ,M2 ,9 ,0xfcefa3f8 )GG(c ,d ,a ,b ,M7 ,14 ,0x676f02d9 )GG(b ,c ,d ,a ,M12 ,20 ,0x8d2a4c8a )第三轮HH(a ,b ,c ,d ,M5 ,4 ,0xfffa3942 )HH(d ,a ,b ,c ,M8 ,11 ,0x8771f681 )HH(c ,d ,a ,b ,M11 ,16 ,0x6d9d6122 )HH(b ,c ,d ,a ,M14 ,23 ,0xfde5380c )HH(a ,b ,c ,d ,M1 ,4 ,0xa4beea44 )HH(d ,a ,b ,c ,M4 ,11 ,0x4bdecfa9 )HH(c ,d ,a ,b ,M7 ,16 ,0xf6bb4b60 )HH(b ,c ,d ,a ,M10 ,23 ,0xbebfbc70 )HH(a ,b ,c ,d ,M13 ,4 ,0x289b7ec6 )HH(d ,a ,b ,c ,M0 ,11 ,0xeaa127fa )HH(c ,d ,a ,b ,M3 ,16 ,0xd4ef3085 )HH(b ,c ,d ,a ,M6 ,23 ,0x04881d05 )HH(a ,b ,c ,d ,M9 ,4 ,0xd9d4d039 )HH(d ,a ,b ,c ,M12 ,11 ,0xe6db99e5 )HH(c ,d ,a ,b ,M15 ,16 ,0x1fa27cf8 )HH(b ,c ,d ,a ,M2 ,23 ,0xc4ac5665 )第四轮II(a ,b ,c ,d ,M0 ,6 ,0xf4292244 )II(d ,a ,b ,c ,M7 ,10 ,0x432aff97 )II(c ,d ,a ,b ,M14 ,15 ,0xab9423a7 )II(b ,c ,d ,a ,M5 ,21 ,0xfc93a039 )II(a ,b ,c ,d ,M12 ,6 ,0x655b59c3 )II(d ,a ,b ,c ,M3 ,10 ,0x8f0ccc92 )II(c ,d ,a ,b ,M10 ,15 ,0xffeff47d )II(b ,c ,d ,a ,M1 ,21 ,0x85845dd1 )II(a ,b ,c ,d ,M8 ,6 ,0x6fa87e4f )II(d ,a ,b ,c ,M15 ,10 ,0xfe2ce6e0 )II(c ,d ,a ,b ,M6 ,15 ,0xa3014314 )II(b ,c ,d ,a ,M13 ,21 ,0x4e0811a1 )II(a ,b ,c ,d ,M4 ,6 ,0xf7537e82 )II(d ,a ,b ,c ,M11 ,10 ,0xbd3af235 )II(c ,d ,a ,b ,M2 ,15 ,0x2ad7d2bb )II(b ,c ,d ,a ,M9 ,21 ,0xeb86d391 ) 经过这64步之后，A=a，B=b，C=c，D=d，然后将ABCD作为处理下一明文块的输入 应用MD5已经广泛使用在为文件传输提供一定的可靠性方面。例如，服务器预先提供一个MD5校验和，用户下载完文件以后，用MD5算法计算下载文件的MD5校验和，然后通过检查这两个校验和是否一致，就能判断下载的文件是否出错。 题图来自unsplash：https://unsplash.com/photos/HsEz1XZ1TO8]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kademlia：一个基于异或度量的P2P信息系统]]></title>
    <url>%2F2019%2F04%2F01%2FKademlia%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E%E5%BC%82%E6%88%96%E5%BA%A6%E9%87%8F%E7%9A%84P2P%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[论文原文：https://link.springer.com/chapter/10.1007%2F3-540-45748-8_5 原文除了摘要，总共有5部分，分别是：介绍、系统描述、证明、实现要点、总结。这里只翻译摘要和核心的系统描述以及实现要点部分 摘要我们描述了一个在易发生故障的环境中具有可证明的一致性和高性能的P2P系统。我们的系统使用一种新的基于异或度量拓扑来进行路由查询和结点定位，这种拓扑简化了算法并易于证明。该拓扑在信息交换时仅传递或增强有用的信息，系统利用这些信息进行并行或异步的信息查询，同时也能容忍节点故障，并且不会给用户带来超时延迟 系统描述我们的系统基本上采取了和其他DHT系统一样的方法。节点的 ID 是 160 位不透明的值，我们的算法也是逐步“逼近”所期望的 ID ，并以对数级的速度收敛到要查询的目标。 Kademlia把一个节点看这一颗二叉树的叶子，每个节点的位置由其ID的最短唯一前缀决定。图一展示了一个唯一前缀为0011节点在树中的位置。对于任意给定的一个节点，我们都把树划分为一系列不包含该节点的逐步降低的子树。最高层的子树有二叉树中不包含该节点的那一半组成，接下来的子树由剩余的不包含该节点的一半组成，以此类推。在示例中的0011节点，子树被圈出来，分别由前缀为0,01,000以及0010的节点构成 Kademlia协议确保每个节点都至少知晓这些子树中的一个节点。有了这个保证，任何一个节点都可以通过ID定位其他节点。1110的示例，其中节点 0011通过逐步查询它所知道的最佳节点来取得和越来越低层次子树的联系；最后查询收敛到目标节点。 接下来，我们会补充一些细节，并更具体的描述查询算法。首先，我们会给出 ID 接近这个概念的准确定义，这样就可以谈及“在距离 key 最近的k个节点上存储或者查询 键值对”这样的行为。然后，我们会介绍一个查询协议，该协议即使在任何节点都不和某个key具有相同的前缀或者和某个给定节点关联的子树中有一些为空的情况下，都可以正常工作。 异或度量每个Kademlia节点都有160位的ID，节点id构造像Chord一样，但是为了简化，我们假设机器在加入系统时选择一个随机的160位标识符。节点传输的每个消息都包含其ID，并且允许接收方在必要时记录发送方的存在。 key同样也是160位的标识符。为了发布和查找键值对，Kademlia依赖于两个标识符之间的距离。给定两个160位标识符x和y,Kademlia将它们之间的距离定义为它们的为异或（d(x,y)），并转化为整数。 我们首先注意到虽然异或不是欧几里得度量，但仍是有效的。很明显，d(x,x) = 0。如果x ≠ y则d(x,y)&gt;0。以及d(x,y)=d(y,x)。除此之外，异或还满足三角不等式，因为d(x,z) = d(x,y) xor d(y,z),而a+b &gt;= a xor b 和chord的顺时针圆周度量一样，异或也是单向的。给定任意一个点x和距离d&gt;0，都会存在一个点y，使得d(x,y) = d。单向性确保所有对相同键的查找都沿着相同的路径收敛，而不管初始节点是什么。因此，沿着查找路径缓存键值对可以缓解热点。就像Pastry一样，但不像Chord，异或拓扑是对称的，即(d(x,y) = d(y,x)) 节点状态Kademlia节点存储彼此之间的路由联系信息。对于每个i（0 &lt;= i &lt; 160），节点都会存储一个含有&lt;IP地址列表;UDP端口;节点ID&gt;列表，每个列表项表示距离自己2^i和2^i+1之间的节点。我们称这些列表为k桶。每个k桶都按照时间顺序进行排序，最后一次看到的节点位于头部，最近一次看到的节点位于尾部。对于较小的i值，为k桶通常是空的(因为没有合适的节点)。对于较大的i值，列表长度可以增长到k，其中k是一个系统范围的全局变量。选择k时，任何给定的k个节点都不太可能在一小时内发生故障(例如k = 20)。 当Kademlia节点接收到来自另一个节点的任何消息(请求或响应)时，它将更新发送方节点ID所在的k桶。如果发送节点已经存在于收件人的k桶中，则收件人将其移动到列表的末尾。如果节点还没有在适当的的k桶中，并且桶的条目数小于k，那么接收方只需在列表的末尾插入新的发送方。但是，如果应村的k桶已满，则接收方将PING k桶的最近最少出现的节点，以决定该做什么。如果最近最少出现的节点没有响应，则将其从k桶中删除，并在末尾插入新的发送者。否则，如果最近最少出现的节点有响应，则将其移动到列表的末尾，并丢弃新发送方的联系人。 k桶有效地实现了一个最近很少键的清除策略，除非活动节点从未从列表中删除。这种对旧的联系的处理是基于对Saroiu等人收集的Gnutella微量数据分析而得出的。图1显示了Gnutella节点继续在线一个小时的百分比，这是当前正常运行的时间函数。节点运行的时间越长，它继续运行一个小时的可能性就越大。通过保留旧的联系人，k桶最大化了它们所存的节点保持在线的可能性。 k桶的第二个好处是，可以抵抗特定的DoS攻击。无法通过向系统中注入新节点来刷新节点的路由状态。Kademlia节点只会在旧节点离开系统时将新节点插入到k桶中。 Kademlia协议Kademlia协议由四个rpc组成：PING, STORE, FIND NODE 和 FIND VALUE。PING探测一个节点，看看它是否在线。STORE指示节点存储键值对，以便以后检索。 FIND NODE以160位的ID作为参数。接收者返回&lt;IP地址;UDP端口;节点ID&gt;三元组表示它知道的最接近目标ID的k个节点。这些三元组可以来自单个k桶，也可以来自多个k桶（如果最近的k桶没有满的话）。在任何情况下，RPC接收方都必须返回k个条目(除非所有k个桶的组合中有少于k个节点，在这种情况下，它返回它所知道的每个节点)。 FIND VALUE的行为类似于FIND NODE，也返回&lt;IP地址;UDP端口;节点ID&gt;三元组，只有一个例外。如果RPC接收方收到了STORE的RPC，它只返回存储值。 在所有RPC中，接收者必须回显一个160位的随机RPC ID，这为地址伪造提供了一定的抵抗力。还可以在RPC应答上附加ping，以便RPC接收方获得对发送方网络地址,从而获得额外保证。 Kademlia参与者必须执行的最重要的过程是定位距离某个给定节点ID最近的k个节点。我们将此过程称为节点查找。Kademlia使用递归算法进行节点查找。查找发起者首先从最近的非空k桶中选择α个节点（如果已知节点数少于α，则选择全部节点）。。发起者发送并行或异步的rpc FIND NODE给α个节点。α是一个全系统的并发性参数，比如3 在递归步骤中，初始节点将FIND NODE重新发送到它从之前的rpc结果中了解到的节点（这个递归可以从先前的RPC返回后开始）。收到响应后，发起者向离目标更近的其中α个未被请求的节点发送FIND NODE。无法快速响应的节点将从考虑中删除，直到它们再次响应。如果一轮查找节点未能返回比已知的更近的节点，则初始节点将FIND NODE重新发送给它尚未查询的k个最近的节点。当初始节点查询并从它所知的k个最近的节点中获得响应时，查找将终止。当α= 1查找算法类似于Chord的信息消耗和延迟检测失败的节点。然而，Kademlia可以通过路由获得更低的延迟，因为它可以灵活地选择k个节点中的任意一个来转发请求。 大多数操作都是根据上面的查找过程实现的。要存储键值对，参与者需要找到距离键最近的k个节点，并向它们发送STORE rpc。此外，每个节点每小时重新发布它拥有的键值对，这确保键值对的持久性概率维持较高水平。通常，我们还需要键值对的原始发布者每24小时重新发布一次。否则，所有的键值对将在最初发布24小时后过期，从而限制系统中的陈旧信息。 最后，为了使键值对的发布-搜索在声明周期中保持一致，我们要求每当一个节点w观察到一个新的节点u时，这个新节点u更接近w的一些键值对时，w将这些对复制到u，而不从自己的数据库中删除。 要查找一个键值对，初始节点首先进行查找，查找id最接近的k个节点。不过，使用的rpc是FIND VALUE。此外，当任何节点返回值时，程序立即停止。出于缓存的目的，一旦查找成功，请求节点将键值对存储在它观察到的最接近目标但没有返回值的节点上。 由于拓扑的单向性，未来对相同键的搜索可能会在查询最近的节点之前命中缓存的条目。在某个键非常流行的时候，系统可能会在许多节点上缓存它。。为了避免“过度缓存”，我们将任何节点数据库中的键值对的过期时间设置为与当前节点和ID最接近的节点之间的节点数量成指数反比。虽然简单的LRU清除将导致类似的生存期分布，但是没有选择缓存大小的天生方法，因为节点不知道系统将存储多少值。 桶中内容经常会保持最新，这是由于通过节点传输的请求流量造成的。为了避免在没有通信量的情况下出现病态情况，每个节点需要在某个桶所在范围内一个小时没有执行节点查找时进行刷新。刷新意味着在桶的范围内随机选择一个ID，并对该ID执行节点搜索。 要加入网络，节点u必须与已经参与其中的节点w有联系。然后，u对自己的节点ID执行节点查找。最后，u刷新所有k桶。在刷新期间，u都填充自己的k桶，并根据需要将自己插入其他节点的k桶中。 路由表根据协议，Kademlia的基本路由表结构相当简单，不过在处理高度不平衡的树时需要稍作改进。路由表是一个二叉树，它的叶子是k桶。每个k桶包含一些节点，它们的id具有一些公共前缀。前缀是k桶在二叉树中的位置。因此每个k桶覆盖ID空间的某个范围，所有k桶一起覆盖整个160位ID空间，没有重叠。 路由树中的节点根据需要动态分配。图4说明了这个过程。最开始，一个节点u的路由树只有一个节点，一个k桶覆盖整个ID空间。当u获得一个新的连接时，他就会将其插入适当的k桶。如果该桶未满，只需简单插入。反之，如果k桶的范围包含u自己的ID，那么这个bucket就会被分成两个新桶，旧的内容被划分到这两个桶中，然后重复插入尝试。如果k桶已满，且不包含u的ID，则直接丢弃新的信息。 一个复杂的情况出现在高度不平衡的树中。假设节点u加入系统，并且是ID从000开始的惟一节点。进一步假设系统已经有超过k个前缀为001的节点。每个带001前缀的节点将有一个空的应该将u插入其中的k桶，但是u在对其k桶进行更新是只会通知到其中k个节点。为了避免这个问题，Kademlia节点将所有有效的联系人保存在至少k个节点大小的子树中，即使这需要分割桶，而节点本身的ID并不驻留在桶中。图5显示了这些额外的分割。当 u 更新这些分割过的 buckets 时，所有具有 001 前缀的节点都会得到通知。 高效的key重发布为了确保键值对的持久性，节点必须定期重新发布key。否则，有两种情况会导致对有效 key 的查询失败。首先，在发布时，最初获得键值对的k个节点中的一些会离开网络。其次，新加入节点的 ID 相比键值对的原始发布节点，可能距离该key更近一些。在这两种情况下，拥有键值对的节点必须要对其进行重新发布，这样就再次保证了从距离该 key 最近的 k 个节点上可以获取该 key 。 为了对节点离开造成的问题的弥补， Kademlia 每一小时就对每个键值对进行重新发布。这种实现会导致很多消息往来，存储键值对的k个节点每小时都会进行一次节点查询，饭后进行k-1出STORErpc调用。幸运的是，可以对这种过程进行优化。首先，当一个节点收到一个针对某个键值对的STORE rpc时，他可以认为该rpc也发送给了其他k-1个节点，因此他就不会重新发布键值对。这就保证了只要重新发布间隔不是精确同步的，对于任何一个键值对来说，每小时只会有一个节点对其进行重新发布。 第二个优化是避免在重新发布key之前进行节点查找。如2.4小节所示，为了解决不平衡树，节点在需要时可以分裂k桶以保持其具有关于一个节点个数超过k的边缘子树的全部知识。在重新发布键值对之前，如果节点u更新了该字数中k个节点的所有k桶，那么他将自动获取关于某个key值最近的k个节点信息。对于这些桶的更新代价可以分摊到许多key的重新发布上。 要想知道为何在对规模大于k的子树中的桶进行更新后，就无需再进行节点查询操作，就得考虑两种情况。如果要被重新发布的key位于该子树覆盖的ID区间内，那么由于该子树的规模至少为 k ，并且 u 具有关于该子树的全部知识，因此u一定知道距离该key最近的 k 个节点。另一方面，如果key位于子树范围之外，而u是距离该key最近的k个节点之一，那么按照 u 的k桶规则，所有距离该key比子树更近一些的区间中的元素都少于k。因此， u 将知道这些k桶中的所有节点，再加上关于子树的知识，就可以得到距离该 key 最近的 k 个节点。 当一个新节点加入系统时，对于每个 key-vaule 对来说，如果该节点为其 k 个最近节点之一，那么必须对其进行存储。系统中原有的节点同样可以通过其边缘子树的完整知识，知道哪些键值对需要存储在该新增节点上。每个了解到新节点的节点都会发起 STORE RPC 把相关的 key-value 对传送到新节点之上。为了避免重复的 STORE RPC ，只有那些自身 ID 比其他节点 ID 更接近 key 的节点才会进行 key-value 对的传送。 实现注意事项在本小节中，我们将介绍两个用来改进 Kademlia 实现性能的重要技术。 优化联系记录对于k桶最基本的属性是能够提供LRU检查，并且在不丢失任何有效信息的情况下删除无效信息。如2.2节所述，如果一个k桶已满，他会在收到该桶范围内的任何一个位置节点的消息时发送一条PING。这个PING用来检测最近最少使用的节点是否仍然有效。如果无效，新的节点为替代带旧的节点。不幸的是，这种行为会导致大量的ping消息充斥在网络中 为了减少这些流量，Kademlia会延迟这个探测行为，直到要发送一条有用的消息给他们时。当一个节点收到一个未知节点的消息时，如果所在的k桶已满，节点会把它放在一个置换缓存中，当节点下次查询是，对于无效的节点会被用缓存中的节点替换。缓存中的节点时按照时间排序的，最近的节点有最高的优先级。 有一个和Kademlia使用UDP相关的问题。当网络丢包时，会丢失一些有效节点的信息。通常丢包意味着网络阻塞，所以Kademlia会锁定那些未响应的节点，并在一个以指数增长的退避时间间隔内不向其发送任何消息。因为在Kademlia查询过程中，大部分情况下只需联系到 k 个节点中的一个，所以一般情况下，系统不会向同一节点重传被丢弃的 RPCs 如果连续五条消息都没有响应，则认为是过期的。如果k桶不满，或缓存为空，那么Kademlia只是将过期信息打上标记，而不是立即清除，这就保证了节点出现短暂的网络故障时，不会完全清除其k桶 加速查询另一个优化是用过增加路由表大小来减少查询的步数。从概念上讲，可以考虑每次使用b位ID而不是一位。和前面介绍一样，期望的步数是log2n。如果把路由表扩大到2^blog2^b n个k桶，我们可以减少步数到log2^b n 2.4小节较少了当Kademlia节点的k桶满且其区间包含了节点自己ID是，如何去分裂该k桶。然而，在实现中，也会把不包含节点自己ID的区间分裂成b-1层。比如，如果b=2，不包含节点ID的那一半会分类一次。如果b=3，会分裂两层，最多四个区间，以此类推。大致的分裂规则是，如果一个满的k桶包含了节点自身的ID或其在路由树中的深度d满足d=O(mod b)，就会被分裂，当前实现是b=5 虽然基于 XOR 的路由算法和 Pastry、 Tapestry以及 Plaxton 分布式搜素算法中第一阶段的路由算法很相似，但是当它们一般化到 b&gt;1 时就都变得非常复杂。如果没有基于XOR的拓扑，就需要另外使用一个算法结构来从具有相同前缀但是后 b 位又不同的节点中找出目标节点。这三个算法采用了不同的方法来解决这个问题，各具缺点；除了大小为O(2^b log2^b n)的主路由表外，它们都需要一个大小为O(2^b)的二级路由表。这增加了启动和维护的成本，也使协议变得复杂，并且对于Pastry和Tapestry来说，也使得对其进行正确性和一致性方面的规范分析变得困难或不可能。有一个针对Plaxton的证明，但是该系统难以适应像 P2P 这样的高故障概率环境。 题图来自unsplash: https://unsplash.com/photos/phIFdC6lA4E]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RSA加密]]></title>
    <url>%2F2019%2F03%2F31%2FRSA%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景RSA是一种非对称加密算法，该算法在1977年由Ron Rivest、Adi Shamir和Leonard Adleman三人提出，算法一起三人姓氏开头字母命名。 对极大整数做因数分解的难度决定了RSA算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA算法愈可靠。假如有人找到一种快速因数分解的算法的话，那么用RSA加密的信息的可靠性就肯定会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的RSA钥匙才可能被强力方式解破。到当前为止，世界上还没有任何可靠的攻击RSA算法的方式。只要其钥匙的长度足够长，用RSA加密的信息实际上是不能被解破的。 算法流程RSA算法本身比较简单，基本流程如下： 选择两个大素数p和q，p不等于q 计算N = p*q 令r=(p-1)(q-1) 寻找一个小于r的的整数e，使e与r互质 寻找一个整数d，使 (d*e) mod r = 1 (N,e)是公钥，(N,d)是私钥 加密时，若明文为P，则密文C = P^e mod N 解密时，P = C^d mod N 举例1234567取 p = 7，Q = 17n = p*q = 119r = 6 * 16 = 96取e = 5取d = 77假设明文为10，密文c = 10^e mod n = 40解密： 40^d mod n = 10 对于英文字母我们可以令a = 1，b = 2,….,z = 26。然后一个字母一个字母加密 RSA安全性分析回顾整个算法。我们公开的是公钥e和n，保密的是私钥d，私钥是由e和r构成的。由于e是公开的，所以攻击者需要求得r。一个途径就是根据公开的n求得p和q就得到了r。但是p和q是很大的素数，导致n也很大，所以因数分解异常困难，有数学分析证明，如果n能达到100位数，那么正确求得q和p需要数十年的时间。 速度毫无疑问，由于涉及大量大数运算，RSA加密速度很慢。一种有效的方法是加密的一方使用一种可靠的对称加密算法加密明文，然后用RSA加密较短的秘钥，最后连同RSA加密的密文和对称加密算法加密的密文一同传输。 数字签名除了用作加密，也可以用作数字签名。首先A计算消息的散列值，然后对散列值用自己的私钥加密，之后连同消息和加密后的密文一起传输给B。B接受到后计算散列值，然后用A的公钥解密，只有解密后的散列值和自己计算的完全一样就可以证明消息未被篡改。 题图来自unsplash：https://unsplash.com/photos/KidY3t8O4PE]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grpc学习]]></title>
    <url>%2F2019%2F03%2F31%2Fgrpc%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[背景gRPC是一个高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf序列化协议开发，且支持众多开发语言。关于ProtoBuf的详细内容可以参考我的这篇文章 根据官方页面显示，目前支持的语言如下： 也就是说在这些语言平台上，完全可以用grpc实现rpc通信，同时又由于protobuf的编码效率高，所以可以实现替代jsonrpc HelloWorld 国际惯例，我们先用go语言写一个grpc版本的hellworld。首先要安装grpc库1go get -u google.golang.org/grpc protobuf定义及编译首先定义protobuf文件如下：1234567891011121314151617181920syntax = &quot;proto3&quot;;option java_multiple_files = true;option java_package = &quot;io.grpc.examples.helloworld&quot;;option java_outer_classname = &quot;HelloWorldProto&quot;;package helloworld;service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;message HelloRequest &#123; string name = 1;&#125;message HelloReply &#123; string msg = 1;&#125; 几点需要注意的，首先protobuf版本为proto3，其中定义了两个message，分别用于请求和响应，又定义了一个service，其中有一个rpc方法，接受请求返回响应 然后执行下面命令生成pb.go文件1protoc ./helloworld/helloworld.proto --go_out=plugins=grpc:./ 我们看一下生成的go代码，首先定义的两个message各自成为一个struct123456789101112type HelloRequest struct &#123; Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"` XXX_NoUnkeyedLiteral struct&#123;&#125; `json:"-"` XXX_unrecognized []byte `json:"-"` XXX_sizecache int32 `json:"-"`&#125;type HelloReply struct &#123; Msg string `protobuf:"bytes,1,opt,name=msg,proto3" json:"msg,omitempty"` XXX_NoUnkeyedLiteral struct&#123;&#125; `json:"-"` XXX_unrecognized []byte `json:"-"` XXX_sizecache int32 `json:"-"`&#125; 这两个struct中含有我们定义message时定义的成员变量。之后我们还定义了一个名为Greeter的服务，它变成了一个interface123type GreeterServer interface &#123; SayHello(context.Context, *HelloRequest) (*HelloReply, error)&#125; 这就是要我们写服务时实现这个接口才能正确定义grpc 服务端服务端代码如下1234567891011121314151617181920type server struct &#123;&#125;func (s *server)SayHello(ctx context.Context, in *helloworld.HelloRequest) (*helloworld.HelloReply, error)&#123; fmt.Println("received:",in.Name) return &amp;helloworld.HelloReply&#123;Msg:"hello " + in.Name&#125;,nil&#125;func main() &#123; lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; s:=grpc.NewServer() helloworld.RegisterGreeterServer(s,&amp;server&#123;&#125;) if err := s.Serve(lis); err != nil &#123; log.Fatalf("failed to serve: %v", err) &#125;&#125; 和写普通rpc代码类型，先定义一个服务类，不过这里要实现我们定义的接口。在main入口里可以发现grpc还是基于tcp传输的，这里的逻辑是定义tcp连接和grpc服务，然后将我们刚才写的服务类注册到grpc中，最后用grpc提供的方法去接管tcp连接即可 客户端客户端代码如下123456789101112131415161718func main() &#123; conn,err:=grpc.Dial("127.0.0.1:1234",grpc.WithInsecure()) if err!=nil &#123; log.Fatal("dial:",err.Error()) &#125; defer conn.Close() c:=helloworld.NewGreeterClient(conn) ctx,cancel:=context.WithTimeout(context.Background(),time.Second) defer cancel() r,err:=c.SayHello(ctx,&amp;helloworld.HelloRequest&#123;Name:"world"&#125;) if err!=nil &#123; log.Fatal("dial:",err.Error()) &#125; fmt.Println("greeting",r.Msg)&#125; 可能是为了降低大家学习成本，grpc的接口设置和go rpc标准包类似。首先利用grpc提供的接口去发起一个连接。接下来，grpc很方便的帮我们包装了一个client类，其中有我们可以调用的rpc方法，省去了之前用字符串表示的麻烦，随后就像函数调用一样去调用远程方法即可，返回一个响应，然后我们从响应中读数据。 有一个小问题需要注意的是，用grpc去发起连接时，目标地址如果是本机地址的话不能像go标准包那样简写为”:1234”，需要像上面代码那样写出全名。 最后先运行服务端代码再运行客户端代码，就成功实现利用grpc通信。该节示例代码见这里 grpc相关概念服务类型 grpc定义了四种服务 单项rpc就是最普通的请求响应模式12rpc SayHello(HelloRequest) returns (HelloResponse)&#123;&#125; 服务端流式rpc客户端向服务端发起一个请求，服务端返回一个数据流响应12rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse)&#123;&#125; 客户端流式rpc客户端向服务端发送数据流请求，客户端仅返回一个响应12rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) &#123;&#125; 双向流式rpc客户端与服务端都以数据流形式通信12rpc BidiHello(stream HelloRequest) returns (stream HelloResponse)&#123;&#125; RPC终止与取消在客户端与服务端，二者对调用的成功与否是独立，可能会出现不同的判断。客户端与服务端可在任何时间取消一个rpc，rpc会立即终止，但只影响之后状态，取消前完成的不会回滚。 超时客户端可以指定超时时间，超过这个时间没有响应测返回DEADLINE_EXCEEDED错误，服务端也可查询还有多久去完成响应。 详细内容实际上上面的helloworld已经可以说明grpc的基本使用，下面只是针对另外几种rpc服务类型进行介绍，这里引用官方的例子，完整代码见这里。 protobuf定义12345678910111213141516171819202122232425262728293031323334353637383940414243service RouteGuide &#123; rpc GetFeature(Point) returns (Feature) &#123;&#125; rpc ListFeatures(Rectangle) returns (stream Feature) &#123;&#125; rpc RecordRoute(stream Point) returns (RouteSummary) &#123;&#125; rpc RouteChat(stream RouteNote) returns (stream RouteNote) &#123;&#125;&#125;message Point &#123; int32 latitude = 1; int32 longitude = 2;&#125;message Rectangle &#123; Point lo = 1; Point hi = 2;&#125;message Feature &#123; string name = 1; Point location = 2;&#125;message RouteNote &#123; Point location = 1; string message = 2;&#125;message RouteSummary &#123; int32 point_count = 1; int32 feature_count = 2; int32 distance = 3; int32 elapsed_time = 4;&#125; 如上所述，我们对四种rpc分别定义了一个方法。编译命令如下1protoc --go_out=plugins=grpc:./ route/route.proto 创建服务端回看刚才生成的代码，有这样一个接口123456type RouteGuideServer interface &#123; GetFeature(context.Context, *Point) (*Feature, error) ListFeatures(*Rectangle, RouteGuide_ListFeaturesServer) error RecordRoute(RouteGuide_RecordRouteServer) error RouteChat(RouteGuide_RouteChatServer) error&#125; 我们的服务端首先要创建一个类实现这个接口 普通rpc12345678func (s *routeGuideServer)GetFeature(ctx context.Context, point *route.Point) (*route.Feature, error)&#123; for _,feature:=range s.savedFeatures&#123; if proto.Equal(feature.Location,point)&#123; return feature,nil &#125; &#125; return &amp;route.Feature&#123;Location:point&#125;,nil&#125; 很简单，参数中的Point和Feature都是我们定义的message，通过输入一个point，然后遍历feature集合，查找符合条件的feature。注意比较两个message可以使用proto包提供的equal方法 服务端流式rpc12345678910func (s *routeGuideServer)ListFeatures(rect *route.Rectangle, stream route.RouteGuide_ListFeaturesServer) error&#123; for _,feature := range s.savedFeatures&#123; if inRange(feature.Location,rect) &#123; if err:=stream.Send(feature);err!=nil&#123; return err &#125; &#125; &#125; return nil&#125; 形象的说，这种rpc就是向服务端发送一个请求，服务端以流的形式返回数据。如代码所示，我们指定一个区域，然后判断所有保存的feature是否在区域内，每判断一个，如果符合条件就以send形式发出。grpc为我们做了很形象的包装，对于输出流，我们只需send即可，不必考虑缓存，同步之类的问题，非常方便。唯一需要注意的是，每send一个数据，就需要判断是否报错，然后随时停止。 客户端流式rpc123456789101112131415161718192021222324252627282930func (s *routeGuideServer)RecordRoute(stream route.RouteGuide_RecordRouteServer) error&#123; var pointCount, featureCount, distance int32 var lastPoint *route.Point startTime := time.Now() for &#123; point,err:=stream.Recv() if err == io.EOF&#123; endTime := time.Now() return stream.SendAndClose(&amp;route.RouteSummary&#123; PointCount:pointCount, FeatureCount:featureCount, Distance:distance, ElapsedTime:int32(endTime.Sub(startTime).Seconds()), &#125;) &#125; if err!=nil&#123; return err &#125; pointCount++ for _,feature := range s.savedFeatures&#123; if proto.Equal(feature.Location,point)&#123; featureCount++ &#125; &#125; if lastPoint != nil&#123; distance += calcDistance(lastPoint,point) &#125; lastPoint = point &#125;&#125; 我们定义的是客户端给服务端发送流式数据，然后服务端返回一个响应。如代码所示，grpc也给我提供了一个形象的封装，对于输入流，我们只需要Recv即可，然后判断输入流是否结束，通过EOF标志位，如果结束返回一个响应。注意这里返回的方法是通过调用SendAndClose方法。通过查看SendAndClose实现，他和上面的send方法一样，都是调用了SendMsg方法。 这段实现的大概意思是，客户端发送一个流，流中包含多个point数据的路径，我们遍历这个流，判断每个point是否在已有的feature集合中，然后计算路径长度，最后返回一个RouteSummary信息。 双向流式rpc123456789101112131415161718192021222324func (s *routeGuideServer)RouteChat(stream route.RouteGuide_RouteChatServer) error&#123; for&#123; in,err:=stream.Recv() if err==io.EOF&#123; return nil &#125; if err!=nil&#123; return err &#125; key := serialize(in.Location) s.mu.Lock() s.routeNotes[key] = append(s.routeNotes[key],in) rn :=make([]*route.RouteNote,len(s.routeNotes[key])) copy(rn,s.routeNotes[key]) s.mu.Unlock() for _,note:=range rn&#123; if err:=stream.Send(note);err!=nil &#123; return err &#125; &#125; &#125;&#125; 既然是双向流，那么就是即能收也能发，如代码所示，每次循环通过Recv从客户端接受一个数据，经过一系列处理后通过send给客户端发送数据。最后知道客户端发送完毕或中间报错为止 最后服务端main方法如下123456789101112131415161718func newServer() *routeGuideServer &#123; s := &amp;routeGuideServer&#123;routeNotes: make(map[string][]*route.RouteNote)&#125; data := exampleData if err := json.Unmarshal(data, &amp;s.savedFeatures); err != nil &#123; log.Fatalf("Failed to load default features: %v", err) &#125; return s&#125;func main() &#123; lis,err:=net.Listen("tcp",":1234") if err!=nil&#123; log.Fatal("listen error:",err.Error()) &#125; server:=grpc.NewServer() route.RegisterRouteGuideServer(server,newServer()) server.Serve(lis)&#125; 和helloworld一样，显示创建grpc服务实例，然后注册服务，最后让grpc接管tcp连接 创建客户端首先创建连接部分还是和helloworld一样123456conn,err:=grpc.Dial("127.0.0.1:1234",grpc.WithInsecure())if err!=nil&#123; log.Fatal("dail error",err.Error())&#125;defer conn.Close()client:=pb.NewRouteGuideClient(conn) 我们接下来还是对四种服务进行调用 普通rpc123456789101112printFeature(client, &amp;pb.Point&#123;Latitude: 409146138, Longitude: -746188906&#125;)func printFeature(client pb.RouteGuideClient, point *pb.Point) &#123; log.Printf("Getting feature for point (%d, %d)", point.Latitude, point.Longitude) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() feature, err := client.GetFeature(ctx, point) if err != nil &#123; log.Fatalf("%v.GetFeatures(_) = _, %v: ", client, err) &#125; log.Println(feature)&#125; 对于普通的rpc我们当做函数调用即可，输入一个point返回一个feature 服务端流式rpc123456789101112131415161718192021222324printFeatures(client, &amp;pb.Rectangle&#123; Lo: &amp;pb.Point&#123;Latitude: 400000000, Longitude: -750000000&#125;, Hi: &amp;pb.Point&#123;Latitude: 420000000, Longitude: -730000000&#125;,&#125;)func printFeatures(client pb.RouteGuideClient, rect *pb.Rectangle) &#123; log.Printf("Looking for features within %v", rect) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.ListFeatures(ctx, rect) if err != nil &#123; log.Fatalf("%v.ListFeatures(_) = _, %v", client, err) &#125; for &#123; feature, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; log.Fatalf("%v.ListFeatures(_) = _, %v", client, err) &#125; log.Println(feature) &#125;&#125; 前面说过，这种类型的rpc是客户端发送一个请求，服务端返回一个数据流。这里我们调用ListFeatures方法，给我们返回一个流，然后我们遍历这个流，通过Recv()一次接受一个数据，并通过EOF标志位判断流是否结束 客户端流式rpc123456789101112131415161718192021222324252627runRecordRoute(client)func runRecordRoute(client pb.RouteGuideClient) &#123; r := rand.New(rand.NewSource(time.Now().UnixNano())) pointCount := int(r.Int31n(100)) + 2 var points []*pb.Point for i := 0; i &lt; pointCount; i++ &#123; points = append(points, randomPoint(r)) &#125; log.Printf("Traversing %d points.", len(points)) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.RecordRoute(ctx) if err != nil &#123; log.Fatalf("%v.RecordRoute(_) = _, %v", client, err) &#125; for _, point := range points &#123; if err := stream.Send(point); err != nil &#123; log.Fatalf("%v.Send(%v) = %v", stream, point, err) &#125; &#125; reply, err := stream.CloseAndRecv() if err != nil &#123; log.Fatalf("%v.CloseAndRecv() got error %v, want %v", stream, err, nil) &#125; log.Printf("Route summary: %v", reply)&#125; 对于这种类型，客户端是发送一系列数据，而服务端返回一个响应，如上面代码所述，我们先随机一些point，然后通过send方法一个一个发送给客户端，发送完后，调用CloseAndRecv关闭流然后等待服务端响应。CloseAndRecv和服务端使用的SendAndClose相对应。 双向流式rpc12345678910111213141516171819202122232425262728293031323334353637383940runRouteChat(client)func runRouteChat(client pb.RouteGuideClient) &#123; notes := []*pb.RouteNote&#123; &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 1&#125;, Message: "First message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 2&#125;, Message: "Second message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 3&#125;, Message: "Third message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 1&#125;, Message: "Fourth message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 2&#125;, Message: "Fifth message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 3&#125;, Message: "Sixth message"&#125;, &#125; ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.RouteChat(ctx) if err != nil &#123; log.Fatalf("%v.RouteChat(_) = _, %v", client, err) &#125; waitc := make(chan struct&#123;&#125;) go func() &#123; for &#123; in, err := stream.Recv() if err == io.EOF &#123; // read done. close(waitc) return &#125; if err != nil &#123; log.Fatalf("Failed to receive a note : %v", err) &#125; log.Printf("Got message %s at point(%d, %d)", in.Message, in.Location.Latitude, in.Location.Longitude) &#125; &#125;() for _, note := range notes &#123; if err := stream.Send(note); err != nil &#123; log.Fatalf("Failed to send a note: %v", err) &#125; &#125; stream.CloseSend() &lt;-waitc&#125; 由于客户端与服务端都是收发流数据，在服务端是收到一个数据处理一个然后返回一个，所以我们在客户端不断的发送数据的同时，也启动一个goroutine去接受数据，在发送完数据后要关闭输出流。 总结 对于普通rpc，客户端就当做方法调用一样去调用某个远端的方法，服务端接受数据后按照返回参数返回值即可 对于服务端流式rpc，客户端通过调用方法发送一个数据，然后利用返回值stream去不断接受数据；而服务端在接受到请求后，不断用send发送数据。 对于客户端流式rpc，客户端通过调用方法获得一个stream后，不断的send发送数据，发送完毕后调用CloseAndRecv关闭输出流并等待响应；而服务端不断使用Recv去接受数据，接受完之后调用SendAndClose关闭输入流发送响应 对于双向流式rpc，客户端通过调用方法获得一个stream后，不断的send发送数据，并在发送的时候启动一个goroutine通过Recv接受数据；而服务端则不断的接受数据、处理数据、返回数据。客户端在发送完毕后注意通过CloseSend关闭输出流]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AES加密]]></title>
    <url>%2F2019%2F03%2F30%2FAES%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景全称Advanced Encryption Standard，即高级加密标准。又称Rijndael加密法。是一个用来替换DES的加密算法，在全世界已经广泛使用，官方文档。 算法简述AES算法支持的秘钥长度和明文块位128~256位（32位为步长），常用的组合是128位明文块和128位密文；128位明文块和256位密文。（严格地说，AES和Rijndael加密法并不完全一样，因为Rijndael加密法可以支持更大范围的区块和密钥长度：AES的区块长度固定为128比特，密钥长度则可以是128，192或256比特；而Rijndael使用的密钥和区块长度均可以是128，192或256比特。） AES密码使用了替换与置换思想，秘钥和明文块的长度决定了需要运行的轮数，最少是10轮，即秘钥和明文块都是128位。算法分为以下两个步骤 一次性初始化操作 轮次操作 本文以128位秘钥和128位明文块为标准介绍 一次性初始化操作扩展秘钥输入的秘钥长度为16字节，需要扩展到11个4*4的矩阵中。也就是说将16字节秘钥扩展为176字节。 秘钥扩展可以表示为下图 扩展出来的第一个矩阵就是输入矩阵，将输入矩阵每4字节记为一个字。以K0=a，k1=b，k2=c，k3=d为例，w0=abcd，依次类推。接着记w0，w1，w2，w3位w数组。用w数组扩展出剩余40个w。剩余40个w分别记为w4，w5，…，w43。其中每个wi都和w(i-1)以及w(i-4)有关，基本规则如下： 若i不是4的倍数，则wi = W(i-1) XOR w(i-4)。若i是4的倍数，wi = T(w(i-1)) XOR w(i-4).函数T流程如下图： T函数分为3部分：旋转，代换，常量异或： 旋转：将一个字中的四个字节循环左移1字节，如abcd变为bcda 代换：使用s盒代换，把每个字节的高四位作为行值，第四位作为列值在S盒寻找输出，S盒如下 常量异或：有10个常量，每轮取一个进行异或，这几个常量如下： 轮数 1 2 3 4 5 6 7 8 9 10 常量值 01 02 04 08 10 20 40 80 1B 36 简单示例12345678910111213141516假设初始秘钥分别为：00 01 02 ... 0F，则w0 = 00 01 02 03w1 = 04 05 06 07w2 = 08 09 0A 0Bw3 = 0C 0D 0E 0F为了计算w4，先计算T(w3):旋转得：0D 0E 0F 0CS盒替换得：D7 AB 76 FE常量异或得：D6 AB 76 FE将T函数输出再与w0异或得w4 = D6 AA 72 FDw5 = w4 XOR w1w6 = w5 XOR w2w7 = w6 XOR w3 明文初始化由于明文块也是128位，即16字节，左移也将这16个字节写位4*4的矩阵，列优先。之后与第一个秘钥对应字节进行异或运算。 轮次运算每一轮依次有以下几步 s盒替换就是将输入的矩阵每个元素进行s盒替换 旋转将矩阵第i行循环左移i个字节，如下列1234567891 5 9 132 6 10 143 7 11 154 8 12 16旋转后1 5 9 136 10 14 211 15 3 716 4 8 12 混合列操作将上一步的结果与常量矩阵相乘，运算规则如下1234567891011121314151617有常量矩阵 2 3 1 1A = 1 2 3 1 1 1 2 3 3 1 1 2有输入矩阵 b1 b5 b9 b13b = b2 b6 b10 b14 b3 b7 b11 b15 b4 b8 b12 b16则A*b结果的第一列如下c1 = (b1*2)XOR(b2*3)XOR(b3*1)XOR(b4*1)c1 = (b1*1)XOR(b2*2)XOR(b3*3)XOR(b4*1)c1 = (b1*1)XOR(b2*1)XOR(b3*2)XOR(b4*3)c1 = (b1*3)XOR(b2*1)XOR(b3*1)XOR(b4*2)实际上数学中的矩阵相乘类似，只不过相加改为了异或 结果还是一个4*4矩阵 秘钥异或将上步输出的矩阵与该轮对应的秘钥进行异或运算 总体流程如下（注意最后一轮没有列混合运算） 解密流程也如上图所示，就是反过来，其中s盒的逆如下 解密的逆列混淆用的是如下常数矩阵去乘以密文矩阵：12340E 0B 0D 0909 0E 0B 0D0D 09 0E 0B0B 0D 09 0E 题图来自unsplash：https://unsplash.com/photos/ARVFsI-32Uk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中rpc源码学习]]></title>
    <url>%2F2019%2F03%2F29%2Fgo-ethereum%E4%B8%ADrpc%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[背景RPC全称Remote Procedure Call，即远程过程调用是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。 运行时一次客户机对服务器的RPC调用，基本过程如下图： go语言中的rpcgo语言的标准包中以及有了对RPC的支持，分别在三个层面上即TCP、HTTP和JSONRPC上提供了支持。除了JSONRPC其余两种都只支持以go语言开发的客户端与服务器。 首先，在Go中一个正确的RPC函数应该满足下面要求 函数必须是可导出的（首字母大写） 必须有两个可导出类型的参数 第一个是接受的参数，第二个是返回参数 函数必须有一个error类型的返回值 例子如下：1func (t *T) MethodName(argType T1, replyType *T2) error HTTP RPC服务端代码123456789101112131415161718type HelloService struct &#123;&#125;func (p *HelloService)Hello(requset string,reply *string)error&#123; *reply = "hello " + requset return nil&#125;func main() &#123; rpc.Register(new(HelloService)) rpc.HandleHTTP() err:=http.ListenAndServe(":1234",nil) if err!=nil &#123; fmt.Println(err.Error()) &#125;&#125; 关键有两点，一个是定义供客户端调用的方法，另一个是注册服务，并使RPC托管http服务，最后正常启动http服务 客户端代码123456789func main() &#123; client,err:=rpc.DialHTTP("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; TPC RPC服务端代码12345678910111213func main() &#123; rpc.Register(new(HelloService)) lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; conn,err:=lis.Accept() if err!=nil &#123; log.Fatal("accept:",err.Error()) &#125; rpc.ServeConn(conn)&#125; 供远程调用的方法和前面的例子一样，不在重复，tcprpc和httprpc的不同点就是在于首先正常启动tcp监听，然后接收到的连接交给rpc即可 客户端代码123456789func main() &#123; client,err:=rpc.Dial("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; 和httprpc的唯一区别就是初始化客户端对象的方法不同 jsonRPC服务端代码12345678910111213func main() &#123; rpc.Register(new(HelloService)) lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; conn,err:=lis.Accept() if err!=nil &#123; log.Fatal("accept:",err.Error()) &#125; jsonrpc.ServeConn(conn)&#125; 相比较tcprpc只是在处理tcp连接时使用rpcjson提供的方法。 客户端代码123456789func main() &#123; client,err:=jsonrpc.Dial("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; 唯一区别也只是在创建client实例时的不同，使用jsonrpc提供的方法 由于tcprpc和httprpc都采用gob编码，所以不能跨语言使用，而jsonrpc采用的json格式编码，可以很方便的跨语言，这里提供一个go语言和java语言交互的例子，其中服务端由go语言编写，如上面所示，java编写的客户端如下：1234567891011121314151617181920212223242526272829303132333435public class ClientRequest &#123; public String method; public String[] params; public int id;&#125;public class ServerResponse &#123; public int id; public String result; public String error;&#125;public static void main(String[] args)&#123; try(Socket client = new Socket("127.0.0.1",1234))&#123; OutputStream out = client.getOutputStream(); Gson gson = new Gson(); ClientRequest request = new ClientRequest(); request.id = 1; request.method = "HelloService.Hello"; request.params = new String[]&#123;"hello"&#125;; out.write(gson.toJson(request).getBytes()); client.shutdownOutput(); InputStream in = client.getInputStream(); int len; byte[] buffer = new byte[1024]; StringBuilder sb = new StringBuilder(); while ((len = in.read(buffer))!=-1) sb.append(new String(buffer,0,len)); ServerResponse response = gson.fromJson(sb.toString(),ServerResponse.class); client.shutdownInput(); System.out.println(response.result); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;&#125; 还是基于TCP通信的，由于是借助json传输的，所以需要有json序列化和反序列化操作，且json格式要符合go语言的规定。go语言中规定请求的格式如下：12345678910111213//客户端请求type clientRequest struct&#123; Method string `json:"method"` Params [1]interface&#123;&#125; `json:"params"` Id uint64 `json:"id"`&#125;//服务端请求type serverRequest struct&#123; Method string `json:"method"` Params *json.RawMessage `json:"params"` Id *json.RawMessage `json:"id"`&#125; 规定响应的格式如下123456789101112//客户端响应type clientResponse struct&#123; Id uint64 `json:"id"` Result *json.RawMessage `json:"result"` Error interface&#123;&#125; `json:"error"`&#125;//服务端响应type serverResponse struct&#123; Id uint64 `json:"id"` Result interface&#123;&#125; `json:"result"` Error interface&#123;&#125; `json:"error"`&#125; 在跨语言交互时，要根据上面的定义，编写对应的json文件 go-ethereum中的rpc主要集中在rpc目录下 server.go服务创建与注册首先从服务端开始看，server的结构体以及创建如下123456789101112131415161718// go-ethereum\rpc\server.gotype Server struct &#123; services serviceRegistry idgen func() ID run int32 codecs mapset.Set&#125;type serviceRegistry struct &#123; mu sync.Mutex services map[string]service&#125;func NewServer() *Server &#123; server := &amp;Server&#123;idgen: randomIDGenerator(), codecs: mapset.NewSet(), run: 1&#125; rpcService := &amp;RPCService&#123;server&#125; //MetadataApi = "rpc" server.RegisterName(MetadataApi, rpcService) return server&#125; 结构体中services的类型是serviceRegistry实际上就是记录了所有注册的服务。run用来控制server的运行。codecs是一个set类型，存储所有编解码器。 在创建server时，randomIDGenerator()是一个id的随机生成器。随后调用RegisterName把自己的实例注册进去（RPCService包装了server类）1234567891011121314151617181920212223242526272829303132333435363738func (s *Server) RegisterName(name string, receiver interface&#123;&#125;) error &#123; return s.services.registerName(name, receiver)&#125;// go-ethereum\rpc\service.gofunc (r *serviceRegistry) registerName(name string, rcvr interface&#123;&#125;) error &#123; rcvrVal := reflect.ValueOf(rcvr) if name == "" &#123; return fmt.Errorf("no service name for type %s", rcvrVal.Type().String()) &#125; callbacks := suitableCallbacks(rcvrVal) if len(callbacks) == 0 &#123; return fmt.Errorf("service %T doesn't have any suitable methods/subscriptions to expose", rcvr) &#125; r.mu.Lock() defer r.mu.Unlock() if r.services == nil &#123; r.services = make(map[string]service) &#125; svc, ok := r.services[name] if !ok &#123; svc = service&#123; name: name, callbacks: make(map[string]*callback), subscriptions: make(map[string]*callback), &#125; r.services[name] = svc &#125; for name, cb := range callbacks &#123; if cb.isSubscribe &#123; svc.subscriptions[name] = cb &#125; else &#123; svc.callbacks[name] = cb &#125; &#125; return nil&#125; suitableCallbacks方法如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// go-ethereum\rpc\service.gofunc suitableCallbacks(receiver reflect.Value) map[string]*callback &#123; typ := receiver.Type() callbacks := make(map[string]*callback) for m := 0; m &lt; typ.NumMethod(); m++ &#123; method := typ.Method(m) if method.PkgPath != "" &#123; continue // method not exported &#125; cb := newCallback(receiver, method.Func) if cb == nil &#123; continue // function invalid &#125; name := formatName(method.Name) callbacks[name] = cb &#125; return callbacks&#125;func newCallback(receiver, fn reflect.Value) *callback &#123; fntype := fn.Type() c := &amp;callback&#123;fn: fn, rcvr: receiver, errPos: -1, isSubscribe: isPubSub(fntype)&#125; c.makeArgTypes() if !allExportedOrBuiltin(c.argTypes) &#123; return nil &#125; outs := make([]reflect.Type, fntype.NumOut()) for i := 0; i &lt; fntype.NumOut(); i++ &#123; outs[i] = fntype.Out(i) &#125; if len(outs) &gt; 2 || !allExportedOrBuiltin(outs) &#123; return nil &#125; switch &#123; case len(outs) == 1 &amp;&amp; isErrorType(outs[0]): c.errPos = 0 case len(outs) == 2: if isErrorType(outs[0]) || !isErrorType(outs[1]) &#123; return nil &#125; c.errPos = 1 &#125; return c&#125;type callback struct &#123; fn reflect.Value rcvr reflect.Value argTypes []reflect.Type hasCtx bool errPos int isSubscribe bool &#125; 在suitableCallbacks内先遍历了server的所有方法，对于可导出的，利用newCallback方法创建一个callback对象。一个callback对象中的几个成员意义如下： fn表示对于的方法 rcvr表示方法所在的类 argtypes存储所有输入参数类型（context除外） hasCtx表示参数中是否有Context类型，. errPos表示error类型的返回值是第几个 isSubscribe表示该方法是否可订阅（满足三个条件：第二个输入参数是Context类型，第一个输出参数是Subscription类型，第二个输出参数是error类型） 最后suitableCallbacks返回一个map存储符合条件的callback。接下来初始化serviceRegistry的services，也是一个map。然后创建一个service，存入services。最后遍历刚才callbacks，将其中的可订阅的方法单独拿出来。 总结一下，所谓的serviceRegistry注册方法就是给一个类，然后遍历所有方法，根据方法的参数与返回值归类，最后以service的形式放到serviceRegistry的services中. 服务启动及rpc请求处理分析1234567891011121314// go-ethereum\rpc\ipc.gofunc (s *Server) ServeListener(l net.Listener) error &#123; for &#123; conn, err := l.Accept() if netutil.IsTemporaryError(err) &#123; log.Warn("RPC accept error", "err", err) continue &#125; else if err != nil &#123; return err &#125; log.Trace("Accepted RPC connection", "conn", conn.RemoteAddr()) go s.ServeCodec(NewJSONCodec(conn), OptionMethodInvocation|OptionSubscriptions) &#125;&#125; 整个是一个无限循环，每次循环接受一个连接，然后启动一个goroutine去调用ServeCodec处理，第一个参数是ServerCodec类型：12345678910111213141516171819func NewJSONCodec(conn Conn) ServerCodec &#123; enc := json.NewEncoder(conn) dec := json.NewDecoder(conn) dec.UseNumber() return NewCodec(conn, enc.Encode, dec.Decode)&#125;func NewCodec(conn Conn, encode, decode func(v interface&#123;&#125;) error) ServerCodec &#123; codec := &amp;jsonCodec&#123; closed: make(chan interface&#123;&#125;), encode: encode, decode: decode, conn: conn, &#125; if ra, ok := conn.(ConnRemoteAddr); ok &#123; codec.remoteAddr = ra.RemoteAddr() &#125; return codec&#125; 具体来说是一个jsonCodec对象，用于读写jsonrpc请求与响应的。ServeCodec的第二个参数是一个选项，但是新版本的go-ethereum不在支持该选项，所以弃用。总的来说codec类型对象就代表的是一个个连接请求 具体来说ServeCodec方法是读取一个请求，然后使用合适的callback去处理，最后返回，来看具体代码123456789101112131415// go-ethereum\rpc\server.gofunc (s *Server) ServeCodec(codec ServerCodec, options CodecOption) &#123; defer codec.Close() if atomic.LoadInt32(&amp;s.run) == 0 &#123; return &#125; s.codecs.Add(codec) defer s.codecs.Remove(codec) c := initClient(codec, s.idgen, &amp;s.services) &lt;-codec.Closed() c.Close()&#125; 前面说过run成员是控制运行的，如果等于0就不执行任何操作。然后将codec添加到set集合中，然后初始化一个Client去处理，最后等待codec关闭后，关闭Client。一个client就代表一个连接。初始化客户端代码如下1234567891011121314151617181920212223// go-ethereum\rpc\client.gofunc initClient(conn ServerCodec, idgen func() ID, services *serviceRegistry) *Client &#123; _, isHTTP := conn.(*httpConn) c := &amp;Client&#123; idgen: idgen, isHTTP: isHTTP, services: services, writeConn: conn, close: make(chan struct&#123;&#125;), closing: make(chan struct&#123;&#125;), didClose: make(chan struct&#123;&#125;), reconnected: make(chan ServerCodec), readOp: make(chan readOp), readErr: make(chan error), reqInit: make(chan *requestOp), reqSent: make(chan error, 1), reqTimeout: make(chan *requestOp), &#125; if !isHTTP &#123; go c.dispatch(conn) &#125; return c&#125; 就是简单的初始化，不过通过判断是否是http类型连接来决定是否分发。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// go-ethereum\rpc\client.gofunc (c *Client) dispatch(codec ServerCodec) &#123; var ( lastOp *requestOp reqInitLock = c.reqInit conn = c.newClientConn(codec) reading = true ) defer func() &#123; close(c.closing) if reading &#123; conn.close(ErrClientQuit, nil) c.drainRead() &#125; close(c.didClose) &#125;() go c.read(codec) for &#123; select &#123; case &lt;-c.close: return case op := &lt;-c.readOp: if op.batch &#123; conn.handler.handleBatch(op.msgs) &#125; else &#123; conn.handler.handleMsg(op.msgs[0]) &#125; case err := &lt;-c.readErr: conn.handler.log.Debug("RPC connection read error", "err", err) conn.close(err, lastOp) reading = false case newcodec := &lt;-c.reconnected: log.Debug("RPC client reconnected", "reading", reading, "conn", newcodec.RemoteAddr()) if reading &#123; conn.close(errClientReconnected, lastOp) c.drainRead() &#125; go c.read(newcodec) reading = true conn = c.newClientConn(newcodec) conn.handler.addRequestOp(lastOp) case op := &lt;-reqInitLock: reqInitLock = nil lastOp = op conn.handler.addRequestOp(op) case err := &lt;-c.reqSent: if err != nil &#123; conn.handler.removeRequestOp(lastOp) &#125; reqInitLock = c.reqInit lastOp = nil case op := &lt;-c.reqTimeout: conn.handler.removeRequestOp(op) &#125; &#125;&#125; 大体上来看dispatch方法是一个无限循环，每次循环都借助channel机制实现对不同的情况做不同处理，在循环阻塞时，启动了一个goroutine，去读取rpc请求12345678910111213func (c *Client) read(codec ServerCodec) &#123; for &#123; msgs, batch, err := codec.Read() if _, ok := err.(*json.SyntaxError); ok &#123; codec.Write(context.Background(), errorMessage(&amp;parseError&#123;err.Error()&#125;)) &#125; if err != nil &#123; c.readErr &lt;- err return &#125; c.readOp &lt;- readOp&#123;msgs, batch&#125; &#125;&#125; 这里就很清楚，直接调用ServerCodec的read方法，我们前面说过ServerCodec是一个个连接请求的包装，而这里的ServerCodec实际上是个jsonCodec类型，我们看看它的read方法123456789101112131415161718192021222324func (c *jsonCodec) Read() (msg []*jsonrpcMessage, batch bool, err error) &#123; var rawmsg json.RawMessage if err := c.decode(&amp;rawmsg); err != nil &#123; return nil, false, err &#125; msg, batch = parseMessage(rawmsg) return msg, batch, nil&#125;func parseMessage(raw json.RawMessage) ([]*jsonrpcMessage, bool) &#123; if !isBatch(raw) &#123; msgs := []*jsonrpcMessage&#123;&#123;&#125;&#125; json.Unmarshal(raw, &amp;msgs[0]) return msgs, false &#125; dec := json.NewDecoder(bytes.NewReader(raw)) dec.Token() // skip '[' var msgs []*jsonrpcMessage for dec.More() &#123; msgs = append(msgs, new(jsonrpcMessage)) dec.Decode(&amp;msgs[len(msgs)-1]) &#125; return msgs, true&#125; 这里的decode就是json.NewDecoder(conn)创建的，它将请求中的数据流转为一个json原始格式信息，为的是接下来反序列化。isBatch检查数据中第一个非空字符是否是“[”，如果是的话表示是一个json数据格式。总之最后解析为jsonrpcMessage对象，结构如下12345678type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125; 我们继续回到read方法中，当正确解析请求的内容时，返回值打包为readOp类型，然后写入Client的readOp这个chan字段中，这时触发dispatch中的select，执行下面逻辑：12345if op.batch &#123; conn.handler.handleBatch(op.msgs)&#125; else &#123; conn.handler.handleMsg(op.msgs[0])&#125; op.batch代表是否有多个jsonrpcMessage，以此执行不同逻辑。这里的conn是一个clientConn类型，包装了ServerCodec以及一个handler。我们下面看一下只有一个message的处理逻辑1234567// go-ethereum\rpc\handler.gofunc (h *handler) handleMsg(msg *jsonrpcMessage) &#123; if ok := h.handleImmediate(msg); ok &#123; return &#125; h.startCallProc(....)&#125; 第一行中handleImmediate处理的是不需要回复的请求，如一个通知或一个响应。通过方法名，ID以及参数等综合判断。对于正常请求调用startCallProc开始处理。123456789func (h *handler) startCallProc(fn func(*callProc)) &#123; h.callWG.Add(1) go func() &#123; ctx, cancel := context.WithCancel(h.rootCtx) defer h.callWG.Done() defer cancel() fn(&amp;callProc&#123;ctx: ctx&#125;) &#125;()&#125; h.callWG是一个sync.WaitGroup类型，为的是线程同步，这里加一表示有一个goroutine在运行，后面启动一个goroutine，这里面的实际逻辑是先前传递进来的func，如下12345678910func(cp *callProc) &#123; answer := h.handleCallMsg(cp, msg) h.addSubscriptions(cp.notifiers) if answer != nil &#123; h.conn.Write(cp.ctx, answer) &#125; for _, n := range cp.notifiers &#123; n.activate() &#125; &#125; 这里调用handleCallMsg去处理message：123456789101112131415161718192021func (h *handler) handleCallMsg(ctx *callProc, msg *jsonrpcMessage) *jsonrpcMessage &#123; start := time.Now() switch &#123; case msg.isNotification(): h.handleCall(ctx, msg) h.log.Debug("Served "+msg.Method, "t", time.Since(start)) return nil case msg.isCall(): resp := h.handleCall(ctx, msg) if resp.Error != nil &#123; h.log.Info("Served "+msg.Method, "reqid", idForLog&#123;msg.ID&#125;, "t", time.Since(start), "err", resp.Error.Message) &#125; else &#123; h.log.Debug("Served "+msg.Method, "reqid", idForLog&#123;msg.ID&#125;, "t", time.Since(start)) &#125; return resp case msg.hasValidID(): return msg.errorResponse(&amp;invalidRequestError&#123;"invalid request"&#125;) default: return errorMessage(&amp;invalidRequestError&#123;"invalid request"&#125;) &#125;&#125; 不管是通知类型还是调用类型，都调用的是handleCall方法：1234567891011121314151617181920func (h *handler) handleCall(cp *callProc, msg *jsonrpcMessage) *jsonrpcMessage &#123; if msg.isSubscribe() &#123; return h.handleSubscribe(cp, msg) &#125; var callb *callback if msg.isUnsubscribe() &#123; callb = h.unsubscribeCb &#125; else &#123; callb = h.reg.callback(msg.Method) &#125; if callb == nil &#123; return msg.errorResponse(&amp;methodNotFoundError&#123;method: msg.Method&#125;) &#125; args, err := parsePositionalArguments(msg.Params, callb.argTypes) if err != nil &#123; return msg.errorResponse(&amp;invalidParamsError&#123;err.Error()&#125;) &#125; return h.runMethod(cp.ctx, msg, callb, args)&#125; 分了三种情况：订阅请求，取消订阅请求以及一般请求。我们先看一般请求：h.reg是serviceRegistry，handler的serviceRegistry是前面dispatch方法创建clientConn时创建handle时传入的，来自于client的services字段，而client的services字段是在server的ServeCodec方法中调用initClient传入的，实际上就是Server的services字段。我们上节了解到在server会有一个registerName动作，会解析rpcserver的所有可导出方法，并用callback包装，而在handleCall中，就调用了serviceRegistry方法123456789func (r *serviceRegistry) callback(method string) *callback &#123; elem := strings.SplitN(method, serviceMethodSeparator, 2) if len(elem) != 2 &#123; return nil &#125; r.mu.Lock() defer r.mu.Unlock() return r.services[elem[0]].callbacks[elem[1]]&#125; 首先解析方法名，然后从services中，这里保存了一系列注册的服务，在从各个服务的callbacks集合中寻找对应的callback。继续回到handleCall，若找的callback不为空，则尝试解析参数：1234567891011121314151617181920212223242526272829303132333435363738394041func parsePositionalArguments(rawArgs json.RawMessage, types []reflect.Type) ([]reflect.Value, error) &#123; dec := json.NewDecoder(bytes.NewReader(rawArgs)) var args []reflect.Value tok, err := dec.Token() switch &#123; case err == io.EOF || tok == nil &amp;&amp; err == nil: case err != nil: return nil, err case tok == json.Delim('['): if args, err = parseArgumentArray(dec, types); err != nil &#123; return nil, err &#125; default: return nil, errors.New("non-array args") &#125; for i := len(args); i &lt; len(types); i++ &#123; if types[i].Kind() != reflect.Ptr &#123; return nil, fmt.Errorf("missing value for required argument %d", i) &#125; args = append(args, reflect.Zero(types[i])) &#125; return args, nil&#125;func parseArgumentArray(dec *json.Decoder, types []reflect.Type) ([]reflect.Value, error) &#123; args := make([]reflect.Value, 0, len(types)) for i := 0; dec.More(); i++ &#123; if i &gt;= len(types) &#123; return args, fmt.Errorf("too many arguments, want at most %d", len(types)) &#125; argval := reflect.New(types[i]) if err := dec.Decode(argval.Interface()); err != nil &#123; return args, fmt.Errorf("invalid argument %d: %v", i, err) &#125; if argval.IsNil() &amp;&amp; types[i].Kind() != reflect.Ptr &#123; return args, fmt.Errorf("missing value for required argument %d", i) &#125; args = append(args, argval.Elem()) &#125; _, err := dec.Token() return args, err&#125; 主要逻辑是在parseArgumentArray中，根据方法的参数列表类型一个一个进行解析，对于没有的参数设为该类型的默认空值，最后返回一组参数。在handleCall的最后去执行方法：12345678910111213141516171819202122232425262728293031323334353637func (h *handler) runMethod(ctx context.Context, msg *jsonrpcMessage, callb *callback, args []reflect.Value) *jsonrpcMessage &#123; result, err := callb.call(ctx, msg.Method, args) if err != nil &#123; return msg.errorResponse(err) &#125; return msg.response(result)&#125;func (c *callback) call(ctx context.Context, method string, args []reflect.Value) (res interface&#123;&#125;, errRes error) &#123; fullargs := make([]reflect.Value, 0, 2+len(args)) if c.rcvr.IsValid() &#123; fullargs = append(fullargs, c.rcvr) &#125; if c.hasCtx &#123; fullargs = append(fullargs, reflect.ValueOf(ctx)) &#125; fullargs = append(fullargs, args...) defer func() &#123; if err := recover(); err != nil &#123; const size = 64 &lt;&lt; 10 buf := make([]byte, size) buf = buf[:runtime.Stack(buf, false)] log.Error("RPC method " + method + " crashed: " + fmt.Sprintf("%v\n%s", err, buf)) errRes = errors.New("method handler crashed") &#125; &#125;() results := c.fn.Call(fullargs) if len(results) == 0 &#123; return nil, nil &#125; if c.errPos &gt;= 0 &amp;&amp; !results[c.errPos].IsNil() &#123; err := results[c.errPos].Interface().(error) return reflect.Value&#123;&#125;, err &#125; return results[0].Interface(), nil&#125; 基本上就是补全参数，然后调用callback中保存的func去执行，然后进行错误处理，最后返回结果也就是响应。回到runMethod中，调用response去包装结果123456789// go-ethereum\rpc\json.gofunc (msg *jsonrpcMessage) response(result interface&#123;&#125;) *jsonrpcMessage &#123; enc, err := json.Marshal(result) if err != nil &#123; // TODO: wrap with 'internal server error' return msg.errorResponse(err) &#125; return &amp;jsonrpcMessage&#123;Version: vsn, ID: msg.ID, Result: enc&#125;&#125; 这一步是将结果序列化，最后包装成为一个jsonrpcMessage。到这里handleCall流程结束，回到handleCallMsg，直接返回响应，再往回调，来到startCallProc方法，如果响应不为空，则调用write写入响应，一次rpc普通调用完成！负责写的还是ServerCodec类型对象，具体就是jsonCodec，最后写入响应流中。 总结一下，大致流程就是当接收到一个网络请求时，就启动一个goroutine，同时创建一个ServerCodec去包装过来的连接，在这个goroutine中会初始化一个client对象，代表一个连接，在初始化之后会进行连接的分发，分发就是有一个无限循环，同时再启动一个goroutine去解析请求信息，根据信息去开始注册的服务中查找合适的callback然后传入请求体重的参数执行响应逻辑，最后在利用ServerCodec去写会响应。 服务的关闭123456789func (s *Server) Stop() &#123; if atomic.CompareAndSwapInt32(&amp;s.run, 1, 0) &#123; log.Debug("RPC server shutting down") s.codecs.Each(func(c interface&#123;&#125;) bool &#123; c.(ServerCodec).Close() return true &#125;) &#125;&#125; 首先将标志位run置0，这样后续新的连接就被放弃（参见ServeCodec方法），然后遍历set，对每个ServerCodec执行close方法。123456func (c *jsonCodec) Close() &#123; c.closer.Do(func() &#123; close(c.closed) c.conn.Close() &#125;)&#125; 主要就是关闭channel和连接。channel关闭后影响ServeCodec方法，原来阻塞地方开始执行，然后关闭client12345678910func (c *Client) Close() &#123; if c.isHTTP &#123; return &#125; select &#123; case c.close &lt;- struct&#123;&#125;&#123;&#125;: &lt;-c.didClose case &lt;-c.didClose: &#125;&#125; 这里首先close这个channel获得值，在dispatch的那个无限循环中的到触发，跳出循环，执行defer逻辑，12345678defer func() &#123; close(c.closing) if reading &#123; conn.close(ErrClientQuit, nil) c.drainRead() &#125; close(c.didClose) &#125;() 这里进行最后善后处理，关闭完didClose后，上面Close()方法中最后阻塞得到解除，方法正常执行完毕。 题图来自unsplash：https://unsplash.com/photos/zNNPSqKRR2c]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC5加密]]></title>
    <url>%2F2019%2F03%2F28%2FRC5%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景RC5全称Rivest Cipher5，,是1994年Ron Rivest设计的（原始论文）。AES的候选算法之一RC6就是基于RC5开发的。这种算法具有块可变，秘钥长度可变，加密轮数可变的特点，非常灵活。并且，操作简单，仅需加法、移位、异或即可完成，而且内存占用极少 基本原理首先加密前要确定块长，轮数和秘钥长度，确定后不可改变。其中块长可选16,32或64位。轮数介于1-255之间，秘钥长度介于0-255字节。为了便于记忆，我们定义RC5-w/r/b表示一个实例，w/r/b分别表示一个字的长度（算法以两个字位一单位），轮数和秘钥长。推荐的最低安全标准为RC5-32/16/16 加密时都先将明文块分两部分，用这两部分开始若干轮计算，每轮都涉及相加、移位和异或，最后输出密文 详细流程初始化操作首相将明文分为A,B两部分。然后A与子秘钥S[0]相加，B与子秘钥S[1]相加，结果分别用2^w求模，得到C,D 每一轮细节 C和D异或得E E循环左移D位 E与子秘钥S[2i]相加得F。同样也要模2^w，i表示第几轮 D与F异或得G G循环左移F位 G与子秘钥S[2i+1]相加得H。同样也要模2^w，i表示第几轮 若还有轮数则C=F，D=H 基本可以写成下列形式12345A = A + S[0]B = B + S[1]for i = 1 to r: A = ((A XOR B) &lt;&lt;&lt; B) + S[2i] B = ((B XOR A) &lt;&lt;&lt; A) + S[2i+1] 秘钥计算子秘钥生成首先取两个常亮P、Q。P与Q在不同的w也就是字长下有不同值： W P Q 16 0xB7E1 0x9E37 32 0xB7E15163 0x9E3779B9 64 0xB7E151628AED2A6B 0x9E3779B97F4A7C15 P、Q计算公式分别如下： 第一个公式中的e表示自然常数，即2.71828… 第二个公式中的φ表示黄金比例，即1.618….。odd表示取最接近给定输入的奇数。P、Q都是魔法数字，没有任何来源根据. 得到两个常数后，令S[0] = P，从i=1开始循环，i每个循环递增1，每次循环计算A = S[i-1]+Q，B = A mod 2^w，S[i] = B。一直循环2(r+1)-1次。表示如下123s[0] = Pfor i = 1 to 2(r+1)-1: s[i] = (s[i-1]+Q) mod 2^w 子秘钥混合该阶段将子秘钥S与秘钥L进行混合1234567i = j = 0A = B = 0do 3 * max(2(r+1), (b*8)/w) times: A = S[i] = (S[i] + A + B) &lt;&lt;&lt; 3 B = L[j] = (L[j] + A + B) &lt;&lt;&lt; (A + B) i = (i + 1) mod 2(r+1) j = (j + 1) mod (b*8)/w 解密解密就是将加密过程颠倒123456for i = r to 1: A = ((B - S[2i+1])&gt;&gt;&gt;A) XOR A B = ((A - S[2i])&gt;&gt;&gt;B) XOR BB = B - S[1]A = A - S[0] 安全性12轮RC5(64位块)容易受到使用了2^44的选定的明文的差分攻击。18–20轮加密则被认为可以提供足够的保护。更大的安全性可以通过增加轮数获得，其代价是减少密码的吞吐量。 题图来自unsplash：https://unsplash.com/photos/WhRsHmFtFXQ]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中ethdb源码学习]]></title>
    <url>%2F2019%2F03%2F27%2Fgo-ethereum%E4%B8%ADethdb%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前面学习了ethereum的编码和数据结构，这里学习一些ethereum的持久化存储也就是数据相关的源码。 背景go-ethereum的数据存储时借助于leveldb数据库，它是Google开发的一种键值对类型的数据库，另外Facebook又基于其开发了RocksDB数据库。简单来说，leveldb具有轻量以及高性能的特点。 原生的leveldb是用c++写的，并不方便直接用到go项目中，好在leveldb的开发者用go重新实现了leveldb，我们可以直接使用(github地址)。 go版本的leveldb需要go1.5以上版本，安装很简单，执行下面命令1go get github.com/syndtr/goleveldb/leveldb go-leveldb使用由于是键值对类型的数据库，所以使用比较简单，下面简单介绍一下基本操作，更高级的操作参见API文档。下面操作示例代码见这里 打开数据库12345db, err := leveldb.OpenFile("db", nil)if(err!=nil)&#123; log.Fatalln(err.Error())&#125;defer db.Close() OpenFile会创建或打开一个数据库。 增删改查123err = db.Put([]byte("key"), []byte("value"), nil)err = db.Delete([]byte("key"), nil)data, err := db.Get([]byte("key"), nil) 基本上就对于put，get，delete几个方法，其中更改一个记录的话也是用put。 普通迭代123456iter := db.NewIterator(nil, nil)for iter.Next() &#123; key := iter.Key() value := iter.Value()&#125;iter.Release() 就是迭代数据库全部键值对 指定起点的迭代首先需要明白的是，leveldb的存储是按key的顺序存储的，所以可以指定一个key，从该key开始遍历1234567iter:=db.NewIterator(nil,nil)for ok:=iter.Seek(key);ok;ok=iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 子集迭代可以指定区间进行迭代1234567iter:=db.NewIterator(&amp;util.Range&#123;Start:[]byte("key2"),Limit:[]byte("key6")&#125;,nil)for iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 前缀迭代只迭代有指定前缀的1234567iter:=db.NewIterator(util.BytesPrefix([]byte(prefix)),nil)for iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 批量写入12345678batch:=new(leveldb.Batch)for i:=0; i&lt;10; i++ &#123; batch.Put([]byte("batch"+strconv.Itoa(i)),[]byte("batch"+strconv.Itoa(i)))&#125;err:=db.Write(batch,nil)if err!=nil &#123; fmt.Println(err)&#125; 源码分析源码集中在ethdb目录内，主要是对leveldb的封装。 interface.go顾名思义就是定义了一些接口，如数据库接口：12345678type Database interface &#123; Putter Deleter Get(key []byte) ([]byte, error) Has(key []byte) (bool, error) Close() NewBatch() Batch&#125; Batch接口。用于批量操作，不能用于并发1234567type Batch interface &#123; Putter Deleter ValueSize() int Write() error Reset()&#125; 上面两个结构又包含了Putter和Deleter接口123456type Putter interface &#123; Put(key []byte, value []byte) error&#125;type Deleter interface &#123; Delete(key []byte) error&#125; database.go构造这就是ethereum所使用的代码，先看结构体1234567891011121314151617type LDBDatabase struct &#123; fn string // filename for reporting db *leveldb.DB // LevelDB instance compTimeMeter metrics.Meter // Meter for measuring the total time spent in database compaction compReadMeter metrics.Meter // Meter for measuring the data read during compaction compWriteMeter metrics.Meter // Meter for measuring the data written during compaction writeDelayNMeter metrics.Meter // Meter for measuring the write delay number due to database compaction writeDelayMeter metrics.Meter // Meter for measuring the write delay duration due to database compaction diskReadMeter metrics.Meter // Meter for measuring the effective amount of data read diskWriteMeter metrics.Meter // Meter for measuring the effective amount of data written quitLock sync.Mutex // Mutex protecting the quit channel access quitChan chan chan error // Quit channel to stop the metrics collection before closing the database log log.Logger // Contextual logger tracking the database path&#125; NewLDBDatabase成员很多，关键的就是一个leveldb.DB对象和几个同步操作的成员。接下来看新建数据库的方法12345678910111213141516171819202122232425262728293031func NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) &#123; logger := log.New("database", file) //从init调用过来时，cache和handles都为0 //默认启动节点，cache为512，handles为0，在node.DefaultConfig配置 if cache &lt; 16 &#123; cache = 16 &#125; if handles &lt; 16 &#123; handles = 16 &#125; logger.Info("Allocated cache and file handles", "cache", common.StorageSize(cache*1024*1024), "handles", handles) db, err := leveldb.OpenFile(file, &amp;opt.Options&#123; OpenFilesCacheCapacity: handles, BlockCacheCapacity: cache / 2 * opt.MiB, WriteBuffer: cache / 4 * opt.MiB, Filter: filter.NewBloomFilter(10), &#125;) if _, corrupted := err.(*errors.ErrCorrupted); corrupted &#123; db, err = leveldb.RecoverFile(file, nil) &#125; if err != nil &#123; return nil, err &#125; return &amp;LDBDatabase&#123; fn: file, db: db, log: logger, &#125;, nil&#125; 逻辑很简单，创建了一个levelDB对象，主要看一下options的内容： OpenFilesCacheCapacity：定义打开的文件缓存大小，默认是500，设为-1或0时表示不缓存 BlockCacheCapacity：定义了一个名为sorted table的缓存容量，默认是8MB，设为-1或0时表示不缓存 WriteBuffer：定义memdb的大小，它是一个内存数据库，默认是4MB. Filter：定义过滤器，优化读性能。这是使用了一个布隆过滤器 put，has，get，delete12345678910111213141516func (db *LDBDatabase) Put(key []byte, value []byte) error &#123; return db.db.Put(key, value, nil)&#125;func (db *LDBDatabase) Has(key []byte) (bool, error) &#123; return db.db.Has(key, nil)&#125;func (db *LDBDatabase) Get(key []byte) ([]byte, error) &#123; dat, err := db.db.Get(key, nil) if err != nil &#123; return nil, err &#125; return dat, nil&#125;func (db *LDBDatabase) Delete(key []byte) error &#123; return db.db.Delete(key, nil)&#125; 都是对leveldb做了封装而已。 Batch及其操作批量读写的封装12345type ldbBatch struct &#123; db *leveldb.DB b *leveldb.Batch size int&#125; put、delete、write、reset1234567891011121314151617181920func (b *ldbBatch) Put(key, value []byte) error &#123; b.b.Put(key, value) b.size += len(value) return nil&#125;func (b *ldbBatch) Delete(key []byte) error &#123; b.b.Delete(key) b.size += 1 return nil&#125;func (b *ldbBatch) Write() error &#123; return b.db.Write(b.b, nil)&#125;func (b *ldbBatch) Reset() &#123; b.b.Reset() b.size = 0&#125; Meter这是用于初始化LDBDatabase的一系列Meter成员用的123456789101112131415func (db *LDBDatabase) Meter(prefix string) &#123; db.compTimeMeter = metrics.NewRegisteredMeter(prefix+"compact/time", nil) db.compReadMeter = metrics.NewRegisteredMeter(prefix+"compact/input", nil) db.compWriteMeter = metrics.NewRegisteredMeter(prefix+"compact/output", nil) db.diskReadMeter = metrics.NewRegisteredMeter(prefix+"disk/read", nil) db.diskWriteMeter = metrics.NewRegisteredMeter(prefix+"disk/write", nil) db.writeDelayMeter = metrics.NewRegisteredMeter(prefix+"compact/writedelay/duration", nil) db.writeDelayNMeter = metrics.NewRegisteredMeter(prefix+"compact/writedelay/counter", nil) db.quitLock.Lock() db.quitChan = make(chan chan error) db.quitLock.Unlock() go db.meter(3 * time.Second)&#125; 这个方法内先初始化各种Meter，然后创建了一个chan，最后启动一个goroutine运行meter，之后每3秒收集一次信息并反馈到Meter。这一段代码比较长，就不贴出来了。主要是利用db.db.GetProperty(“leveldb.stats”)获取信息，信息格式如下：123456// Level | Tables | Size(MB) | Time(sec) | Read(MB) | Write(MB)// -------+------------+---------------+---------------+---------------+---------------// 0 | 0 | 0.00000 | 1.27969 | 0.00000 | 12.31098// 1 | 85 | 109.27913 | 28.09293 | 213.92493 | 214.26294// 2 | 523 | 1000.37159 | 7.26059 | 66.86342 | 66.77884// 3 | 570 | 1113.18458 | 0.00000 | 0.00000 | 0.00000 下面就是解析这个字符串并写入Meter。另外一点这段代周期循环的关键代码如下1234567for i := 1; errc == nil &amp;&amp; merr == nil; i++ &#123; //.... select &#123; case errc = &lt;-db.quitChan: case &lt;-time.After(refresh): &#125;&#125; 到select出会阻塞，3秒后进行下一次循环，退出时向Meter方法中初始化的chan发送信息，导致errc不为nil，就自然退出循环 close12345678910111213141516171819func (db *LDBDatabase) Close() &#123; db.quitLock.Lock() defer db.quitLock.Unlock() if db.quitChan != nil &#123; errc := make(chan error) db.quitChan &lt;- errc if err := &lt;-errc; err != nil &#123; db.log.Error("Metrics collection failed", "err", err) &#125; db.quitChan = nil &#125; err := db.db.Close() if err == nil &#123; db.log.Info("Database closed") &#125; else &#123; db.log.Error("Failed to close database", "err", err) &#125;&#125; 退出代码也很简单，主要就是在加锁环境下，向quitChan写入信息，停止meter，然后等待反馈（在meter发出反馈），最后关闭数据库。 memory_database.go这是一个用于测试的基于内存的数据库。在源码中主要是在geth初始化时，如果最后创建数据库时依旧没有有效的datadir则使用这个数据库代替 构造12345678910type MemDatabase struct &#123; db map[string][]byte lock sync.RWMutex&#125;func NewMemDatabase() *MemDatabase &#123; return &amp;MemDatabase&#123; db: make(map[string][]byte), &#125;&#125; 可见就是基于map的封装。 基础操作123456789101112131415161718192021222324252627282930313233func (db *MemDatabase) Put(key []byte, value []byte) error &#123; db.lock.Lock() defer db.lock.Unlock() db.db[string(key)] = common.CopyBytes(value) return nil&#125;func (db *MemDatabase) Has(key []byte) (bool, error) &#123; db.lock.RLock() defer db.lock.RUnlock() _, ok := db.db[string(key)] return ok, nil&#125;func (db *MemDatabase) Get(key []byte) ([]byte, error) &#123; db.lock.RLock() defer db.lock.RUnlock() if entry, ok := db.db[string(key)]; ok &#123; return common.CopyBytes(entry), nil &#125; return nil, errors.New("not found")&#125;func (db *MemDatabase) Delete(key []byte) error &#123; db.lock.Lock() defer db.lock.Unlock() delete(db.db, string(key)) return nil&#125; 全是基于map操作，只不过进行了加锁 Batch1234567891011121314151617181920212223242526272829303132333435363738394041type memBatch struct &#123; db *MemDatabase writes []kv size int&#125;type kv struct &#123; k, v []byte del bool&#125;func (db *MemDatabase) NewBatch() Batch &#123; return &amp;memBatch&#123;db: db&#125;&#125;func (b *memBatch) Put(key, value []byte) error &#123; b.writes = append(b.writes, kv&#123;common.CopyBytes(key), common.CopyBytes(value), false&#125;) b.size += len(value) return nil&#125;func (b *memBatch) Delete(key []byte) error &#123; b.writes = append(b.writes, kv&#123;common.CopyBytes(key), nil, true&#125;) b.size += 1 return nil&#125;func (b *memBatch) Write() error &#123; b.db.lock.Lock() defer b.db.lock.Unlock() for _, kv := range b.writes &#123; if kv.del &#123; delete(b.db.db, string(kv.k)) continue &#125; b.db.db[string(kv.k)] = kv.v &#125; return nil&#125;func (b *memBatch) Reset() &#123; b.writes = b.writes[:0] b.size = 0&#125; 批量操作先存储在一个KV类型的数组内，等到写入时遍历那个数组，依次存入数据库 table.go与table_batch.go这两个也是对数据的封装，之所以叫table是因为实例化一个table时要指定一个前缀，之后利用table的基本操作都会给key添加指定的前缀。table_batch也类似，直接看一下table.go的源码12345678910111213141516171819202122func NewTable(db Database, prefix string) Database &#123; return &amp;table&#123; db: db, prefix: prefix, &#125;&#125;func (dt *table) Put(key []byte, value []byte) error &#123; return dt.db.Put(append([]byte(dt.prefix), key...), value)&#125;func (dt *table) Has(key []byte) (bool, error) &#123; return dt.db.Has(append([]byte(dt.prefix), key...))&#125;func (dt *table) Get(key []byte) ([]byte, error) &#123; return dt.db.Get(append([]byte(dt.prefix), key...))&#125;func (dt *table) Delete(key []byte) error &#123; return dt.db.Delete(append([]byte(dt.prefix), key...))&#125;]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC4加密]]></title>
    <url>%2F2019%2F03%2F27%2FRC4%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景RC4全名Rivest Cipher 4，是1987年Ron Rivest设计的一种流加密法，属于对称加密算法，曾经是WEP、TLS等使用的加密算法，它速度较快，且设计简单，所以使用较广 基本原理首先RC4的秘钥是可变的，长度在1~256个字节之间，开始前我们需要一个初始化状态向量，在进行初始置换后生产流秘钥进行加密。对于解密则是和加密一样的算法。 详细流程S的初始化 首先定义一个长度为1~256个字节的秘钥K。 初始化一个向量S，S[0] = 0,S[1] = 1, … ,S[255] = 255 创建临时数组T，T的长度是256，T用K填充，填不满的循环用K填充，直到T被填满 S的初始置换T数组的作用是对S进行初始置换，置换规则如下：将S[i]与S[j]交换，其中j = (j + S[i] + T[i]) mod 256。j的初始值是0 流秘钥生成根据如下计算：i = (i+1) mod 256，i初始值为0；j = (j + s[i]) mod 256,j初始值位0。然后交换s[i]和S[j]。令t = (S[i] + S[j]) mod 256。输出S[t]作为秘钥通明文进行一字节一字节的加密（异或运算） 简单实现java代码简单实现如下123456789101112131415161718192021222324252627282930313233public class RC4 &#123; private int[] S = new int[256]; RC4(byte[] keys) throws Exception &#123; int keyLen = keys.length; if (keyLen &lt;1 || keyLen &gt; 256) throw new Exception("秘钥长度错误"); int[] T = new int[256]; for (int i = 0;i&lt;256;i++)&#123; S[i] = i; &#125; int j = 0; for (int i = 0;i&lt;256;i++)&#123; j = (j + S[i] + keys[i % keyLen]) % 256; int temp = S[i]; S[i] = S[j]; S[j] = temp; &#125; &#125; public byte[] encrypt(byte[] msgs)&#123; int i = 0,j = 0; byte[] out = new byte[msgs.length]; for (int k = 0;k&lt;msgs.length;k++)&#123; i = (i+1)%256; j = (j+S[i])%256; int temp = S[i]; S[i] = S[j]; S[j] = temp; out[k] = (byte) (msgs[k] ^ S[(S[i] + S[j])%256]); &#125; return out; &#125;&#125; 验证123456public static void main(String[] args) throws Exception &#123; RC4 rc4 = new RC4("123".getBytes()); byte[] out = rc4.encrypt("abcdefg".getBytes()); Base64.Encoder encoder = Base64.getEncoder(); System.out.println(new String(encoder.encode(out))); &#125; 最后输出：MpLc5oASYw== 使用第三方RC4加密验证： 解密验证，由于说解密算法和加密算法一致，所以我们不必做任何修改，直接如下：1234567public static void main(String[] args) throws Exception &#123; RC4 rc4 = new RC4("123".getBytes()); byte[] out = rc4.encrypt("abcdefg".getBytes()); RC4 rc41 = new RC4("123".getBytes()); System.out.println(new String(rc41.encrypt(out))); &#125; 需要注意的一点是，解密时要新建一个RC4对象，原来的对象在加密时S数组已经发生交换，不能使用。 总结RC4算法通过上面实现来看非常简单，没有什么复杂计算，只有简单的交换和异或运算，秘钥也足够长，是一种比较理想的算法。但是弱密钥会导致算法不安全，另外由于更好的算法出现，RC4目前已经很少使用。 题图来自unsplash：https://unsplash.com/photos/B9j-xgMVf90]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中trie源码学习]]></title>
    <url>%2F2019%2F03%2F26%2Fgo-ethereum%E4%B8%ADtrie%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[MPT（Merkle Patricia Tree），是以太坊实现中广泛使用的一种数据结构，如在区块头中就保存了状态树，交易树和收据树这三棵树的根的hash，而这三棵树就是MPT。MPT是Trie树、Patricia Trie树和Merkle树的变形，下面我们就来详细了解一下 背景Trie树Trie树又称前缀树或字典树。顾名思义一个节点的所有孩子都具有同样的前缀，就像字典一样把单词按前缀分类排序。 在Trie树中，根节点不保存信息，每个节点的最大孩子数量相同（若是保存英文字母，不区分大小写，则最多有26个孩子）。 从根节点开始，到某一节点，路径上的字符组合起来就是该节点对应的字符串 没有重复的节点 语言说起来比较抽象，看一张图就很清楚了 如上图所示，这棵树可能保存了:A,to,tea,ted,ten,i,in,inn这8个字符串（具体某个节点表示的仅仅是前缀还是字符串还要根据节点参数判断）。java实现见这里 Trie树具有查找效率高的特点，但是稀疏现象比较严重，空间利用率低。Trie树常用于搜索提示，如输入前几个字母，就可以很快的提示一些可能匹配的字符串。 Patricia Trie实际上是基数树，或压缩前缀树。根据名字可知，是对前缀进行一定的压缩，为了是缓解Trie树空间利用率不高的问题。如下图 从图中我们可以知道，如果以Trie树存储romane和romanus，对于他们的公共前缀roman我们要创建5个先后依赖的节点，在第5层处分叉，对于us又需要两层节点。而对于基数树，可以把roman合并为一个节点，us也合并为一个节点，这样原本至少7层才能表示的现在2层即可。 关于这种树的实现我们会在后面源码分析提到 Merkle树Merkle Tree，通常也被称作Hash Tree。这种树的的主要作用是验证。它结构上大多情况是一颗二叉树，叶子结点都以数据库的hash值作为标签，其他结点都是其子节点的标签拼接后再做hash。他可以高效的安全的验证大型数据结构的内容。 如上图，数据的每一块都对应一个叶子，叶子内存储该块的hash，之后层层做hash运算，最后得到根节点的一个hash值。我们只需要验证根节点的hash是否相同，就能判断整个文件是否完整或者是否被人恶意篡改。另外，通过重建整个树，可以很快的知道具体哪一部分出错。具体在区块链中，无论比特币还是以太坊，都是只在区块头中存储根节点，从而来判断是否一致。 以太坊的MPT一般而言MPT的存储借鉴的是Patricia Trie。与一般的存储英文字符串不同，MPT存储的是hash值，每一位有0-f共16种可能，不过MPT又对其进行了扩展。 首先，定义了三种节点： branch：分支节点，一个长度为17的list，分别是0-f共16位，再加一个value。最后的value代表该节点可能对某个key是终点，用于存取值 leaf：叶子节点，和Trie树的叶子结点类型 extension：扩展节点，纯粹的路径节点，其中的值时其它节点hash，可以理解为一个指向其他节点的指针 看一张经典的图会比较容易理解： 在图中，右上角四对键值就是图中树所存储的内容。首先他们都有前缀a7，所以根节点就是一个扩展节点，它的指针指向一个分支节点，分支节点用到了1、7、f三个值，1、f分别指向两个叶子节点，因为没有其他key和他们有除a7外的公共前缀，分支节点7指向一个扩展节点，因为右上角第二和第四个还有公共前缀d3，随后在指向一个分支节点，再找值分为两个叶子节点。叶子结点的value就存着每个键值对中的value. 源码分析ethereum关于这部分的源码集中在trie目录下 结点定义见代码：1234567891011121314151617181920// go-ethereum\trie\node.gotype node interface &#123; fstring(string) string cache() (hashNode, bool) canUnload(cachegen, cachelimit uint16) bool&#125;type ( fullNode struct &#123; Children [17]node // Actual trie node data to encode/decode (needs custom encoder) flags nodeFlag &#125; shortNode struct &#123; Key []byte Val node flags nodeFlag &#125; hashNode []byte valueNode []byte) 虽说黄皮书中定义了3种结点，但这里只有两种节点，分别是fullnode和shortnode。fullnode就是分支节点，可见其有一个长度为17的数组。shortnode可以代表扩展节点或叶子节点，因为二者结构是一样的，区分两种节点主要看val的值。另外还有两种节点，虽然是字节数组类型的，但是他们都实现了node接口的全部方法，所以也是节点类型。 树的构造先看一下树的结构：12345type Trie struct &#123; db *Database root node cachegen, cachelimit uint16&#125; root就是根节点，db就是数据库，树的结构最后要存到数据库中，启动时再加载出来。对于cachegen，每次提交其值都会增加，新节点会标记cachegen，如果当前的cachegen - cachelimit大于node的cache时代，那么node会从cache里面卸载，以便节约内存。 创建一棵树12345678910111213141516func New(root common.Hash, db *Database) (*Trie, error) &#123; if db == nil &#123; panic("trie.New called without a database") &#125; trie := &amp;Trie&#123; db: db, &#125; if root != (common.Hash&#123;&#125;) &amp;&amp; root != emptyRoot &#123; rootnode, err := trie.resolveHash(root[:], nil) if err != nil &#123; return nil, err &#125; trie.root = rootnode &#125; return trie, nil&#125; new方法接受一个hash和一个数据库指针，首席确保指针不为空，然后初始化树，之后再判断传入的hash是否为空值，若不是则从数据库加载，否则返回一个空树。 插入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960func (t *Trie) insert(n node, prefix, key []byte, value node) (bool, node, error) &#123; if len(key) == 0 &#123; if v, ok := n.(valueNode); ok &#123; return !bytes.Equal(v, value.(valueNode)), value, nil &#125; return true, value, nil &#125; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) if matchlen == len(n.Key) &#123; dirty, nn, err := t.insert(n.Val, append(prefix, key[:matchlen]...), key[matchlen:], value) if !dirty || err != nil &#123; return false, n, err &#125; return true, &amp;shortNode&#123;n.Key, nn, t.newFlag()&#125;, nil &#125; branch := &amp;fullNode&#123;flags: t.newFlag()&#125; var err error _, branch.Children[n.Key[matchlen]], err = t.insert(nil, append(prefix, n.Key[:matchlen+1]...), n.Key[matchlen+1:], n.Val) if err != nil &#123; return false, nil, err &#125; _, branch.Children[key[matchlen]], err = t.insert(nil, append(prefix, key[:matchlen+1]...), key[matchlen+1:], value) if err != nil &#123; return false, nil, err &#125; if matchlen == 0 &#123; return true, branch, nil &#125; return true, &amp;shortNode&#123;key[:matchlen], branch, t.newFlag()&#125;, nil case *fullNode: dirty, nn, err := t.insert(n.Children[key[0]], append(prefix, key[0]), key[1:], value) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn return true, n, nil case nil: return true, &amp;shortNode&#123;key, value, t.newFlag()&#125;, nil case hashNode: rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.insert(rn, prefix, key, value) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf("%T: invalid node: %v", n, n)) &#125;&#125; 几个参数分别是：n代表当前的结点。prefix代表已经搜索过的前缀，key表示尚未处理的部分，二者拼接到一起就是完整的key。value表示要插入的值。返回值中bool表示是否改变了树，node表示插入后子树的根节点。通过参数可以猜到这是通过递归进行操作的。 代码的第一个if判断中，若key的长度为0，表示key已经遍历完了，同时也找到了一个节点。判断这个节点是否是valueNode类型节点，若是的话，判断要插入的值和结点的值是否相等，来判断是否改变了树。若不是valueNode类型节点，就直接更新value，同时指明树已经改变了。 若还在变量key的途中，则根据当前节点的类型进行判断： 若是shortNode节点，表示是一个叶子节点或扩展节点，则调用prefixLen方法计算公共前缀长度。若公共前缀长度就等于key的长度，说明二者的可以是一样的，则按照需要更新value。若只有部分公共前缀，则需要构造一个分支节点，将原来的节点和要插入的作为新分支节点的孩子插入。最后对刚才的公共前缀进行判断，若为0，表示没有公共前缀，则用新的分支节点替换掉原来的节点，若不为零，则将新的分支节点作为原节点的孩子，并改变原节点的可以。注意给分支节点添加孩子时，也是调用的insert，只不过n为nil，这对应后面的一种情况，稍后分析。 若是fullNode，也就是分支节点，则直接寻找对应的位置尝试插入，注意分支节点对于位置的孩子可能为空，为shortNode或者fullnode，不管为什么，最终继续递归，并按需更新孩子即可 若是nil，这种情况可能会一棵空树时候出现，这是新建一个shortNode节点作为根节点，返回即可。同时，在上文向分支节点插入孩子时也会出现，同样也是新建shortNode结点作为分支节点孩子即可。 若是hashNode，可以理解为一个指针，但是数据都在数据库，需要取数据库取值插入 最后不满足定义的四种节点，报错 最后总结一点，对于shortNode节点，要么进行更新，要么新建扩展节点进行插入，对于fullNode，要么成为其某个孩子，要么更新其值，要么为其添加扩展节点，进行扩展。总之新的叶子节点插入操作都是在扩展节点上完成的。 删除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778func (t *Trie) delete(n node, prefix, key []byte) (bool, node, error) &#123; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) if matchlen &lt; len(n.Key) &#123; return false, n, nil // don't replace n on mismatch &#125; if matchlen == len(key) &#123; return true, nil, nil // remove n entirely for whole matches &#125; dirty, child, err := t.delete(n.Val, append(prefix, key[:len(n.Key)]...), key[len(n.Key):]) if !dirty || err != nil &#123; return false, n, err &#125; switch child := child.(type) &#123; case *shortNode: return true, &amp;shortNode&#123;concat(n.Key, child.Key...), child.Val, t.newFlag()&#125;, nil default: return true, &amp;shortNode&#123;n.Key, child, t.newFlag()&#125;, nil &#125; case *fullNode: dirty, nn, err := t.delete(n.Children[key[0]], append(prefix, key[0]), key[1:]) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn pos := -1 //遍历后，若pos大于等于0，表示只有一个孩子 //若pos等于-2则孩子数量大于一个 for i, cld := range &amp;n.Children &#123; if cld != nil &#123; if pos == -1 &#123; pos = i &#125; else &#123; pos = -2 break &#125; &#125; &#125; if pos &gt;= 0 &#123; if pos != 16 &#123; cnode, err := t.resolve(n.Children[pos], prefix) if err != nil &#123; return false, nil, err &#125; if cnode, ok := cnode.(*shortNode); ok &#123; k := append([]byte&#123;byte(pos)&#125;, cnode.Key...) return true, &amp;shortNode&#123;k, cnode.Val, t.newFlag()&#125;, nil &#125; &#125; return true, &amp;shortNode&#123;[]byte&#123;byte(pos)&#125;, n.Children[pos], t.newFlag()&#125;, nil &#125; return true, n, nil case valueNode: return true, nil, nil case nil: return false, nil, nil case hashNode: rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.delete(rn, prefix, key) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf("%T: invalid node: %v (%v)", n, n, key)) &#125;&#125; 参数和返回值和插入操作类似，不在赘述。依旧是判断当前节点类型： 若为shortNode结点，首先也是计算公共前缀。若公共前缀的长度小于当前节点key的长度，表示没有匹配到。若公共前缀的长度等于要删除的key的长度，表示匹配到子树，直接删除该节点为根的子树。若公共前缀的长度等于当前节点key的长度，也就是当前节点的key是要删除key的一部分，说明还要向下查找。但是删除完后要对节点做处理，若子节点fullnode节点删除孩子后孩子数量大于1个，则只改变当前节点的flag。若删除后孩子数量小于等于一个，则要对节点进行合并，也就是对前缀进行合并 若为fullnode结点，则直接根据key的第一个字符取尝试删除某个孩子。然后遍历孩子，判断非空的数量，若大于两个则不做处理，若只有一个，进行节点的合并。 若为valueNode节点，直接删除，返回 若为nil，一般在阐述fullnode的孩子时遇到，表示没有匹配，不做处理 若为hashNode，表示还在数据库中，则先加载，在尝试删除 查询也就是Get方法，见代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func (t *Trie) Get(key []byte) []byte &#123; res, err := t.TryGet(key) if err != nil &#123; log.Error(fmt.Sprintf("Unhandled trie error: %v", err)) &#125; return res&#125;func (t *Trie) TryGet(key []byte) ([]byte, error) &#123; key = keybytesToHex(key) //转为16进制半字节 value, newroot, didResolve, err := t.tryGet(t.root, key, 0) if err == nil &amp;&amp; didResolve &#123; t.root = newroot &#125; return value, err&#125;func (t *Trie) tryGet(origNode node, key []byte, pos int) (value []byte, newnode node, didResolve bool, err error) &#123; switch n := (origNode).(type) &#123; case nil: return nil, nil, false, nil case valueNode: return n, n, false, nil case *shortNode: if len(key)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, key[pos:pos+len(n.Key)]) &#123; // key not found in trie return nil, n, false, nil &#125; value, newnode, didResolve, err = t.tryGet(n.Val, key, pos+len(n.Key)) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.Val = newnode n.flags.gen = t.cachegen &#125; return value, n, didResolve, err case *fullNode: value, newnode, didResolve, err = t.tryGet(n.Children[key[pos]], key, pos+1) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.flags.gen = t.cachegen n.Children[key[pos]] = newnode &#125; return value, n, didResolve, err case hashNode: child, err := t.resolveHash(n, key[:pos]) if err != nil &#123; return nil, n, true, err &#125; value, newnode, _, err := t.tryGet(child, key, pos) return value, newnode, true, err default: panic(fmt.Sprintf("%T: invalid node: %v", origNode, origNode)) &#125;&#125; 查找的逻辑也很简单，首先要把byte数组转为16进制半字节的数组形式，使用keybytesToHex方法（后面会讲）。之后从根节点开始，调用tryGet递归查询，也分一下几种情况： 若为空，表示没有找到 若为valueNode节点，直接返回即可 若为shortNode，如果当前节点的key长度大于本次递归要查找的或即使长度相等但内容不一样的，则表示没有匹配的，否则继续递归查找 若为fullNode结点，则递归到孩子中寻找 若为hashNode结点，则先从数据库中加载，在尝试递归查询 编码主要是encoding.go，处理树的三种编码格式的互相转换。 keybytes：原始字节数组，大部分trie的函数都用这种格式 hex：hex编码，将一个字节用两个字节表示，编码时，将8位二进制码重新分组成两个4位的字节，其中一个字节的低4位是原字节的高四位，另一个字节的低4位是原数据的低4位，高4位都补0。编码后再在尾部跟上一个标志位0x10，标识是叶子节点或者扩展节点 compact：compact编码，就是Hex-Prefix Encoding，在黄皮书中的附录C有说明。是hex编码的变体。第一个字节的高位存储标志位，低位存储0（长度为偶数）或hex编码的第一个半字节（长度为奇数）。总之最后长度是偶数。数学描述如下（f(t)表示hex编码的标志位是否存在）： 下面具体看源码： hexToCompacthex编码转compact编码12345678910111213141516func hexToCompact(hex []byte) []byte &#123; terminator := byte(0) if hasTerm(hex) &#123; terminator = 1 hex = hex[:len(hex)-1] &#125; buf := make([]byte, len(hex)/2+1) buf[0] = terminator &lt;&lt; 5 // the flag byte if len(hex)&amp;1 == 1 &#123; buf[0] |= 1 &lt;&lt; 4 // odd flag buf[0] |= hex[0] // first nibble is contained in the first byte hex = hex[1:] &#125; decodeNibbles(hex, buf[1:]) return buf&#125; hasTerm判断最后一字节是否是16，也就是有没有标志位，若是则terminator标记为1，并去除hex编码的标志位。接下来写入compat编码的标志位，首先terminator右移5位，再判断hex编码长度的奇偶性，并根据情况改下标志位。然后解码hex编码改为compat编码，流程和黄皮书一致。 compactToHexcompact编码转hex编码12345678910111213func compactToHex(compact []byte) []byte &#123; if len(compact) == 0 &#123; return compact &#125; base := keybytesToHex(compact) // delete terminator flag if base[0] &lt; 2 &#123; base = base[:len(base)-1] &#125; // apply odd flag chop := 2 - base[0]&amp;1 return base[chop:]&#125; 可见先看做一般字节数组，然后转为hex编码。然后判断是否有标志位。首先根据黄皮书规定，compact编码的第一字节的高四位有这几种情况：12340000 hex编码没有标志位，且长度为偶数0001 hex编码没有标志位，且长度为奇数0010 hex编码有标志位，且长度为偶数0011 hex编码有标志位，且长度为奇数 根据上面四种情况，删除最后的标志位。然后在根据第一位的值，决定是删除前两位还是第一位 keybytesToHex原始数组转hex编码12345678910func keybytesToHex(str []byte) []byte &#123; l := len(str)*2 + 1 var nibbles = make([]byte, l) for i, b := range str &#123; nibbles[i*2] = b / 16 nibbles[i*2+1] = b % 16 &#125; nibbles[l-1] = 16 return nibbles&#125; 很简单，就是一个字节拆为两个字节，利用整除和取余，最后加一个标志位。 hexToKeybyteshex编码还原12345678910111213141516func hexToKeybytes(hex []byte) []byte &#123; if hasTerm(hex) &#123; hex = hex[:len(hex)-1] &#125; if len(hex)&amp;1 != 0 &#123; panic("can't convert hex key of odd length") &#125; key := make([]byte, len(hex)/2) decodeNibbles(hex, key) return key&#125;func decodeNibbles(nibbles []byte, bytes []byte) &#123; for bi, ni := 0, 0; ni &lt; len(nibbles); bi, ni = bi+1, ni+2 &#123; bytes[bi] = nibbles[ni]&lt;&lt;4 | nibbles[ni+1] &#125;&#125; 先根据需求去除标志位，再具体转换。可见将两字节还原为一字节时就是利用移位和或逻辑。 序列化序列化就是将一课树存储到数据库中123456789101112131415161718192021// go-ethereum\trie\trie.gofunc (t *Trie) Commit(onleaf LeafCallback) (root common.Hash, err error) &#123; if t.db == nil &#123; panic("commit called on trie with nil database") &#125; hash, cached, err := t.hashRoot(t.db, onleaf) if err != nil &#123; return common.Hash&#123;&#125;, err &#125; t.root = cached t.cachegen++ return common.BytesToHash(hash.(hashNode)), nil&#125;func (t *Trie) hashRoot(db *Database, onleaf LeafCallback) (node, node, error) &#123; if t.root == nil &#123; return hashNode(emptyRoot.Bytes()), nil, nil &#125; h := newHasher(t.cachegen, t.cachelimit, onleaf) defer returnHasherToPool(h) return h.hash(t.root, db, true)&#125; 这一部分主要是创建了hasher，然后利用hash方法去实现。进入hasher的代码123456// go-ethereum\trie\hasher.gofunc newHasher(cachegen, cachelimit uint16, onleaf LeafCallback) *hasher &#123; h := hasherPool.Get().(*hasher) h.cachegen, h.cachelimit, h.onleaf = cachegen, cachelimit, onleaf return h&#125; hasherPool是一个对象池，newHasher方法主要是从中尝试取或者创建一个hasher对象。下面看hash方法：123456789101112131415161718192021222324252627282930313233343536func (h *hasher) hash(n node, db *Database, force bool) (node, node, error) &#123; if hash, dirty := n.cache(); hash != nil &#123; if db == nil &#123; return hash, n, nil &#125; if n.canUnload(h.cachegen, h.cachelimit) &#123; cacheUnloadCounter.Inc(1) return hash, hash, nil &#125; if !dirty &#123; return hash, n, nil &#125; &#125; collapsed, cached, err := h.hashChildren(n, db) if err != nil &#123; return hashNode&#123;&#125;, n, err &#125; hashed, err := h.store(collapsed, db, force) if err != nil &#123; return hashNode&#123;&#125;, n, err &#125; cachedHash, _ := hashed.(hashNode) switch cn := cached.(type) &#123; case *shortNode: cn.flags.hash = cachedHash if db != nil &#123; cn.flags.dirty = false &#125; case *fullNode: cn.flags.hash = cachedHash if db != nil &#123; cn.flags.dirty = false &#125; &#125; return hashed, cached, nil&#125; 第一个if我们后面再解释，接下来的hashChildren是一个关键点，它将所有的子节点换为他们的hash1234567891011121314151617181920212223242526272829303132333435func (h *hasher) hashChildren(original node, db *Database) (node, node, error) &#123; var err error switch n := original.(type) &#123; case *shortNode: collapsed, cached := n.copy(), n.copy() collapsed.Key = hexToCompact(n.Key) cached.Key = common.CopyBytes(n.Key) if _, ok := n.Val.(valueNode); !ok &#123; collapsed.Val, cached.Val, err = h.hash(n.Val, db, false) if err != nil &#123; return original, original, err &#125; &#125; return collapsed, cached, nil case *fullNode: subtrees collapsed, cached := n.copy(), n.copy() for i := 0; i &lt; 16; i++ &#123; if n.Children[i] != nil &#123; collapsed.Children[i], cached.Children[i], err = h.hash(n.Children[i], db, false) if err != nil &#123; return original, original, err &#125; &#125; &#125; cached.Children[16] = n.Children[16] return collapsed, cached, nil default: return n, original, nil &#125;&#125; 主要也是根据结点类型进行操作。 对于shortNode节点，先对key从hex编码转为compact编码，然后递归调用hash把子节点也改为hash 对于fullNode结点，遍历所有孩子，递归调用hash方法 对于其他类型节点原样返回 再回到hash方法，接下来调用store方法。12345678910111213141516171819202122232425262728293031323334353637383940func (h *hasher) store(n node, db *Database, force bool) (node, error) &#123; if _, isHash := n.(hashNode); n == nil || isHash &#123; return n, nil &#125; h.tmp.Reset() if err := rlp.Encode(&amp;h.tmp, n); err != nil &#123; panic("encode error: " + err.Error()) &#125; if len(h.tmp) &lt; 32 &amp;&amp; !force &#123; return n, nil // Nodes smaller than 32 bytes are stored inside their parent &#125; database. hash, _ := n.cache() if hash == nil &#123; hash = h.makeHashNode(h.tmp) &#125; if db != nil &#123; cache hash := common.BytesToHash(hash) db.lock.Lock() db.insert(hash, h.tmp, n) db.lock.Unlock() if h.onleaf != nil &#123; switch n := n.(type) &#123; case *shortNode: if child, ok := n.Val.(valueNode); ok &#123; h.onleaf(child, hash) &#125; case *fullNode: for i := 0; i &lt; 16; i++ &#123; if child, ok := n.Children[i].(valueNode); ok &#123; h.onleaf(child, hash) &#125; &#125; &#125; &#125; &#125; return hash, nil&#125; 首先判断节点类型，若本身就是hashNode或为空不存储。然后对节点编码。详细流程不在赘述，参考RLP编码学习。编码之后的结果存在tmp这个字节数组中。接下来判断是否强制存储，然后计算根节点编码后结果hash，最后存储到数据库，键就是刚才计算的hash。 再次回到hash方法，存储成功后。将存储的键转为hashNode类，然后判断cached（实际是跟节点的copy）的类型，对于是shortNode和fullNode类型，将其flags成员的hash值进行修改，然后返回hash值和cached。 反序列化不同于序列化，反序列化在trie的源码中就多次出现，主要是下面方法123456789func (t *Trie) resolveHash(n hashNode, prefix []byte) (node, error) &#123; cacheMissCounter.Inc(1) hash := common.BytesToHash(n) if node := t.db.node(hash, t.cachegen); node != nil &#123; return node, nil &#125; return nil, &amp;MissingNodeError&#123;NodeHash: hash, Path: prefix&#125;&#125; 主要逻辑在node方法中123456789101112131415161718192021222324252627// go-ethereum\trie\database.gofunc (db *Database) node(hash common.Hash, cachegen uint16) node &#123; if db.cleans != nil &#123; if enc, err := db.cleans.Get(string(hash[:])); err == nil &amp;&amp; enc != nil &#123; memcacheCleanHitMeter.Mark(1) memcacheCleanReadMeter.Mark(int64(len(enc))) return mustDecodeNode(hash[:], enc, cachegen) &#125; &#125; db.lock.RLock() dirty := db.dirties[hash] db.lock.RUnlock() if dirty != nil &#123; return dirty.obj(hash, cachegen) &#125; enc, err := db.diskdb.Get(hash[:]) if err != nil || enc == nil &#123; return nil &#125; if db.cleans != nil &#123; db.cleans.Set(string(hash[:]), enc) memcacheCleanMissMeter.Mark(1) memcacheCleanWriteMeter.Mark(int64(len(enc))) &#125; return mustDecodeNode(hash[:], enc, cachegen)&#125; 这也是一个典型的二级缓存的例子，首先尝试从内存缓存中获取，若没有，则从磁盘的数据库中获取，最后实际反序列化操作都在mustDecodeNode方法中123456789101112131415161718192021222324252627// go-ethereum\trie\node.gofunc mustDecodeNode(hash, buf []byte, cachegen uint16) node &#123; n, err := decodeNode(hash, buf, cachegen) if err != nil &#123; panic(fmt.Sprintf("node %x: %v", hash, err)) &#125; return n&#125;func decodeNode(hash, buf []byte, cachegen uint16) (node, error) &#123; if len(buf) == 0 &#123; return nil, io.ErrUnexpectedEOF &#125; elems, _, err := rlp.SplitList(buf) if err != nil &#123; return nil, fmt.Errorf("decode error: %v", err) &#125; switch c, _ := rlp.CountValues(elems); c &#123; case 2: n, err := decodeShort(hash, elems, cachegen) return n, wrapError(err, "short") case 17: n, err := decodeFull(hash, elems, cachegen) return n, wrapError(err, "full") default: return nil, fmt.Errorf("invalid number of list elements: %v", c) &#125;&#125; 首先解释一下涉及到的几个rlp方法，通过学习rlp编码我们知道，rlp编码一般由一个标志位+前缀+内容组成，SplitList方法返回的就是内容以及剩余内容（未被解析的）。对于复合类型，也就是编码中的第二种数据来源–多维数组类型，它的rlp编码内容部分是由多个单独的子类型rlp编码组合而成的，CountValues就是统计有多少个子部分。 接下来一个switch就是根据有多少子内容区分节点的类型，如代码中所述，2个子内容的就是shortNode，17个的就是fullNode，注意这点可能会有些人有疑问，我们定义节点的时候，这两类节点可不止这几个成员变量，这是因为在存储时节点都被转化为rawShortNode和rawFullNode两种简单类型（ go-ethereum\trie\database.go），只保留关键信息。我们接下来再看具体的反序列化方法123456789101112131415161718192021222324252627282930313233343536373839404142func decodeShort(hash, elems []byte, cachegen uint16) (node, error) &#123; kbuf, rest, err := rlp.SplitString(elems) if err != nil &#123; return nil, err &#125; flag := nodeFlag&#123;hash: hash, gen: cachegen&#125; key := compactToHex(kbuf) if hasTerm(key) &#123; val, _, err := rlp.SplitString(rest) if err != nil &#123; return nil, fmt.Errorf("invalid value node: %v", err) &#125; return &amp;shortNode&#123;key, append(valueNode&#123;&#125;, val...), flag&#125;, nil &#125; r, _, err := decodeRef(rest, cachegen) if err != nil &#123; return nil, wrapError(err, "val") &#125; return &amp;shortNode&#123;key, r, flag&#125;, nil&#125;func decodeRef(buf []byte, cachegen uint16) (node, []byte, error) &#123; kind, val, rest, err := rlp.Split(buf) if err != nil &#123; return nil, buf, err &#125; switch &#123; case kind == rlp.List: if size := len(buf) - len(rest); size &gt; hashLen &#123; err := fmt.Errorf("oversized embedded node (size is %d bytes, want size &lt; %d)", size, hashLen) return nil, buf, err &#125; n, err := decodeNode(nil, buf, cachegen) return n, rest, err case kind == rlp.String &amp;&amp; len(val) == 0: return nil, rest, nil case kind == rlp.String &amp;&amp; len(val) == 32: return append(hashNode&#123;&#125;, val...), rest, nil default: return nil, nil, fmt.Errorf("invalid RLP string size %d (want 0 or 32)", len(val)) &#125;&#125; 逻辑还是很清晰的，首先使用SplitString，分理处内容和剩余数据，然后将内容转为hex编码，再判断value是否有标志位来决定是否是叶子节点，若是叶子节点，则解析剩余的内容。若不是，则使用decodeRef来解析剩余内容。decodeRef首先也是分离出rlp编码各部分，先判断类型，再根据类型生成具体的节点。最后回到decodeShort构造出一个完整的节点。另外decodeFull流程也类似，不在赘述。主要思想就是一层一层剥开rlp编码，根据具体类型生成具体节点。 trie的cachetrie除了有数据库和根节点这两个成员变量，还有cachegen, cachelimit用于缓存管理的变量。trie树在每次commit时都会将cachegen加1（见上面序列化部分源码），然后在每次插入节点时都会把cachegen写入新节点，利用的是newFlag方法123func (t *Trie) newFlag() nodeFlag &#123; return nodeFlag&#123;dirty: true, gen: t.cachegen&#125;&#125; 当trie.cachegen - node.cachegen &gt; cachelimit时，就会把节点从内存中卸载（删除），用的是canUnload方法判断，每个继承node接口的类都实现了该方法：1234func (n *fullNode) canUnload(gen, limit uint16) bool &#123; return n.flags.canUnload(gen, limit) &#125;func (n *shortNode) canUnload(gen, limit uint16) bool &#123; return n.flags.canUnload(gen, limit) &#125;func (n hashNode) canUnload(uint16, uint16) bool &#123; return false &#125;func (n valueNode) canUnload(uint16, uint16) bool &#123; return false &#125; 卸载的作用是节省内存，所以说经过几次commit后，就会有节点被从内存中删除，删除是在hash方法中，也就是那个方法的第一个if1234567891011121314func (h *hasher) hash(n node, db *Database, force bool) (node, node, error) &#123; if hash, dirty := n.cache(); hash != nil &#123; if db == nil &#123; return hash, n, nil &#125; if n.canUnload(h.cachegen, h.cachelimit) &#123; cacheUnloadCounter.Inc(1) return hash, hash, nil &#125; if !dirty &#123; return hash, n, nil &#125; &#125; .... 获取hash是首先从节点的cache中获取，若存在的话，先不急着返回，首先判断是否可卸载，若可以，则卸载，注意卸载方式很有意思，不返回节点实例，而是返回一个hash表示节点，然后需要的时候在反序列化即可。注意若节点没有缓存hash值，则一定不进行卸载。 SecureTrie最后还有一个SecureTrie，是为了避免使用很长的key导致性能下降。SecureTrie包装了trie，所有的key都转化为keccak256计算的hash，但在数据库中存储原始key123456type SecureTrie struct &#123; trie Trie hashKeyBuf [common.HashLength]byte secKeyCache map[string][]byte //hash值和key值的映射 secKeyCacheOwner *SecureTrie &#125; 题图来自unsplash：https://unsplash.com/photos/hnw3Al47-KE]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA加密]]></title>
    <url>%2F2019%2F03%2F26%2FIDEA%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景IDEA全称International Data Encryption Algorithm，即国际数据加密算法。也是一种强大的加密算法，原本目的是取代DES，但是由于专利的存在，IDEA并没有DES使用广泛，但是如PGP加密程序就是用的IDEA。 IDEA和DES一样，都是可逆的，加解密算法相同，也利用了扩展和混淆思想 基本原理加密前明文进行分块，每块64位，秘钥位128位。加密时，首先将明文分为4组，每组16位，作为第一轮的输入，总共需要8轮。在每一轮中，从128位的秘钥中产生6组子秘钥，每组16位，用这6组子秘钥对输入的4组明文进行一系列操作，产生一轮的输出，并作为下一轮输入。8轮结束后进行一次变换，这次变换需要4个子秘钥，组合起来得到64位密文。 轮次每一轮有14步，基本流程如下（我们将4组输入定义为P1-P4，6组秘钥定义为k1-K6）： P1与K1相乘 P2与K2相加 P3与K3相加 P4与K4相乘 第1步结果与第2步结果异或 第2步结果与第4步结果异或 第5步结果与K5相乘 第6步结果和第7步结果相乘 第8步与K6相乘 第7步与第9步相加 第1步结果与第9步结果异或 第3步结果与第9步结果异或 第2步结果与第10步结果异或 第4步结果与第10步结果异或 第11，13，12，14分别为输出的第1-4组，示意图如下（图中红圈代表相乘运算，篮圈代表异或运算，绿圈代表相加运算： 注意步骤中的加或乘并不是简单的加与乘。对于加法，加之后用2^16(即65536)求模。对于乘法，乘之后用2^16 + 1(即65537)求模。求模主要是为了保证输出为16位。 子秘钥生成总体来看，前8轮每轮需要8个子秘钥，最后一个输出变换需要4个子秘钥 第一轮第一轮开始前我们有一组128位的原始秘钥，第一轮用前96位，每16位一组，公6组 第二轮第二轮先使用没有用的32位，共两组，还差4组64位秘钥。然后将原始秘钥循环左移25位，再取前64位，作为后四组秘钥。 第三轮上一轮还剩64位，作为该轮的前四组秘钥，然后再左移25位，选前32位作为剩下两组子秘钥。 后面几轮一次类推，每次都先使用上一轮未使用的，对于不够的先循环左移，再取秘钥 输出变换第8轮之后，有四组输出，然后进行输出变换，具体过程如下(将4组输出定义为R1-R4，4组秘钥定义为K1-K4)： R1与K1相乘 R2与K2相加 R3与K3相加 R4与K4相乘 注意，相加相乘还是和之前8轮里的加和乘一样操作。对于子秘钥，第8轮是刚好把128位的后96位用完。这一次，依旧先左移25位，然后取前64位作为4组秘钥 解密解密算法和加密算法是一样的，只是秘钥有所不同。 第i(1-9)轮的解密秘钥的前4四个子秘钥由加密过程中第10-i轮的前四个子秘钥得出 其中第1与第4个子秘钥为对应子秘钥关于2^16 + 1的乘法逆元 第 2 个和第 3 个子密钥的取法为：1.当轮数为 2，…，8 时，取相应的第 3 个和第 2 个的子密钥的2^16加法逆元 2.当轮数为 1 或 9 时，取相应的第 2 个和第 3 个子密钥对应的2^16加法逆元 第 5 和第 6 个密钥不变 简单实现java代码见这里 题图来自unsplash：https://unsplash.com/photos/WDOJ5256Cvk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DES加密]]></title>
    <url>%2F2019%2F03%2F25%2FDES%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[DES加密基本上属于学习加密算法的必修内容，这里也来梳理一下整个算法 背景DES全称Data Encryption Standard，也就是数据加密标准，也被称作Data Encryption ALgorithm，DEA，数据加密算法。分类上，它属于对称秘钥加密块密码。1976年被被美国联邦政府的国家标准局确定为联邦资料处理标准，随后再全世界广泛应用，成为一种通用加密算法。虽然现在这种算法已经不安全了，但是它使用的一些思想和理念深深影响可后来许多加密算法。这个算法的官方文档见这里 基本原理首先这是一种块加密算法，以64位为一块，输出的密文也是64位，加解密使用相同的秘钥，秘钥的长度是56位。对于秘钥，最初是64位的，不过在算法开始前会丢弃8位（第8,16,24,32,40,48,56,64位）。 之后算法的主要思想是对明文进行替换和变换（也称混淆和扩散），这是香农提出的思想，对后世的密码算法有重要影响。混淆是为了保证密文中不会出现明文线索，扩散则是增加明文的冗余度。 DES主要步骤如下： 将明文进行初始置换（IP） 将置换后的块分为左右两部分 对每一部分进行16轮加密 将加密后的两部分拼接起来，进行最终置换（FP），得到密文 如下图： 详细过程初始置换在加密前需要进行一次初始置换，称为IP，结束后有一个最终置换，FP，这两个操作在密码学上几乎没有任何意义，只是在最初设计时，为了简化输入输出数据库的过程而被纳入加密流程。 初始置换借助的是一个置换表，如下表： 表中数字代表明文中该位的位置，如第一个是58，则代表将明文中的第58位放到置换后的第一位，依次类推 DES的一轮每一轮包含秘钥变换，扩展置换，S盒替换，P盒替换和异或交换这几步。也被统称为费斯妥函数，也就是开始那张图中的F函数 秘钥变换首先秘钥有56位，这一步是从这56位中选取48位，作为这一轮的子秘钥。变换的基本规则是，将56位分为两部分，各28位，每一轮循环左移一位或两位，具体情况如下表： 移位后，具体如何挑选48位，是根据下表挑选： 和初始置换类似，表中数字也是表示的该位在原秘钥中的位置，如第一位14表示将秘钥的第14位写在这里，后面依次类推 由于是将56位变为48位，这一步也称为压缩置换 扩展置换经过初始置换后，得到两个32位的明文部分，称为左右明文，而这一步就是将右明文扩展到48位。具体过程如下 将32位明文分为8组，每组4位 将每组的4位扩展为6位，实际上是重复每组的第一和第4位，但不是简单的重复，每组之间是有依赖的，简单描述就是，原来每位右移移位，第一位由上一组的第四位填充（第一组由最后一组填充），第六位由下一组的第一位填充（最后一组由第一组填充） 由于这一步极有规律，可以表示为下面的变换表： 这个表使用和前面的一样，不在赘述 S盒替换前一步将32位明文变为48位，这样就可以和秘钥进行异或操作，最后得到48位的输出，S盒的作用就是将这48位变为32位，总共有8个S盒，每个盒接受6位输入，产生4位输出，随后将48位变为32位。 8个S盒如下 关于S盒的使用如下，首先把一个S和看做4行16列的表格，首先输入有6位，将其中间四位看做列号，首尾两位看做行号。如输入101101，则行号就是11=3，列号就是0110=6，则就取s盒第3行第6位（行列都从0开始计数），如使用第二个S盒就输出2，转为4位二进制就是0010 P盒替换经s盒替换后，输出32位结果，之后进行一次简单的P和置换，置换表如下： 异或与交换P和置换不改变位数，输出还是32位，之后将输出的32位与左明文进行异或（前面一系列步骤都是再对右明文处理），运算结果成为下一轮的右明文，而原来的有明文变成下一轮的左明文，这就是所谓的交换 最后一张图总结这几步： 最终置换这样重复16轮之后，得到一个64位的密文。然后在进行最终置换，置换表如下： 解密通过前文可知，加密过程是极其繁琐和复杂的，许多替换不深入研究是不能了解其意义的，但是对于解密而言，就体现了DES算法的强大之处，它的加密算法和解密算法是一样的，唯一区别就是那16轮中用的秘钥要反过来，如第1轮解密要用第16轮加密秘钥。不过由于秘钥是独立运算的，所以可以事先计算好16轮加密所使用的全部秘钥。 DES变体双重DES从字面意思很好理解，就是使用两个秘钥，进行两次加密。解密时反向操作两次即可。如果说单一DES加密破解需要搜索2^56个秘钥，则双重DES就需要搜索2^112个秘钥 双重DES的中间人攻击这是一种理论上的攻击，我们假设攻击者知道明文和密文，需要找到加密的两个秘钥。首先创建两张表，第一张表存储所有可能的密码对明文块加密后的结果，第二张表存储所有可能的密码对密文块解密后的结果，比对两张表的结果，相同的那两行所用的秘钥就是加密过程中用的秘钥。 三重DES三个秘钥的三重DES比较简单，就是用三个秘钥，加密三次 两个秘钥的三重DES使用两个秘钥，首先用秘钥K1执行加密，再用K2解密，再用K1加密，这种模式成为加解加模式（EDE） DES的实现我们这里用java实现一下DES，完整源码见这里 注意在下面移位操作中，对于二进制字符串，我们认为最左边为第1位。 构造函数和构造密钥组对于构造函数要求出入一个字节数组作为密钥，长度必须是8字节，然后准备两个long类型数组存储加密和解密子密钥，由于子密钥是48位，所以用64位的long类型存储1234567891011121314151617181920212223242526private long[] encryptKeys = new long[16];private long[] decryptKeys = new long[16];MyDES(byte[] bytes) throws Exception &#123; if (bytes.length!=8) throw new Exception("密钥长度错误"); generateSubKey(bytes);&#125;private void generateSubKey(byte[] keyBytes) &#123; long key = bytesToLong(keyBytes); //64位密钥转为64位long类型表示 long pc1Result = permute(PC1,key,64); //从64位中选56位 int l = (int) (pc1Result &gt;&gt;&gt; 28); //密钥左半部分 int r = (int) (pc1Result &amp; 0xfffffff); //密钥右半部分 for (int i = 0; i&lt;16;i++)&#123; //左右部分分别循环左移 l = (l &lt;&lt; KEY_ROTATE[i]) | (l &gt;&gt;&gt; (28-KEY_ROTATE[i])); r = (r &lt;&lt; KEY_ROTATE[i]) | (r &gt;&gt;&gt; (28-KEY_ROTATE[i])); //拼接密钥 long temp = ((l &amp; 0xfffffffL) &lt;&lt; 28) | (r &amp; 0xfffffffL); //从56位密钥中选择48位 encryptKeys[i] = permute(PC2,temp,56); //解密密钥组是加密密钥组的倒序 decryptKeys[15-i] = encryptKeys[i]; &#125;&#125; 轮次操作详细代码如下，关键步骤见注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private byte[] des(byte[] bytes,long[] subkeys)&#123; long msg = bytesToLong(bytes); //将64位明文块用long类型表示 long IPResult = permute(IP,msg,64); //初始置换 //明文块分为左右两部分 int l = (int) (IPResult &gt;&gt;&gt; 32); int r = (int) (IPResult &amp; 0xffffffff); int temp = 0; for (int i = 0;i&lt;16;i++)&#123; temp = r; //暂存右半部分，作为下一轮的左半部分输入 r = l ^ f(r, subkeys[i]); //左半部分和右半部分经费斯妥函数运算后异或 l = temp; //新一轮的左半部分为该轮输入的右半部分 &#125; //最终置换，注意由于最后一轮不需要左右交换， //而我们上面代码进行了左右交换，所以这里要在进行一次左右交换 long FPResult = permute(FP,((r &amp; 0xffffffffL) &lt;&lt; 32) | (l &amp; 0xffffffffL),64); //将long类型转换为64位字节数组 return longTobytes(FPResult);&#125;//费斯妥函数private int f(int src, long subkey) &#123; //32位扩展为48位 long rExpand = permute(EXPAND,src&amp;0xffffffffL,32); //与子密钥异或 long sIn = rExpand ^ subkey; //s盒置换 long sOut = sBox(sIn); //P盒置换 int pResult = (int) permute(P,sOut,32); return pResult;&#125;//S盒置换private long sBox(long sIn) &#123; long result = 0; int r = 0,c = 0; for (int i = 0; i&lt; 8;i++)&#123; //取低6位 byte input = (byte) (sIn &amp; 0x3f); //取6位输入的首位两位计算行数 r = ((input &amp; 0x20)&gt;&gt;&gt;4) | (input &amp;0x1); //取6位输入的中间4位计算列数 c = (input &amp; 0x1e) &gt;&gt;&gt; 1; //生成的4位输出进行适当移位 result |= (S[7-i][r][c] &amp; 0xffL) &lt;&lt; (i*4); //输出右移6位，一般下一次循环取低6位 sIn &gt;&gt;&gt;= 6; &#125; return result;&#125; 测试与验证1234567public static void main(String[] args) throws Exception &#123; MyDES myDES = new MyDES("12345678".getBytes()); byte[] enc = myDES.encrypt("abcdefgh".getBytes()); System.out.println(byteToHexString(enc)); byte[] dec = myDES.decrypt(enc); System.out.println(new String(dec));&#125; 上面加密结果转为16进制字符串之后为94d4436bc3b5b693，与网上在线加密（注意比对时要选择ECB模式，而且大多数都会默认填充，即使明文已经达到了64位，所以要将网上结果去除尾部16个十六进制字符）测试结果一致，解密也可以正常得出原文。 题图来自unsplash：https://unsplash.com/photos/E7PlRr9ZfoM]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分组密码中的算法模式]]></title>
    <url>%2F2019%2F03%2F24%2F%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E4%B8%AD%E7%9A%84%E7%AE%97%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[算法模式是块加密中一系列步骤中基本，同一种加密方法采用不同的模式会产生不同的密文，安全性也不尽相同 电子密码薄（ECB）模式这是块加密中最简单的模式，如定义每块为64位，则将明文每64位分一组，之后对每组使用相同的秘钥和加密算法进行单独加密。解密时也是按64位分组，用同样的秘钥和加密方法进行解密即可。这种方法只适合于短消息，因为如果有重复信息，密文也会产生重复，易被攻击。加解密示意图如下： 加密块链接（CBC）模式这种模式的特点是对前一个块加密的结果会影响当前块的加密，确保了每条消息的唯一性。基本过程如下： 首先随机出一个与分组等长的初始文本块，然后用该文本块和第一个要加密的块做异或运算，并对运算结果进行加密 加密第二个块时，用第一个块加密之后的密文与第二个块进行异或运算，并对运算结果使用和第一块相同的算法和秘钥进行加密 依次类推，关键点是，在加密前使用上一块的密文与当前块做异或运算，之后再加密 可以抽象为下面数学表达(Ek表示加密函数，Ci表示明文的第几块)： 示意图如下： 对于解密，首先要了解一下异或运算的一个重要性质，就是连用两次异或后能恢复原值，即 A = A XOR B XOR B。由于这个性质异或就天然的有隐藏和还原信息的功能，所以解密算法如下 首先对密文块1进行解密，解密后再和加密时使用的初始文本块做异或运算就得到了原文. 对其他密文块也是一样，先解密，再与前一个密文块做异或，就得到原文 可以抽象为下面数学表达(Dk表示解密函数，Ci表示明文的第几块)： 示意图如下： 这种模式虽然很好的隐藏了信息，但是由于加密时都要依赖前面的信息，所以只能串行加密。不能并行运算。但是解密时可以并行运算 加密反馈（CFB）模式首先并不是所有程序都能处理数据库，如一个输入系统，需要以安全方式在信道中立即传输信息，这就要求数据用更小的单元进行加密（如8位，以byte长度）。所以出现了CFB模式。基本流程如下： 首先也需要一个64位的初始化向量，并将其放在移位寄存器中，并对该初始化向量进行加密，得到64位的初始密文 将加密过的初始化向量前j位和明文前j为进行异或，作为密文输出 将寄存器中的初始化向量左移j位，并将刚才加密的j位拼接到初始化向量尾部 然后重复上面步骤，即再对寄存器中的新初始化向量加密，随后再加密明文前j位，再进行左移个补充操作，最后再循环 示意图如下： 解密也很简单，由于明文是和移位寄存器中加密过的内容做异或后得到的密文，所以根据异或的性质，只需把密文和移位寄存器（初始内容还是加密时选定初始内容）中加密过的内容再做一次异或就得到明文（注意解密之后，寄存器中内容也要同步移位）示意图如下： 这种模式虽然和CBC很像，但是有一个优点，就是明文是不需要填充为分组的整数倍数长度的，明文和密文有相等长度，且较为灵活。 输出反馈（OFB）模式这种模式和CFB模型类似，但是没有CFB那么复杂，直接看一下示意图比较清晰： 可见主要区别是移位寄存器中的内容不再受密文的影响，而是每次独立进行加密。这样做的一大好处是某一位出错后，仅影响该位的密文，而和后面无关，前面CBC和CFB每次加密都会用到前面的信息，某一位出错将会影响后面所有输出。 解密过程也就相对较简单，将密文和初始向量加密后的信息做异或处理即可，随后也同步更新移位寄存器中内容。示意图如下 计数器(CTR)模式这种模式也被成为ICM(Integer Counter Mode)或SIC模式(Segmented Integer Counter) 这种模式类似于OFB模式，只不过将寄存器中的值换做一个计数器，计数器在任意时间产生不同的输出，之后对该输出进行加密，并用加密过的结果和明文异或，得到的结果作为密文。示意图（注意图中计数器的输出采用的是一个初始化向量和整数拼接的方式）如下： 解密方法和OFB类似，不在赘述，直接看示意图 这种方式的一大特点是可以并行加密，由于不同块的计数器输出是可以事先预测的，所以可以实现并行加密。 题图来自unsplash: https://unsplash.com/photos/pdRsf77OBoo]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protobuf学习及编码深入]]></title>
    <url>%2F2019%2F03%2F22%2FProtobuf%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%BC%96%E7%A0%81%E6%B7%B1%E5%85%A5%2F</url>
    <content type="text"><![CDATA[简介按照官方的介绍，Protocol buffers是一种与具体平台或者编程语言无关的可扩展的序列化语言，类似于XML或者JSON，由其对比XML而言，具有更小更快更简单的特点。接下来我们就来了解一下这个东西。 简单使用一般而言，使用步骤有三步。首先定义Protobuf模板文件，以.proto为后缀；然后生成特定语言的接口代码；最后利用接口代码进行序列化或者反序列操作。整体步骤和我们利用一些第三方库如Gson去操作json文件类似，下面就具体看一下这几个过程： 定义Protobuf文件下面这个例子是官方文档给出，定义了一个地址簿的数据结构：12345678910111213141516syntax = &quot;proto2&quot;;package tutorial;option java_package = &quot;code.protobuf&quot;;option java_outer_classname = &quot;AddressBookProtos&quot;;message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3;&#125;message AddressBook &#123; repeated Person people = 1;&#125; 具体语法我们稍后再介绍，首先可以看到，Protobuf文件的格式很像一些面向对象语言中类的定义，上面例子一个message就像一个类定义，类之间可以嵌套。AddressBook中有Person对象，Person中又有PhoneNumber对象。Person中也有一些基本类型如string和int。用过Gson之类的库解析json的应该感觉这和解析json时定义的类很像。 编译写好Protobuf文件后，就相当于写好一个模板文件，在不同平台或者不同语言间交互时都以这个文件为标准，但是还不能直接，根据具体的编程语言，我们还要有接口文件，我们可以利用官方给的编译工具生成我们需要的接口代码，以java语言为例：1protoc --java_out=src\ src\code\protobuf\addressbook.proto –java_out表示生成的接口文件路径，由于我们在Protobuf文件文件中定义了java_package，所以只需指定包所在目录即可，生成的文件会自动放在具体包下，最后指定Protobuf文件具体路径。生成的文件名在Protobuf文件中java_outer_classname字段定义。 接口操作执行完命令后，在code.protobuf包下生成了AddressBookProtos.java文件(要使用这个代码还需要导入相关库)。代码还是很长的，我们仅仅定义了一个简单的地址簿数据结构，就生成了近2000行代码，但是对于我们所使用的接口而言，生成的这个代码其实就是一个JavaBean类，它使用了建造者模式，当我们要构造一个Person对象时，如下：12345678AddressBookProtos.Person john = AddressBookProtos.Person.newBuilder().setId(1234) .setName("John") .setEmail("john@163.com") .addPhones(AddressBookProtos.Person.PhoneNumber.newBuilder() .setNumber("15463") .setType(AddressBookProtos.Person.PhoneType.HOME) .build()) .build(); 除了常用的get与set方法，还提供了：toString()方法用于转为有意义的字符串形式；isInitialized()方法用于检测所有必需字段是否设置；clear()方法用于清空所有字段；mergeFrom(Message other)用于合并两个对象。 当然作为序列化工具，生成的对象也提供了序列化和反序列化相关的方法：toByteArray()和parseFrom(byte[] data)。另外还可以直接操作流：writeTo(OutputStream output)和parseFrom(InputStream input)。 简单示例这里演示一个简单的跨语言的传输数据的例子。使用Go语言编写服务端，java编写客户端，从客户端向服务端发送数据。protobuf文件还使用上面的例子，这里在使用编译工具编译go语言的接口文件，protobuf文件不用做任何修改：1protoc --go_out=.\ src\code\protobuf\addressbook.proto java的客户端代码如下：123456789101112131415161718public static void main(String[] args) &#123; AddressBookProtos.Person person = AddressBookProtos.Person.newBuilder() .setName("jack") .setId(1) .setEmail("jack@163.com") .build(); AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .addPeople(person) .build(); try (Socket socket = new Socket("127.0.0.1",1234))&#123; OutputStream out = socket.getOutputStream(); out.write(book.toByteArray()); socket.shutdownOutput(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; go的服务端代码如下12345678910111213141516171819func main() &#123; listener,err:=net.Listen("tcp",":1234") if err!=nil&#123; log.Fatalln("Listen：",err.Error()) &#125; con,err:=listener.Accept() if err!=nil&#123; log.Fatalln("Accept：",err.Error()) &#125; result,err:=ioutil.ReadAll(con) if err!=nil&#123; log.Fatalln("ReadAll：",err.Error()) &#125; book := &amp;tutorial.AddressBook&#123;&#125; if err := proto.Unmarshal(result, book); err != nil &#123; log.Fatalln("Failed to parse address book:", err) &#125; fmt.Println(*book.People[0].Email)&#125; 详细语法首先在文件第一行在指定语法版本，如：syntax = “proto2”; 基本字段类型message中每个字段都要指定数据类型。如下表： 分配字段编号如例子中所示，每个字段都要分配一个独一无二编号，编号范围在1~536,870,911，主要是为了标记字段，并且不能改变，需要注意的是19000到19999是不能使用的。关于编号，官方文档建议，对于频繁使用的元素应当使用1到15的编号，因为这些序号被编码为1byte，而16到2047被编码为2byte。 字段约束有以下几个修饰词:123required：使用时必须被指定的字段optional：可以不被指定，但是最多只能指定一个repeated：可以出现次的，也可以不出现，相当于数组的概念。官方建议使用[packed=true]选项提高编码效率：repeated int32 samples = 4 [packed=true]; 了解完字段类型，编号，约束词以后，我们可以得到message中一个字段的完整定义:12字段约束 类型 名称 = 字段编号;required string query = 1; 注释类似于java等语言的注释风格：使用// 或/**/ 保留字对于以删除的字段，若是后面再被使用，可能会导致问题，所以可以用reserved标记出来，若被使用编译器将报错。reserved使用方法如下：1234message Foo &#123; reserved 2, 15, 9 to 11; reserved &quot;foo&quot;, &quot;bar&quot;;&#125; 注意字段和编号不能混合在一起用reserved标记 可选字段的默认值对于optional修饰的字段，若未定义，会有一个与字段类型对应的默认值，如string为空，bool为false等，我们也可以指定默认值如下所示：1optional int32 result_per_page = 3 [default = 10]; 枚举类型定义如下：123456789enum Corpus &#123; UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; &#125; 在一个枚举中，可以指定一些相同值的成员，这样会被解析为别名，同时需要加上option allow_alias = true123456enum EnumAllowingAlias &#123; option allow_alias = true; UNKNOWN = 0; STARTED = 1; RUNNING = 1;&#125; 若在一个message中使用另一个message的enum可以以MessageType.EnumType的形式调用 导包protobuf也有导包的概念，如果要从一个proto文件中引用另一个proto文件中的一个message，需要使用import关键字进行导包。注意在编译时使用-I指定搜索包的路径，否则只会默认搜索当前目录下的文件 嵌套定义12345678message SearchResponse &#123; message Result &#123; required string url = 1; optional string title = 2; repeated string snippets = 3; &#125; repeated Result result = 1;&#125; 上面例子在一个message中定义了另一个message，使用时利用SearchResponse.Result引用内部定义的message Extensions扩展实际上是一个占位符，它代表未在原始文件中定义的字段123message Foo &#123; extensions 100 to 199;&#125; 其他用户可以使用extensions指定的字段为原来的message添加新字段123extend Foo &#123; optional int32 bar = 126;&#125; 访问extension也有特殊的api，示例：123456789101112//序列化AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .setExtension(AddressBookProtos.bar,10) .build();byte[] out = book.toByteArray();//反序列化ExtensionRegistry registry = ExtensionRegistry.newInstance();registry.add(AddressBookProtos.bar);AddressBookProtos.AddressBook ob = AddressBookProtos.AddressBook.parseFrom(out,registry);System.out.println(ob.hasExtension(AddressBookProtos.bar)); 注意在反序列化时候要注册需要解析的extension，并作为参数传入parseFrom Oneofoneof的出现是为了实现这样的需求：一个message中有多个成员，但同一时间只能有一个成员被赋值。12345oneof test&#123; string a = 4; string b = 5; string c = 6; &#125; 1234567891011121314AddressBookProtos.Person p2 = AddressBookProtos.Person.newBuilder() .setName("tom") .setId(2) .setEmail("tom@163.com") .setA("hello") .setB("world") .build();AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .addPeople(p2) .build(); byte[] out = book.toByteArray();AddressBookProtos.AddressBook ob = AddressBookProtos.AddressBook.parseFrom(out);System.out.println(ob.getPeople(0).hasA());System.out.println(ob.getPeople(0).hasB()); 可见我们虽然同时对A，B都进行了赋值，但是只有B被赋值成功，也就是同时只有一个成员可以被赋值需要有以下几点注意： 对一个成员赋值，会自动清除其他已赋值的成员 extension不支持oneof oneof不能被修饰为repeated 实际上对于oneof修饰的一组成员，完全可以把它们当做普通的optional成员看待，只不过这几个成员之间又互相依赖关系 另外，oneof： 安全的移除或添加字段，但会可能会导致数据丢失 可以删除一个oneof，也可能会导致数据丢失 可以分割或合并oneof，效果类似移除或添加字段 maps一般意义上的映射数据类型。1map&lt;string, Project&gt; projects = 3; key可以使任何整数或string（也就是浮点和字节类型除外），枚举也不能做为key。value可以是除map外的任何类型。注意事项： extension不支持map map不能有repeated, optional, 或 required修饰 map是无序的 map等效于下面的实现：123456message MapFieldEntry &#123; optional key_type key = 1; optional value_type value = 2;&#125;repeated MapFieldEntry map_field = N; Message更新更新需要遵循以下规则 不要改变已有字段的编号 新字段只能使用optional或repeated修饰。这样也很好理解，旧的代码序列化的数据仍然可以被新代码解析，否则会由于缺少required而报错 非required修饰的字段可以被移除，但是注意被删除的字段所使用的编号不能再次使用 只要类型或者编号不便，非required字段可以转为extension int32, uint32, int64, uint64 和 bool 是可以互相兼容的，也就是可以互相转换 sint32和sint64彼此兼容，但不和其他整数类型兼容 string和bytes互相兼容，前提是使用UTF-8编码 fixed32和sfixed32、fixed64、sfixed64是兼容的 optional与repeated是兼容的，若输入的是repeated，在解析为optional时，以最后一个输入为主，或合并输入 可以改变默认值，但要注意不同版本的protobuf文件的默认不同时会在带来潜在的冲突 enum 和 int32, uint32, int64, uint64是兼容的 将optional改为oneof是安全的 packages在proto文件中指定package字段来防止名字冲突。在java中，除非指定java_package字段，否则会以package作为包名 自定义选项 java_package ：指定生成的java文件所在的包 java_outer_classname ：指定生成的java文件名 optimize_for ：优化选项，有SPEED, CODE_SIZE, 和 LITE_RUNTIME三种选择。SPEED是默认选项，对代码进行优化。CODE_SIZE可以减小生成代码量，但解析速度会下降，LITE_RUNTIME生成的代码最少，但会失去一些特性4.deprecated：被标记为true的字段表示不再使用：optional int32 old_field = 6 [deprecated=true]; proto3语法proto3的语法和2有很多相似之处，所以这里只介绍一些不同点 版本号当然版本号要更改为proto31syntax = &quot;proto3&quot;; 修饰词移除了required修饰词；所有字段默认都是singular，也就是原来的optional，但是不能显式的指定为singularrepeated被保留了 正常情况下一个message书写如下：1234567syntax = &quot;proto3&quot;;message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3;&#125; 默认值取消了default选项，也就是说默认值只能有系统默认指定，如字符串为空串，bool型为false，数字为0等。还有对于枚举类，默认是编号为0的成员。 枚举类型必须有一个编号为0的成员来作为其第一个成员。 未知字段在3.5版本之前，不能被解析的字段会被直接抛弃，但是在3.5版本之后，这种特性又回归到proto2上，即不能被解析的字段仍然会保留到下次序列化的输出中 any用于替代extensions，不过尚在开发中 编码Varints规则protobuf的编码基础是Varints，它是将整数序列化为一个或多个byte的方法。 Varints规则是用每byte的第7位存储值，第8位为标志位，若标志位为1，表示后面还有数据，若为0，表示该byte为最后一个。最后Varints采用小端存储。下面举一个例子：123456以整数300为例，300的二进制表示如下： 100101100按小端存储并每7位一组： 0101100 0000010再加上标志位，最终表示如下： 10101100 00000010 Varints的优点是，由于标志位存在，省去了编码长度的表示，其次越小的数编码越短，但是由于标志位的存在，也牺牲了容量，如4byte实际可用表示数值的只有28位 基本编码规则我们首先看一下message中每个成员变量的定义1int32 a = 1; 有三部分组成，变量类型，变量名和变量序号。其中变量名只是为了帮助我们做识别，在编码时不会写入，仅仅用变量序号作为标识，所以也就有了在更新message时序号不能复用的规则，以及可以安全地添加新成员（没有被识别的会直接跳过）。 在编码中，成员变量是以键值对形式出现的，键有两部分组成：成员序号加上成员类型代码，具体代码如下 总共有6种代码，其中group使用的两个代码已被弃用，但是依旧保留。这6个代码需要3位二进制表示，所以键的组成是：字段编号+类型代码（加好表示拼接，并不是运算），示例如下：123456789当我们有一个inst32类型的成员a，编号为1，被赋值为150时由于是int32类型，根据上图采用varint规则，首先对150进行Varints规则编码（过程略）： 10010110 00000001由于是int32类型，类型代码为0，编号为1，类型代码采用三位二进制表示为000，二者拼接之后如下： 0001000所以a的最终编码为 0001000 10010110 00000001改用16进制表示如下 08 96 01 其他类型规则sint32, sint64对于Varints规则不适用与存储负数，负数最高位为1，造成编码极大的浪费，为了节省空间，引入了ZigZag编码格式，基本思想就是将有符号整数转为无符号整数。转换规则如下：12(n &lt;&lt; 1) ^ (n &gt;&gt; 31) #sint32(n &lt;&lt; 1) ^ (n &gt;&gt; 63) #sint64 示例如下： 转为无符号的整数后，再用varints编码即可。 64-bit 和 32-bit 类型这两种分有不同的类型代码，而且编码时不进行其他转换，直接以64位或32位原始存储（注意也是小端存储），读取时根据类型代码直接读取64位或32位 Strings类型代码2表示一类Length-delimited数据。这种编码类型还附带有长度信息，就是在键值之间附加一个用varints编码的长度编码，例子如下：123456789我们有一个string类型的变量b，编号为2，赋值为testing首先testing的utf-8编码如下： 74 65 73 74 69 6e 67长度为7，varints格式编码如下： 00000111编号加类型代码拼接后如下： 00010010最后组合在一起用十六进制表示如下： 12 07 74 65 73 74 69 6e 67 除了表示字符串这种简单信息，还可以表示其他message，如下：123456789101112message Test3 &#123; optional Test1 c = 3;&#125;其中Test1：message Test1 &#123; optional int32 a = 1;&#125;我们对Test1中a赋值为150，上面已经计算过，最后编码为 08 96 01对于Test1类型的变量c表示如下：首先原始数据就是08 96 01，长度为3，编号为3，类型代码为2，组合起来就是 1a 03 08 96 01 packed在proto3中packed为默认的，在proto2中需要手动指定。使用proto3 模式将会使编码更加紧凑（主要针对repeated 类型）。设想，对于一个repeated类型的成员，他们有多个值时，虽然值不同，前键都是相同的，我们可以减少键的数量，如下例：12345假设有一个int32类型的变量d，序号为4，是一个repeated类型，我们赋了4个值，分别是3,270,86942.使用packed模式后，如下22 06 03 8E 02 9E A7 05注意22是编号加类型代码（为2，指packed repeated fields），06表示数据长度后面实际数据，都是varints编码，但是互有区分 顺序编解码顺序和字段顺序无关，由键值对保证即可。未知字段会写在已知字段后。]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Playfair密码]]></title>
    <url>%2F2019%2F03%2F20%2FPlayfair%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[背景这种加密方法是1854年Charles Wheatstone发明的，由Lord Playfair推广，所以命名为Playfair密码。它在一战和二战中都有使用，虽然在一战中就被破译，但是由于使用简单，可以用来保护一些敏感但不很关键的信息，即使被破译，信息也已经过时。 详细流程创建矩阵这种密码使用一个5*5的矩阵作为一个密码表，用作加密解密时的秘钥。这个矩阵由一个关键词生成，首先将关键词从左到右，从上到下填入矩阵，遇到重复元素则省略，写完之后按照字母表顺序，将未出现的字母填充到剩余位置，知道整个矩阵被填满。 如以PLAYFAIREXAMPLE为关键词，生成的矩阵如下： 你可能注意到，密码表中缺少J，由于只有25个空位，对于字母大于25的语言，可以将某两个合并，或者省去出现频率少的，这里把i和j进行了合并 加密加密之前首先将明文两两分组），对每一组分别进行以下处理 在密码表中找到每组中两个字母的位置 若果两个字母相同或组中只有一个字母，则插入一个字母，如X或Q（如果最后一个字母或者重复的字母是X，可以添加Q，替换方法可自定义） 如果两个字母在密码表的同一行，则用这两个字母右边的字母进行替换，如(I,E)替换为(R,X)。我们定义第一列是最后一列的右边 如果两个字母在密码表的同一列，则用这两个字母的下方字母进行替换，如(E,O)替换为(D,V)。我们定义第一行是最后一行的下边 如果两个字母不在同一行同一列，则用对角线上的字母进行替换，至于是行替换或列替换可以自行定义。如(M,Y)替换为(X,F)，使用的是行替换 解密解密就很简单了，基本就是加密的逆过程，还是利用密码表，如在同一行的话，用左边替换，同一列用上面的替换，在对角线上的还是不变。具体过程见后面实现。 示例如还以PLAYFAIREXAMPLE为关键词，明文为MYNAMEISTOM，加密过程如下： 生成矩阵，如上图 分组：MY NA ME IS TO MX (最后一个单独字母补X) 根据密码表替换 XF OL IX MK VK IM 最后密文为： XFOLIXMKVKIM 简单实现这里只是简单实现了Playfair密码原理，有些地方如包含标点符号，非英文字母的情况并没有处理，有兴趣的可以自行修改123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125public class PlayFair &#123; char[][] table = new char[5][5]; //密码表 PlayFair(String key)&#123; generateTable(key);//根据关键字生成密码表 &#125; private void generateTable(String key)&#123; key = key.replaceAll(" ","").toUpperCase(); char[] keys = key.toCharArray(); int count = 0; char alphabet = 'A'; ArrayList&lt;Character&gt; list = new ArrayList&lt;&gt;(); for (int i = 0;i&lt;5;i++)&#123; for (int j = 0;j&lt;5;j++)&#123; while(count &lt; keys.length &amp;&amp; list.contains(keys[count]))&#123; //寻找关键字中不重复的字母 count++; &#125; if (count &lt; keys.length)&#123; table[i][j] = keys[count]; list.add(keys[count]); count++; &#125;else&#123; while (alphabet &lt;= 'Z' &amp;&amp; (list.contains(alphabet) || alphabet == 'J'))&#123; //按顺序从字母表中填充 alphabet++; &#125; table[i][j] = alphabet; alphabet++; &#125; &#125; &#125; &#125; public String encryption(String msg)&#123; //加密算法 msg = msg.replaceAll(" ","").toUpperCase(); char[] msgs = msg.toCharArray(); StringBuffer result = new StringBuffer(); for (int i = 0;i&lt;msgs.length;i++)&#123; char a = msgs[i];//获取分组第一个字母 i++; char b; if (i&lt;msgs.length)&#123; //判读是否越界 if (msgs[i] == a)&#123; //是否重复 if (a == 'X')&#123; //若是X重复，添加Q b = 'Q'; &#125;else&#123; b = 'X'; &#125; i--; &#125;else&#123; b = msgs[i]; &#125; &#125;else&#123; //越界，就是最后只剩一个字母 if (a == 'X')&#123; //若最后一个是X，补Q b = 'Q'; &#125;else&#123; b = 'X'; &#125; &#125; int[] locA = find(a); //寻找分组第一个字母位置 int[] locB = find(b); //寻找分组第二个字母位置 if(locA[0] == locB[0])&#123; //若在同一行 a = locA[1]+1&lt;5?table[locA[0]][locA[1]+1]:table[locA[0]][0]; b = locB[1]+1&lt;5?table[locB[0]][locB[1]+1]:table[locB[0]][0]; &#125;else if(locA[1] == locB[1])&#123; //若在同一列 a = locA[0]+1&lt;5?table[locA[0]+1][locA[1]]:table[0][locA[1]]; b = locB[0]+1&lt;5?table[locB[0]+1][locB[1]]:table[0][locB[1]]; &#125;else&#123; //不在同一行同一列，行替换 a = table[locA[0]][locB[1]]; b = table[locB[0]][locA[1]]; &#125; result.append(a); result.append(b); &#125; return result.toString(); &#125; public String decrypt(String msg)&#123; //解密算法 msg = msg.replaceAll(" ","").toUpperCase(); char[] msgs = msg.toCharArray(); if (msgs.length%2!=0)&#123; //密文不是偶数个，报错 return "error: The length of ciphertext is odd"; &#125; StringBuffer result = new StringBuffer(); for (int i = 0;i&lt;msgs.length;i++)&#123; char a = msgs[i]; i++; char b = msgs[i]; int[] locA = find(a);//寻找分组第一个字母位置 int[] locB = find(b);//寻找分组第二个字母位置 if(locA[0] == locB[0])&#123; //若在同一行 a = locA[1]-1&gt;-1?table[locA[0]][locA[1]-1]:table[locA[0]][4]; b = locB[1]-1&gt;-1?table[locB[0]][locB[1]-1]:table[locB[0]][4]; &#125;else if(locA[1] == locB[1])&#123; //若在同一列 a = locA[0]-1&gt;-1?table[locA[0]-1][locA[1]]:table[4][locA[1]]; b = locB[0]-1&gt;-1?table[locB[0]-1][locB[1]]:table[4][locB[1]]; &#125;else&#123; //不在同一行同一列 a = table[locA[0]][locB[1]]; b = table[locB[0]][locA[1]]; &#125; result.append(a); result.append(b); &#125; return result.toString(); &#125; private int[] find(char c)&#123; //寻找字母在表中位置 if (c == 'J')//对于J当做I处理 c = 'I'; for (int i = 0;i&lt;5;i++)&#123; for (int j = 0;j&lt;5;j++)&#123; if (table[i][j] == c) return new int[]&#123;i,j&#125;; &#125; &#125; return new int[]&#123;-1,-1&#125;; &#125; public static void main(String[] args) &#123;//测试代码 PlayFair p = new PlayFair("PLAYFAIREXAMPLE"); String msg = p.encryption("MYNAMEISTOM"); System.out.println("ciphertext：" + msg); System.out.println("plaintext：" + p.decrypt(msg)); &#125;&#125; 小结本质上Playfair密码仍然是替换型的密码算法。与一般的替换算法相比，他的替换不固定，每个字母都有可能替换为任意一个其他字母。另外实现简单，一个不同秘钥生成不同密码表，产生不同的替换可能。但是它依然可以被破解，首先它是按照顺序读取的，密文与明文基本上一一对应，从而也暴露的密文结构；其次，密码表最后填充时是按照字母表顺序填充，可借助字母出现频率构造密码表，一旦一部分被构造出来，剩下的很容易破解；]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rlp编码学习]]></title>
    <url>%2F2019%2F03%2F19%2Frlp%E7%BC%96%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[RLP的全称是Recursive Length Prefix，是以太坊实现中普遍使用的一种序列化方法，在黄皮书的附录B中有详细的定义，我们这里也简要学习一下 源数据RLP定义了两种源数据，一种是一维的字节数组；另外一种是多维字节数组，也就是一维数组的嵌套。所有要序列化的数据类型，都要有一定的方法转为上述两种格式，转换的方法可以根据不同的实现自己定义。在黄皮书中给出了源数据的定义： RLP定义函数定义如下： 可见分别定义了两个函数，对应了上一节中的两种源数据，分别解释一下这两个函数 源数据为一维字节数组当数据为简单的一维字节数组时，有以下三种序列化规则: 当只含有一个字节时，而且这个字节又小于128，则不做任何处理，直接输出，对应上图第一种情况 当字节数组的长度小于56时，则加上一个前缀，这个前缀等于128+字节数组长度，对应上图第二种情况 若不符合上述两种情况，则加上这样两个前缀，第一个前缀等于183+字节数组长度在大端表示时的长度，第二个前缀为字节数组长度的大端表示，对应上图第三种情况（所谓大端表示就是将高位字节排放在内存的低地址端，0x1234表示为00 00 12 34，BE函数就是去除前面的零，也可以理解为实际长度） 源数据为嵌套的多维字节数组当数据为嵌套的多维数组形式时，有以下两种序列化规则： 首先对数组中每一个子元素都递归使用上一小节中的规则序列化，注意序列化时对象都要为一维字节数组，若子元素也是嵌套格式，则递归调用，之后将每个子元素序列化结果拼接起来。对于拼接后的长度： 若长度小于56，则加上这样一个前缀，这个前缀等于192+拼接后的长度，对应上图第一种情况 若长度大于等于56，则加上这样两个前缀，第一个前缀等于247+拼接后字节数组长度在大端表示时的长度，第二个前缀为拼接后的长度的大端表示，对应上图第二种情况 源数据是标量数据首先RLP只能用于处理正整数，处理是要先用BE函数处理，去掉前导0后，当做字节数组处理，如下图： 解码实际上了解到编码规则后，解码就很简单，关键就是第一个字节，这个字节标识使用哪种情况编码 当位于[0,128)区间时，对应源数据是一维字节数组的第一种情况，就是单一字节 当位于[128,184)区间时，对应源数据是一维字节数组的第二种情况，就是长度小于56的一维字节数组 当位于[184,192)区间时，对应源数据是一维字节数组的第三种情况，这时观察第二个前缀，第二个前缀长度等于第一个字节减去183，然后计算原始数据的真正长度 当位于[192,247)区间时，对于源数据是多维字节数组的第一种情况，就是拼接长度小于56，递归解析其后数据 当位于[247,256)区间时，对于源数据是多维字节数组的第二种情况，类似于第三条规则，先实际计算出第二个前缀的长度，在解析数原始数据长度，在递归解析出原始数据 源码解析源码主要集中在go-ethereum\rlp目录下，再去除一些测试代码，实际功能代码并不多，关键如下：1234decode.go //解码器，就是反序列化encode.go //编码器，就是序列化raw.go //未解码的RLP数据typecache.go //类型缓存， 类型缓存记录了类型-&gt;(编码器|解码器)的内容。 typecache由于go-ethereum是用go语言实现的，而go语言没有方法重载，所以对于不同类型的数据要手动指定需要的编解码器。这个类主要功能是给我们返回一个typeinfo类型的对象，这个对象保存在对应数据类型的编解码方法1234type typeinfo struct &#123; decoder writer&#125; 去创建一个typeinfo需要从cachedTypeInfo方法开始：1234567891011121314151617181920212223242526272829303132333435363738// go-ethereum\rlp\typecache.gofunc cachedTypeInfo(typ reflect.Type, tags tags) (*typeinfo, error) &#123; typeCacheMutex.RLock() info := typeCache[typekey&#123;typ, tags&#125;] //尝试从缓存中国区 typeCacheMutex.RUnlock() if info != nil &#123; //获取成功 return info, nil &#125; typeCacheMutex.Lock() //加锁，避免多线程多次创建 defer typeCacheMutex.Unlock() return cachedTypeInfo1(typ, tags)&#125;func cachedTypeInfo1(typ reflect.Type, tags tags) (*typeinfo, error) &#123; key := typekey&#123;typ, tags&#125; info := typeCache[key]//再次尝试获取，确保只创建一次 if info != nil &#123; //获取成功 return info, nil &#125; typeCache[key] = new(typeinfo) //创建一个空对象 info, err := genTypeInfo(typ, tags) //实际创建对象 if err != nil &#123; //创建失败 delete(typeCache, key) return nil, err &#125; *typeCache[key] = *info //存储到map中 return typeCache[key], err&#125;func genTypeInfo(typ reflect.Type, tags tags) (info *typeinfo, err error) &#123; info = new(typeinfo) if info.decoder, err = makeDecoder(typ, tags); err != nil &#123; return nil, err &#125; if info.writer, err = makeWriter(typ, tags); err != nil &#123; return nil, err &#125; return info, nil&#125; 可见对每种类型，都是单例模式。上述代码中实际创建编解码器的方法是makeDecoder和makeWriter。这两个方法详见下文 encode对于编码器的使用，一般调用Encode函数：123456789101112func Encode(w io.Writer, val interface&#123;&#125;) error &#123; if outer, ok := w.(*encbuf); ok &#123;//判断是否是encbuf类型的writer return outer.encode(val) &#125; eb := encbufPool.Get().(*encbuf) //从并发变量池中获取一个encbuf对象 defer encbufPool.Put(eb) eb.reset() //清空原有数据 if err := eb.encode(val); err != nil &#123; //编码 return err &#125; return eb.toWriter(w)&#125; 编码的核心操作在encbuf的encode方法：12345678func (w *encbuf) encode(val interface&#123;&#125;) error &#123; rval := reflect.ValueOf(val) ti, err := cachedTypeInfo(rval.Type(), tags&#123;&#125;) if err != nil &#123; return err &#125; return ti.writer(rval, w)&#125; 这里就接上了上一节typecache中的方法，这里通过makeWriter确定编码器1234567891011121314151617181920212223242526272829303132333435func makeWriter(typ reflect.Type, ts tags) (writer, error) &#123; kind := typ.Kind() switch &#123; case typ == rawValueType: return writeRawValue, nil case typ.Implements(encoderInterface): return writeEncoder, nil case kind != reflect.Ptr &amp;&amp; reflect.PtrTo(typ).Implements(encoderInterface): return writeEncoderNoPtr, nil case kind == reflect.Interface: return writeInterface, nil case typ.AssignableTo(reflect.PtrTo(bigInt)): return writeBigIntPtr, nil case typ.AssignableTo(bigInt): return writeBigIntNoPtr, nil case isUint(kind): return writeUint, nil case kind == reflect.Bool: return writeBool, nil case kind == reflect.String: return writeString, nil case kind == reflect.Slice &amp;&amp; isByte(typ.Elem()): return writeBytes, nil case kind == reflect.Array &amp;&amp; isByte(typ.Elem()): return writeByteArray, nil case kind == reflect.Slice || kind == reflect.Array: return makeSliceWriter(typ, ts) case kind == reflect.Struct: return makeStructWriter(typ) case kind == reflect.Ptr: return makePtrWriter(typ) default: return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ) &#125;&#125; 就是简单的根据不同的类型创建不同的编码方法，以string为例：1234567891011121314151617181920func writeString(val reflect.Value, w *encbuf) error &#123; s := val.String() if len(s) == 1 &amp;&amp; s[0] &lt;= 0x7f &#123;//只有一个字符，且小于128 w.str = append(w.str, s[0]) &#125; else &#123; w.encodeStringHeader(len(s))//添加前缀 w.str = append(w.str, s...) &#125; return nil&#125;func (w *encbuf) encodeStringHeader(size int) &#123; if size &lt; 56 &#123; //长度小于56 w.str = append(w.str, 0x80+byte(size))//前缀是128+长度 &#125; else &#123; //其他情况 sizesize := putint(w.sizebuf[1:], uint64(size)) //将长度的大端表示写入sizebuf w.sizebuf[0] = 0xB7 + byte(sizesize) //第一个前缀183+字符串长度在大端表示后的长度 w.str = append(w.str, w.sizebuf[:sizesize+1]...)//拼接第二个前缀，字符串长度的大端表示 &#125;&#125; 详细过程见注释，基本过程和RLP定义的一样。对于结构体可能有些特殊：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func makeStructWriter(typ reflect.Type) (writer, error) &#123; fields, err := structFields(typ) //分析结构体每个字段，根据情况指定每个字段的编码方法 if err != nil &#123; return nil, err &#125; writer := func(val reflect.Value, w *encbuf) error &#123; //编码器具体方法 lh := w.list() for _, f := range fields &#123; if err := f.info.writer(val.Field(f.index), w); err != nil &#123; return err &#125; &#125; w.listEnd(lh) return nil &#125; return writer, nil&#125;// go-ethereum\rlp\typecache.gofunc structFields(typ reflect.Type) (fields []field, err error) &#123; for i := 0; i &lt; typ.NumField(); i++ &#123; if f := typ.Field(i); f.PkgPath == "" &#123; // 若果是可导出的，也就是首字母大写，PkgPath为空，不可导出会返回包名 tags, err := parseStructTag(typ, i)//解析每个字段的标签，就是字段后``中定义的 if err != nil &#123; return nil, err &#125; if tags.ignored &#123; continue &#125; info, err := cachedTypeInfo1(f.Type, tags)//根据类型获取cachedTypeInfo，包含编解码器 if err != nil &#123; return nil, err &#125; fields = append(fields, field&#123;i, info&#125;) &#125; &#125; return fields, nil&#125;func parseStructTag(typ reflect.Type, fi int) (tags, error) &#123; f := typ.Field(fi) var ts tags for _, t := range strings.Split(f.Tag.Get("rlp"), ",") &#123; switch t = strings.TrimSpace(t); t &#123; case "": case "-": ts.ignored = true case "nil": ts.nilOK = true case "tail": ts.tail = true if fi != typ.NumField()-1 &#123; return ts, fmt.Errorf(`rlp: invalid struct tag "tail" for %v.%s (must be on last field)`, typ, f.Name) &#125; if f.Type.Kind() != reflect.Slice &#123; return ts, fmt.Errorf(`rlp: invalid struct tag "tail" for %v.%s (field type is not slice)`, typ, f.Name) &#125; default: return ts, fmt.Errorf("rlp: unknown struct tag %q on %v.%s", t, typ, f.Name) &#125; &#125; return ts, nil&#125; 结构体类型的虽然复杂，但也是具体到每个字段执行不同的序列化方法，最后进行拼接。 decode对于解码器一般调用Decode函数：1234567891011121314151617181920212223242526func Decode(r io.Reader, val interface&#123;&#125;) error &#123; return NewStream(r, 0).Decode(val)&#125;func (s *Stream) Decode(val interface&#123;&#125;) error &#123; if val == nil &#123; return errDecodeIntoNil &#125; rval := reflect.ValueOf(val) rtyp := rval.Type() if rtyp.Kind() != reflect.Ptr &#123; //判断是否为指针类型 return errNoPointer &#125; if rval.IsNil() &#123; return errDecodeIntoNil &#125; info, err := cachedTypeInfo(rtyp.Elem(), tags&#123;&#125;) //获取编解码方法 if err != nil &#123; return err &#125; err = info.decoder(s, rval.Elem())//解码 if decErr, ok := err.(*decodeError); ok &amp;&amp; len(decErr.ctx) &gt; 0 &#123; decErr.ctx = append(decErr.ctx, fmt.Sprint("(", rtyp.Elem(), ")")) &#125; return err&#125; 注意decode的逻辑是从Stream中获取源数据，最后解析到val中，所以需要val是一个指针类型，接下来又回到typecache中，通过判断val的类型获取所需的解码器。12345678910111213141516171819202122232425262728293031323334func makeDecoder(typ reflect.Type, tags tags) (dec decoder, err error) &#123; kind := typ.Kind() switch &#123; case typ == rawValueType: return decodeRawValue, nil case typ.Implements(decoderInterface): return decodeDecoder, nil case kind != reflect.Ptr &amp;&amp; reflect.PtrTo(typ).Implements(decoderInterface): return decodeDecoderNoPtr, nil case typ.AssignableTo(reflect.PtrTo(bigInt)): return decodeBigInt, nil case typ.AssignableTo(bigInt): return decodeBigIntNoPtr, nil case isUint(kind): return decodeUint, nil case kind == reflect.Bool: return decodeBool, nil case kind == reflect.String: return decodeString, nil case kind == reflect.Slice || kind == reflect.Array: return makeListDecoder(typ, tags) case kind == reflect.Struct: return makeStructDecoder(typ) case kind == reflect.Ptr: if tags.nilOK &#123; return makeOptionalPtrDecoder(typ) &#125; return makePtrDecoder(typ) case kind == reflect.Interface: return decodeInterface, nil default: return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ) &#125;&#125; 以string为例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192func decodeString(s *Stream, val reflect.Value) error &#123; b, err := s.Bytes() if err != nil &#123; return wrapStreamError(err, val.Type()) &#125; val.SetString(string(b)) //还原为string return nil&#125;func (s *Stream) Bytes() ([]byte, error) &#123; kind, size, err := s.Kind() if err != nil &#123; return nil, err &#125; switch kind &#123; case Byte: s.kind = -1 return []byte&#123;s.byteval&#125;, nil case String: b := make([]byte, size) //根据数据长度指定byte数组 if err = s.readFull(b); err != nil &#123; //读取原始数据 return nil, err &#125; if size == 1 &amp;&amp; b[0] &lt; 128 &#123; return nil, ErrCanonSize &#125; return b, nil default: return nil, ErrExpectedString &#125;&#125;func (s *Stream) Kind() (kind Kind, size uint64, err error) &#123; var tos *listpos if len(s.stack) &gt; 0 &#123; tos = &amp;s.stack[len(s.stack)-1] &#125; if s.kind &lt; 0 &#123; s.kinderr = nil if tos != nil &amp;&amp; tos.pos == tos.size &#123; return 0, 0, EOL &#125; s.kind, s.size, s.kinderr = s.readKind() //读取原始数据类型以及长度 if s.kinderr == nil &#123; if tos == nil &#123; if s.limited &amp;&amp; s.size &gt; s.remaining &#123; s.kinderr = ErrValueTooLarge &#125; &#125; else &#123; if s.size &gt; tos.size-tos.pos &#123; s.kinderr = ErrElemTooLarge &#125; &#125; &#125; &#125; return s.kind, s.size, s.kinderr&#125;func (s *Stream) readKind() (kind Kind, size uint64, err error) &#123; b, err := s.readByte() //读第一个byte if err != nil &#123; if len(s.stack) == 0 &#123; switch err &#123; case io.ErrUnexpectedEOF: err = io.EOF case ErrValueTooLarge: err = io.EOF &#125; &#125; return 0, 0, err &#125; s.byteval = 0 switch &#123; //根据第一字节的只判断原始数据类型 case b &lt; 0x80: //原始数据只有一个byte，且小于128 s.byteval = b return Byte, 0, nil case b &lt; 0xB8: //原始数据长度小于56 //返回的第二个数据获得原始数据长度 return String, uint64(b - 0x80), nil case b &lt; 0xC0: size, err = s.readUint(b - 0xB7) if err == nil &amp;&amp; size &lt; 56 &#123; err = ErrCanonSize &#125; return String, size, err case b &lt; 0xF8: return List, uint64(b - 0xC0), nil default: size, err = s.readUint(b - 0xF7) if err == nil &amp;&amp; size &lt; 56 &#123; err = ErrCanonSize &#125; return List, size, err &#125;&#125; 可见流程就是rlp编码的逆向过程，和我们之前讲的解码方法一样，关键是通过第一个字节获取原始数据的类型，然后推算出原始数据的长度，最后解析即可 小结最后，go-ethereum源码中rlp实现部分还是很完整的，并且没有什么其他依赖，都使用的是go标准包，所以可以单独拿出来做一个库，以后遇到需要用rlp编码的地方，可以直接拿来使用。还有这一部分源码大量的使用了反射，对于学习go语言反射也是很好的一个素材]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言signal包使用指南]]></title>
    <url>%2F2019%2F02%2F27%2FGo%E8%AF%AD%E8%A8%80signal%E5%8C%85%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[go语言学习笔记：signal包 os/signal主要用于实现对信号的处理(官方文档) 信号类型首先关于linux信号机制课自行查找资料，这里不再赘述。linux中的全部信号如下图： 在go中预定义了几种信号：1234567891011121314151617//"syscall"const ( // More invented values for signals SIGHUP = Signal(0x1) SIGINT = Signal(0x2) SIGQUIT = Signal(0x3) SIGILL = Signal(0x4) SIGTRAP = Signal(0x5) SIGABRT = Signal(0x6) SIGBUS = Signal(0x7) SIGFPE = Signal(0x8) SIGKILL = Signal(0x9) SIGSEGV = Signal(0xb) SIGPIPE = Signal(0xd) SIGALRM = Signal(0xe) SIGTERM = Signal(0xf)) 首先在这么多信号中，SIGKILL和SIGSTOP是无法被程序捕获的，其中SIGKILL就是我们常用的kill -9 pid方法锁触发的。其次一些有程序执行中的错误所触发的同步信号如SIGBUS，SIGFPE和SIGSEGV，go会将其转为panic，不过若是我们通过kill方式触发也是可以被捕获的。 除了那些同步信号，其余都是异步信号，是由内核或其他程序发送的，我们都可以捕获。 在异步信号中，当程序丢失终端时收到SIGHUP，在终端按下中断字符(一般为ctrl+c)时收到SIGINT，在终端按下退出字符(一般为^\)时收到SIGQUIT。 正常的，信号都是有默认动作的，最常见的如按下ctrl+c退出程序。其余的SIGHUP，SIGINT或SIGTERM信号导致程序退出。SIGQUIT，SIGILL，SIGTRAP，SIGABRT，SIGSTKFLT，SIGEMT或SIGSYS信号导致程序以堆栈转储退出。SIGTSTP，SIGTTIN或SIGTTOU信号获取系统默认行为（shell使用这些信号进行作业控制）。SIGPROF会被go运行时捕获实现runtime.CPUProfile. 捕获信号signal包中提供了Notify方法，用于注册所要监听的信号。1func Notify(c chan&lt;- os.Signal, sig ...os.Signal) 该方法需要提供一个Signal类型的channel，以及要监听的信号(当不指定时会监听所有信号)。当有信号到来时，会被写入所传入的channel中，之后拿出来即可。下例是一个监听ctrl+c退出的程序：1234567func main() &#123; c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGINT) s := &lt;-c fmt.Println("Got signal:", s)&#125; 上述程序会在第五行阻塞，直到有一个信号过来。运行结果如下： 其余apifunc Stop(c chan&lt;- os.Signal)这个方法用于停止监听信号，之后不会再往所指定的channel中写入任何内容。搭配Notify使用如下：12345678go func() &#123; sigc := make(chan os.Signal, 1) signal.Notify(sigc, syscall.SIGINT, syscall.SIGTERM) //监听信号 defer signal.Stop(sigc) //确保关闭 &lt;-sigc //线程阻塞 log.Info("Got interrupt, shutting down...") go Stop() //执行程序停止逻辑 &#125;() func Ignore(sig …os.Signal)忽略指定的信号，同理，若是未指定，忽略所有信号 func Ignored(sig os.Signal) bool检查某个信号是否被忽略 func Reset(sig …os.Signal)重置之前调用Notify时的处理。也就是不在捕获信号，进行默认操作。注意和Ignore的区别，Ignore是不对信号做任何操作，Reset是恢复默认操作。 附录部分信号说明(图片来源于网络)：]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[geth的init流程分析]]></title>
    <url>%2F2019%2F02%2F26%2Fgeth%E7%9A%84init%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[go-ethereum源码学习：init流程 geth总览首先看一下geth这个程序的总体设计，其主要代码位于go-ethereum\cmd\geth里面，先看main.go,这是一个利用urfave/cli开发的命令行程序，关于这个库的简单介绍见这里。在开头var代码块中中实例化了cli的app对象:1234567891011121314app = utils.NewApp(gitCommit, "the go-ethereum command line interface")func NewApp(gitCommit, usage string) *cli.App &#123; app := cli.NewApp() app.Name = filepath.Base(os.Args[0]) app.Author = "" //app.Authors = nil app.Email = "" app.Version = params.VersionWithMeta //见go-ethereum\params\version.go 生成版本号 if len(gitCommit) &gt;= 8 &#123; app.Version += "-" + gitCommit[:8] //gitCommit之前在编译时定义 &#125; app.Usage = usage return app&#125; 实例化之后，定义了大量flag，详细信息可以输入geth -h或到官方文档查看。接下来，在init()方法中进行进一步初始化，添加了大量command及先前定义的flag。并定义了geth的action：1234567891011app.Action = gethfunc geth(ctx *cli.Context) error &#123; if args := ctx.Args(); len(args) &gt; 0 &#123; //仅执行geth时，不能有任何附加参数 return fmt.Errorf("invalid command: %q", args[0]) &#125; node := makeFullNode(ctx) //创建默认节点 defer node.Close() startNode(ctx, node) node.Wait() return nil&#125; 在init中还定义了app.Before用于初始化工作：123456789101112131415161718192021222324252627282930313233app.Before = func(ctx *cli.Context) error &#123; logdir := "" if ctx.GlobalBool(utils.DashboardEnabledFlag.Name) &#123; logdir = (&amp;node.Config&#123;DataDir: utils.MakeDataDir(ctx)&#125;).ResolvePath("logs") &#125; if err := debug.Setup(ctx, logdir); err != nil &#123; //见\go-ethereum\internal\debug\flags.go return err &#125; // Cap the cache allowance and tune the garbage collector var mem gosigar.Mem //见\go-ethereum\vendor\github.com\elastic\gosigar\sigar_interface.go //获取系统内存信息 if err := mem.Get(); err == nil &#123; //配置缓存 allowance := int(mem.Total / 1024 / 1024 / 3) if cache := ctx.GlobalInt(utils.CacheFlag.Name); cache &gt; allowance &#123; log.Warn("Sanitizing cache to Go's GC limits", "provided", cache, "updated", allowance) ctx.GlobalSet(utils.CacheFlag.Name, strconv.Itoa(allowance)) &#125; &#125; // Ensure Go's GC ignores the database cache for trigger percentage cache := ctx.GlobalInt(utils.CacheFlag.Name) gogc := math.Max(20, math.Min(100, 100/(float64(cache)/1024))) log.Debug("Sanitizing Go's GC trigger", "percent", int(gogc)) godebug.SetGCPercent(int(gogc)) //设置垃圾收集目标百分比 // Start metrics export if enabled utils.SetupMetrics(ctx) //默认是关闭的，开关在\go-ethereum\metrics\metrics.go // Start system runtime metrics collection go metrics.CollectProcessMetrics(3 * time.Second) //默认不会启动 return nil &#125; 随后也定义了app.After逻辑12345app.After = func(ctx *cli.Context) error &#123; debug.Exit() console.Stdin.Close() // 重置终端模式 return nil &#125; 接下来进入main函数123456func main() &#123; if err := app.Run(os.Args); err != nil &#123; //运行处理程序 fmt.Fprintln(os.Stderr, err) os.Exit(1) &#125;&#125; 到这里，geth大致轮廓就看完了，随后会根据用户输入的命令执行相应的逻辑。 init这是初始化函数。源码中描述如下 The init command initializes a new genesis block and definition for the network.This is a destructive action and changes the network in which you will beparticipating.It expects the genesis file as argument. 一般使用如下1geth init gen.json --datadir ./mychain/ 需要指定一个json文件，可选择指定数据存储路径。在源码定义如下：123456789101112// go-ethereum\cmd\geth\chaincmd.goinitCommand = cli.Command&#123; Action: utils.MigrateFlags(initGenesis), Name: "init", Usage: "Bootstrap and initialize a new genesis block", ArgsUsage: "&lt;genesisPath&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, &#125;, Category: "BLOCKCHAIN COMMANDS", Description: `.....`, &#125; 可见子命令名就是init，没有别名，只有一个flag，定义如下1234567// go-ethereum\cmd\utils\flags.goDataDirFlag = DirectoryFlag&#123; Name: "datadir", Usage: "Data directory for the databases and keystore", Value: DirectoryString&#123;node.DefaultDataDir()&#125;, //获取默认目录，见go-ethereum\node\defaults.go //linux下为/home/&lt;user&gt;/.ethereum &#125; DirectoryString定义如下123456789101112131415161718192021// go-ethereum\cmd\utils\customflags.gotype DirectoryString struct &#123; Value string&#125;func (self *DirectoryString) String() string &#123; return self.Value&#125;func (self *DirectoryString) Set(value string) error &#123; self.Value = expandPath(value) return nil&#125;func expandPath(p string) string &#123; if strings.HasPrefix(p, &quot;~/&quot;) || strings.HasPrefix(p, &quot;~\\&quot;) &#123; if home := homeDir(); home != &quot;&quot; &#123; p = home + p[1:] &#125; &#125; return path.Clean(os.ExpandEnv(p))&#125; DataDirFlag作用主要就是定义初始化生成数据的存储路径，之后我们看initCommand的action，这个是关键：1Action: utils.MigrateFlags(initGenesis), 调用了utils.MigrateFlags，定义如下1234567891011// \go-ethereum\cmd\utils\flags.gofunc MigrateFlags(action func(ctx *cli.Context) error) func(*cli.Context) error &#123; return func(ctx *cli.Context) error &#123; for _, name := range ctx.FlagNames() &#123; if ctx.IsSet(name) &#123; ctx.GlobalSet(name, ctx.String(name)) &#125; &#125; return action(ctx) &#125;&#125; 这个方法并没有什么实际意义，只是将所有用户指定的flag以GlobalSet的形式存了起来，主要逻辑在传递进来的action，我们这里传递的action如下：12345678910111213141516171819202122232425262728293031323334// go-ethereum\cmd\geth\chaincmd.gofunc initGenesis(ctx *cli.Context) error &#123; // Make sure we have a valid genesis JSON genesisPath := ctx.Args().First() //获取genesis.json if len(genesisPath) == 0 &#123; utils.Fatalf("Must supply path to genesis JSON file") &#125; file, err := os.Open(genesisPath) if err != nil &#123; utils.Fatalf("Failed to read genesis file: %v", err) &#125; defer file.Close() genesis := new(core.Genesis) //Genesis结构体见 go-ethereum\core\genesis.go if err := json.NewDecoder(file).Decode(genesis); err != nil &#123; //解析json文件，遇到错误就退出 utils.Fatalf("invalid genesis file: %v", err) &#125; // Open an initialise both full and light databases stack := makeFullNode(ctx) //建立默认节点 defer stack.Close() for _, name := range []string&#123;"chaindata", "lightchaindata"&#125; &#123; chaindb, err := stack.OpenDatabase(name, 0, 0) //创建数据库 if err != nil &#123; utils.Fatalf("Failed to open database: %v", err) &#125; _, hash, err := core.SetupGenesisBlock(chaindb, genesis) //写创世区块内容 if err != nil &#123; utils.Fatalf("Failed to write genesis block: %v", err) &#125; log.Info("Successfully wrote genesis state", "database", name, "hash", hash) &#125; return nil&#125; 刚开始，获取了子命令参数，也就是我们指定的genesis.json的文件，然后尝试打开并解析其中内容，任何一步出错的就终止程序，之后调用了stack := makeFullNode(ctx)，这一部分比较繁琐，实现如下1234567891011121314151617181920212223242526272829303132333435363738394041424344// go-ethereum\cmd\geth\config.gofunc makeFullNode(ctx *cli.Context) *node.Node &#123; stack, cfg := makeConfigNode(ctx) if ctx.GlobalIsSet(utils.ConstantinopleOverrideFlag.Name) &#123; cfg.Eth.ConstantinopleOverride = new(big.Int).SetUint64(ctx.GlobalUint64(utils.ConstantinopleOverrideFlag.Name)) &#125; utils.RegisterEthService(stack, &amp;cfg.Eth) //注册eth服务， eth服务是以太坊的主要的服务。是以太坊功能的提供者。 if ctx.GlobalBool(utils.DashboardEnabledFlag.Name) &#123; //默认是false utils.RegisterDashboardService(stack, &amp;cfg.Dashboard, gitCommit) &#125; // Whisper must be explicitly enabled by specifying at least 1 whisper flag or in dev mode //Whisper是一个独立模块，用来进行加密通讯的功能。 需要显式的提供参数来启用，或者是处于开发模式。 shhEnabled := enableWhisper(ctx) //自动启动的条件没有手动配置Whisper并且处于开发者模式 shhAutoEnabled := !ctx.GlobalIsSet(utils.WhisperEnabledFlag.Name) &amp;&amp; ctx.GlobalIsSet(utils.DeveloperFlag.Name) //二者满足一个就启动（注册shh服务）,一般都不满足 if shhEnabled || shhAutoEnabled &#123; if ctx.GlobalIsSet(utils.WhisperMaxMessageSizeFlag.Name) &#123; cfg.Shh.MaxMessageSize = uint32(ctx.Int(utils.WhisperMaxMessageSizeFlag.Name)) &#125; if ctx.GlobalIsSet(utils.WhisperMinPOWFlag.Name) &#123; cfg.Shh.MinimumAcceptedPOW = ctx.Float64(utils.WhisperMinPOWFlag.Name) &#125; if ctx.GlobalIsSet(utils.WhisperRestrictConnectionBetweenLightClientsFlag.Name) &#123; cfg.Shh.RestrictConnectionBetweenLightClients = true &#125; utils.RegisterShhService(stack, &amp;cfg.Shh) &#125; // Configure GraphQL if required if ctx.GlobalIsSet(utils.GraphQLEnabledFlag.Name) &#123; if err := graphql.RegisterGraphQLService(stack, cfg.Node.GraphQLEndpoint(), cfg.Node.GraphQLCors, cfg.Node.GraphQLVirtualHosts, cfg.Node.HTTPTimeouts); err != nil &#123; utils.Fatalf("Failed to register the Ethereum service: %v", err) &#125; &#125; // Add the Ethereum Stats daemon if requested. if cfg.Ethstats.URL != "" &#123; utils.RegisterEthStatsService(stack, cfg.Ethstats.URL) &#125; return stack&#125; 第一行调用了makeConfigNode，实现如下1234567891011121314151617181920212223242526272829303132333435363738// go-ethereum\cmd\geth\config.gofunc makeConfigNode(ctx *cli.Context) (*node.Node, gethConfig) &#123; // Load defaults. //加载各个模块的默认配置 cfg := gethConfig&#123; Eth: eth.DefaultConfig, // go-ethereum\eth\config.go //Ethereum主网的默认配置，如NetworkId，SyncMode等 Shh: whisper.DefaultConfig, // go-ethereum\whisper\whisperv6\config.go Node: defaultNodeConfig(), //见defaultNodeConfig()，默认节点配置 Dashboard: dashboard.DefaultConfig, //一个独立模块，见go-ethereum\dashboard\README &#125; // Load config file. //加载配置文件，一般未指定配置文件，此处为空 if file := ctx.GlobalString(configFileFlag.Name); file != "" &#123; if err := loadConfig(file, &amp;cfg); err != nil &#123; utils.Fatalf("%v", err) &#125; &#125; // Apply flags. //从flag加载配置 utils.SetULC(ctx, &amp;cfg.Eth) //ULC:Ultra Light client go-ethereum\cmd\utils\flags.go utils.SetNodeConfig(ctx, &amp;cfg.Node) stack, err := node.New(&amp;cfg.Node) //实例化node对象 go-ethereum\node\node.go //stack就是Node对象 if err != nil &#123; utils.Fatalf("Failed to create the protocol stack: %v", err) &#125; utils.SetEthConfig(ctx, stack, &amp;cfg.Eth) if ctx.GlobalIsSet(utils.EthStatsURLFlag.Name) &#123; cfg.Ethstats.URL = ctx.GlobalString(utils.EthStatsURLFlag.Name) &#125; utils.SetShhConfig(ctx, stack, &amp;cfg.Shh) utils.SetDashboardConfig(ctx, &amp;cfg.Dashboard) return stack, cfg&#125; 这个方法首先加载代码中的默认配置，之后加载配置文件配置，随后加载用户在命令行指定的配置，由于我们分析的是init流程，所以大部分配置都是默认配置，相关代码注释见这里代码注释 经过makeConfigNode之后，我们获得stack, cfg，stack是一个node对象，cfg是配置信息。回到makeFullNode，初始化node后，又调用了utils.RegisterEthService(stack, &amp;cfg.Eth)取注册eth服务，eth服务是以太坊功能的主要服务提供者：12345678910111213141516171819202122// go-ethereum\cmd\utils\flags.gofunc RegisterEthService(stack *node.Node, cfg *eth.Config) &#123; var err error //默认是FastSync if cfg.SyncMode == downloader.LightSync &#123; err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) &#123; return les.New(ctx, cfg) &#125;) &#125; else &#123; err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) &#123; fullNode, err := eth.New(ctx, cfg) if fullNode != nil &amp;&amp; cfg.LightServ &gt; 0 &#123; ls, _ := les.NewLesServer(fullNode, cfg) fullNode.AddLesServer(ls) &#125; return fullNode, err &#125;) &#125; if err != nil &#123; Fatalf("Failed to register the Ethereum service: %v", err) &#125;&#125; 我们看一下Register的实现：12345678910111213// go-ethereum\node\node.gofunc (n *Node) Register(constructor ServiceConstructor) error &#123; n.lock.Lock() //同步操作 defer n.lock.Unlock() if n.server != nil &#123; return ErrNodeRunning &#125; //将ServiceConstructor添加到serviceFuncs这个切片中,ServiceConstructor定义如下 //type ServiceConstructor func(ctx *ServiceContext) (Service, error) n.serviceFuncs = append(n.serviceFuncs, constructor) return nil&#125; 逻辑很简单，就是将要注册的东西存起来。我们再来看注册的eth服务的内容。我们分析的是init的流程，默认的同步模式是FastSync，调用eth.New(ctx, cfg)，创建了一个Ethereum对象，这里我们暂不分析创建过程，只需知道这里实例化了了一个Ethereum对象，也就是变量fullNode。在回到makeConfigNode，后面就是根据具体情况去注册各种服务，如DashboardService，ShhService等，套路和eth注册是一样的。需要注意的是，这里面除了eth服务是必须的，其他的都是可选的。最后返回stack，也就是node对象 实际上，在我们分析的流程中，initGenesis调用的makeFullNode方法都是在做初始化。回到initGenesis，makeFullNode之后有一个遍历，遍历了两个字符串：”chaindata”, “lightchaindata”。他们的用处是用来创建数据库：12345678910// go-ethereum\node\node.gochaindb, err := stack.OpenDatabase(name, 0, 0)func (n *Node) OpenDatabase(name string, cache, handles int) (ethdb.Database, error) &#123; if n.config.DataDir == "" &#123; return ethdb.NewMemDatabase(), nil //如果路径为空，创建内存数据库，实际上就是放在内存中的一个map // go-ethereum\ethdb\memory_database.go &#125; return ethdb.NewLDBDatabase(n.config.ResolvePath(name), cache, handles)&#125; 1234567891011121314151617181920212223242526272829303132333435// go-ethereum\ethdb\database.gofunc NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) &#123; logger := log.New("database", file) //从init调用过来时，cache和handles都为0 //默认启动节点，cache为512，handles为0，在node.DefaultConfig配置 // Ensure we have some minimal caching and file guarantees if cache &lt; 16 &#123; cache = 16 &#125; if handles &lt; 16 &#123; handles = 16 &#125; logger.Info("Allocated cache and file handles", "cache", common.StorageSize(cache*1024*1024), "handles", handles) // Open the db and recover any potential corruptions db, err := leveldb.OpenFile(file, &amp;opt.Options&#123; OpenFilesCacheCapacity: handles, BlockCacheCapacity: cache / 2 * opt.MiB, WriteBuffer: cache / 4 * opt.MiB, // Two of these are used internally Filter: filter.NewBloomFilter(10), &#125;) if _, corrupted := err.(*errors.ErrCorrupted); corrupted &#123; db, err = leveldb.RecoverFile(file, nil) &#125; // (Re)check for errors and abort if opening of the db failed if err != nil &#123; return nil, err &#125; return &amp;LDBDatabase&#123; fn: file, db: db, log: logger, &#125;, nil&#125; 这里使用的levelDB数据库，关于这个数据库的介绍与使用见这里。逻辑很简单就是在指定位置创建levelDB数据库。数据库创建完成后，回到initGenesis，接下来开始写内容：123456789101112131415161718192021222324252627_, hash, err := core.SetupGenesisBlock(chaindb, genesis)// go-ethereum\core\genesis.gofunc SetupGenesisBlock(db ethdb.Database, genesis *Genesis) (*params.ChainConfig, common.Hash, error) &#123; return SetupGenesisBlockWithOverride(db, genesis, nil)&#125;func SetupGenesisBlockWithOverride(db ethdb.Database, genesis *Genesis, constantinopleOverride *big.Int) (*params.ChainConfig, common.Hash, error) &#123; if genesis != nil &amp;&amp; genesis.Config == nil &#123; //如果json，没有配置config部分，则退出 return params.AllEthashProtocolChanges, common.Hash&#123;&#125;, errGenesisNoConfig &#125; // Just commit the new block if there is no stored genesis block. stored := rawdb.ReadCanonicalHash(db, 0) // go-ethereum\core\rawdb\accessors_chain.go //从数据库中获取创世区块的hash if (stored == common.Hash&#123;&#125;) &#123; //如果为空，init会进入这个分支 if genesis == nil &#123; log.Info("Writing default main-net genesis block") genesis = DefaultGenesisBlock() &#125; else &#123; log.Info("Writing custom genesis block") &#125; // 写入数据库 block, err := genesis.Commit(db) return genesis.Config, block.Hash(), err &#125; .....&#125; 首先利用rawdb.ReadCanonicalHash(db, 0)或取genesis区块，由于是初始化，自然获取不到，进入下面的if分枝，首先调用了Commit(db)：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// go-ethereum\core\genesis.gofunc (g *Genesis) Commit(db ethdb.Database) (*types.Block, error) &#123; block := g.ToBlock(db) if block.Number().Sign() != 0 &#123; return nil, fmt.Errorf("can't commit genesis block with number &gt; 0") &#125; // go-ethereum\core\rawdb\accessors_chain.go 写入各种信息 rawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty) rawdb.WriteBlock(db, block) rawdb.WriteReceipts(db, block.Hash(), block.NumberU64(), nil) rawdb.WriteCanonicalHash(db, block.Hash(), block.NumberU64()) rawdb.WriteHeadBlockHash(db, block.Hash()) rawdb.WriteHeadHeaderHash(db, block.Hash()) config := g.Config if config == nil &#123; config = params.AllEthashProtocolChanges &#125; rawdb.WriteChainConfig(db, block.Hash(), config) return block, nil&#125;func (g *Genesis) ToBlock(db ethdb.Database) *types.Block &#123; if db == nil &#123; //如果数据库为nil，建立一个内存数据库 db = ethdb.NewMemDatabase() &#125; statedb, _ := state.New(common.Hash&#123;&#125;, state.NewDatabase(db)) // go-ethereum\core\state\statedb.go // go-ethereum\core\state\database.go //state.New：根据给定的Tried创建一个新的状态() //state.NewDatabase：创建一个内存数据库 for addr, account := range g.Alloc &#123; //遍历json文件中的alloc配置 statedb.AddBalance(addr, account.Balance) statedb.SetCode(addr, account.Code) statedb.SetNonce(addr, account.Nonce) for key, value := range account.Storage &#123; statedb.SetState(addr, key, value) &#125; &#125; root := statedb.IntermediateRoot(false) head := &amp;types.Header&#123; //go-ethereum\core\types\block.go 创建区块头 Number: new(big.Int).SetUint64(g.Number), Nonce: types.EncodeNonce(g.Nonce), Time: new(big.Int).SetUint64(g.Timestamp), ParentHash: g.ParentHash, Extra: g.ExtraData, GasLimit: g.GasLimit, GasUsed: g.GasUsed, Difficulty: g.Difficulty, MixDigest: g.Mixhash, Coinbase: g.Coinbase, Root: root, &#125; if g.GasLimit == 0 &#123; head.GasLimit = params.GenesisGasLimit //默认为4712388 go-ethereum\params\protocol_params.go &#125; if g.Difficulty == nil &#123; head.Difficulty = params.GenesisDifficulty //默认为131072 &#125; statedb.Commit(false) statedb.Database().TrieDB().Commit(root, true) return types.NewBlock(head, nil, nil, nil)//创建一个新的区块 go-ethereum\core\types\block.go //每个区块有四部分内容，区块头，交易列表，叔块，收据&#125; Commit方法中首先调用了ToBlock，在这里创建了一个实例化的区块对象并返回，之后再Commit中写入各种信息到数据库中，我们以总难度为例，看它是如何写入的：1234567891011rawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty)func WriteTd(db DatabaseWriter, hash common.Hash, number uint64, td *big.Int) &#123; data, err := rlp.EncodeToBytes(td) if err != nil &#123; log.Crit("Failed to RLP encode block total difficulty", "err", err) &#125; if err := db.Put(headerTDKey(number, hash), data); err != nil &#123; log.Crit("Failed to store block total difficulty", "err", err) &#125;&#125; 首先WriteTd接收四个参数，分别是数据库的实例，区块hash，区块编号，难度值。之后将难度值进行RLP编码，然后调用db.Put()写入数据库，写入的键是headerTDKey(number, hash)，值就是编码过得数据。在commit的最后，写入所有数据后，返回了区块实例，然后回到initGenesis方法，最终返回了错误信息和区块hash。到此init的流程就结束了。创世区块的内容也被写入了数据库。]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum编译流程简单学习]]></title>
    <url>%2F2019%2F02%2F21%2Fgo-ethereum%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[go-ethereum源码学习：源码编译流程 一般，在根目录下执行make geth 或者 make all编译go-ethereum。前者仅编译go-ethereum主程序，后者编译所有模块。详见go-ethereum的README 以make geth为例，进入go-ethereum根目录下，打开Makefile文件，执行的逻辑是1234geth: build/env.sh go run build/ci.go install ./cmd/geth @echo "Done building." @echo "Run \"$(GOBIN)/geth\" to launch geth." 可见直接执行了build/env.sh脚本，传入的参数为go run build/ci.go install ./cmd/geth 进入这个脚本文件，签名若干行都是在进行目录和环境设置，只有最后一行起到编译作用1exec "$@" exec指执行后面的跟的命令，$@是一个变量，存储着传给这个脚本的所有参数，这里的参数就是上面说的go run build/ci.go install ./cmd/geth ./cmd/geth，这就是go的编译命令，他编译运行的是build/ci.go文件，顺便还传入了参数install ./cmd/geth 首先在这个文件开头，我们可以知道这也是一个CLI程序，和我们编译生成的geth类似，在开头列出了一些命令的格式，如第一行就是我们流程中将要执行的1234Available commands are: install [ -arch architecture ] [ -cc compiler ] [ packages... ] ... 我们所要执行的就是 install ./cmd/geth，没有任何附加参数。 先从main函数开始，在这里的switch结构中，判断了第一个参数，我们这里为install，执行doInstall(os.Args[2:])，传入的参数自然为./cmd/geth。doInstall这个方法也比较简单，首先，利用flag进行参数解析，然后判断了go的版本后，最后根据需求拼凑编译指令。这一部分关键步骤注释见这里]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go的CLI程序开发]]></title>
    <url>%2F2019%2F02%2F21%2Fgo%E7%9A%84CLI%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[go语言学习笔记：CLI程序开发 CLI(command-line interface)就是命令行界面，我们在linux命令行中输入的一个个指令都是CLI程序，典型如tar命令，一般使用go开发一个命令行程序有以下几种方法 Arguments这个算是最基本的方法，但也是最繁琐的。主要借助os.Args，查看源码，介绍如下 12// Args hold the command-line arguments, starting with the program name.var Args []string 这里告诉我们这个数组切片保存了命令行的参数，且第一个参数程序名。这里需要注意的一点是，就算一个参数不附加，os.Args这个数组也是有一个值的，就是当前的程序，所以我们在通过len(os.Args)判断是否有额外参数时，len(os.Args)&gt;1才能说明有额外参数 既然我们可以通过这个数组获取所有参数，那么就可以通过一系列参数判断，开发出一个命令行程序，但无疑是很繁琐的，所以go标准库中提供了一个简单的库来帮助我们 flag我们先引入一个小例子 12345func main() &#123; dir := flag.String("dir","/home/user","data directory") flag.Parse() fmt.Println(*dir)&#125; 之后再命令行输入下面命令去运行，123456789101112131415161718go run example.go 输出/home/usergo run example.go -dir /etc/opt 输出/etc/optgo run in.go -h输出：Usage of .../example.exe -dir string data directory (default &quot;/home/user&quot;) go run example.go -dirs /etc输出：flag provided but not defined: -dirsUsage of .../example.exe -dir string data directory (default &quot;/home/user&quot;) 可以看出这已经是一个比较完善的命令程序，我们指定了参数名：dir，默认值：”/home/user”，以及参数解释：”data directory”。之后flag包自动帮我们解析参数，并附带了-h帮助信息，以及未定义参数的提示信息 通过上面的例子基本可以了解flag大体使用方法，首先定义一些参数，之后flag.Parse()进行解析，最后使用解析到的数据即可，关于Parse()源码如下 123func Parse() &#123; CommandLine.Parse(os.Args[1:])&#125; 可见也是用的os.Args[1:]作为输入，只不过这个包帮我们做好了匹配及错误处理而已。接下来详细学习一下用法 flag定义基本上分三大类： flag.Xxx(name,value,usage) *Xxx Xxx表示相应的数据类型，如Bool，Float64，Int，String等等，参数都是三个：名称，默认值，用法介绍。返回值1是相应类型的一个指针变量。例子如下： 1dir := flag.String("dir","/home/user","data directory") flag.XxxVar(p,name,value,usage) Xxx也是表示相应的数据类型，和上面那个一样，区别是多了一个参数，需要传入一个变量的引用，然后解析时会把值赋给这个变量，没有返回值，例子如下 12var dir stringflag.StringVar(&amp;dir,"dir","/home/user","data directory") flag.Var(value,name,usage) 当包中预定义的数据类型不能满足要求时，就需要这个方法了，第一个参数是一个引用，其类是实现flag.Value 接口，剩下的两个参数意义和上边的一样。先看一下这个接口 1234type Value interface &#123; String() string Set(string) error&#125; 基本上就是要定义存取方法，只不过存取的值都必须是string类型，举一个简单的例子 1234567891011121314151617181920212223242526272829303132type student struct &#123; name string age int64&#125;func (s *student) String()string&#123; return s.name+string(s.age)&#125;func (s *student) Set(str string)error&#123; slice:=strings.Split(str,",") if len(slice)!=2 &#123; return errors.New("bad format") &#125; i,err:=strconv.ParseInt(slice[1],10,64) if err!=nil &#123; return err &#125; s.name = slice[0] s.age = i return nil&#125;func main() &#123; var dir student flag.Var(&amp;dir,"stu","student info") flag.Parse() fmt.Println(dir.name,"+++",dir.age)&#125;//用法//go run example.go -stu wang,21 flag格式一般形式如下： 123-flag-flag = x-flag x //仅适用于非boolean类型flag 其中-和–都是允许的 flag解析会在遇到第一个非flag参数或单独的–之后停止，例 123456func main() &#123; n := flag.Int("n",0,"number") flag.Parse() fmt.Println(*n) fmt.Println(flag.NArg())&#125; 下面的命令都会由于提前停止解析得不到所要的值 123go run example.go 45 -n 1 //flag.NArg()会返回3go run example.go - -n 1 //flag.NArg()会返回3go run example.go -- -n 1 //flag.NArg()会返回2，--被当做终止符 其他方法 Arg(i int)string ， Args()[]string ， NArg()int ， NFlag()int Arg(i int)返回的是在被flag解析后，第i个剩余的参数，没有的话返回空字符串 Args()返回的是被flag解析后，剩余参数数组切片 NArg()返回的是被flag解析后，剩余参数的个数 NFlag()返回的是接收到的flag参数个数（并不是定义的个数） 12345678910111213n := flag.Int("n",0,"number")flag.Parse()fmt.Println(n)fmt.Println(flag.Arg(1))//输入&gt;go run example.go -n 1 454 555，返回555 //输入&gt;go run example.go -n 1 454 ，返回空 fmt.Println(flag.Args())//输入&gt;go run example.go -n 1 454 555，返回[454,555]fmt.Println(flag.NArg())//输入&gt;go run example.go -n 1 454 555,返回2fmt.Println(flag.NFlag())//输入&gt;go run example.go -n 1 454 555，返回1 //输入&gt;go run example.go 454 555，返回0 flag.Parsed()bool 判断参数是否解析过 Set(name, value string) error 给指定的flag赋值 flag.Usage 库里已经帮我们自动生成了一套帮助信息，可以使用-h或-help查看，另外我们也可以自己定制，重写Usage例 123 flag.Usage = func() &#123; fmt.Println("hello world")&#125; 另外我们也可以看一下源码，原来的帮助信息是怎么生成的 1234var Usage = func() &#123; fmt.Fprintf(CommandLine.Output(), "Usage of %s:\n", os.Args[0]) PrintDefaults()&#125; 可见，先是打印了os.Args[0]，也就是程序信息，之后调用了PrintDefaults()，打印了所有flag的信息 urfave/cli其实官方给出的flag已能满足大部分要求，如果有更复杂的需要，可以借助这个强大的第三方包urfave/cli 安装与导包1go get github.com/urfave/cli 123import ( "gopkg.in/urfave/cli.v1") 简单使用该包的github主页有详细的使用说明，这里就不一一赘述了，只简单说一下常用的使用流程 实例化App对象 1app := cli.NewApp() 配置App信息 123456789101112131415161718192021222324252627282930313233343536//这个包可以配置丰富的App描述信息，如名称，版本号，作者，版权信息，程序简介等app.Name = "HelloWorld"app.Version = "1.0.0"app.Authors = []cli.Author&#123; cli.Author&#123; Name: "Tom", Email: "Tom@example.com", &#125;,&#125;app.Copyright = "(c) 1999 Serious Enterprise"app.Usage = "greet"app.UsageText = "Example program"//输入go run example.go -h后显示如下/*NAME: HelloWorld - greetUSAGE: Example programVERSION: 1.0.0AUTHOR: Tom &lt;Tom@example.com&gt;COMMANDS: help, h Shows a list of commands or help for one commandGLOBAL OPTIONS: --help, -h show help --version, -v print the versionCOPYRIGHT: (c) 1999 Serious Enterprise*/ 定义程序执行逻辑 这里是指程序运行的逻辑。主要是配置app.Action，例：12345app.Action = func(c *cli.Context) &#123; fmt.Println("hello world") &#125;//go run example.go //输出hello world 当然我们也可以不在这里定义主程序逻辑，在这里定义的一个好处是cli.Context携带了许多有用的上下文环境变量供我们使用，后面可以见到。 app.Action是执行程序时执行的逻辑，我们也可以定义在程序执行前后所要插入的逻辑，定义app.Before与app.After即可，例123456789101112131415161718192021222324func main() &#123; app := cli.NewApp() app.Before = func(context *cli.Context) error &#123; fmt.Println("before hello world") return nil; &#125; app.Action = func(c *cli.Context) &#123; fmt.Println("hello world") &#125; app.After = func(context *cli.Context) error &#123; fmt.Println("after hello world") return nil; &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125;//执行go run example.go/* 输出：before hello worldhello worldafter hello world*/ 注意：如果app.Before返回的error不为空，app.Action的内容将不会执行，而不管app.Action与app.Before中是否有错误发生，app.After的内容都会执行，app.After可用于收尾工作。 定义flag 这里的flag概念和上文中go的标准包中flag类似，直接看一个例子：12345678910111213141516171819202122func main() &#123; app := cli.NewApp() app.Flags = []cli.Flag&#123; cli.StringFlag&#123; Name:"path", Value:"/home/", Usage:"setting path", &#125;, &#125; app.Action = func(c *cli.Context) &#123; fmt.Println(c.String("path")) &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal("aaa",err) &#125;&#125;//输入go run example.go -path /home/base//输出：/home/base//输入go run example.go//输出：/home/ 定义起来很简单，关键几个要素就是Name和Value，取值时使用cli.Context提供的对应取值方法即可。包内预定义了许多种类型的flag，基本涵盖了所有基本类型，详见这里 另外在取值时，除了调用如c.Int(),c.String()之类的方法，还可以在定义flag时直接绑定到某些变量上，如：123456var age intcli.IntFlag&#123; Name:"age", Value:100, Destination:&amp;age,&#125; 另外，还可以配置flag的简写或别名，只需在定义Name时定义多个名称，中间用逗号隔开即可，例：123456cli.IntFlag&#123; Name:"age,a,ege", Value:100, Destination:&amp;age,&#125;,//-age -a -ege 都是有效的 配置子命令 如git push …中push就是一个子命令，这个包为我们提供了便捷定义子命令及其动作的方法12345678910111213app.Commands = []cli.Command&#123; &#123; Name: "push", Aliases: []string&#123;"p"&#125;, Usage: "push a file to the server", Action: func(c *cli.Context) error &#123; fmt.Println("push flie: ", c.Args().First())//c.Args().First()取命令后的第一个参数 return nil &#125;, &#125;, &#125;//执行go run example.go push test.txt//输出：push flie: test.txt 用法很简单，指定命名名，别名用法，以及相应动作即可。另外子命令可以像它的一个程序一样，有自己flag，Before，After，甚至是自己的子命令，使用Subcommands定义 注意，如果即定义了app的action，又定义了子命令的action，同一时间只能执行一个，如调用子命令时，app的action就不会执行 启动程序 所有配置都配置完成后，就需要启动程序，不然是不会生效的1234err := app.Run(os.Args)if err != nil &#123; log.Fatal("aaa",err)&#125; 最后给出一个详细例子，这是给出的，基本上涵盖了所有配置要点:例子]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F20%2Fhello-world%2F</url>
    <content type="text"><![CDATA[一切都从Hello World开始！ Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
