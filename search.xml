<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[go-ethereum中ethdb源码学习]]></title>
    <url>%2F2019%2F03%2F27%2Fgo-ethereum%E4%B8%ADethdb%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前面学习了ethereum的编码和数据结构，这里学习一些ethereum的持久化存储也就是数据相关的源码。 背景go-ethereum的数据存储时借助于leveldb数据库，它是Google开发的一种键值对类型的数据库，另外Facebook又基于其开发了RocksDB数据库。简单来说，leveldb具有轻量以及高性能的特点。 原生的leveldb是用c++写的，并不方便直接用到go项目中，好在leveldb的开发者用go重新实现了leveldb，我们可以直接使用(github地址)。 go版本的leveldb需要go1.5以上版本，安装很简单，执行下面命令1go get github.com/syndtr/goleveldb/leveldb go-leveldb使用由于是键值对类型的数据库，所以使用比较简单，下面简单介绍一下基本操作，更高级的操作参见API文档。下面操作示例代码见这里 打开数据库12345db, err := leveldb.OpenFile("db", nil)if(err!=nil)&#123; log.Fatalln(err.Error())&#125;defer db.Close() OpenFile会创建或打开一个数据库。 增删改查123err = db.Put([]byte("key"), []byte("value"), nil)err = db.Delete([]byte("key"), nil)data, err := db.Get([]byte("key"), nil) 基本上就对于put，get，delete几个方法，其中更改一个记录的话也是用put。 普通迭代123456iter := db.NewIterator(nil, nil)for iter.Next() &#123; key := iter.Key() value := iter.Value()&#125;iter.Release() 就是迭代数据库全部键值对 指定起点的迭代首先需要明白的是，leveldb的存储是按key的顺序存储的，所以可以指定一个key，从该key开始遍历1234567iter:=db.NewIterator(nil,nil)for ok:=iter.Seek(key);ok;ok=iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 子集迭代可以指定区间进行迭代1234567iter:=db.NewIterator(&amp;util.Range&#123;Start:[]byte("key2"),Limit:[]byte("key6")&#125;,nil)for iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 前缀迭代只迭代有指定前缀的1234567iter:=db.NewIterator(util.BytesPrefix([]byte(prefix)),nil)for iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 批量写入12345678batch:=new(leveldb.Batch)for i:=0; i&lt;10; i++ &#123; batch.Put([]byte("batch"+strconv.Itoa(i)),[]byte("batch"+strconv.Itoa(i)))&#125;err:=db.Write(batch,nil)if err!=nil &#123; fmt.Println(err)&#125; 源码分析源码集中在ethdb目录内，主要是对leveldb的封装。 interface.go顾名思义就是定义了一些接口，如数据库接口：12345678type Database interface &#123; Putter Deleter Get(key []byte) ([]byte, error) Has(key []byte) (bool, error) Close() NewBatch() Batch&#125; Batch接口。用于批量操作，不能用于并发1234567type Batch interface &#123; Putter Deleter ValueSize() int Write() error Reset()&#125; 上面两个结构又包含了Putter和Deleter接口123456type Putter interface &#123; Put(key []byte, value []byte) error&#125;type Deleter interface &#123; Delete(key []byte) error&#125; database.go构造这就是ethereum所使用的代码，先看结构体1234567891011121314151617type LDBDatabase struct &#123; fn string // filename for reporting db *leveldb.DB // LevelDB instance compTimeMeter metrics.Meter // Meter for measuring the total time spent in database compaction compReadMeter metrics.Meter // Meter for measuring the data read during compaction compWriteMeter metrics.Meter // Meter for measuring the data written during compaction writeDelayNMeter metrics.Meter // Meter for measuring the write delay number due to database compaction writeDelayMeter metrics.Meter // Meter for measuring the write delay duration due to database compaction diskReadMeter metrics.Meter // Meter for measuring the effective amount of data read diskWriteMeter metrics.Meter // Meter for measuring the effective amount of data written quitLock sync.Mutex // Mutex protecting the quit channel access quitChan chan chan error // Quit channel to stop the metrics collection before closing the database log log.Logger // Contextual logger tracking the database path&#125; NewLDBDatabase成员很多，关键的就是一个leveldb.DB对象和几个同步操作的成员。接下来看新建数据库的方法12345678910111213141516171819202122232425262728293031func NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) &#123; logger := log.New("database", file) //从init调用过来时，cache和handles都为0 //默认启动节点，cache为512，handles为0，在node.DefaultConfig配置 if cache &lt; 16 &#123; cache = 16 &#125; if handles &lt; 16 &#123; handles = 16 &#125; logger.Info("Allocated cache and file handles", "cache", common.StorageSize(cache*1024*1024), "handles", handles) db, err := leveldb.OpenFile(file, &amp;opt.Options&#123; OpenFilesCacheCapacity: handles, BlockCacheCapacity: cache / 2 * opt.MiB, WriteBuffer: cache / 4 * opt.MiB, Filter: filter.NewBloomFilter(10), &#125;) if _, corrupted := err.(*errors.ErrCorrupted); corrupted &#123; db, err = leveldb.RecoverFile(file, nil) &#125; if err != nil &#123; return nil, err &#125; return &amp;LDBDatabase&#123; fn: file, db: db, log: logger, &#125;, nil&#125; 逻辑很简单，创建了一个levelDB对象，主要看一下options的内容： OpenFilesCacheCapacity：定义打开的文件缓存大小，默认是500，设为-1或0时表示不缓存 BlockCacheCapacity：定义了一个名为sorted table的缓存容量，默认是8MB，设为-1或0时表示不缓存 WriteBuffer：定义memdb的大小，它是一个内存数据库，默认是4MB. Filter：定义过滤器，优化读性能。这是使用了一个布隆过滤器 put，has，get，delete12345678910111213141516func (db *LDBDatabase) Put(key []byte, value []byte) error &#123; return db.db.Put(key, value, nil)&#125;func (db *LDBDatabase) Has(key []byte) (bool, error) &#123; return db.db.Has(key, nil)&#125;func (db *LDBDatabase) Get(key []byte) ([]byte, error) &#123; dat, err := db.db.Get(key, nil) if err != nil &#123; return nil, err &#125; return dat, nil&#125;func (db *LDBDatabase) Delete(key []byte) error &#123; return db.db.Delete(key, nil)&#125; 都是对leveldb做了封装而已。 Batch及其操作批量读写的封装12345type ldbBatch struct &#123; db *leveldb.DB b *leveldb.Batch size int&#125; put、delete、write、reset1234567891011121314151617181920func (b *ldbBatch) Put(key, value []byte) error &#123; b.b.Put(key, value) b.size += len(value) return nil&#125;func (b *ldbBatch) Delete(key []byte) error &#123; b.b.Delete(key) b.size += 1 return nil&#125;func (b *ldbBatch) Write() error &#123; return b.db.Write(b.b, nil)&#125;func (b *ldbBatch) Reset() &#123; b.b.Reset() b.size = 0&#125; Meter这是用于初始化LDBDatabase的一系列Meter成员用的123456789101112131415func (db *LDBDatabase) Meter(prefix string) &#123; db.compTimeMeter = metrics.NewRegisteredMeter(prefix+"compact/time", nil) db.compReadMeter = metrics.NewRegisteredMeter(prefix+"compact/input", nil) db.compWriteMeter = metrics.NewRegisteredMeter(prefix+"compact/output", nil) db.diskReadMeter = metrics.NewRegisteredMeter(prefix+"disk/read", nil) db.diskWriteMeter = metrics.NewRegisteredMeter(prefix+"disk/write", nil) db.writeDelayMeter = metrics.NewRegisteredMeter(prefix+"compact/writedelay/duration", nil) db.writeDelayNMeter = metrics.NewRegisteredMeter(prefix+"compact/writedelay/counter", nil) db.quitLock.Lock() db.quitChan = make(chan chan error) db.quitLock.Unlock() go db.meter(3 * time.Second)&#125; 这个方法内先初始化各种Meter，然后创建了一个chan，最后启动一个goroutine运行meter，之后每3秒收集一次信息并反馈到Meter。这一段代码比较长，就不贴出来了。主要是利用db.db.GetProperty(“leveldb.stats”)获取信息，信息格式如下：123456// Level | Tables | Size(MB) | Time(sec) | Read(MB) | Write(MB)// -------+------------+---------------+---------------+---------------+---------------// 0 | 0 | 0.00000 | 1.27969 | 0.00000 | 12.31098// 1 | 85 | 109.27913 | 28.09293 | 213.92493 | 214.26294// 2 | 523 | 1000.37159 | 7.26059 | 66.86342 | 66.77884// 3 | 570 | 1113.18458 | 0.00000 | 0.00000 | 0.00000 下面就是解析这个字符串并写入Meter。另外一点这段代周期循环的关键代码如下1234567for i := 1; errc == nil &amp;&amp; merr == nil; i++ &#123; //.... select &#123; case errc = &lt;-db.quitChan: case &lt;-time.After(refresh): &#125;&#125; 到select出会阻塞，3秒后进行下一次循环，退出时向Meter方法中初始化的chan发送信息，导致errc不为nil，就自然退出循环 close12345678910111213141516171819func (db *LDBDatabase) Close() &#123; db.quitLock.Lock() defer db.quitLock.Unlock() if db.quitChan != nil &#123; errc := make(chan error) db.quitChan &lt;- errc if err := &lt;-errc; err != nil &#123; db.log.Error("Metrics collection failed", "err", err) &#125; db.quitChan = nil &#125; err := db.db.Close() if err == nil &#123; db.log.Info("Database closed") &#125; else &#123; db.log.Error("Failed to close database", "err", err) &#125;&#125; 退出代码也很简单，主要就是在加锁环境下，向quitChan写入信息，停止meter，然后等待反馈（在meter发出反馈），最后关闭数据库。 memory_database.go这是一个用于测试的基于内存的数据库。在源码中主要是在geth初始化时，如果最后创建数据库时依旧没有有效的datadir则使用这个数据库代替 构造12345678910type MemDatabase struct &#123; db map[string][]byte lock sync.RWMutex&#125;func NewMemDatabase() *MemDatabase &#123; return &amp;MemDatabase&#123; db: make(map[string][]byte), &#125;&#125; 可见就是基于map的封装。 基础操作123456789101112131415161718192021222324252627282930313233func (db *MemDatabase) Put(key []byte, value []byte) error &#123; db.lock.Lock() defer db.lock.Unlock() db.db[string(key)] = common.CopyBytes(value) return nil&#125;func (db *MemDatabase) Has(key []byte) (bool, error) &#123; db.lock.RLock() defer db.lock.RUnlock() _, ok := db.db[string(key)] return ok, nil&#125;func (db *MemDatabase) Get(key []byte) ([]byte, error) &#123; db.lock.RLock() defer db.lock.RUnlock() if entry, ok := db.db[string(key)]; ok &#123; return common.CopyBytes(entry), nil &#125; return nil, errors.New("not found")&#125;func (db *MemDatabase) Delete(key []byte) error &#123; db.lock.Lock() defer db.lock.Unlock() delete(db.db, string(key)) return nil&#125; 全是基于map操作，只不过进行了加锁 Batch1234567891011121314151617181920212223242526272829303132333435363738394041type memBatch struct &#123; db *MemDatabase writes []kv size int&#125;type kv struct &#123; k, v []byte del bool&#125;func (db *MemDatabase) NewBatch() Batch &#123; return &amp;memBatch&#123;db: db&#125;&#125;func (b *memBatch) Put(key, value []byte) error &#123; b.writes = append(b.writes, kv&#123;common.CopyBytes(key), common.CopyBytes(value), false&#125;) b.size += len(value) return nil&#125;func (b *memBatch) Delete(key []byte) error &#123; b.writes = append(b.writes, kv&#123;common.CopyBytes(key), nil, true&#125;) b.size += 1 return nil&#125;func (b *memBatch) Write() error &#123; b.db.lock.Lock() defer b.db.lock.Unlock() for _, kv := range b.writes &#123; if kv.del &#123; delete(b.db.db, string(kv.k)) continue &#125; b.db.db[string(kv.k)] = kv.v &#125; return nil&#125;func (b *memBatch) Reset() &#123; b.writes = b.writes[:0] b.size = 0&#125; 批量操作先存储在一个KV类型的数组内，等到写入时遍历那个数组，依次存入数据库 table.go与table_batch.go这两个也是对数据的封装，之所以叫table是因为实例化一个table时要指定一个前缀，之后利用table的基本操作都会给key添加指定的前缀。table_batch也类似，直接看一下table.go的源码12345678910111213141516171819202122func NewTable(db Database, prefix string) Database &#123; return &amp;table&#123; db: db, prefix: prefix, &#125;&#125;func (dt *table) Put(key []byte, value []byte) error &#123; return dt.db.Put(append([]byte(dt.prefix), key...), value)&#125;func (dt *table) Has(key []byte) (bool, error) &#123; return dt.db.Has(append([]byte(dt.prefix), key...))&#125;func (dt *table) Get(key []byte) ([]byte, error) &#123; return dt.db.Get(append([]byte(dt.prefix), key...))&#125;func (dt *table) Delete(key []byte) error &#123; return dt.db.Delete(append([]byte(dt.prefix), key...))&#125;]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC4加密]]></title>
    <url>%2F2019%2F03%2F27%2FRC4%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景RC4全名Rivest Cipher 4，是1987年Ron Rivest设计的一种流加密法，属于对称加密算法，曾经是WEP、TLS等使用的加密算法，它速度较快，且设计简单，所以使用较广 基本原理首先RC4的秘钥是可变的，长度在1~256个字节之间，开始前我们需要一个初始化状态向量，在进行初始置换后生产流秘钥进行加密。对于解密则是和加密一样的算法。 详细流程S的初始化 首先定义一个长度为1~256个字节的秘钥K。 初始化一个向量S，S[0] = 0,S[1] = 1, … ,S[255] = 255 创建临时数组T，T的长度是256，T用K填充，填不满的循环用K填充，直到T被填满 S的初始置换T数组的作用是对S进行初始置换，置换规则如下：将S[i]与S[j]交换，其中j = (j + S[i] + T[i]) mod 256。j的初始值是0 流秘钥生成根据如下计算：i = (i+1) mod 256，i初始值为0；j = (j + s[i]) mod 256,j初始值位0。然后交换s[i]和S[j]。令t = (S[i] + S[j]) mod 256。输出S[t]作为秘钥通明文进行一字节一字节的加密（异或运算） 简单实现java代码简单实现如下123456789101112131415161718192021222324252627282930313233public class RC4 &#123; private int[] S = new int[256]; RC4(byte[] keys) throws Exception &#123; int keyLen = keys.length; if (keyLen &lt;1 || keyLen &gt; 256) throw new Exception("秘钥长度错误"); int[] T = new int[256]; for (int i = 0;i&lt;256;i++)&#123; S[i] = i; &#125; int j = 0; for (int i = 0;i&lt;256;i++)&#123; j = (j + S[i] + keys[i % keyLen]) % 256; int temp = S[i]; S[i] = S[j]; S[j] = temp; &#125; &#125; public byte[] encrypt(byte[] msgs)&#123; int i = 0,j = 0; byte[] out = new byte[msgs.length]; for (int k = 0;k&lt;msgs.length;k++)&#123; i = (i+1)%256; j = (j+S[i])%256; int temp = S[i]; S[i] = S[j]; S[j] = temp; out[k] = (byte) (msgs[k] ^ S[(S[i] + S[j])%256]); &#125; return out; &#125;&#125; 验证123456public static void main(String[] args) throws Exception &#123; RC4 rc4 = new RC4("123".getBytes()); byte[] out = rc4.encrypt("abcdefg".getBytes()); Base64.Encoder encoder = Base64.getEncoder(); System.out.println(new String(encoder.encode(out))); &#125; 最后输出：MpLc5oASYw== 使用第三方RC4加密验证： 解密验证，由于说解密算法和加密算法一致，所以我们不必做任何修改，直接如下：1234567public static void main(String[] args) throws Exception &#123; RC4 rc4 = new RC4("123".getBytes()); byte[] out = rc4.encrypt("abcdefg".getBytes()); RC4 rc41 = new RC4("123".getBytes()); System.out.println(new String(rc41.encrypt(out))); &#125; 需要注意的一点是，解密时要新建一个RC4对象，原来的对象在加密时S数组已经发生交换，不能使用。 总结RC4算法通过上面实现来看非常简单，没有什么复杂计算，只有简单的交换和异或运算，秘钥也足够长，是一种比较理想的算法。但是弱密钥会导致算法不安全，另外由于更好的算法出现，RC4目前已经很少使用。 题图来自unsplash：https://unsplash.com/photos/B9j-xgMVf90]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中trie源码学习]]></title>
    <url>%2F2019%2F03%2F26%2Fgo-ethereum%E4%B8%ADtrie%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[MPT（Merkle Patricia Tree），是以太坊实现中广泛使用的一种数据结构，如在区块头中就保存了状态树，交易树和收据树这三棵树的根的hash，而这三棵树就是MPT。MPT是Trie树、Patricia Trie树和Merkle树的变形，下面我们就来详细了解一下 背景Trie树Trie树又称前缀树或字典树。顾名思义一个节点的所有孩子都具有同样的前缀，就像字典一样把单词按前缀分类排序。 在Trie树中，根节点不保存信息，每个节点的最大孩子数量相同（若是保存英文字母，不区分大小写，则最多有26个孩子）。 从根节点开始，到某一节点，路径上的字符组合起来就是该节点对应的字符串 没有重复的节点 语言说起来比较抽象，看一张图就很清楚了 如上图所示，这棵树可能保存了:A,to,tea,ted,ten,i,in,inn这8个字符串（具体某个节点表示的仅仅是前缀还是字符串还要根据节点参数判断）。java实现见这里 Trie树具有查找效率高的特点，但是稀疏现象比较严重，空间利用率低。Trie树常用于搜索提示，如输入前几个字母，就可以很快的提示一些可能匹配的字符串。 Patricia Trie实际上是基数树，或压缩前缀树。根据名字可知，是对前缀进行一定的压缩，为了是缓解Trie树空间利用率不高的问题。如下图 从图中我们可以知道，如果以Trie树存储romane和romanus，对于他们的公共前缀roman我们要创建5个先后依赖的节点，在第5层处分叉，对于us又需要两层节点。而对于基数树，可以把roman合并为一个节点，us也合并为一个节点，这样原本至少7层才能表示的现在2层即可。 关于这种树的实现我们会在后面源码分析提到 Merkle树Merkle Tree，通常也被称作Hash Tree。这种树的的主要作用是验证。它结构上大多情况是一颗二叉树，叶子结点都以数据库的hash值作为标签，其他结点都是其子节点的标签拼接后再做hash。他可以高效的安全的验证大型数据结构的内容。 如上图，数据的每一块都对应一个叶子，叶子内存储该块的hash，之后层层做hash运算，最后得到根节点的一个hash值。我们只需要验证根节点的hash是否相同，就能判断整个文件是否完整或者是否被人恶意篡改。另外，通过重建整个树，可以很快的知道具体哪一部分出错。具体在区块链中，无论比特币还是以太坊，都是只在区块头中存储根节点，从而来判断是否一致。 以太坊的MPT一般而言MPT的存储借鉴的是Patricia Trie。与一般的存储英文字符串不同，MPT存储的是hash值，每一位有0-f共16种可能，不过MPT又对其进行了扩展。 首先，定义了三种节点： branch：分支节点，一个长度为17的list，分别是0-f共16位，再加一个value。最后的value代表该节点可能对某个key是终点，用于存取值 leaf：叶子节点，和Trie树的叶子结点类型 extension：扩展节点，纯粹的路径节点，其中的值时其它节点hash，可以理解为一个指向其他节点的指针 看一张经典的图会比较容易理解： 在图中，右上角四对键值就是图中树所存储的内容。首先他们都有前缀a7，所以根节点就是一个扩展节点，它的指针指向一个分支节点，分支节点用到了1、7、f三个值，1、f分别指向两个叶子节点，因为没有其他key和他们有除a7外的公共前缀，分支节点7指向一个扩展节点，因为右上角第二和第四个还有公共前缀d3，随后在指向一个分支节点，再找值分为两个叶子节点。叶子结点的value就存着每个键值对中的value. 源码分析ethereum关于这部分的源码集中在trie目录下 结点定义见代码：1234567891011121314151617181920// go-ethereum\trie\node.gotype node interface &#123; fstring(string) string cache() (hashNode, bool) canUnload(cachegen, cachelimit uint16) bool&#125;type ( fullNode struct &#123; Children [17]node // Actual trie node data to encode/decode (needs custom encoder) flags nodeFlag &#125; shortNode struct &#123; Key []byte Val node flags nodeFlag &#125; hashNode []byte valueNode []byte) 虽说黄皮书中定义了3种结点，但这里只有两种节点，分别是fullnode和shortnode。fullnode就是分支节点，可见其有一个长度为17的数组。shortnode可以代表扩展节点或叶子节点，因为二者结构是一样的，区分两种节点主要看val的值。另外还有两种节点，虽然是字节数组类型的，但是他们都实现了node接口的全部方法，所以也是节点类型。 树的构造先看一下树的结构：12345type Trie struct &#123; db *Database root node cachegen, cachelimit uint16&#125; root就是根节点，db就是数据库，树的结构最后要存到数据库中，启动时再加载出来。对于cachegen，每次提交其值都会增加，新节点会标记cachegen，如果当前的cachegen - cachelimit大于node的cache时代，那么node会从cache里面卸载，以便节约内存。 创建一棵树12345678910111213141516func New(root common.Hash, db *Database) (*Trie, error) &#123; if db == nil &#123; panic("trie.New called without a database") &#125; trie := &amp;Trie&#123; db: db, &#125; if root != (common.Hash&#123;&#125;) &amp;&amp; root != emptyRoot &#123; rootnode, err := trie.resolveHash(root[:], nil) if err != nil &#123; return nil, err &#125; trie.root = rootnode &#125; return trie, nil&#125; new方法接受一个hash和一个数据库指针，首席确保指针不为空，然后初始化树，之后再判断传入的hash是否为空值，若不是则从数据库加载，否则返回一个空树。 插入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960func (t *Trie) insert(n node, prefix, key []byte, value node) (bool, node, error) &#123; if len(key) == 0 &#123; if v, ok := n.(valueNode); ok &#123; return !bytes.Equal(v, value.(valueNode)), value, nil &#125; return true, value, nil &#125; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) if matchlen == len(n.Key) &#123; dirty, nn, err := t.insert(n.Val, append(prefix, key[:matchlen]...), key[matchlen:], value) if !dirty || err != nil &#123; return false, n, err &#125; return true, &amp;shortNode&#123;n.Key, nn, t.newFlag()&#125;, nil &#125; branch := &amp;fullNode&#123;flags: t.newFlag()&#125; var err error _, branch.Children[n.Key[matchlen]], err = t.insert(nil, append(prefix, n.Key[:matchlen+1]...), n.Key[matchlen+1:], n.Val) if err != nil &#123; return false, nil, err &#125; _, branch.Children[key[matchlen]], err = t.insert(nil, append(prefix, key[:matchlen+1]...), key[matchlen+1:], value) if err != nil &#123; return false, nil, err &#125; if matchlen == 0 &#123; return true, branch, nil &#125; return true, &amp;shortNode&#123;key[:matchlen], branch, t.newFlag()&#125;, nil case *fullNode: dirty, nn, err := t.insert(n.Children[key[0]], append(prefix, key[0]), key[1:], value) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn return true, n, nil case nil: return true, &amp;shortNode&#123;key, value, t.newFlag()&#125;, nil case hashNode: rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.insert(rn, prefix, key, value) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf("%T: invalid node: %v", n, n)) &#125;&#125; 几个参数分别是：n代表当前的结点。prefix代表已经搜索过的前缀，key表示尚未处理的部分，二者拼接到一起就是完整的key。value表示要插入的值。返回值中bool表示是否改变了树，node表示插入后子树的根节点。通过参数可以猜到这是通过递归进行操作的。 代码的第一个if判断中，若key的长度为0，表示key已经遍历完了，同时也找到了一个节点。判断这个节点是否是valueNode类型节点，若是的话，判断要插入的值和结点的值是否相等，来判断是否改变了树。若不是valueNode类型节点，就直接更新value，同时指明树已经改变了。 若还在变量key的途中，则根据当前节点的类型进行判断： 若是shortNode节点，表示是一个叶子节点或扩展节点，则调用prefixLen方法计算公共前缀长度。若公共前缀长度就等于key的长度，说明二者的可以是一样的，则按照需要更新value。若只有部分公共前缀，则需要构造一个分支节点，将原来的节点和要插入的作为新分支节点的孩子插入。最后对刚才的公共前缀进行判断，若为0，表示没有公共前缀，则用新的分支节点替换掉原来的节点，若不为零，则将新的分支节点作为原节点的孩子，并改变原节点的可以。注意给分支节点添加孩子时，也是调用的insert，只不过n为nil，这对应后面的一种情况，稍后分析。 若是fullNode，也就是分支节点，则直接寻找对应的位置尝试插入，注意分支节点对于位置的孩子可能为空，为shortNode或者fullnode，不管为什么，最终继续递归，并按需更新孩子即可 若是nil，这种情况可能会一棵空树时候出现，这是新建一个shortNode节点作为根节点，返回即可。同时，在上文向分支节点插入孩子时也会出现，同样也是新建shortNode结点作为分支节点孩子即可。 若是hashNode，可以理解为一个指针，但是数据都在数据库，需要取数据库取值插入 最后不满足定义的四种节点，报错 最后总结一点，对于shortNode节点，要么进行更新，要么新建扩展节点进行插入，对于fullNode，要么成为其某个孩子，要么更新其值，要么为其添加扩展节点，进行扩展。总之新的叶子节点插入操作都是在扩展节点上完成的。 删除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778func (t *Trie) delete(n node, prefix, key []byte) (bool, node, error) &#123; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) if matchlen &lt; len(n.Key) &#123; return false, n, nil // don't replace n on mismatch &#125; if matchlen == len(key) &#123; return true, nil, nil // remove n entirely for whole matches &#125; dirty, child, err := t.delete(n.Val, append(prefix, key[:len(n.Key)]...), key[len(n.Key):]) if !dirty || err != nil &#123; return false, n, err &#125; switch child := child.(type) &#123; case *shortNode: return true, &amp;shortNode&#123;concat(n.Key, child.Key...), child.Val, t.newFlag()&#125;, nil default: return true, &amp;shortNode&#123;n.Key, child, t.newFlag()&#125;, nil &#125; case *fullNode: dirty, nn, err := t.delete(n.Children[key[0]], append(prefix, key[0]), key[1:]) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn pos := -1 //遍历后，若pos大于等于0，表示只有一个孩子 //若pos等于-2则孩子数量大于一个 for i, cld := range &amp;n.Children &#123; if cld != nil &#123; if pos == -1 &#123; pos = i &#125; else &#123; pos = -2 break &#125; &#125; &#125; if pos &gt;= 0 &#123; if pos != 16 &#123; cnode, err := t.resolve(n.Children[pos], prefix) if err != nil &#123; return false, nil, err &#125; if cnode, ok := cnode.(*shortNode); ok &#123; k := append([]byte&#123;byte(pos)&#125;, cnode.Key...) return true, &amp;shortNode&#123;k, cnode.Val, t.newFlag()&#125;, nil &#125; &#125; return true, &amp;shortNode&#123;[]byte&#123;byte(pos)&#125;, n.Children[pos], t.newFlag()&#125;, nil &#125; return true, n, nil case valueNode: return true, nil, nil case nil: return false, nil, nil case hashNode: rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.delete(rn, prefix, key) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf("%T: invalid node: %v (%v)", n, n, key)) &#125;&#125; 参数和返回值和插入操作类似，不在赘述。依旧是判断当前节点类型： 若为shortNode结点，首先也是计算公共前缀。若公共前缀的长度小于当前节点key的长度，表示没有匹配到。若公共前缀的长度等于要删除的key的长度，表示匹配到子树，直接删除该节点为根的子树。若公共前缀的长度等于当前节点key的长度，也就是当前节点的key是要删除key的一部分，说明还要向下查找。但是删除完后要对节点做处理，若子节点fullnode节点删除孩子后孩子数量大于1个，则只改变当前节点的flag。若删除后孩子数量小于等于一个，则要对节点进行合并，也就是对前缀进行合并 若为fullnode结点，则直接根据key的第一个字符取尝试删除某个孩子。然后遍历孩子，判断非空的数量，若大于两个则不做处理，若只有一个，进行节点的合并。 若为valueNode节点，直接删除，返回 若为nil，一般在阐述fullnode的孩子时遇到，表示没有匹配，不做处理 若为hashNode，表示还在数据库中，则先加载，在尝试删除 查询也就是Get方法，见代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func (t *Trie) Get(key []byte) []byte &#123; res, err := t.TryGet(key) if err != nil &#123; log.Error(fmt.Sprintf("Unhandled trie error: %v", err)) &#125; return res&#125;func (t *Trie) TryGet(key []byte) ([]byte, error) &#123; key = keybytesToHex(key) //转为16进制半字节 value, newroot, didResolve, err := t.tryGet(t.root, key, 0) if err == nil &amp;&amp; didResolve &#123; t.root = newroot &#125; return value, err&#125;func (t *Trie) tryGet(origNode node, key []byte, pos int) (value []byte, newnode node, didResolve bool, err error) &#123; switch n := (origNode).(type) &#123; case nil: return nil, nil, false, nil case valueNode: return n, n, false, nil case *shortNode: if len(key)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, key[pos:pos+len(n.Key)]) &#123; // key not found in trie return nil, n, false, nil &#125; value, newnode, didResolve, err = t.tryGet(n.Val, key, pos+len(n.Key)) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.Val = newnode n.flags.gen = t.cachegen &#125; return value, n, didResolve, err case *fullNode: value, newnode, didResolve, err = t.tryGet(n.Children[key[pos]], key, pos+1) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.flags.gen = t.cachegen n.Children[key[pos]] = newnode &#125; return value, n, didResolve, err case hashNode: child, err := t.resolveHash(n, key[:pos]) if err != nil &#123; return nil, n, true, err &#125; value, newnode, _, err := t.tryGet(child, key, pos) return value, newnode, true, err default: panic(fmt.Sprintf("%T: invalid node: %v", origNode, origNode)) &#125;&#125; 查找的逻辑也很简单，首先要把byte数组转为16进制半字节的数组形式，使用keybytesToHex方法（后面会讲）。之后从根节点开始，调用tryGet递归查询，也分一下几种情况： 若为空，表示没有找到 若为valueNode节点，直接返回即可 若为shortNode，如果当前节点的key长度大于本次递归要查找的或即使长度相等但内容不一样的，则表示没有匹配的，否则继续递归查找 若为fullNode结点，则递归到孩子中寻找 若为hashNode结点，则先从数据库中加载，在尝试递归查询 编码主要是encoding.go，处理树的三种编码格式的互相转换。 keybytes：原始字节数组，大部分trie的函数都用这种格式 hex：hex编码，将一个字节用两个字节表示，编码时，将8位二进制码重新分组成两个4位的字节，其中一个字节的低4位是原字节的高四位，另一个字节的低4位是原数据的低4位，高4位都补0。编码后再在尾部跟上一个标志位0x10，标识是叶子节点或者扩展节点 compact：compact编码，就是Hex-Prefix Encoding，在黄皮书中的附录C有说明。是hex编码的变体。第一个字节的高位存储标志位，低位存储0（长度为偶数）或hex编码的第一个半字节（长度为奇数）。总之最后长度是偶数。数学描述如下（f(t)表示hex编码的标志位是否存在）： 下面具体看源码： hexToCompacthex编码转compact编码12345678910111213141516func hexToCompact(hex []byte) []byte &#123; terminator := byte(0) if hasTerm(hex) &#123; terminator = 1 hex = hex[:len(hex)-1] &#125; buf := make([]byte, len(hex)/2+1) buf[0] = terminator &lt;&lt; 5 // the flag byte if len(hex)&amp;1 == 1 &#123; buf[0] |= 1 &lt;&lt; 4 // odd flag buf[0] |= hex[0] // first nibble is contained in the first byte hex = hex[1:] &#125; decodeNibbles(hex, buf[1:]) return buf&#125; hasTerm判断最后一字节是否是16，也就是有没有标志位，若是则terminator标记为1，并去除hex编码的标志位。接下来写入compat编码的标志位，首先terminator右移5位，再判断hex编码长度的奇偶性，并根据情况改下标志位。然后解码hex编码改为compat编码，流程和黄皮书一致。 compactToHexcompact编码转hex编码12345678910111213func compactToHex(compact []byte) []byte &#123; if len(compact) == 0 &#123; return compact &#125; base := keybytesToHex(compact) // delete terminator flag if base[0] &lt; 2 &#123; base = base[:len(base)-1] &#125; // apply odd flag chop := 2 - base[0]&amp;1 return base[chop:]&#125; 可见先看做一般字节数组，然后转为hex编码。然后判断是否有标志位。首先根据黄皮书规定，compact编码的第一字节的高四位有这几种情况：12340000 hex编码没有标志位，且长度为偶数0001 hex编码没有标志位，且长度为奇数0010 hex编码有标志位，且长度为偶数0011 hex编码有标志位，且长度为奇数 根据上面四种情况，删除最后的标志位。然后在根据第一位的值，决定是删除前两位还是第一位 keybytesToHex原始数组转hex编码12345678910func keybytesToHex(str []byte) []byte &#123; l := len(str)*2 + 1 var nibbles = make([]byte, l) for i, b := range str &#123; nibbles[i*2] = b / 16 nibbles[i*2+1] = b % 16 &#125; nibbles[l-1] = 16 return nibbles&#125; 很简单，就是一个字节拆为两个字节，利用整除和取余，最后加一个标志位。 hexToKeybyteshex编码还原12345678910111213141516func hexToKeybytes(hex []byte) []byte &#123; if hasTerm(hex) &#123; hex = hex[:len(hex)-1] &#125; if len(hex)&amp;1 != 0 &#123; panic("can't convert hex key of odd length") &#125; key := make([]byte, len(hex)/2) decodeNibbles(hex, key) return key&#125;func decodeNibbles(nibbles []byte, bytes []byte) &#123; for bi, ni := 0, 0; ni &lt; len(nibbles); bi, ni = bi+1, ni+2 &#123; bytes[bi] = nibbles[ni]&lt;&lt;4 | nibbles[ni+1] &#125;&#125; 先根据需求去除标志位，再具体转换。可见将两字节还原为一字节时就是利用移位和或逻辑。 序列化序列化就是将一课树存储到数据库中123456789101112131415161718192021// go-ethereum\trie\trie.gofunc (t *Trie) Commit(onleaf LeafCallback) (root common.Hash, err error) &#123; if t.db == nil &#123; panic("commit called on trie with nil database") &#125; hash, cached, err := t.hashRoot(t.db, onleaf) if err != nil &#123; return common.Hash&#123;&#125;, err &#125; t.root = cached t.cachegen++ return common.BytesToHash(hash.(hashNode)), nil&#125;func (t *Trie) hashRoot(db *Database, onleaf LeafCallback) (node, node, error) &#123; if t.root == nil &#123; return hashNode(emptyRoot.Bytes()), nil, nil &#125; h := newHasher(t.cachegen, t.cachelimit, onleaf) defer returnHasherToPool(h) return h.hash(t.root, db, true)&#125; 这一部分主要是创建了hasher，然后利用hash方法去实现。进入hasher的代码123456// go-ethereum\trie\hasher.gofunc newHasher(cachegen, cachelimit uint16, onleaf LeafCallback) *hasher &#123; h := hasherPool.Get().(*hasher) h.cachegen, h.cachelimit, h.onleaf = cachegen, cachelimit, onleaf return h&#125; hasherPool是一个对象池，newHasher方法主要是从中尝试取或者创建一个hasher对象。下面看hash方法：123456789101112131415161718192021222324252627282930313233343536func (h *hasher) hash(n node, db *Database, force bool) (node, node, error) &#123; if hash, dirty := n.cache(); hash != nil &#123; if db == nil &#123; return hash, n, nil &#125; if n.canUnload(h.cachegen, h.cachelimit) &#123; cacheUnloadCounter.Inc(1) return hash, hash, nil &#125; if !dirty &#123; return hash, n, nil &#125; &#125; collapsed, cached, err := h.hashChildren(n, db) if err != nil &#123; return hashNode&#123;&#125;, n, err &#125; hashed, err := h.store(collapsed, db, force) if err != nil &#123; return hashNode&#123;&#125;, n, err &#125; cachedHash, _ := hashed.(hashNode) switch cn := cached.(type) &#123; case *shortNode: cn.flags.hash = cachedHash if db != nil &#123; cn.flags.dirty = false &#125; case *fullNode: cn.flags.hash = cachedHash if db != nil &#123; cn.flags.dirty = false &#125; &#125; return hashed, cached, nil&#125; 第一个if我们后面再解释，接下来的hashChildren是一个关键点，它将所有的子节点换为他们的hash1234567891011121314151617181920212223242526272829303132333435func (h *hasher) hashChildren(original node, db *Database) (node, node, error) &#123; var err error switch n := original.(type) &#123; case *shortNode: collapsed, cached := n.copy(), n.copy() collapsed.Key = hexToCompact(n.Key) cached.Key = common.CopyBytes(n.Key) if _, ok := n.Val.(valueNode); !ok &#123; collapsed.Val, cached.Val, err = h.hash(n.Val, db, false) if err != nil &#123; return original, original, err &#125; &#125; return collapsed, cached, nil case *fullNode: subtrees collapsed, cached := n.copy(), n.copy() for i := 0; i &lt; 16; i++ &#123; if n.Children[i] != nil &#123; collapsed.Children[i], cached.Children[i], err = h.hash(n.Children[i], db, false) if err != nil &#123; return original, original, err &#125; &#125; &#125; cached.Children[16] = n.Children[16] return collapsed, cached, nil default: return n, original, nil &#125;&#125; 主要也是根据结点类型进行操作。 对于shortNode节点，先对key从hex编码转为compact编码，然后递归调用hash把子节点也改为hash 对于fullNode结点，遍历所有孩子，递归调用hash方法 对于其他类型节点原样返回 再回到hash方法，接下来调用store方法。12345678910111213141516171819202122232425262728293031323334353637383940func (h *hasher) store(n node, db *Database, force bool) (node, error) &#123; if _, isHash := n.(hashNode); n == nil || isHash &#123; return n, nil &#125; h.tmp.Reset() if err := rlp.Encode(&amp;h.tmp, n); err != nil &#123; panic("encode error: " + err.Error()) &#125; if len(h.tmp) &lt; 32 &amp;&amp; !force &#123; return n, nil // Nodes smaller than 32 bytes are stored inside their parent &#125; database. hash, _ := n.cache() if hash == nil &#123; hash = h.makeHashNode(h.tmp) &#125; if db != nil &#123; cache hash := common.BytesToHash(hash) db.lock.Lock() db.insert(hash, h.tmp, n) db.lock.Unlock() if h.onleaf != nil &#123; switch n := n.(type) &#123; case *shortNode: if child, ok := n.Val.(valueNode); ok &#123; h.onleaf(child, hash) &#125; case *fullNode: for i := 0; i &lt; 16; i++ &#123; if child, ok := n.Children[i].(valueNode); ok &#123; h.onleaf(child, hash) &#125; &#125; &#125; &#125; &#125; return hash, nil&#125; 首先判断节点类型，若本身就是hashNode或为空不存储。然后对节点编码。详细流程不在赘述，参考RLP编码学习。编码之后的结果存在tmp这个字节数组中。接下来判断是否强制存储，然后计算根节点编码后结果hash，最后存储到数据库，键就是刚才计算的hash。 再次回到hash方法，存储成功后。将存储的键转为hashNode类，然后判断cached（实际是跟节点的copy）的类型，对于是shortNode和fullNode类型，将其flags成员的hash值进行修改，然后返回hash值和cached。 反序列化不同于序列化，反序列化在trie的源码中就多次出现，主要是下面方法123456789func (t *Trie) resolveHash(n hashNode, prefix []byte) (node, error) &#123; cacheMissCounter.Inc(1) hash := common.BytesToHash(n) if node := t.db.node(hash, t.cachegen); node != nil &#123; return node, nil &#125; return nil, &amp;MissingNodeError&#123;NodeHash: hash, Path: prefix&#125;&#125; 主要逻辑在node方法中123456789101112131415161718192021222324252627// go-ethereum\trie\database.gofunc (db *Database) node(hash common.Hash, cachegen uint16) node &#123; if db.cleans != nil &#123; if enc, err := db.cleans.Get(string(hash[:])); err == nil &amp;&amp; enc != nil &#123; memcacheCleanHitMeter.Mark(1) memcacheCleanReadMeter.Mark(int64(len(enc))) return mustDecodeNode(hash[:], enc, cachegen) &#125; &#125; db.lock.RLock() dirty := db.dirties[hash] db.lock.RUnlock() if dirty != nil &#123; return dirty.obj(hash, cachegen) &#125; enc, err := db.diskdb.Get(hash[:]) if err != nil || enc == nil &#123; return nil &#125; if db.cleans != nil &#123; db.cleans.Set(string(hash[:]), enc) memcacheCleanMissMeter.Mark(1) memcacheCleanWriteMeter.Mark(int64(len(enc))) &#125; return mustDecodeNode(hash[:], enc, cachegen)&#125; 这也是一个典型的二级缓存的例子，首先尝试从内存缓存中获取，若没有，则从磁盘的数据库中获取，最后实际反序列化操作都在mustDecodeNode方法中123456789101112131415161718192021222324252627// go-ethereum\trie\node.gofunc mustDecodeNode(hash, buf []byte, cachegen uint16) node &#123; n, err := decodeNode(hash, buf, cachegen) if err != nil &#123; panic(fmt.Sprintf("node %x: %v", hash, err)) &#125; return n&#125;func decodeNode(hash, buf []byte, cachegen uint16) (node, error) &#123; if len(buf) == 0 &#123; return nil, io.ErrUnexpectedEOF &#125; elems, _, err := rlp.SplitList(buf) if err != nil &#123; return nil, fmt.Errorf("decode error: %v", err) &#125; switch c, _ := rlp.CountValues(elems); c &#123; case 2: n, err := decodeShort(hash, elems, cachegen) return n, wrapError(err, "short") case 17: n, err := decodeFull(hash, elems, cachegen) return n, wrapError(err, "full") default: return nil, fmt.Errorf("invalid number of list elements: %v", c) &#125;&#125; 首先解释一下涉及到的几个rlp方法，通过学习rlp编码我们知道，rlp编码一般由一个标志位+前缀+内容组成，SplitList方法返回的就是内容以及剩余内容（未被解析的）。对于复合类型，也就是编码中的第二种数据来源–多维数组类型，它的rlp编码内容部分是由多个单独的子类型rlp编码组合而成的，CountValues就是统计有多少个子部分。 接下来一个switch就是根据有多少子内容区分节点的类型，如代码中所述，2个子内容的就是shortNode，17个的就是fullNode，注意这点可能会有些人有疑问，我们定义节点的时候，这两类节点可不止这几个成员变量，这是因为在存储时节点都被转化为rawShortNode和rawFullNode两种简单类型（ go-ethereum\trie\database.go），只保留关键信息。我们接下来再看具体的反序列化方法123456789101112131415161718192021222324252627282930313233343536373839404142func decodeShort(hash, elems []byte, cachegen uint16) (node, error) &#123; kbuf, rest, err := rlp.SplitString(elems) if err != nil &#123; return nil, err &#125; flag := nodeFlag&#123;hash: hash, gen: cachegen&#125; key := compactToHex(kbuf) if hasTerm(key) &#123; val, _, err := rlp.SplitString(rest) if err != nil &#123; return nil, fmt.Errorf("invalid value node: %v", err) &#125; return &amp;shortNode&#123;key, append(valueNode&#123;&#125;, val...), flag&#125;, nil &#125; r, _, err := decodeRef(rest, cachegen) if err != nil &#123; return nil, wrapError(err, "val") &#125; return &amp;shortNode&#123;key, r, flag&#125;, nil&#125;func decodeRef(buf []byte, cachegen uint16) (node, []byte, error) &#123; kind, val, rest, err := rlp.Split(buf) if err != nil &#123; return nil, buf, err &#125; switch &#123; case kind == rlp.List: if size := len(buf) - len(rest); size &gt; hashLen &#123; err := fmt.Errorf("oversized embedded node (size is %d bytes, want size &lt; %d)", size, hashLen) return nil, buf, err &#125; n, err := decodeNode(nil, buf, cachegen) return n, rest, err case kind == rlp.String &amp;&amp; len(val) == 0: return nil, rest, nil case kind == rlp.String &amp;&amp; len(val) == 32: return append(hashNode&#123;&#125;, val...), rest, nil default: return nil, nil, fmt.Errorf("invalid RLP string size %d (want 0 or 32)", len(val)) &#125;&#125; 逻辑还是很清晰的，首先使用SplitString，分理处内容和剩余数据，然后将内容转为hex编码，再判断value是否有标志位来决定是否是叶子节点，若是叶子节点，则解析剩余的内容。若不是，则使用decodeRef来解析剩余内容。decodeRef首先也是分离出rlp编码各部分，先判断类型，再根据类型生成具体的节点。最后回到decodeShort构造出一个完整的节点。另外decodeFull流程也类似，不在赘述。主要思想就是一层一层剥开rlp编码，根据具体类型生成具体节点。 trie的cachetrie除了有数据库和根节点这两个成员变量，还有cachegen, cachelimit用于缓存管理的变量。trie树在每次commit时都会将cachegen加1（见上面序列化部分源码），然后在每次插入节点时都会把cachegen写入新节点，利用的是newFlag方法123func (t *Trie) newFlag() nodeFlag &#123; return nodeFlag&#123;dirty: true, gen: t.cachegen&#125;&#125; 当trie.cachegen - node.cachegen &gt; cachelimit时，就会把节点从内存中卸载（删除），用的是canUnload方法判断，每个继承node接口的类都实现了该方法：1234func (n *fullNode) canUnload(gen, limit uint16) bool &#123; return n.flags.canUnload(gen, limit) &#125;func (n *shortNode) canUnload(gen, limit uint16) bool &#123; return n.flags.canUnload(gen, limit) &#125;func (n hashNode) canUnload(uint16, uint16) bool &#123; return false &#125;func (n valueNode) canUnload(uint16, uint16) bool &#123; return false &#125; 卸载的作用是节省内存，所以说经过几次commit后，就会有节点被从内存中删除，删除是在hash方法中，也就是那个方法的第一个if1234567891011121314func (h *hasher) hash(n node, db *Database, force bool) (node, node, error) &#123; if hash, dirty := n.cache(); hash != nil &#123; if db == nil &#123; return hash, n, nil &#125; if n.canUnload(h.cachegen, h.cachelimit) &#123; cacheUnloadCounter.Inc(1) return hash, hash, nil &#125; if !dirty &#123; return hash, n, nil &#125; &#125; .... 获取hash是首先从节点的cache中获取，若存在的话，先不急着返回，首先判断是否可卸载，若可以，则卸载，注意卸载方式很有意思，不返回节点实例，而是返回一个hash表示节点，然后需要的时候在反序列化即可。注意若节点没有缓存hash值，则一定不进行卸载。 SecureTrie最后还有一个SecureTrie，是为了避免使用很长的key导致性能下降。SecureTrie包装了trie，所有的key都转化为keccak256计算的hash，但在数据库中存储原始key123456type SecureTrie struct &#123; trie Trie hashKeyBuf [common.HashLength]byte secKeyCache map[string][]byte //hash值和key值的映射 secKeyCacheOwner *SecureTrie &#125; 题图来自unsplash：https://unsplash.com/photos/hnw3Al47-KE]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA加密]]></title>
    <url>%2F2019%2F03%2F26%2FIDEA%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景IDEA全称International Data Encryption Algorithm，即国际数据加密算法。也是一种强大的加密算法，原本目的是取代DES，但是由于专利的存在，IDEA并没有DES使用广泛，但是如PGP加密程序就是用的IDEA。 IDEA和DES一样，都是可逆的，加解密算法相同，也利用了扩展和混淆思想 基本原理加密前明文进行分块，每块64位，秘钥位128位。加密时，首先将明文分为4组，每组16位，作为第一轮的输入，总共需要8轮。在每一轮中，从128位的秘钥中产生6组子秘钥，每组16位，用这6组子秘钥对输入的4组明文进行一系列操作，产生一轮的输出，并作为下一轮输入。8轮结束后进行一次变换，这次变换需要4个子秘钥，组合起来得到64位密文。 轮次每一轮有14步，基本流程如下（我们将4组输入定义为P1-P4，6组秘钥定义为k1-K6）： P1与K1相乘 P2与K2相加 P3与K3相加 P4与K4相乘 第1步结果与第2步结果异或 第2步结果与第4步结果异或 第5步结果与K5相乘 第6步结果和第7步结果相乘 第8步与K6相乘 第7步与第9步相加 第1步结果与第9步结果异或 第3步结果与第9步结果异或 第2步结果与第10步结果异或 第4步结果与第10步结果异或 第11，13，12，14分别为输出的第1-4组，示意图如下（图中红圈代表相乘运算，篮圈代表异或运算，绿圈代表相加运算： 注意步骤中的加或乘并不是简单的加与乘。对于加法，加之后用2^16(即65536)求模。对于乘法，乘之后用2^16 + 1(即65537)求模。求模主要是为了保证输出为16位。 子秘钥生成总体来看，前8轮每轮需要8个子秘钥，最后一个输出变换需要4个子秘钥 第一轮第一轮开始前我们有一组128位的原始秘钥，第一轮用前96位，每16位一组，公6组 第二轮第二轮先使用没有用的32位，共两组，还差4组64位秘钥。然后将原始秘钥循环左移25位，再取前64位，作为后四组秘钥。 第三轮上一轮还剩64位，作为该轮的前四组秘钥，然后再左移25位，选前32位作为剩下两组子秘钥。 后面几轮一次类推，每次都先使用上一轮未使用的，对于不够的先循环左移，再取秘钥 输出变换第8轮之后，有四组输出，然后进行输出变换，具体过程如下(将4组输出定义为R1-R4，4组秘钥定义为K1-K4)： R1与K1相乘 R2与K2相加 R3与K3相加 R4与K4相乘 注意，相加相乘还是和之前8轮里的加和乘一样操作。对于子秘钥，第8轮是刚好把128位的后96位用完。这一次，依旧先左移25位，然后取前64位作为4组秘钥 解密解密算法和加密算法是一样的，只是秘钥有所不同。 第i(1-9)轮的解密秘钥的前4四个子秘钥由加密过程中第10-i轮的前四个子秘钥得出 其中第1与第4个子秘钥为对应子秘钥关于2^16 + 1的乘法逆元 第 2 个和第 3 个子密钥的取法为：1.当轮数为 2，…，8 时，取相应的第 3 个和第 2 个的子密钥的2^16加法逆元 2.当轮数为 1 或 9 时，取相应的第 2 个和第 3 个子密钥对应的2^16加法逆元 第 5 和第 6 个密钥不变 简单实现java代码见这里 题图来自unsplash：https://unsplash.com/photos/WDOJ5256Cvk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DES加密]]></title>
    <url>%2F2019%2F03%2F25%2FDES%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[DES加密基本上属于学习加密算法的必修内容，这里也来梳理一下整个算法 背景DES全称Data Encryption Standard，也就是数据加密标准，也被称作Data Encryption ALgorithm，DEA，数据加密算法。分类上，它属于对称秘钥加密块密码。1976年被被美国联邦政府的国家标准局确定为联邦资料处理标准，随后再全世界广泛应用，成为一种通用加密算法。虽然现在这种算法已经不安全了，但是它使用的一些思想和理念深深影响可后来许多加密算法。这个算法的官方文档见这里 基本原理首先这是一种块加密算法，以64位为一块，输出的密文也是64位，加解密使用相同的秘钥，秘钥的长度是56位。对于秘钥，最初是64位的，不过在算法开始前会丢弃8位（第8,16,24,32,40,48,56,64位）。 之后算法的主要思想是对明文进行替换和变换（也称混淆和扩散），这是香农提出的思想，对后世的密码算法有重要影响。混淆是为了保证密文中不会出现明文线索，扩散则是增加明文的冗余度。 DES主要步骤如下： 将明文进行初始置换（IP） 将置换后的块分为左右两部分 对每一部分进行16轮加密 将加密后的两部分拼接起来，进行最终置换（FP），得到密文 如下图： 详细过程初始置换在加密前需要进行一次初始置换，称为IP，结束后有一个最终置换，FP，这两个操作在密码学上几乎没有任何意义，只是在最初设计时，为了简化输入输出数据库的过程而被纳入加密流程。 初始置换借助的是一个置换表，如下表： 表中数字代表明文中该位的位置，如第一个是58，则代表将明文中的第58位放到置换后的第一位，依次类推 DES的一轮每一轮包含秘钥变换，扩展置换，S盒替换，P盒替换和异或交换这几步。也被统称为费斯妥函数，也就是开始那张图中的F函数 秘钥变换首先秘钥有56位，这一步是从这56位中选取48位，作为这一轮的子秘钥。变换的基本规则是，将56位分为两部分，各28位，每一轮循环左移一位或两位，具体情况如下表： 移位后，具体如何挑选48位，是根据下表挑选： 和初始置换类似，表中数字也是表示的该位在原秘钥中的位置，如第一位14表示将秘钥的第14位写在这里，后面依次类推 由于是将56位变为48位，这一步也称为压缩置换 扩展置换经过初始置换后，得到两个32位的明文部分，称为左右明文，而这一步就是将右明文扩展到48位。具体过程如下 将32位明文分为8组，每组4位 将每组的4位扩展为6位，实际上是重复每组的第一和第4位，但不是简单的重复，每组之间是有依赖的，简单描述就是，原来每位右移移位，第一位由上一组的第四位填充（第一组由最后一组填充），第六位由下一组的第一位填充（最后一组由第一组填充） 由于这一步极有规律，可以表示为下面的变换表： 这个表使用和前面的一样，不在赘述 S盒替换前一步将32位明文变为48位，这样就可以和秘钥进行异或操作，最后得到48位的输出，S盒的作用就是将这48位变为32位，总共有8个S盒，每个盒接受6位输入，产生4位输出，随后将48位变为32位。 8个S盒如下 关于S盒的使用如下，首先把一个S和看做4行16列的表格，首先输入有6位，将其中间四位看做列号，首尾两位看做行号。如输入101101，则行号就是11=3，列号就是0110=6，则就取s盒第3行第6位（行列都从0开始计数），如使用第二个S盒就输出2，转为4位二进制就是0010 P盒替换经s盒替换后，输出32位结果，之后进行一次简单的P和置换，置换表如下： 异或与交换P和置换不改变位数，输出还是32位，之后将输出的32位与左明文进行异或（前面一系列步骤都是再对右明文处理），运算结果成为下一轮的右明文，而原来的有明文变成下一轮的左明文，这就是所谓的交换 最后一张图总结这几步： 最终置换这样重复16轮之后，得到一个64位的密文。然后在进行最终置换，置换表如下： 解密通过前文可知，加密过程是极其繁琐和复杂的，许多替换不深入研究是不能了解其意义的，但是对于解密而言，就体现了DES算法的强大之处，它的加密算法和解密算法是一样的，唯一区别就是那16轮中用的秘钥要反过来，如第1轮解密要用第16轮加密秘钥。不过由于秘钥是独立运算的，所以可以事先计算好16轮加密所使用的全部秘钥。 DES变体双重DES从字面意思很好理解，就是使用两个秘钥，进行两次加密。解密时反向操作两次即可。如果说单一DES加密破解需要搜索2^56个秘钥，则双重DES就需要搜索2^112个秘钥 双重DES的中间人攻击这是一种理论上的攻击，我们假设攻击者知道明文和密文，需要找到加密的两个秘钥。首先创建两张表，第一张表存储所有可能的密码对明文块加密后的结果，第二张表存储所有可能的密码对密文块解密后的结果，比对两张表的结果，相同的那两行所用的秘钥就是加密过程中用的秘钥。 三重DES三个秘钥的三重DES比较简单，就是用三个秘钥，加密三次 两个秘钥的三重DES使用两个秘钥，首先用秘钥K1执行加密，再用K2解密，再用K1加密，这种模式成为加解加模式（EDE） 题图来自unsplash：https://unsplash.com/photos/E7PlRr9ZfoM]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分组密码中的算法模式]]></title>
    <url>%2F2019%2F03%2F24%2F%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E4%B8%AD%E7%9A%84%E7%AE%97%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[算法模式是块加密中一系列步骤中基本，同一种加密方法采用不同的模式会产生不同的密文，安全性也不尽相同 电子密码薄（ECB）模式这是块加密中最简单的模式，如定义每块为64位，则将明文每64位分一组，之后对每组使用相同的秘钥和加密算法进行单独加密。解密时也是按64位分组，用同样的秘钥和加密方法进行解密即可。这种方法只适合于短消息，因为如果有重复信息，密文也会产生重复，易被攻击。加解密示意图如下： 加密块链接（CBC）模式这种模式的特点是对前一个块加密的结果会影响当前块的加密，确保了每条消息的唯一性。基本过程如下： 首先随机出一个与分组等长的初始文本块，然后用该文本块和第一个要加密的块做异或运算，并对运算结果进行加密 加密第二个块时，用第一个块加密之后的密文与第二个块进行异或运算，并对运算结果使用和第一块相同的算法和秘钥进行加密 依次类推，关键点是，在加密前使用上一块的密文与当前块做异或运算，之后再加密 可以抽象为下面数学表达(Ek表示加密函数，Ci表示明文的第几块)： 示意图如下： 对于解密，首先要了解一下异或运算的一个重要性质，就是连用两次异或后能恢复原值，即 A = A XOR B XOR B。由于这个性质异或就天然的有隐藏和还原信息的功能，所以解密算法如下 首先对密文块1进行解密，解密后再和加密时使用的初始文本块做异或运算就得到了原文. 对其他密文块也是一样，先解密，再与前一个密文块做异或，就得到原文 可以抽象为下面数学表达(Dk表示解密函数，Ci表示明文的第几块)： 示意图如下： 这种模式虽然很好的隐藏了信息，但是由于加密时都要依赖前面的信息，所以只能串行加密。不能并行运算。但是解密时可以并行运算 加密反馈（CFB）模式首先并不是所有程序都能处理数据库，如一个输入系统，需要以安全方式在信道中立即传输信息，这就要求数据用更小的单元进行加密（如8位，以byte长度）。所以出现了CFB模式。基本流程如下： 首先也需要一个64位的初始化向量，并将其放在移位寄存器中，并对该初始化向量进行加密，得到64位的初始密文 将加密过的初始化向量前j位和明文前j为进行异或，作为密文输出 将寄存器中的初始化向量左移j位，并将刚才加密的j位拼接到初始化向量尾部 然后重复上面步骤，即再对寄存器中的新初始化向量加密，随后再加密明文前j位，再进行左移个补充操作，最后再循环 示意图如下： 解密也很简单，由于明文是和移位寄存器中加密过的内容做异或后得到的密文，所以根据异或的性质，只需把密文和移位寄存器（初始内容还是加密时选定初始内容）中加密过的内容再做一次异或就得到明文（注意解密之后，寄存器中内容也要同步移位）示意图如下： 这种模式虽然和CBC很像，但是有一个优点，就是明文是不需要填充为分组的整数倍数长度的，明文和密文有相等长度，且较为灵活。 输出反馈（OFB）模式这种模式和CFB模型类似，但是没有CFB那么复杂，直接看一下示意图比较清晰： 可见主要区别是移位寄存器中的内容不再受密文的影响，而是每次独立进行加密。这样做的一大好处是某一位出错后，仅影响该位的密文，而和后面无关，前面CBC和CFB每次加密都会用到前面的信息，某一位出错将会影响后面所有输出。 解密过程也就相对较简单，将密文和初始向量加密后的信息做异或处理即可，随后也同步更新移位寄存器中内容。示意图如下 计数器(CTR)模式这种模式也被成为ICM(Integer Counter Mode)或SIC模式(Segmented Integer Counter) 这种模式类似于OFB模式，只不过将寄存器中的值换做一个计数器，计数器在任意时间产生不同的输出，之后对该输出进行加密，并用加密过的结果和明文异或，得到的结果作为密文。示意图（注意图中计数器的输出采用的是一个初始化向量和整数拼接的方式）如下： 解密方法和OFB类似，不在赘述，直接看示意图 这种方式的一大特点是可以并行加密，由于不同块的计数器输出是可以事先预测的，所以可以实现并行加密。 题图来自unsplash: https://unsplash.com/photos/pdRsf77OBoo]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protobuf学习及编码深入]]></title>
    <url>%2F2019%2F03%2F22%2FProtobuf%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%BC%96%E7%A0%81%E6%B7%B1%E5%85%A5%2F</url>
    <content type="text"><![CDATA[简介按照官方的介绍，Protocol buffers是一种与具体平台或者编程语言无关的可扩展的序列化语言，类似于XML或者JSON，由其对比XML而言，具有更小更快更简单的特点。接下来我们就来了解一下这个东西。 简单使用一般而言，使用步骤有三步。首先定义Protobuf模板文件，以.proto为后缀；然后生成特定语言的接口代码；最后利用接口代码进行序列化或者反序列操作。整体步骤和我们利用一些第三方库如Gson去操作json文件类似，下面就具体看一下这几个过程： 定义Protobuf文件下面这个例子是官方文档给出，定义了一个地址簿的数据结构：12345678910111213141516syntax = &quot;proto2&quot;;package tutorial;option java_package = &quot;code.protobuf&quot;;option java_outer_classname = &quot;AddressBookProtos&quot;;message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3;&#125;message AddressBook &#123; repeated Person people = 1;&#125; 具体语法我们稍后再介绍，首先可以看到，Protobuf文件的格式很像一些面向对象语言中类的定义，上面例子一个message就像一个类定义，类之间可以嵌套。AddressBook中有Person对象，Person中又有PhoneNumber对象。Person中也有一些基本类型如string和int。用过Gson之类的库解析json的应该感觉这和解析json时定义的类很像。 编译写好Protobuf文件后，就相当于写好一个模板文件，在不同平台或者不同语言间交互时都以这个文件为标准，但是还不能直接，根据具体的编程语言，我们还要有接口文件，我们可以利用官方给的编译工具生成我们需要的接口代码，以java语言为例：1protoc --java_out=src\ src\code\protobuf\addressbook.proto –java_out表示生成的接口文件路径，由于我们在Protobuf文件文件中定义了java_package，所以只需指定包所在目录即可，生成的文件会自动放在具体包下，最后指定Protobuf文件具体路径。生成的文件名在Protobuf文件中java_outer_classname字段定义。 接口操作执行完命令后，在code.protobuf包下生成了AddressBookProtos.java文件(要使用这个代码还需要导入相关库)。代码还是很长的，我们仅仅定义了一个简单的地址簿数据结构，就生成了近2000行代码，但是对于我们所使用的接口而言，生成的这个代码其实就是一个JavaBean类，它使用了建造者模式，当我们要构造一个Person对象时，如下：12345678AddressBookProtos.Person john = AddressBookProtos.Person.newBuilder().setId(1234) .setName("John") .setEmail("john@163.com") .addPhones(AddressBookProtos.Person.PhoneNumber.newBuilder() .setNumber("15463") .setType(AddressBookProtos.Person.PhoneType.HOME) .build()) .build(); 除了常用的get与set方法，还提供了：toString()方法用于转为有意义的字符串形式；isInitialized()方法用于检测所有必需字段是否设置；clear()方法用于清空所有字段；mergeFrom(Message other)用于合并两个对象。 当然作为序列化工具，生成的对象也提供了序列化和反序列化相关的方法：toByteArray()和parseFrom(byte[] data)。另外还可以直接操作流：writeTo(OutputStream output)和parseFrom(InputStream input)。 简单示例这里演示一个简单的跨语言的传输数据的例子。使用Go语言编写服务端，java编写客户端，从客户端向服务端发送数据。protobuf文件还使用上面的例子，这里在使用编译工具编译go语言的接口文件，protobuf文件不用做任何修改：1protoc --go_out=.\ src\code\protobuf\addressbook.proto java的客户端代码如下：123456789101112131415161718public static void main(String[] args) &#123; AddressBookProtos.Person person = AddressBookProtos.Person.newBuilder() .setName("jack") .setId(1) .setEmail("jack@163.com") .build(); AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .addPeople(person) .build(); try (Socket socket = new Socket("127.0.0.1",1234))&#123; OutputStream out = socket.getOutputStream(); out.write(book.toByteArray()); socket.shutdownOutput(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; go的服务端代码如下12345678910111213141516171819func main() &#123; listener,err:=net.Listen("tcp",":1234") if err!=nil&#123; log.Fatalln("Listen：",err.Error()) &#125; con,err:=listener.Accept() if err!=nil&#123; log.Fatalln("Accept：",err.Error()) &#125; result,err:=ioutil.ReadAll(con) if err!=nil&#123; log.Fatalln("ReadAll：",err.Error()) &#125; book := &amp;tutorial.AddressBook&#123;&#125; if err := proto.Unmarshal(result, book); err != nil &#123; log.Fatalln("Failed to parse address book:", err) &#125; fmt.Println(*book.People[0].Email)&#125; 详细语法首先在文件第一行在指定语法版本，如：syntax = “proto2”; 基本字段类型message中每个字段都要指定数据类型。如下表： 分配字段编号如例子中所示，每个字段都要分配一个独一无二编号，编号范围在1~536,870,911，主要是为了标记字段，并且不能改变，需要注意的是19000到19999是不能使用的。关于编号，官方文档建议，对于频繁使用的元素应当使用1到15的编号，因为这些序号被编码为1byte，而16到2047被编码为2byte。 字段约束有以下几个修饰词:123required：使用时必须被指定的字段optional：可以不被指定，但是最多只能指定一个repeated：可以出现次的，也可以不出现，相当于数组的概念。官方建议使用[packed=true]选项提高编码效率：repeated int32 samples = 4 [packed=true]; 了解完字段类型，编号，约束词以后，我们可以得到message中一个字段的完整定义:12字段约束 类型 名称 = 字段编号;required string query = 1; 注释类似于java等语言的注释风格：使用// 或/**/ 保留字对于以删除的字段，若是后面再被使用，可能会导致问题，所以可以用reserved标记出来，若被使用编译器将报错。reserved使用方法如下：1234message Foo &#123; reserved 2, 15, 9 to 11; reserved &quot;foo&quot;, &quot;bar&quot;;&#125; 注意字段和编号不能混合在一起用reserved标记 可选字段的默认值对于optional修饰的字段，若未定义，会有一个与字段类型对应的默认值，如string为空，bool为false等，我们也可以指定默认值如下所示：1optional int32 result_per_page = 3 [default = 10]; 枚举类型定义如下：123456789enum Corpus &#123; UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; &#125; 在一个枚举中，可以指定一些相同值的成员，这样会被解析为别名，同时需要加上option allow_alias = true123456enum EnumAllowingAlias &#123; option allow_alias = true; UNKNOWN = 0; STARTED = 1; RUNNING = 1;&#125; 若在一个message中使用另一个message的enum可以以MessageType.EnumType的形式调用 导包protobuf也有导包的概念，如果要从一个proto文件中引用另一个proto文件中的一个message，需要使用import关键字进行导包。注意在编译时使用-I指定搜索包的路径，否则只会默认搜索当前目录下的文件 嵌套定义12345678message SearchResponse &#123; message Result &#123; required string url = 1; optional string title = 2; repeated string snippets = 3; &#125; repeated Result result = 1;&#125; 上面例子在一个message中定义了另一个message，使用时利用SearchResponse.Result引用内部定义的message Extensions扩展实际上是一个占位符，它代表未在原始文件中定义的字段123message Foo &#123; extensions 100 to 199;&#125; 其他用户可以使用extensions指定的字段为原来的message添加新字段123extend Foo &#123; optional int32 bar = 126;&#125; 访问extension也有特殊的api，示例：123456789101112//序列化AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .setExtension(AddressBookProtos.bar,10) .build();byte[] out = book.toByteArray();//反序列化ExtensionRegistry registry = ExtensionRegistry.newInstance();registry.add(AddressBookProtos.bar);AddressBookProtos.AddressBook ob = AddressBookProtos.AddressBook.parseFrom(out,registry);System.out.println(ob.hasExtension(AddressBookProtos.bar)); 注意在反序列化时候要注册需要解析的extension，并作为参数传入parseFrom Oneofoneof的出现是为了实现这样的需求：一个message中有多个成员，但同一时间只能有一个成员被赋值。12345oneof test&#123; string a = 4; string b = 5; string c = 6; &#125; 1234567891011121314AddressBookProtos.Person p2 = AddressBookProtos.Person.newBuilder() .setName("tom") .setId(2) .setEmail("tom@163.com") .setA("hello") .setB("world") .build();AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .addPeople(p2) .build(); byte[] out = book.toByteArray();AddressBookProtos.AddressBook ob = AddressBookProtos.AddressBook.parseFrom(out);System.out.println(ob.getPeople(0).hasA());System.out.println(ob.getPeople(0).hasB()); 可见我们虽然同时对A，B都进行了赋值，但是只有B被赋值成功，也就是同时只有一个成员可以被赋值需要有以下几点注意： 对一个成员赋值，会自动清除其他已赋值的成员 extension不支持oneof oneof不能被修饰为repeated 实际上对于oneof修饰的一组成员，完全可以把它们当做普通的optional成员看待，只不过这几个成员之间又互相依赖关系 另外，oneof： 安全的移除或添加字段，但会可能会导致数据丢失 可以删除一个oneof，也可能会导致数据丢失 可以分割或合并oneof，效果类似移除或添加字段 maps一般意义上的映射数据类型。1map&lt;string, Project&gt; projects = 3; key可以使任何整数或string（也就是浮点和字节类型除外），枚举也不能做为key。value可以是除map外的任何类型。注意事项： extension不支持map map不能有repeated, optional, 或 required修饰 map是无序的 map等效于下面的实现：123456message MapFieldEntry &#123; optional key_type key = 1; optional value_type value = 2;&#125;repeated MapFieldEntry map_field = N; Message更新更新需要遵循以下规则 不要改变已有字段的编号 新字段只能使用optional或repeated修饰。这样也很好理解，旧的代码序列化的数据仍然可以被新代码解析，否则会由于缺少required而报错 非required修饰的字段可以被移除，但是注意被删除的字段所使用的编号不能再次使用 只要类型或者编号不便，非required字段可以转为extension int32, uint32, int64, uint64 和 bool 是可以互相兼容的，也就是可以互相转换 sint32和sint64彼此兼容，但不和其他整数类型兼容 string和bytes互相兼容，前提是使用UTF-8编码 fixed32和sfixed32、fixed64、sfixed64是兼容的 optional与repeated是兼容的，若输入的是repeated，在解析为optional时，以最后一个输入为主，或合并输入 可以改变默认值，但要注意不同版本的protobuf文件的默认不同时会在带来潜在的冲突 enum 和 int32, uint32, int64, uint64是兼容的 将optional改为oneof是安全的 packages在proto文件中指定package字段来防止名字冲突。在java中，除非指定java_package字段，否则会以package作为包名 自定义选项 java_package ：指定生成的java文件所在的包 java_outer_classname ：指定生成的java文件名 optimize_for ：优化选项，有SPEED, CODE_SIZE, 和 LITE_RUNTIME三种选择。SPEED是默认选项，对代码进行优化。CODE_SIZE可以减小生成代码量，但解析速度会下降，LITE_RUNTIME生成的代码最少，但会失去一些特性4.deprecated：被标记为true的字段表示不再使用：optional int32 old_field = 6 [deprecated=true]; proto3语法proto3的语法和2有很多相似之处，所以这里只介绍一些不同点 版本号当然版本号要更改为proto31syntax = &quot;proto3&quot;; 修饰词移除了required修饰词；所有字段默认都是singular，也就是原来的optional，但是不能显式的指定为singularrepeated被保留了 正常情况下一个message书写如下：1234567syntax = &quot;proto3&quot;;message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3;&#125; 默认值取消了default选项，也就是说默认值只能有系统默认指定，如字符串为空串，bool型为false，数字为0等。还有对于枚举类，默认是编号为0的成员。 枚举类型必须有一个编号为0的成员来作为其第一个成员。 未知字段在3.5版本之前，不能被解析的字段会被直接抛弃，但是在3.5版本之后，这种特性又回归到proto2上，即不能被解析的字段仍然会保留到下次序列化的输出中 any用于替代extensions，不过尚在开发中 编码Varints规则protobuf的编码基础是Varints，它是将整数序列化为一个或多个byte的方法。 Varints规则是用每byte的第7位存储值，第8位为标志位，若标志位为1，表示后面还有数据，若为0，表示该byte为最后一个。最后Varints采用小端存储。下面举一个例子：123456以整数300为例，300的二进制表示如下： 100101100按小端存储并每7位一组： 0101100 0000010再加上标志位，最终表示如下： 10101100 00000010 Varints的优点是，由于标志位存在，省去了编码长度的表示，其次越小的数编码越短，但是由于标志位的存在，也牺牲了容量，如4byte实际可用表示数值的只有28位 基本编码规则我们首先看一下message中每个成员变量的定义1int32 a = 1; 有三部分组成，变量类型，变量名和变量序号。其中变量名只是为了帮助我们做识别，在编码时不会写入，仅仅用变量序号作为标识，所以也就有了在更新message时序号不能复用的规则，以及可以安全地添加新成员（没有被识别的会直接跳过）。 在编码中，成员变量是以键值对形式出现的，键有两部分组成：成员序号加上成员类型代码，具体代码如下 总共有6种代码，其中group使用的两个代码已被弃用，但是依旧保留。这6个代码需要3位二进制表示，所以键的组成是：字段编号+类型代码（加好表示拼接，并不是运算），示例如下：123456789当我们有一个inst32类型的成员a，编号为1，被赋值为150时由于是int32类型，根据上图采用varint规则，首先对150进行Varints规则编码（过程略）： 10010110 00000001由于是int32类型，类型代码为0，编号为1，类型代码采用三位二进制表示为000，二者拼接之后如下： 0001000所以a的最终编码为 0001000 10010110 00000001改用16进制表示如下 08 96 01 其他类型规则sint32, sint64对于Varints规则不适用与存储负数，负数最高位为1，造成编码极大的浪费，为了节省空间，引入了ZigZag编码格式，基本思想就是将有符号整数转为无符号整数。转换规则如下：12(n &lt;&lt; 1) ^ (n &gt;&gt; 31) #sint32(n &lt;&lt; 1) ^ (n &gt;&gt; 63) #sint64 示例如下： 转为无符号的整数后，再用varints编码即可。 64-bit 和 32-bit 类型这两种分有不同的类型代码，而且编码时不进行其他转换，直接以64位或32位原始存储（注意也是小端存储），读取时根据类型代码直接读取64位或32位 Strings类型代码2表示一类Length-delimited数据。这种编码类型还附带有长度信息，就是在键值之间附加一个用varints编码的长度编码，例子如下：123456789我们有一个string类型的变量b，编号为2，赋值为testing首先testing的utf-8编码如下： 74 65 73 74 69 6e 67长度为7，varints格式编码如下： 00000111编号加类型代码拼接后如下： 00010010最后组合在一起用十六进制表示如下： 12 07 74 65 73 74 69 6e 67 除了表示字符串这种简单信息，还可以表示其他message，如下：123456789101112message Test3 &#123; optional Test1 c = 3;&#125;其中Test1：message Test1 &#123; optional int32 a = 1;&#125;我们对Test1中a赋值为150，上面已经计算过，最后编码为 08 96 01对于Test1类型的变量c表示如下：首先原始数据就是08 96 01，长度为3，编号为3，类型代码为2，组合起来就是 1a 03 08 96 01 packed在proto3中packed为默认的，在proto2中需要手动指定。使用proto3 模式将会使编码更加紧凑（主要针对repeated 类型）。设想，对于一个repeated类型的成员，他们有多个值时，虽然值不同，前键都是相同的，我们可以减少键的数量，如下例：12345假设有一个int32类型的变量d，序号为4，是一个repeated类型，我们赋了4个值，分别是3,270,86942.使用packed模式后，如下22 06 03 8E 02 9E A7 05注意22是编号加类型代码（为2，指packed repeated fields），06表示数据长度后面实际数据，都是varints编码，但是互有区分 顺序编解码顺序和字段顺序无关，由键值对保证即可。未知字段会写在已知字段后。]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Playfair密码]]></title>
    <url>%2F2019%2F03%2F20%2FPlayfair%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[背景这种加密方法是1854年Charles Wheatstone发明的，由Lord Playfair推广，所以命名为Playfair密码。它在一战和二战中都有使用，虽然在一战中就被破译，但是由于使用简单，可以用来保护一些敏感但不很关键的信息，即使被破译，信息也已经过时。 详细流程创建矩阵这种密码使用一个5*5的矩阵作为一个密码表，用作加密解密时的秘钥。这个矩阵由一个关键词生成，首先将关键词从左到右，从上到下填入矩阵，遇到重复元素则省略，写完之后按照字母表顺序，将未出现的字母填充到剩余位置，知道整个矩阵被填满。 如以PLAYFAIREXAMPLE为关键词，生成的矩阵如下： 你可能注意到，密码表中缺少J，由于只有25个空位，对于字母大于25的语言，可以将某两个合并，或者省去出现频率少的，这里把i和j进行了合并 加密加密之前首先将明文两两分组），对每一组分别进行以下处理 在密码表中找到每组中两个字母的位置 若果两个字母相同或组中只有一个字母，则插入一个字母，如X或Q（如果最后一个字母或者重复的字母是X，可以添加Q，替换方法可自定义） 如果两个字母在密码表的同一行，则用这两个字母右边的字母进行替换，如(I,E)替换为(R,X)。我们定义第一列是最后一列的右边 如果两个字母在密码表的同一列，则用这两个字母的下方字母进行替换，如(E,O)替换为(D,V)。我们定义第一行是最后一行的下边 如果两个字母不在同一行同一列，则用对角线上的字母进行替换，至于是行替换或列替换可以自行定义。如(M,Y)替换为(X,F)，使用的是行替换 解密解密就很简单了，基本就是加密的逆过程，还是利用密码表，如在同一行的话，用左边替换，同一列用上面的替换，在对角线上的还是不变。具体过程见后面实现。 示例如还以PLAYFAIREXAMPLE为关键词，明文为MYNAMEISTOM，加密过程如下： 生成矩阵，如上图 分组：MY NA ME IS TO MX (最后一个单独字母补X) 根据密码表替换 XF OL IX MK VK IM 最后密文为： XFOLIXMKVKIM 简单实现这里只是简单实现了Playfair密码原理，有些地方如包含标点符号，非英文字母的情况并没有处理，有兴趣的可以自行修改123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125public class PlayFair &#123; char[][] table = new char[5][5]; //密码表 PlayFair(String key)&#123; generateTable(key);//根据关键字生成密码表 &#125; private void generateTable(String key)&#123; key = key.replaceAll(" ","").toUpperCase(); char[] keys = key.toCharArray(); int count = 0; char alphabet = 'A'; ArrayList&lt;Character&gt; list = new ArrayList&lt;&gt;(); for (int i = 0;i&lt;5;i++)&#123; for (int j = 0;j&lt;5;j++)&#123; while(count &lt; keys.length &amp;&amp; list.contains(keys[count]))&#123; //寻找关键字中不重复的字母 count++; &#125; if (count &lt; keys.length)&#123; table[i][j] = keys[count]; list.add(keys[count]); count++; &#125;else&#123; while (alphabet &lt;= 'Z' &amp;&amp; (list.contains(alphabet) || alphabet == 'J'))&#123; //按顺序从字母表中填充 alphabet++; &#125; table[i][j] = alphabet; alphabet++; &#125; &#125; &#125; &#125; public String encryption(String msg)&#123; //加密算法 msg = msg.replaceAll(" ","").toUpperCase(); char[] msgs = msg.toCharArray(); StringBuffer result = new StringBuffer(); for (int i = 0;i&lt;msgs.length;i++)&#123; char a = msgs[i];//获取分组第一个字母 i++; char b; if (i&lt;msgs.length)&#123; //判读是否越界 if (msgs[i] == a)&#123; //是否重复 if (a == 'X')&#123; //若是X重复，添加Q b = 'Q'; &#125;else&#123; b = 'X'; &#125; i--; &#125;else&#123; b = msgs[i]; &#125; &#125;else&#123; //越界，就是最后只剩一个字母 if (a == 'X')&#123; //若最后一个是X，补Q b = 'Q'; &#125;else&#123; b = 'X'; &#125; &#125; int[] locA = find(a); //寻找分组第一个字母位置 int[] locB = find(b); //寻找分组第二个字母位置 if(locA[0] == locB[0])&#123; //若在同一行 a = locA[1]+1&lt;5?table[locA[0]][locA[1]+1]:table[locA[0]][0]; b = locB[1]+1&lt;5?table[locB[0]][locB[1]+1]:table[locB[0]][0]; &#125;else if(locA[1] == locB[1])&#123; //若在同一列 a = locA[0]+1&lt;5?table[locA[0]+1][locA[1]]:table[0][locA[1]]; b = locB[0]+1&lt;5?table[locB[0]+1][locB[1]]:table[0][locB[1]]; &#125;else&#123; //不在同一行同一列，行替换 a = table[locA[0]][locB[1]]; b = table[locB[0]][locA[1]]; &#125; result.append(a); result.append(b); &#125; return result.toString(); &#125; public String decrypt(String msg)&#123; //解密算法 msg = msg.replaceAll(" ","").toUpperCase(); char[] msgs = msg.toCharArray(); if (msgs.length%2!=0)&#123; //密文不是偶数个，报错 return "error: The length of ciphertext is odd"; &#125; StringBuffer result = new StringBuffer(); for (int i = 0;i&lt;msgs.length;i++)&#123; char a = msgs[i]; i++; char b = msgs[i]; int[] locA = find(a);//寻找分组第一个字母位置 int[] locB = find(b);//寻找分组第二个字母位置 if(locA[0] == locB[0])&#123; //若在同一行 a = locA[1]-1&gt;-1?table[locA[0]][locA[1]-1]:table[locA[0]][4]; b = locB[1]-1&gt;-1?table[locB[0]][locB[1]-1]:table[locB[0]][4]; &#125;else if(locA[1] == locB[1])&#123; //若在同一列 a = locA[0]-1&gt;-1?table[locA[0]-1][locA[1]]:table[4][locA[1]]; b = locB[0]-1&gt;-1?table[locB[0]-1][locB[1]]:table[4][locB[1]]; &#125;else&#123; //不在同一行同一列 a = table[locA[0]][locB[1]]; b = table[locB[0]][locA[1]]; &#125; result.append(a); result.append(b); &#125; return result.toString(); &#125; private int[] find(char c)&#123; //寻找字母在表中位置 if (c == 'J')//对于J当做I处理 c = 'I'; for (int i = 0;i&lt;5;i++)&#123; for (int j = 0;j&lt;5;j++)&#123; if (table[i][j] == c) return new int[]&#123;i,j&#125;; &#125; &#125; return new int[]&#123;-1,-1&#125;; &#125; public static void main(String[] args) &#123;//测试代码 PlayFair p = new PlayFair("PLAYFAIREXAMPLE"); String msg = p.encryption("MYNAMEISTOM"); System.out.println("ciphertext：" + msg); System.out.println("plaintext：" + p.decrypt(msg)); &#125;&#125; 小结本质上Playfair密码仍然是替换型的密码算法。与一般的替换算法相比，他的替换不固定，每个字母都有可能替换为任意一个其他字母。另外实现简单，一个不同秘钥生成不同密码表，产生不同的替换可能。但是它依然可以被破解，首先它是按照顺序读取的，密文与明文基本上一一对应，从而也暴露的密文结构；其次，密码表最后填充时是按照字母表顺序填充，可借助字母出现频率构造密码表，一旦一部分被构造出来，剩下的很容易破解；]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rlp编码学习]]></title>
    <url>%2F2019%2F03%2F19%2Frlp%E7%BC%96%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[RLP的全称是Recursive Length Prefix，是以太坊实现中普遍使用的一种序列化方法，在黄皮书的附录B中有详细的定义，我们这里也简要学习一下 源数据RLP定义了两种源数据，一种是一维的字节数组；另外一种是多维字节数组，也就是一维数组的嵌套。所有要序列化的数据类型，都要有一定的方法转为上述两种格式，转换的方法可以根据不同的实现自己定义。在黄皮书中给出了源数据的定义： RLP定义函数定义如下： 可见分别定义了两个函数，对应了上一节中的两种源数据，分别解释一下这两个函数 源数据为一维字节数组当数据为简单的一维字节数组时，有以下三种序列化规则: 当只含有一个字节时，而且这个字节又小于128，则不做任何处理，直接输出，对应上图第一种情况 当字节数组的长度小于56时，则加上一个前缀，这个前缀等于128+字节数组长度，对应上图第二种情况 若不符合上述两种情况，则加上这样两个前缀，第一个前缀等于183+字节数组长度在大端表示时的长度，第二个前缀为字节数组长度的大端表示，对应上图第三种情况（所谓大端表示就是将高位字节排放在内存的低地址端，0x1234表示为00 00 12 34，BE函数就是去除前面的零，也可以理解为实际长度） 源数据为嵌套的多维字节数组当数据为嵌套的多维数组形式时，有以下两种序列化规则： 首先对数组中每一个子元素都递归使用上一小节中的规则序列化，注意序列化时对象都要为一维字节数组，若子元素也是嵌套格式，则递归调用，之后将每个子元素序列化结果拼接起来。对于拼接后的长度： 若长度小于56，则加上这样一个前缀，这个前缀等于192+拼接后的长度，对应上图第一种情况 若长度大于等于56，则加上这样两个前缀，第一个前缀等于247+拼接后字节数组长度在大端表示时的长度，第二个前缀为拼接后的长度的大端表示，对应上图第二种情况 源数据是标量数据首先RLP只能用于处理正整数，处理是要先用BE函数处理，去掉前导0后，当做字节数组处理，如下图： 解码实际上了解到编码规则后，解码就很简单，关键就是第一个字节，这个字节标识使用哪种情况编码 当位于[0,128)区间时，对应源数据是一维字节数组的第一种情况，就是单一字节 当位于[128,184)区间时，对应源数据是一维字节数组的第二种情况，就是长度小于56的一维字节数组 当位于[184,192)区间时，对应源数据是一维字节数组的第三种情况，这时观察第二个前缀，第二个前缀长度等于第一个字节减去183，然后计算原始数据的真正长度 当位于[192,247)区间时，对于源数据是多维字节数组的第一种情况，就是拼接长度小于56，递归解析其后数据 当位于[247,256)区间时，对于源数据是多维字节数组的第二种情况，类似于第三条规则，先实际计算出第二个前缀的长度，在解析数原始数据长度，在递归解析出原始数据 源码解析源码主要集中在go-ethereum\rlp目录下，再去除一些测试代码，实际功能代码并不多，关键如下：1234decode.go //解码器，就是反序列化encode.go //编码器，就是序列化raw.go //未解码的RLP数据typecache.go //类型缓存， 类型缓存记录了类型-&gt;(编码器|解码器)的内容。 typecache由于go-ethereum是用go语言实现的，而go语言没有方法重载，所以对于不同类型的数据要手动指定需要的编解码器。这个类主要功能是给我们返回一个typeinfo类型的对象，这个对象保存在对应数据类型的编解码方法1234type typeinfo struct &#123; decoder writer&#125; 去创建一个typeinfo需要从cachedTypeInfo方法开始：1234567891011121314151617181920212223242526272829303132333435363738// go-ethereum\rlp\typecache.gofunc cachedTypeInfo(typ reflect.Type, tags tags) (*typeinfo, error) &#123; typeCacheMutex.RLock() info := typeCache[typekey&#123;typ, tags&#125;] //尝试从缓存中国区 typeCacheMutex.RUnlock() if info != nil &#123; //获取成功 return info, nil &#125; typeCacheMutex.Lock() //加锁，避免多线程多次创建 defer typeCacheMutex.Unlock() return cachedTypeInfo1(typ, tags)&#125;func cachedTypeInfo1(typ reflect.Type, tags tags) (*typeinfo, error) &#123; key := typekey&#123;typ, tags&#125; info := typeCache[key]//再次尝试获取，确保只创建一次 if info != nil &#123; //获取成功 return info, nil &#125; typeCache[key] = new(typeinfo) //创建一个空对象 info, err := genTypeInfo(typ, tags) //实际创建对象 if err != nil &#123; //创建失败 delete(typeCache, key) return nil, err &#125; *typeCache[key] = *info //存储到map中 return typeCache[key], err&#125;func genTypeInfo(typ reflect.Type, tags tags) (info *typeinfo, err error) &#123; info = new(typeinfo) if info.decoder, err = makeDecoder(typ, tags); err != nil &#123; return nil, err &#125; if info.writer, err = makeWriter(typ, tags); err != nil &#123; return nil, err &#125; return info, nil&#125; 可见对每种类型，都是单例模式。上述代码中实际创建编解码器的方法是makeDecoder和makeWriter。这两个方法详见下文 encode对于编码器的使用，一般调用Encode函数：123456789101112func Encode(w io.Writer, val interface&#123;&#125;) error &#123; if outer, ok := w.(*encbuf); ok &#123;//判断是否是encbuf类型的writer return outer.encode(val) &#125; eb := encbufPool.Get().(*encbuf) //从并发变量池中获取一个encbuf对象 defer encbufPool.Put(eb) eb.reset() //清空原有数据 if err := eb.encode(val); err != nil &#123; //编码 return err &#125; return eb.toWriter(w)&#125; 编码的核心操作在encbuf的encode方法：12345678func (w *encbuf) encode(val interface&#123;&#125;) error &#123; rval := reflect.ValueOf(val) ti, err := cachedTypeInfo(rval.Type(), tags&#123;&#125;) if err != nil &#123; return err &#125; return ti.writer(rval, w)&#125; 这里就接上了上一节typecache中的方法，这里通过makeWriter确定编码器1234567891011121314151617181920212223242526272829303132333435func makeWriter(typ reflect.Type, ts tags) (writer, error) &#123; kind := typ.Kind() switch &#123; case typ == rawValueType: return writeRawValue, nil case typ.Implements(encoderInterface): return writeEncoder, nil case kind != reflect.Ptr &amp;&amp; reflect.PtrTo(typ).Implements(encoderInterface): return writeEncoderNoPtr, nil case kind == reflect.Interface: return writeInterface, nil case typ.AssignableTo(reflect.PtrTo(bigInt)): return writeBigIntPtr, nil case typ.AssignableTo(bigInt): return writeBigIntNoPtr, nil case isUint(kind): return writeUint, nil case kind == reflect.Bool: return writeBool, nil case kind == reflect.String: return writeString, nil case kind == reflect.Slice &amp;&amp; isByte(typ.Elem()): return writeBytes, nil case kind == reflect.Array &amp;&amp; isByte(typ.Elem()): return writeByteArray, nil case kind == reflect.Slice || kind == reflect.Array: return makeSliceWriter(typ, ts) case kind == reflect.Struct: return makeStructWriter(typ) case kind == reflect.Ptr: return makePtrWriter(typ) default: return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ) &#125;&#125; 就是简单的根据不同的类型创建不同的编码方法，以string为例：1234567891011121314151617181920func writeString(val reflect.Value, w *encbuf) error &#123; s := val.String() if len(s) == 1 &amp;&amp; s[0] &lt;= 0x7f &#123;//只有一个字符，且小于128 w.str = append(w.str, s[0]) &#125; else &#123; w.encodeStringHeader(len(s))//添加前缀 w.str = append(w.str, s...) &#125; return nil&#125;func (w *encbuf) encodeStringHeader(size int) &#123; if size &lt; 56 &#123; //长度小于56 w.str = append(w.str, 0x80+byte(size))//前缀是128+长度 &#125; else &#123; //其他情况 sizesize := putint(w.sizebuf[1:], uint64(size)) //将长度的大端表示写入sizebuf w.sizebuf[0] = 0xB7 + byte(sizesize) //第一个前缀183+字符串长度在大端表示后的长度 w.str = append(w.str, w.sizebuf[:sizesize+1]...)//拼接第二个前缀，字符串长度的大端表示 &#125;&#125; 详细过程见注释，基本过程和RLP定义的一样。对于结构体可能有些特殊：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func makeStructWriter(typ reflect.Type) (writer, error) &#123; fields, err := structFields(typ) //分析结构体每个字段，根据情况指定每个字段的编码方法 if err != nil &#123; return nil, err &#125; writer := func(val reflect.Value, w *encbuf) error &#123; //编码器具体方法 lh := w.list() for _, f := range fields &#123; if err := f.info.writer(val.Field(f.index), w); err != nil &#123; return err &#125; &#125; w.listEnd(lh) return nil &#125; return writer, nil&#125;// go-ethereum\rlp\typecache.gofunc structFields(typ reflect.Type) (fields []field, err error) &#123; for i := 0; i &lt; typ.NumField(); i++ &#123; if f := typ.Field(i); f.PkgPath == "" &#123; // 若果是可导出的，也就是首字母大写，PkgPath为空，不可导出会返回包名 tags, err := parseStructTag(typ, i)//解析每个字段的标签，就是字段后``中定义的 if err != nil &#123; return nil, err &#125; if tags.ignored &#123; continue &#125; info, err := cachedTypeInfo1(f.Type, tags)//根据类型获取cachedTypeInfo，包含编解码器 if err != nil &#123; return nil, err &#125; fields = append(fields, field&#123;i, info&#125;) &#125; &#125; return fields, nil&#125;func parseStructTag(typ reflect.Type, fi int) (tags, error) &#123; f := typ.Field(fi) var ts tags for _, t := range strings.Split(f.Tag.Get("rlp"), ",") &#123; switch t = strings.TrimSpace(t); t &#123; case "": case "-": ts.ignored = true case "nil": ts.nilOK = true case "tail": ts.tail = true if fi != typ.NumField()-1 &#123; return ts, fmt.Errorf(`rlp: invalid struct tag "tail" for %v.%s (must be on last field)`, typ, f.Name) &#125; if f.Type.Kind() != reflect.Slice &#123; return ts, fmt.Errorf(`rlp: invalid struct tag "tail" for %v.%s (field type is not slice)`, typ, f.Name) &#125; default: return ts, fmt.Errorf("rlp: unknown struct tag %q on %v.%s", t, typ, f.Name) &#125; &#125; return ts, nil&#125; 结构体类型的虽然复杂，但也是具体到每个字段执行不同的序列化方法，最后进行拼接。 decode对于解码器一般调用Decode函数：1234567891011121314151617181920212223242526func Decode(r io.Reader, val interface&#123;&#125;) error &#123; return NewStream(r, 0).Decode(val)&#125;func (s *Stream) Decode(val interface&#123;&#125;) error &#123; if val == nil &#123; return errDecodeIntoNil &#125; rval := reflect.ValueOf(val) rtyp := rval.Type() if rtyp.Kind() != reflect.Ptr &#123; //判断是否为指针类型 return errNoPointer &#125; if rval.IsNil() &#123; return errDecodeIntoNil &#125; info, err := cachedTypeInfo(rtyp.Elem(), tags&#123;&#125;) //获取编解码方法 if err != nil &#123; return err &#125; err = info.decoder(s, rval.Elem())//解码 if decErr, ok := err.(*decodeError); ok &amp;&amp; len(decErr.ctx) &gt; 0 &#123; decErr.ctx = append(decErr.ctx, fmt.Sprint("(", rtyp.Elem(), ")")) &#125; return err&#125; 注意decode的逻辑是从Stream中获取源数据，最后解析到val中，所以需要val是一个指针类型，接下来又回到typecache中，通过判断val的类型获取所需的解码器。12345678910111213141516171819202122232425262728293031323334func makeDecoder(typ reflect.Type, tags tags) (dec decoder, err error) &#123; kind := typ.Kind() switch &#123; case typ == rawValueType: return decodeRawValue, nil case typ.Implements(decoderInterface): return decodeDecoder, nil case kind != reflect.Ptr &amp;&amp; reflect.PtrTo(typ).Implements(decoderInterface): return decodeDecoderNoPtr, nil case typ.AssignableTo(reflect.PtrTo(bigInt)): return decodeBigInt, nil case typ.AssignableTo(bigInt): return decodeBigIntNoPtr, nil case isUint(kind): return decodeUint, nil case kind == reflect.Bool: return decodeBool, nil case kind == reflect.String: return decodeString, nil case kind == reflect.Slice || kind == reflect.Array: return makeListDecoder(typ, tags) case kind == reflect.Struct: return makeStructDecoder(typ) case kind == reflect.Ptr: if tags.nilOK &#123; return makeOptionalPtrDecoder(typ) &#125; return makePtrDecoder(typ) case kind == reflect.Interface: return decodeInterface, nil default: return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ) &#125;&#125; 以string为例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192func decodeString(s *Stream, val reflect.Value) error &#123; b, err := s.Bytes() if err != nil &#123; return wrapStreamError(err, val.Type()) &#125; val.SetString(string(b)) //还原为string return nil&#125;func (s *Stream) Bytes() ([]byte, error) &#123; kind, size, err := s.Kind() if err != nil &#123; return nil, err &#125; switch kind &#123; case Byte: s.kind = -1 return []byte&#123;s.byteval&#125;, nil case String: b := make([]byte, size) //根据数据长度指定byte数组 if err = s.readFull(b); err != nil &#123; //读取原始数据 return nil, err &#125; if size == 1 &amp;&amp; b[0] &lt; 128 &#123; return nil, ErrCanonSize &#125; return b, nil default: return nil, ErrExpectedString &#125;&#125;func (s *Stream) Kind() (kind Kind, size uint64, err error) &#123; var tos *listpos if len(s.stack) &gt; 0 &#123; tos = &amp;s.stack[len(s.stack)-1] &#125; if s.kind &lt; 0 &#123; s.kinderr = nil if tos != nil &amp;&amp; tos.pos == tos.size &#123; return 0, 0, EOL &#125; s.kind, s.size, s.kinderr = s.readKind() //读取原始数据类型以及长度 if s.kinderr == nil &#123; if tos == nil &#123; if s.limited &amp;&amp; s.size &gt; s.remaining &#123; s.kinderr = ErrValueTooLarge &#125; &#125; else &#123; if s.size &gt; tos.size-tos.pos &#123; s.kinderr = ErrElemTooLarge &#125; &#125; &#125; &#125; return s.kind, s.size, s.kinderr&#125;func (s *Stream) readKind() (kind Kind, size uint64, err error) &#123; b, err := s.readByte() //读第一个byte if err != nil &#123; if len(s.stack) == 0 &#123; switch err &#123; case io.ErrUnexpectedEOF: err = io.EOF case ErrValueTooLarge: err = io.EOF &#125; &#125; return 0, 0, err &#125; s.byteval = 0 switch &#123; //根据第一字节的只判断原始数据类型 case b &lt; 0x80: //原始数据只有一个byte，且小于128 s.byteval = b return Byte, 0, nil case b &lt; 0xB8: //原始数据长度小于56 //返回的第二个数据获得原始数据长度 return String, uint64(b - 0x80), nil case b &lt; 0xC0: size, err = s.readUint(b - 0xB7) if err == nil &amp;&amp; size &lt; 56 &#123; err = ErrCanonSize &#125; return String, size, err case b &lt; 0xF8: return List, uint64(b - 0xC0), nil default: size, err = s.readUint(b - 0xF7) if err == nil &amp;&amp; size &lt; 56 &#123; err = ErrCanonSize &#125; return List, size, err &#125;&#125; 可见流程就是rlp编码的逆向过程，和我们之前讲的解码方法一样，关键是通过第一个字节获取原始数据的类型，然后推算出原始数据的长度，最后解析即可 小结最后，go-ethereum源码中rlp实现部分还是很完整的，并且没有什么其他依赖，都使用的是go标准包，所以可以单独拿出来做一个库，以后遇到需要用rlp编码的地方，可以直接拿来使用。还有这一部分源码大量的使用了反射，对于学习go语言反射也是很好的一个素材]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言signal包使用指南]]></title>
    <url>%2F2019%2F02%2F27%2FGo%E8%AF%AD%E8%A8%80signal%E5%8C%85%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[go语言学习笔记：signal包 os/signal主要用于实现对信号的处理(官方文档) 信号类型首先关于linux信号机制课自行查找资料，这里不再赘述。linux中的全部信号如下图： 在go中预定义了几种信号：1234567891011121314151617//"syscall"const ( // More invented values for signals SIGHUP = Signal(0x1) SIGINT = Signal(0x2) SIGQUIT = Signal(0x3) SIGILL = Signal(0x4) SIGTRAP = Signal(0x5) SIGABRT = Signal(0x6) SIGBUS = Signal(0x7) SIGFPE = Signal(0x8) SIGKILL = Signal(0x9) SIGSEGV = Signal(0xb) SIGPIPE = Signal(0xd) SIGALRM = Signal(0xe) SIGTERM = Signal(0xf)) 首先在这么多信号中，SIGKILL和SIGSTOP是无法被程序捕获的，其中SIGKILL就是我们常用的kill -9 pid方法锁触发的。其次一些有程序执行中的错误所触发的同步信号如SIGBUS，SIGFPE和SIGSEGV，go会将其转为panic，不过若是我们通过kill方式触发也是可以被捕获的。 除了那些同步信号，其余都是异步信号，是由内核或其他程序发送的，我们都可以捕获。 在异步信号中，当程序丢失终端时收到SIGHUP，在终端按下中断字符(一般为ctrl+c)时收到SIGINT，在终端按下退出字符(一般为^\)时收到SIGQUIT。 正常的，信号都是有默认动作的，最常见的如按下ctrl+c退出程序。其余的SIGHUP，SIGINT或SIGTERM信号导致程序退出。SIGQUIT，SIGILL，SIGTRAP，SIGABRT，SIGSTKFLT，SIGEMT或SIGSYS信号导致程序以堆栈转储退出。SIGTSTP，SIGTTIN或SIGTTOU信号获取系统默认行为（shell使用这些信号进行作业控制）。SIGPROF会被go运行时捕获实现runtime.CPUProfile. 捕获信号signal包中提供了Notify方法，用于注册所要监听的信号。1func Notify(c chan&lt;- os.Signal, sig ...os.Signal) 该方法需要提供一个Signal类型的channel，以及要监听的信号(当不指定时会监听所有信号)。当有信号到来时，会被写入所传入的channel中，之后拿出来即可。下例是一个监听ctrl+c退出的程序：1234567func main() &#123; c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGINT) s := &lt;-c fmt.Println("Got signal:", s)&#125; 上述程序会在第五行阻塞，直到有一个信号过来。运行结果如下： 其余apifunc Stop(c chan&lt;- os.Signal)这个方法用于停止监听信号，之后不会再往所指定的channel中写入任何内容。搭配Notify使用如下：12345678go func() &#123; sigc := make(chan os.Signal, 1) signal.Notify(sigc, syscall.SIGINT, syscall.SIGTERM) //监听信号 defer signal.Stop(sigc) //确保关闭 &lt;-sigc //线程阻塞 log.Info("Got interrupt, shutting down...") go Stop() //执行程序停止逻辑 &#125;() func Ignore(sig …os.Signal)忽略指定的信号，同理，若是未指定，忽略所有信号 func Ignored(sig os.Signal) bool检查某个信号是否被忽略 func Reset(sig …os.Signal)重置之前调用Notify时的处理。也就是不在捕获信号，进行默认操作。注意和Ignore的区别，Ignore是不对信号做任何操作，Reset是恢复默认操作。 附录部分信号说明(图片来源于网络)：]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[geth的init流程分析]]></title>
    <url>%2F2019%2F02%2F26%2Fgeth%E7%9A%84init%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[go-ethereum源码学习：init流程 geth总览首先看一下geth这个程序的总体设计，其主要代码位于go-ethereum\cmd\geth里面，先看main.go,这是一个利用urfave/cli开发的命令行程序，关于这个库的简单介绍见这里。在开头var代码块中中实例化了cli的app对象:1234567891011121314app = utils.NewApp(gitCommit, "the go-ethereum command line interface")func NewApp(gitCommit, usage string) *cli.App &#123; app := cli.NewApp() app.Name = filepath.Base(os.Args[0]) app.Author = "" //app.Authors = nil app.Email = "" app.Version = params.VersionWithMeta //见go-ethereum\params\version.go 生成版本号 if len(gitCommit) &gt;= 8 &#123; app.Version += "-" + gitCommit[:8] //gitCommit之前在编译时定义 &#125; app.Usage = usage return app&#125; 实例化之后，定义了大量flag，详细信息可以输入geth -h或到官方文档查看。接下来，在init()方法中进行进一步初始化，添加了大量command及先前定义的flag。并定义了geth的action：1234567891011app.Action = gethfunc geth(ctx *cli.Context) error &#123; if args := ctx.Args(); len(args) &gt; 0 &#123; //仅执行geth时，不能有任何附加参数 return fmt.Errorf("invalid command: %q", args[0]) &#125; node := makeFullNode(ctx) //创建默认节点 defer node.Close() startNode(ctx, node) node.Wait() return nil&#125; 在init中还定义了app.Before用于初始化工作：123456789101112131415161718192021222324252627282930313233app.Before = func(ctx *cli.Context) error &#123; logdir := "" if ctx.GlobalBool(utils.DashboardEnabledFlag.Name) &#123; logdir = (&amp;node.Config&#123;DataDir: utils.MakeDataDir(ctx)&#125;).ResolvePath("logs") &#125; if err := debug.Setup(ctx, logdir); err != nil &#123; //见\go-ethereum\internal\debug\flags.go return err &#125; // Cap the cache allowance and tune the garbage collector var mem gosigar.Mem //见\go-ethereum\vendor\github.com\elastic\gosigar\sigar_interface.go //获取系统内存信息 if err := mem.Get(); err == nil &#123; //配置缓存 allowance := int(mem.Total / 1024 / 1024 / 3) if cache := ctx.GlobalInt(utils.CacheFlag.Name); cache &gt; allowance &#123; log.Warn("Sanitizing cache to Go's GC limits", "provided", cache, "updated", allowance) ctx.GlobalSet(utils.CacheFlag.Name, strconv.Itoa(allowance)) &#125; &#125; // Ensure Go's GC ignores the database cache for trigger percentage cache := ctx.GlobalInt(utils.CacheFlag.Name) gogc := math.Max(20, math.Min(100, 100/(float64(cache)/1024))) log.Debug("Sanitizing Go's GC trigger", "percent", int(gogc)) godebug.SetGCPercent(int(gogc)) //设置垃圾收集目标百分比 // Start metrics export if enabled utils.SetupMetrics(ctx) //默认是关闭的，开关在\go-ethereum\metrics\metrics.go // Start system runtime metrics collection go metrics.CollectProcessMetrics(3 * time.Second) //默认不会启动 return nil &#125; 随后也定义了app.After逻辑12345app.After = func(ctx *cli.Context) error &#123; debug.Exit() console.Stdin.Close() // 重置终端模式 return nil &#125; 接下来进入main函数123456func main() &#123; if err := app.Run(os.Args); err != nil &#123; //运行处理程序 fmt.Fprintln(os.Stderr, err) os.Exit(1) &#125;&#125; 到这里，geth大致轮廓就看完了，随后会根据用户输入的命令执行相应的逻辑。 init这是初始化函数。源码中描述如下 The init command initializes a new genesis block and definition for the network.This is a destructive action and changes the network in which you will beparticipating.It expects the genesis file as argument. 一般使用如下1geth init gen.json --datadir ./mychain/ 需要指定一个json文件，可选择指定数据存储路径。在源码定义如下：123456789101112// go-ethereum\cmd\geth\chaincmd.goinitCommand = cli.Command&#123; Action: utils.MigrateFlags(initGenesis), Name: "init", Usage: "Bootstrap and initialize a new genesis block", ArgsUsage: "&lt;genesisPath&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, &#125;, Category: "BLOCKCHAIN COMMANDS", Description: `.....`, &#125; 可见子命令名就是init，没有别名，只有一个flag，定义如下1234567// go-ethereum\cmd\utils\flags.goDataDirFlag = DirectoryFlag&#123; Name: "datadir", Usage: "Data directory for the databases and keystore", Value: DirectoryString&#123;node.DefaultDataDir()&#125;, //获取默认目录，见go-ethereum\node\defaults.go //linux下为/home/&lt;user&gt;/.ethereum &#125; DirectoryString定义如下123456789101112131415161718192021// go-ethereum\cmd\utils\customflags.gotype DirectoryString struct &#123; Value string&#125;func (self *DirectoryString) String() string &#123; return self.Value&#125;func (self *DirectoryString) Set(value string) error &#123; self.Value = expandPath(value) return nil&#125;func expandPath(p string) string &#123; if strings.HasPrefix(p, &quot;~/&quot;) || strings.HasPrefix(p, &quot;~\\&quot;) &#123; if home := homeDir(); home != &quot;&quot; &#123; p = home + p[1:] &#125; &#125; return path.Clean(os.ExpandEnv(p))&#125; DataDirFlag作用主要就是定义初始化生成数据的存储路径，之后我们看initCommand的action，这个是关键：1Action: utils.MigrateFlags(initGenesis), 调用了utils.MigrateFlags，定义如下1234567891011// \go-ethereum\cmd\utils\flags.gofunc MigrateFlags(action func(ctx *cli.Context) error) func(*cli.Context) error &#123; return func(ctx *cli.Context) error &#123; for _, name := range ctx.FlagNames() &#123; if ctx.IsSet(name) &#123; ctx.GlobalSet(name, ctx.String(name)) &#125; &#125; return action(ctx) &#125;&#125; 这个方法并没有什么实际意义，只是将所有用户指定的flag以GlobalSet的形式存了起来，主要逻辑在传递进来的action，我们这里传递的action如下：12345678910111213141516171819202122232425262728293031323334// go-ethereum\cmd\geth\chaincmd.gofunc initGenesis(ctx *cli.Context) error &#123; // Make sure we have a valid genesis JSON genesisPath := ctx.Args().First() //获取genesis.json if len(genesisPath) == 0 &#123; utils.Fatalf("Must supply path to genesis JSON file") &#125; file, err := os.Open(genesisPath) if err != nil &#123; utils.Fatalf("Failed to read genesis file: %v", err) &#125; defer file.Close() genesis := new(core.Genesis) //Genesis结构体见 go-ethereum\core\genesis.go if err := json.NewDecoder(file).Decode(genesis); err != nil &#123; //解析json文件，遇到错误就退出 utils.Fatalf("invalid genesis file: %v", err) &#125; // Open an initialise both full and light databases stack := makeFullNode(ctx) //建立默认节点 defer stack.Close() for _, name := range []string&#123;"chaindata", "lightchaindata"&#125; &#123; chaindb, err := stack.OpenDatabase(name, 0, 0) //创建数据库 if err != nil &#123; utils.Fatalf("Failed to open database: %v", err) &#125; _, hash, err := core.SetupGenesisBlock(chaindb, genesis) //写创世区块内容 if err != nil &#123; utils.Fatalf("Failed to write genesis block: %v", err) &#125; log.Info("Successfully wrote genesis state", "database", name, "hash", hash) &#125; return nil&#125; 刚开始，获取了子命令参数，也就是我们指定的genesis.json的文件，然后尝试打开并解析其中内容，任何一步出错的就终止程序，之后调用了stack := makeFullNode(ctx)，这一部分比较繁琐，实现如下1234567891011121314151617181920212223242526272829303132333435363738394041424344// go-ethereum\cmd\geth\config.gofunc makeFullNode(ctx *cli.Context) *node.Node &#123; stack, cfg := makeConfigNode(ctx) if ctx.GlobalIsSet(utils.ConstantinopleOverrideFlag.Name) &#123; cfg.Eth.ConstantinopleOverride = new(big.Int).SetUint64(ctx.GlobalUint64(utils.ConstantinopleOverrideFlag.Name)) &#125; utils.RegisterEthService(stack, &amp;cfg.Eth) //注册eth服务， eth服务是以太坊的主要的服务。是以太坊功能的提供者。 if ctx.GlobalBool(utils.DashboardEnabledFlag.Name) &#123; //默认是false utils.RegisterDashboardService(stack, &amp;cfg.Dashboard, gitCommit) &#125; // Whisper must be explicitly enabled by specifying at least 1 whisper flag or in dev mode //Whisper是一个独立模块，用来进行加密通讯的功能。 需要显式的提供参数来启用，或者是处于开发模式。 shhEnabled := enableWhisper(ctx) //自动启动的条件没有手动配置Whisper并且处于开发者模式 shhAutoEnabled := !ctx.GlobalIsSet(utils.WhisperEnabledFlag.Name) &amp;&amp; ctx.GlobalIsSet(utils.DeveloperFlag.Name) //二者满足一个就启动（注册shh服务）,一般都不满足 if shhEnabled || shhAutoEnabled &#123; if ctx.GlobalIsSet(utils.WhisperMaxMessageSizeFlag.Name) &#123; cfg.Shh.MaxMessageSize = uint32(ctx.Int(utils.WhisperMaxMessageSizeFlag.Name)) &#125; if ctx.GlobalIsSet(utils.WhisperMinPOWFlag.Name) &#123; cfg.Shh.MinimumAcceptedPOW = ctx.Float64(utils.WhisperMinPOWFlag.Name) &#125; if ctx.GlobalIsSet(utils.WhisperRestrictConnectionBetweenLightClientsFlag.Name) &#123; cfg.Shh.RestrictConnectionBetweenLightClients = true &#125; utils.RegisterShhService(stack, &amp;cfg.Shh) &#125; // Configure GraphQL if required if ctx.GlobalIsSet(utils.GraphQLEnabledFlag.Name) &#123; if err := graphql.RegisterGraphQLService(stack, cfg.Node.GraphQLEndpoint(), cfg.Node.GraphQLCors, cfg.Node.GraphQLVirtualHosts, cfg.Node.HTTPTimeouts); err != nil &#123; utils.Fatalf("Failed to register the Ethereum service: %v", err) &#125; &#125; // Add the Ethereum Stats daemon if requested. if cfg.Ethstats.URL != "" &#123; utils.RegisterEthStatsService(stack, cfg.Ethstats.URL) &#125; return stack&#125; 第一行调用了makeConfigNode，实现如下1234567891011121314151617181920212223242526272829303132333435363738// go-ethereum\cmd\geth\config.gofunc makeConfigNode(ctx *cli.Context) (*node.Node, gethConfig) &#123; // Load defaults. //加载各个模块的默认配置 cfg := gethConfig&#123; Eth: eth.DefaultConfig, // go-ethereum\eth\config.go //Ethereum主网的默认配置，如NetworkId，SyncMode等 Shh: whisper.DefaultConfig, // go-ethereum\whisper\whisperv6\config.go Node: defaultNodeConfig(), //见defaultNodeConfig()，默认节点配置 Dashboard: dashboard.DefaultConfig, //一个独立模块，见go-ethereum\dashboard\README &#125; // Load config file. //加载配置文件，一般未指定配置文件，此处为空 if file := ctx.GlobalString(configFileFlag.Name); file != "" &#123; if err := loadConfig(file, &amp;cfg); err != nil &#123; utils.Fatalf("%v", err) &#125; &#125; // Apply flags. //从flag加载配置 utils.SetULC(ctx, &amp;cfg.Eth) //ULC:Ultra Light client go-ethereum\cmd\utils\flags.go utils.SetNodeConfig(ctx, &amp;cfg.Node) stack, err := node.New(&amp;cfg.Node) //实例化node对象 go-ethereum\node\node.go //stack就是Node对象 if err != nil &#123; utils.Fatalf("Failed to create the protocol stack: %v", err) &#125; utils.SetEthConfig(ctx, stack, &amp;cfg.Eth) if ctx.GlobalIsSet(utils.EthStatsURLFlag.Name) &#123; cfg.Ethstats.URL = ctx.GlobalString(utils.EthStatsURLFlag.Name) &#125; utils.SetShhConfig(ctx, stack, &amp;cfg.Shh) utils.SetDashboardConfig(ctx, &amp;cfg.Dashboard) return stack, cfg&#125; 这个方法首先加载代码中的默认配置，之后加载配置文件配置，随后加载用户在命令行指定的配置，由于我们分析的是init流程，所以大部分配置都是默认配置，相关代码注释见这里代码注释 经过makeConfigNode之后，我们获得stack, cfg，stack是一个node对象，cfg是配置信息。回到makeFullNode，初始化node后，又调用了utils.RegisterEthService(stack, &amp;cfg.Eth)取注册eth服务，eth服务是以太坊功能的主要服务提供者：12345678910111213141516171819202122// go-ethereum\cmd\utils\flags.gofunc RegisterEthService(stack *node.Node, cfg *eth.Config) &#123; var err error //默认是FastSync if cfg.SyncMode == downloader.LightSync &#123; err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) &#123; return les.New(ctx, cfg) &#125;) &#125; else &#123; err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) &#123; fullNode, err := eth.New(ctx, cfg) if fullNode != nil &amp;&amp; cfg.LightServ &gt; 0 &#123; ls, _ := les.NewLesServer(fullNode, cfg) fullNode.AddLesServer(ls) &#125; return fullNode, err &#125;) &#125; if err != nil &#123; Fatalf("Failed to register the Ethereum service: %v", err) &#125;&#125; 我们看一下Register的实现：12345678910111213// go-ethereum\node\node.gofunc (n *Node) Register(constructor ServiceConstructor) error &#123; n.lock.Lock() //同步操作 defer n.lock.Unlock() if n.server != nil &#123; return ErrNodeRunning &#125; //将ServiceConstructor添加到serviceFuncs这个切片中,ServiceConstructor定义如下 //type ServiceConstructor func(ctx *ServiceContext) (Service, error) n.serviceFuncs = append(n.serviceFuncs, constructor) return nil&#125; 逻辑很简单，就是将要注册的东西存起来。我们再来看注册的eth服务的内容。我们分析的是init的流程，默认的同步模式是FastSync，调用eth.New(ctx, cfg)，创建了一个Ethereum对象，这里我们暂不分析创建过程，只需知道这里实例化了了一个Ethereum对象，也就是变量fullNode。在回到makeConfigNode，后面就是根据具体情况去注册各种服务，如DashboardService，ShhService等，套路和eth注册是一样的。需要注意的是，这里面除了eth服务是必须的，其他的都是可选的。最后返回stack，也就是node对象 实际上，在我们分析的流程中，initGenesis调用的makeFullNode方法都是在做初始化。回到initGenesis，makeFullNode之后有一个遍历，遍历了两个字符串：”chaindata”, “lightchaindata”。他们的用处是用来创建数据库：12345678910// go-ethereum\node\node.gochaindb, err := stack.OpenDatabase(name, 0, 0)func (n *Node) OpenDatabase(name string, cache, handles int) (ethdb.Database, error) &#123; if n.config.DataDir == "" &#123; return ethdb.NewMemDatabase(), nil //如果路径为空，创建内存数据库，实际上就是放在内存中的一个map // go-ethereum\ethdb\memory_database.go &#125; return ethdb.NewLDBDatabase(n.config.ResolvePath(name), cache, handles)&#125; 1234567891011121314151617181920212223242526272829303132333435// go-ethereum\ethdb\database.gofunc NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) &#123; logger := log.New("database", file) //从init调用过来时，cache和handles都为0 //默认启动节点，cache为512，handles为0，在node.DefaultConfig配置 // Ensure we have some minimal caching and file guarantees if cache &lt; 16 &#123; cache = 16 &#125; if handles &lt; 16 &#123; handles = 16 &#125; logger.Info("Allocated cache and file handles", "cache", common.StorageSize(cache*1024*1024), "handles", handles) // Open the db and recover any potential corruptions db, err := leveldb.OpenFile(file, &amp;opt.Options&#123; OpenFilesCacheCapacity: handles, BlockCacheCapacity: cache / 2 * opt.MiB, WriteBuffer: cache / 4 * opt.MiB, // Two of these are used internally Filter: filter.NewBloomFilter(10), &#125;) if _, corrupted := err.(*errors.ErrCorrupted); corrupted &#123; db, err = leveldb.RecoverFile(file, nil) &#125; // (Re)check for errors and abort if opening of the db failed if err != nil &#123; return nil, err &#125; return &amp;LDBDatabase&#123; fn: file, db: db, log: logger, &#125;, nil&#125; 这里使用的levelDB数据库，关于这个数据库的介绍与使用见这里。逻辑很简单就是在指定位置创建levelDB数据库。数据库创建完成后，回到initGenesis，接下来开始写内容：123456789101112131415161718192021222324252627_, hash, err := core.SetupGenesisBlock(chaindb, genesis)// go-ethereum\core\genesis.gofunc SetupGenesisBlock(db ethdb.Database, genesis *Genesis) (*params.ChainConfig, common.Hash, error) &#123; return SetupGenesisBlockWithOverride(db, genesis, nil)&#125;func SetupGenesisBlockWithOverride(db ethdb.Database, genesis *Genesis, constantinopleOverride *big.Int) (*params.ChainConfig, common.Hash, error) &#123; if genesis != nil &amp;&amp; genesis.Config == nil &#123; //如果json，没有配置config部分，则退出 return params.AllEthashProtocolChanges, common.Hash&#123;&#125;, errGenesisNoConfig &#125; // Just commit the new block if there is no stored genesis block. stored := rawdb.ReadCanonicalHash(db, 0) // go-ethereum\core\rawdb\accessors_chain.go //从数据库中获取创世区块的hash if (stored == common.Hash&#123;&#125;) &#123; //如果为空，init会进入这个分支 if genesis == nil &#123; log.Info("Writing default main-net genesis block") genesis = DefaultGenesisBlock() &#125; else &#123; log.Info("Writing custom genesis block") &#125; // 写入数据库 block, err := genesis.Commit(db) return genesis.Config, block.Hash(), err &#125; .....&#125; 首先利用rawdb.ReadCanonicalHash(db, 0)或取genesis区块，由于是初始化，自然获取不到，进入下面的if分枝，首先调用了Commit(db)：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// go-ethereum\core\genesis.gofunc (g *Genesis) Commit(db ethdb.Database) (*types.Block, error) &#123; block := g.ToBlock(db) if block.Number().Sign() != 0 &#123; return nil, fmt.Errorf("can't commit genesis block with number &gt; 0") &#125; // go-ethereum\core\rawdb\accessors_chain.go 写入各种信息 rawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty) rawdb.WriteBlock(db, block) rawdb.WriteReceipts(db, block.Hash(), block.NumberU64(), nil) rawdb.WriteCanonicalHash(db, block.Hash(), block.NumberU64()) rawdb.WriteHeadBlockHash(db, block.Hash()) rawdb.WriteHeadHeaderHash(db, block.Hash()) config := g.Config if config == nil &#123; config = params.AllEthashProtocolChanges &#125; rawdb.WriteChainConfig(db, block.Hash(), config) return block, nil&#125;func (g *Genesis) ToBlock(db ethdb.Database) *types.Block &#123; if db == nil &#123; //如果数据库为nil，建立一个内存数据库 db = ethdb.NewMemDatabase() &#125; statedb, _ := state.New(common.Hash&#123;&#125;, state.NewDatabase(db)) // go-ethereum\core\state\statedb.go // go-ethereum\core\state\database.go //state.New：根据给定的Tried创建一个新的状态() //state.NewDatabase：创建一个内存数据库 for addr, account := range g.Alloc &#123; //遍历json文件中的alloc配置 statedb.AddBalance(addr, account.Balance) statedb.SetCode(addr, account.Code) statedb.SetNonce(addr, account.Nonce) for key, value := range account.Storage &#123; statedb.SetState(addr, key, value) &#125; &#125; root := statedb.IntermediateRoot(false) head := &amp;types.Header&#123; //go-ethereum\core\types\block.go 创建区块头 Number: new(big.Int).SetUint64(g.Number), Nonce: types.EncodeNonce(g.Nonce), Time: new(big.Int).SetUint64(g.Timestamp), ParentHash: g.ParentHash, Extra: g.ExtraData, GasLimit: g.GasLimit, GasUsed: g.GasUsed, Difficulty: g.Difficulty, MixDigest: g.Mixhash, Coinbase: g.Coinbase, Root: root, &#125; if g.GasLimit == 0 &#123; head.GasLimit = params.GenesisGasLimit //默认为4712388 go-ethereum\params\protocol_params.go &#125; if g.Difficulty == nil &#123; head.Difficulty = params.GenesisDifficulty //默认为131072 &#125; statedb.Commit(false) statedb.Database().TrieDB().Commit(root, true) return types.NewBlock(head, nil, nil, nil)//创建一个新的区块 go-ethereum\core\types\block.go //每个区块有四部分内容，区块头，交易列表，叔块，收据&#125; Commit方法中首先调用了ToBlock，在这里创建了一个实例化的区块对象并返回，之后再Commit中写入各种信息到数据库中，我们以总难度为例，看它是如何写入的：1234567891011rawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty)func WriteTd(db DatabaseWriter, hash common.Hash, number uint64, td *big.Int) &#123; data, err := rlp.EncodeToBytes(td) if err != nil &#123; log.Crit("Failed to RLP encode block total difficulty", "err", err) &#125; if err := db.Put(headerTDKey(number, hash), data); err != nil &#123; log.Crit("Failed to store block total difficulty", "err", err) &#125;&#125; 首先WriteTd接收四个参数，分别是数据库的实例，区块hash，区块编号，难度值。之后将难度值进行RLP编码，然后调用db.Put()写入数据库，写入的键是headerTDKey(number, hash)，值就是编码过得数据。在commit的最后，写入所有数据后，返回了区块实例，然后回到initGenesis方法，最终返回了错误信息和区块hash。到此init的流程就结束了。创世区块的内容也被写入了数据库。]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum编译流程简单学习]]></title>
    <url>%2F2019%2F02%2F21%2Fgo-ethereum%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[go-ethereum源码学习：源码编译流程 一般，在根目录下执行make geth 或者 make all编译go-ethereum。前者仅编译go-ethereum主程序，后者编译所有模块。详见go-ethereum的README 以make geth为例，进入go-ethereum根目录下，打开Makefile文件，执行的逻辑是1234geth: build/env.sh go run build/ci.go install ./cmd/geth @echo "Done building." @echo "Run \"$(GOBIN)/geth\" to launch geth." 可见直接执行了build/env.sh脚本，传入的参数为go run build/ci.go install ./cmd/geth 进入这个脚本文件，签名若干行都是在进行目录和环境设置，只有最后一行起到编译作用1exec "$@" exec指执行后面的跟的命令，$@是一个变量，存储着传给这个脚本的所有参数，这里的参数就是上面说的go run build/ci.go install ./cmd/geth ./cmd/geth，这就是go的编译命令，他编译运行的是build/ci.go文件，顺便还传入了参数install ./cmd/geth 首先在这个文件开头，我们可以知道这也是一个CLI程序，和我们编译生成的geth类似，在开头列出了一些命令的格式，如第一行就是我们流程中将要执行的1234Available commands are: install [ -arch architecture ] [ -cc compiler ] [ packages... ] ... 我们所要执行的就是 install ./cmd/geth，没有任何附加参数。 先从main函数开始，在这里的switch结构中，判断了第一个参数，我们这里为install，执行doInstall(os.Args[2:])，传入的参数自然为./cmd/geth。doInstall这个方法也比较简单，首先，利用flag进行参数解析，然后判断了go的版本后，最后根据需求拼凑编译指令。这一部分关键步骤注释见这里]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go的CLI程序开发]]></title>
    <url>%2F2019%2F02%2F21%2Fgo%E7%9A%84CLI%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[CLI(command-line interface)就是命令行界面，我们在linux命令行中输入的一个个指令都是CLI程序，典型如tar命令，一般使用go开发一个命令行程序有以下几种方法 Arguments这个算是最基本的方法，但也是最繁琐的。主要借助os.Args，查看源码，介绍如下 12// Args hold the command-line arguments, starting with the program name.var Args []string 这里告诉我们这个数组切片保存了命令行的参数，且第一个参数程序名。这里需要注意的一点是，就算一个参数不附加，os.Args这个数组也是有一个值的，就是当前的程序，所以我们在通过len(os.Args)判断是否有额外参数时，len(os.Args)&gt;1才能说明有额外参数 既然我们可以通过这个数组获取所有参数，那么就可以通过一系列参数判断，开发出一个命令行程序，但无疑是很繁琐的，所以go标准库中提供了一个简单的库来帮助我们 flag我们先引入一个小例子 12345func main() &#123; dir := flag.String("dir","/home/user","data directory") flag.Parse() fmt.Println(*dir)&#125; 之后再命令行输入下面命令去运行，123456789101112131415161718go run example.go 输出/home/usergo run example.go -dir /etc/opt 输出/etc/optgo run in.go -h输出：Usage of .../example.exe -dir string data directory (default &quot;/home/user&quot;) go run example.go -dirs /etc输出：flag provided but not defined: -dirsUsage of .../example.exe -dir string data directory (default &quot;/home/user&quot;) 可以看出这已经是一个比较完善的命令程序，我们指定了参数名：dir，默认值：”/home/user”，以及参数解释：”data directory”。之后flag包自动帮我们解析参数，并附带了-h帮助信息，以及未定义参数的提示信息 通过上面的例子基本可以了解flag大体使用方法，首先定义一些参数，之后flag.Parse()进行解析，最后使用解析到的数据即可，关于Parse()源码如下 123func Parse() &#123; CommandLine.Parse(os.Args[1:])&#125; 可见也是用的os.Args[1:]作为输入，只不过这个包帮我们做好了匹配及错误处理而已。接下来详细学习一下用法 flag定义基本上分三大类： flag.Xxx(name,value,usage) *Xxx Xxx表示相应的数据类型，如Bool，Float64，Int，String等等，参数都是三个：名称，默认值，用法介绍。返回值1是相应类型的一个指针变量。例子如下： 1dir := flag.String("dir","/home/user","data directory") flag.XxxVar(p,name,value,usage) Xxx也是表示相应的数据类型，和上面那个一样，区别是多了一个参数，需要传入一个变量的引用，然后解析时会把值赋给这个变量，没有返回值，例子如下 12var dir stringflag.StringVar(&amp;dir,"dir","/home/user","data directory") flag.Var(value,name,usage) 当包中预定义的数据类型不能满足要求时，就需要这个方法了，第一个参数是一个引用，其类是实现flag.Value 接口，剩下的两个参数意义和上边的一样。先看一下这个接口 1234type Value interface &#123; String() string Set(string) error&#125; 基本上就是要定义存取方法，只不过存取的值都必须是string类型，举一个简单的例子 1234567891011121314151617181920212223242526272829303132type student struct &#123; name string age int64&#125;func (s *student) String()string&#123; return s.name+string(s.age)&#125;func (s *student) Set(str string)error&#123; slice:=strings.Split(str,",") if len(slice)!=2 &#123; return errors.New("bad format") &#125; i,err:=strconv.ParseInt(slice[1],10,64) if err!=nil &#123; return err &#125; s.name = slice[0] s.age = i return nil&#125;func main() &#123; var dir student flag.Var(&amp;dir,"stu","student info") flag.Parse() fmt.Println(dir.name,"+++",dir.age)&#125;//用法//go run example.go -stu wang,21 flag格式一般形式如下： 123-flag-flag = x-flag x //仅适用于非boolean类型flag 其中-和–都是允许的 flag解析会在遇到第一个非flag参数或单独的–之后停止，例 123456func main() &#123; n := flag.Int("n",0,"number") flag.Parse() fmt.Println(*n) fmt.Println(flag.NArg())&#125; 下面的命令都会由于提前停止解析得不到所要的值 123go run example.go 45 -n 1 //flag.NArg()会返回3go run example.go - -n 1 //flag.NArg()会返回3go run example.go -- -n 1 //flag.NArg()会返回2，--被当做终止符 其他方法 Arg(i int)string ， Args()[]string ， NArg()int ， NFlag()int Arg(i int)返回的是在被flag解析后，第i个剩余的参数，没有的话返回空字符串 Args()返回的是被flag解析后，剩余参数数组切片 NArg()返回的是被flag解析后，剩余参数的个数 NFlag()返回的是接收到的flag参数个数（并不是定义的个数） 12345678910111213n := flag.Int("n",0,"number")flag.Parse()fmt.Println(n)fmt.Println(flag.Arg(1))//输入&gt;go run example.go -n 1 454 555，返回555 //输入&gt;go run example.go -n 1 454 ，返回空 fmt.Println(flag.Args())//输入&gt;go run example.go -n 1 454 555，返回[454,555]fmt.Println(flag.NArg())//输入&gt;go run example.go -n 1 454 555,返回2fmt.Println(flag.NFlag())//输入&gt;go run example.go -n 1 454 555，返回1 //输入&gt;go run example.go 454 555，返回0 flag.Parsed()bool 判断参数是否解析过 Set(name, value string) error 给指定的flag赋值 flag.Usage 库里已经帮我们自动生成了一套帮助信息，可以使用-h或-help查看，另外我们也可以自己定制，重写Usage例 123 flag.Usage = func() &#123; fmt.Println("hello world")&#125; 另外我们也可以看一下源码，原来的帮助信息是怎么生成的 1234var Usage = func() &#123; fmt.Fprintf(CommandLine.Output(), "Usage of %s:\n", os.Args[0]) PrintDefaults()&#125; 可见，先是打印了os.Args[0]，也就是程序信息，之后调用了PrintDefaults()，打印了所有flag的信息 urfave/cli其实官方给出的flag已能满足大部分要求，如果有更复杂的需要，可以借助这个强大的第三方包urfave/cli 安装与导包1go get github.com/urfave/cli 123import ( "gopkg.in/urfave/cli.v1") 简单使用该包的github主页有详细的使用说明，这里就不一一赘述了，只简单说一下常用的使用流程 实例化App对象 1app := cli.NewApp() 配置App信息 123456789101112131415161718192021222324252627282930313233343536//这个包可以配置丰富的App描述信息，如名称，版本号，作者，版权信息，程序简介等app.Name = "HelloWorld"app.Version = "1.0.0"app.Authors = []cli.Author&#123; cli.Author&#123; Name: "Tom", Email: "Tom@example.com", &#125;,&#125;app.Copyright = "(c) 1999 Serious Enterprise"app.Usage = "greet"app.UsageText = "Example program"//输入go run example.go -h后显示如下/*NAME: HelloWorld - greetUSAGE: Example programVERSION: 1.0.0AUTHOR: Tom &lt;Tom@example.com&gt;COMMANDS: help, h Shows a list of commands or help for one commandGLOBAL OPTIONS: --help, -h show help --version, -v print the versionCOPYRIGHT: (c) 1999 Serious Enterprise*/ 定义程序执行逻辑 这里是指程序运行的逻辑。主要是配置app.Action，例：12345app.Action = func(c *cli.Context) &#123; fmt.Println("hello world") &#125;//go run example.go //输出hello world 当然我们也可以不在这里定义主程序逻辑，在这里定义的一个好处是cli.Context携带了许多有用的上下文环境变量供我们使用，后面可以见到。 app.Action是执行程序时执行的逻辑，我们也可以定义在程序执行前后所要插入的逻辑，定义app.Before与app.After即可，例123456789101112131415161718192021222324func main() &#123; app := cli.NewApp() app.Before = func(context *cli.Context) error &#123; fmt.Println("before hello world") return nil; &#125; app.Action = func(c *cli.Context) &#123; fmt.Println("hello world") &#125; app.After = func(context *cli.Context) error &#123; fmt.Println("after hello world") return nil; &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125;//执行go run example.go/* 输出：before hello worldhello worldafter hello world*/ 注意：如果app.Before返回的error不为空，app.Action的内容将不会执行，而不管app.Action与app.Before中是否有错误发生，app.After的内容都会执行，app.After可用于收尾工作。 定义flag 这里的flag概念和上文中go的标准包中flag类似，直接看一个例子：12345678910111213141516171819202122func main() &#123; app := cli.NewApp() app.Flags = []cli.Flag&#123; cli.StringFlag&#123; Name:"path", Value:"/home/", Usage:"setting path", &#125;, &#125; app.Action = func(c *cli.Context) &#123; fmt.Println(c.String("path")) &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal("aaa",err) &#125;&#125;//输入go run example.go -path /home/base//输出：/home/base//输入go run example.go//输出：/home/ 定义起来很简单，关键几个要素就是Name和Value，取值时使用cli.Context提供的对应取值方法即可。包内预定义了许多种类型的flag，基本涵盖了所有基本类型，详见这里 另外在取值时，除了调用如c.Int(),c.String()之类的方法，还可以在定义flag时直接绑定到某些变量上，如：123456var age intcli.IntFlag&#123; Name:"age", Value:100, Destination:&amp;age,&#125; 另外，还可以配置flag的简写或别名，只需在定义Name时定义多个名称，中间用逗号隔开即可，例：123456cli.IntFlag&#123; Name:"age,a,ege", Value:100, Destination:&amp;age,&#125;,//-age -a -ege 都是有效的 配置子命令 如git push …中push就是一个子命令，这个包为我们提供了便捷定义子命令及其动作的方法12345678910111213app.Commands = []cli.Command&#123; &#123; Name: "push", Aliases: []string&#123;"p"&#125;, Usage: "push a file to the server", Action: func(c *cli.Context) error &#123; fmt.Println("push flie: ", c.Args().First())//c.Args().First()取命令后的第一个参数 return nil &#125;, &#125;, &#125;//执行go run example.go push test.txt//输出：push flie: test.txt 用法很简单，指定命名名，别名用法，以及相应动作即可。另外子命令可以像它的一个程序一样，有自己flag，Before，After，甚至是自己的子命令，使用Subcommands定义 注意，如果即定义了app的action，又定义了子命令的action，同一时间只能执行一个，如调用子命令时，app的action就不会执行 启动程序 所有配置都配置完成后，就需要启动程序，不然是不会生效的1234err := app.Run(os.Args)if err != nil &#123; log.Fatal("aaa",err)&#125; 最后给出一个详细例子，这是给出的，基本上涵盖了所有配置要点:例子]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F20%2Fhello-world%2F</url>
    <content type="text"><![CDATA[一切都从Hello World开始！ Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
