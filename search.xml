<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[geth子命令源码分析：init、account]]></title>
    <url>%2F2019%2F06%2F08%2Fgeth%E5%AD%90%E5%91%BD%E4%BB%A4%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%9Ainit%E3%80%81account%2F</url>
    <content type="text"><![CDATA[geth总览首先看一下geth这个程序的总体设计，其主要代码位于go-ethereum\cmd\geth里面，先看main.go,这是一个利用urfave/cli开发的命令行程序，关于这个库的简单介绍见这里。在开头var代码块中中实例化了cli的app对象:1234567891011121314app = utils.NewApp(gitCommit, "the go-ethereum command line interface")func NewApp(gitCommit, usage string) *cli.App &#123; app := cli.NewApp() app.Name = filepath.Base(os.Args[0]) app.Author = "" //app.Authors = nil app.Email = "" app.Version = params.VersionWithMeta //见go-ethereum\params\version.go 生成版本号 if len(gitCommit) &gt;= 8 &#123; app.Version += "-" + gitCommit[:8] //gitCommit之前在编译时定义 &#125; app.Usage = usage return app&#125; 实例化之后，定义了大量flag，详细信息可以输入geth -h或到官方文档查看。接下来，在init()方法中进行进一步初始化，添加了大量command及先前定义的flag。并定义了geth的action：1234567891011app.Action = gethfunc geth(ctx *cli.Context) error &#123; if args := ctx.Args(); len(args) &gt; 0 &#123; return fmt.Errorf("invalid command: %q", args[0]) &#125; node := makeFullNode(ctx) defer node.Close() startNode(ctx, node) node.Wait() return nil&#125; 这是关于geth启动流程的代码，我们后续再分析。在init中还定义了app.Before用于初始化工作：123456789101112131415161718192021222324252627282930313233app.Before = func(ctx *cli.Context) error &#123; logdir := "" if ctx.GlobalBool(utils.DashboardEnabledFlag.Name) &#123; logdir = (&amp;node.Config&#123;DataDir: utils.MakeDataDir(ctx)&#125;).ResolvePath("logs") &#125; if err := debug.Setup(ctx, logdir); err != nil &#123; //见\go-ethereum\internal\debug\flags.go return err &#125; // Cap the cache allowance and tune the garbage collector var mem gosigar.Mem //见\go-ethereum\vendor\github.com\elastic\gosigar\sigar_interface.go //获取系统内存信息 if err := mem.Get(); err == nil &#123; //配置缓存 allowance := int(mem.Total / 1024 / 1024 / 3) if cache := ctx.GlobalInt(utils.CacheFlag.Name); cache &gt; allowance &#123; log.Warn("Sanitizing cache to Go's GC limits", "provided", cache, "updated", allowance) ctx.GlobalSet(utils.CacheFlag.Name, strconv.Itoa(allowance)) &#125; &#125; // Ensure Go's GC ignores the database cache for trigger percentage cache := ctx.GlobalInt(utils.CacheFlag.Name) gogc := math.Max(20, math.Min(100, 100/(float64(cache)/1024))) log.Debug("Sanitizing Go's GC trigger", "percent", int(gogc)) godebug.SetGCPercent(int(gogc)) //设置垃圾收集目标百分比 // Start metrics export if enabled utils.SetupMetrics(ctx) //默认是关闭的，开关在\go-ethereum\metrics\metrics.go // Start system runtime metrics collection go metrics.CollectProcessMetrics(3 * time.Second) //默认不会启动 return nil &#125; 随后也定义了app.After逻辑12345app.After = func(ctx *cli.Context) error &#123; debug.Exit() console.Stdin.Close() // 重置终端模式 return nil &#125; 接下来进入main函数123456func main() &#123; if err := app.Run(os.Args); err != nil &#123; //运行处理程序 fmt.Fprintln(os.Stderr, err) os.Exit(1) &#125;&#125; 到这里，geth大致轮廓就看完了，随后会根据用户输入的命令执行相应的逻辑。 init这是初始化函数。源码中描述如下 The init command initializes a new genesis block and definition for the network.This is a destructive action and changes the network in which you will beparticipating.It expects the genesis file as argument. 一般使用如下1geth init gen.json --datadir ./mychain/ 需要指定一个json文件，可选择指定数据存储路径。在源码定义如下：123456789101112// go-ethereum\cmd\geth\chaincmd.goinitCommand = cli.Command&#123; Action: utils.MigrateFlags(initGenesis), Name: "init", Usage: "Bootstrap and initialize a new genesis block", ArgsUsage: "&lt;genesisPath&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, &#125;, Category: "BLOCKCHAIN COMMANDS", Description: `.....`, &#125; 可见子命令名就是init，没有别名，只有一个flag，定义如下1234567// go-ethereum\cmd\utils\flags.goDataDirFlag = DirectoryFlag&#123; Name: "datadir", Usage: "Data directory for the databases and keystore", Value: DirectoryString&#123;node.DefaultDataDir()&#125;, //获取默认目录，见go-ethereum\node\defaults.go //linux下为/home/&lt;user&gt;/.ethereum &#125; DirectoryString定义如下123456789101112131415161718192021// go-ethereum\cmd\utils\customflags.gotype DirectoryString struct &#123; Value string&#125;func (self *DirectoryString) String() string &#123; return self.Value&#125;func (self *DirectoryString) Set(value string) error &#123; self.Value = expandPath(value) return nil&#125;func expandPath(p string) string &#123; if strings.HasPrefix(p, &quot;~/&quot;) || strings.HasPrefix(p, &quot;~\\&quot;) &#123; if home := homeDir(); home != &quot;&quot; &#123; p = home + p[1:] &#125; &#125; return path.Clean(os.ExpandEnv(p))&#125; DataDirFlag作用主要就是定义初始化生成数据的存储路径，之后我们看initCommand的action，这个是关键：1Action: utils.MigrateFlags(initGenesis), 调用了utils.MigrateFlags，定义如下1234567891011// \go-ethereum\cmd\utils\flags.gofunc MigrateFlags(action func(ctx *cli.Context) error) func(*cli.Context) error &#123; return func(ctx *cli.Context) error &#123; for _, name := range ctx.FlagNames() &#123; if ctx.IsSet(name) &#123; ctx.GlobalSet(name, ctx.String(name)) &#125; &#125; return action(ctx) &#125;&#125; 这个方法并没有什么实际意义，只是将所有用户指定的flag以GlobalSet的形式存了起来，主要逻辑在传递进来的action，我们这里传递的action如下：123456789101112131415161718192021222324252627282930313233// go-ethereum\cmd\geth\chaincmd.gofunc initGenesis(ctx *cli.Context) error &#123; genesisPath := ctx.Args().First() if len(genesisPath) == 0 &#123; utils.Fatalf("Must supply path to genesis JSON file") &#125; file, err := os.Open(genesisPath) if err != nil &#123; utils.Fatalf("Failed to read genesis file: %v", err) &#125; defer file.Close() genesis := new(core.Genesis) if err := json.NewDecoder(file).Decode(genesis); err != nil &#123; utils.Fatalf("invalid genesis file: %v", err) &#125; stack := makeFullNode(ctx) defer stack.Close() for _, name := range []string&#123;"chaindata", "lightchaindata"&#125; &#123; chaindb, err := stack.OpenDatabase(name, 0, 0) if err != nil &#123; utils.Fatalf("Failed to open database: %v", err) &#125; _, hash, err := core.SetupGenesisBlock(chaindb, genesis) if err != nil &#123; utils.Fatalf("Failed to write genesis block: %v", err) &#125; log.Info("Successfully wrote genesis state", "database", name, "hash", hash) &#125; return nil&#125; 第一行获取我们传入的json文件路径，然后代开这个文件，并解析成一个创世区块对象，中间有一步出错就返回。到这里已经根据我们的json文件创建了一个创世区块对象genesis。接着使用makeFullNode创建了一个节点，这个在分析geth启动流程时详细分析，这里只用知道他给我们返回一个node对象，代表一个节点。 接着遍历了一个字符串数组，为的是创建数据库目录，用的是OpenDatabase方法，最终创建的两个数据库默认情况分别在datadir/geth/chaindata，datadir/geth/lightchaindata。之后调用SetupGenesisBlock方法写入创世区块，这个方法在我们F分析创世区块时分析过，就是把我们定义的创世区块内如写入数据库，最后打印log。 account这是账户相关的自命令，定义如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455accountCommand = cli.Command&#123; Name: "account", Usage: "Manage accounts", Category: "ACCOUNT COMMANDS", Description: ``, Subcommands: []cli.Command&#123; &#123; Name: "list", Usage: "Print summary of existing accounts", Action: utils.MigrateFlags(accountList), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, &#125;, Description: `...`, &#125;, &#123; Name: "new", Usage: "Create a new account", Action: utils.MigrateFlags(accountCreate), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.PasswordFileFlag, utils.LightKDFFlag, &#125;, Description: `...`, &#125;, &#123; Name: "update", Usage: "Update an existing account", Action: utils.MigrateFlags(accountUpdate), ArgsUsage: "&lt;address&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.LightKDFFlag, &#125;, Description: `...`, &#125;, &#123; Name: "import", Usage: "Import a private key into a new account", Action: utils.MigrateFlags(accountImport), Flags: []cli.Flag&#123; utils.DataDirFlag, utils.KeyStoreDirFlag, utils.PasswordFileFlag, utils.LightKDFFlag, &#125;, ArgsUsage: "&lt;keyFile&gt;", Description: `...`, &#125;, &#125;, &#125; 这个命令的名称就是account，没有别名也没有直接的flag，但是有几个二级命令 list这个命令的作用是列出所有的账户，有两个flag。DataDirFlag用来指定节点目录，使用–datadir指定；KeyStoreDirFlag用来指定秘钥存储路径，使用–keystoreh指定。改名了的动作如下，注意还是MigrateFlags包裹一个方法的形式，直接看动作1234567891011func accountList(ctx *cli.Context) error &#123; stack, _ := makeConfigNode(ctx) var index int for _, wallet := range stack.AccountManager().Wallets() &#123; for _, account := range wallet.Accounts() &#123; fmt.Printf("Account #%d: &#123;%x&#125; %s\n", index, account.Address, &amp;account.URL) index++ &#125; &#125; return nil&#125; 很简单就是首先使用makeConfigNode构造一个节点，这里之所以不用makeFullNode是因为不必注册服务。之后获取节点的账户管理者，再获取所有钱包，遍历每个钱包的账户打印出来即可。 new这是新建一个账户的命令，命令名就是new，有四个flag。前两个和list的一样。后面的，PasswordFileFlag是用来指定账户密码的文件，使用–password指定，默认为空。LightKDFFlag是表示是否要降低秘钥生成时cpu和ram的用量，是一个布尔类型，需要的话使用–lightkdf开启。我们接着看主要逻辑12345678910111213141516171819202122232425func accountCreate(ctx *cli.Context) error &#123; cfg := gethConfig&#123;Node: defaultNodeConfig()&#125; if file := ctx.GlobalString(configFileFlag.Name); file != "" &#123; if err := loadConfig(file, &amp;cfg); err != nil &#123; utils.Fatalf("%v", err) &#125; &#125; utils.SetNodeConfig(ctx, &amp;cfg.Node) scryptN, scryptP, keydir, err := cfg.Node.AccountConfig() if err != nil &#123; utils.Fatalf("Failed to read configuration: %v", err) &#125; password := getPassPhrase("Your new account is locked with a password. Please give a password. Do not forget this password.", true, 0, utils.MakePasswordList(ctx)) address, err := keystore.StoreKey(keydir, password, scryptN, scryptP) if err != nil &#123; utils.Fatalf("Failed to create account: %v", err) &#125; fmt.Printf("Address: &#123;%x&#125;\n", address) return nil&#125; 开始时施加在默认及用户配置，然后设置配置，接着调用AccountConfig获取了几个变量，分别是scrypt算法的N参数scryptN，scrypt算法的P参数scryptP，秘钥存储目录及错误。没有错误的话，调用getPassPhrase获取密码12345678910111213141516171819202122232425262728293031323334353637383940414243func getPassPhrase(prompt string, confirmation bool, i int, passwords []string) string &#123; if len(passwords) &gt; 0 &#123; if i &lt; len(passwords) &#123; return passwords[i] &#125; return passwords[len(passwords)-1] &#125; if prompt != "" &#123; fmt.Println(prompt) &#125; password, err := console.Stdin.PromptPassword("Passphrase: ") if err != nil &#123; utils.Fatalf("Failed to read passphrase: %v", err) &#125; if confirmation &#123; confirm, err := console.Stdin.PromptPassword("Repeat passphrase: ") if err != nil &#123; utils.Fatalf("Failed to read passphrase confirmation: %v", err) &#125; if password != confirm &#123; utils.Fatalf("Passphrases do not match") &#125; &#125; return password&#125;func MakePasswordList(ctx *cli.Context) []string &#123; path := ctx.GlobalString(PasswordFileFlag.Name) if path == "" &#123; return nil &#125; text, err := ioutil.ReadFile(path) if err != nil &#123; Fatalf("Failed to read password file: %v", err) &#125; lines := strings.Split(string(text), "\n") for i := range lines &#123; lines[i] = strings.TrimRight(lines[i], "\r") &#125; return lines&#125; MakePasswordList方法是从我们用–password指定的文件中读取密码，该文件每一行表示一个密码。在getPassPhrase中，刚才读取的密码个数大于0，则取第一个作为密码。否则进入一个交互环境，让用户输入密码，用的是PromptPassword方法，之后还要输入第二遍进行验证。回到accountCreate中，取到密码后使用StoreKey生产账户1234567891011121314151617181920func StoreKey(dir, auth string, scryptN, scryptP int) (common.Address, error) &#123; _, a, err := storeNewKey(&amp;keyStorePassphrase&#123;dir, scryptN, scryptP, false&#125;, rand.Reader, auth) return a.Address, err&#125;func storeNewKey(ks keyStore, rand io.Reader, auth string) (*Key, accounts.Account, error) &#123; key, err := newKey(rand) if err != nil &#123; return nil, accounts.Account&#123;&#125;, err &#125; a := accounts.Account&#123; Address: key.Address, URL: accounts.URL&#123;Scheme: KeyStoreScheme, Path: ks.JoinPath(keyFileName(key.Address))&#125;, &#125; if err := ks.StoreKey(a.URL.Path, key, auth); err != nil &#123; zeroKey(key.PrivateKey) return nil, a, err &#125; return key, a, err&#125; 直接调用的是storeNewKey方法，不要过创建了一个keyStorePassphrase对象，他实现了keyStore接口。storeNewKey方法先调用了newKey方法生成椭圆曲线加密的私钥，并转为Key对象1234567891011121314151617func newKey(rand io.Reader) (*Key, error) &#123; privateKeyECDSA, err := ecdsa.GenerateKey(crypto.S256(), rand) if err != nil &#123; return nil, err &#125; return newKeyFromECDSA(privateKeyECDSA), nil&#125;func newKeyFromECDSA(privateKeyECDSA *ecdsa.PrivateKey) *Key &#123; id := uuid.NewRandom() key := &amp;Key&#123; Id: id, Address: crypto.PubkeyToAddress(privateKeyECDSA.PublicKey), PrivateKey: privateKeyECDSA, &#125; return key&#125; 注意这里实际上也就是生成了账户地址，就是私钥对应的公钥，不过要简单处理一下1234567891011func PubkeyToAddress(p ecdsa.PublicKey) common.Address &#123; pubBytes := FromECDSAPub(&amp;p) return common.BytesToAddress(Keccak256(pubBytes[1:])[12:])&#125;func FromECDSAPub(pub *ecdsa.PublicKey) []byte &#123; if pub == nil || pub.X == nil || pub.Y == nil &#123; return nil &#125; return elliptic.Marshal(S256(), pub.X, pub.Y)&#125; 首先将公钥的的曲线方程、基点等参数以字节数组形式表示，然后将这个数组舍弃第一个字节后做一次Keccak256哈希运算，然后取后20个字节作为账户地址。 newKeyFromECDSA最后返回的是一个Key对象，还包含一个16字节的随机编号。回到storeNewKey中，此时组建一个account对象，表示一个账户，包含该账户的地址以及url，格式是keystore://文件名。文件名如下生成1234func keyFileName(keyAddr common.Address) string &#123; ts := time.Now().UTC() return fmt.Sprintf("UTC--%s--%s", toISO8601(ts), hex.EncodeToString(keyAddr[:]))&#125; 有两部分组成，第一部分是创建时间，第二部分是地址的16进制表示。接着调用StoreKey方法存储秘钥，这是keyStorePassphrase的方法12345678910111213141516171819202122232425func (ks keyStorePassphrase) StoreKey(filename string, key *Key, auth string) error &#123; keyjson, err := EncryptKey(key, auth, ks.scryptN, ks.scryptP) if err != nil &#123; return err &#125; // Write into temporary file tmpName, err := writeTemporaryKeyFile(filename, keyjson) if err != nil &#123; return err &#125; if !ks.skipKeyFileVerification &#123; // Verify that we can decrypt the file with the given password. _, err = ks.GetKey(key.Address, tmpName, auth) if err != nil &#123; msg := "An error was encountered when saving and verifying the keystore file. \n" + "This indicates that the keystore is corrupted. \n" + "The corrupted file is stored at \n%v\n" + "Please file a ticket at:\n\n" + "https://github.com/ethereum/go-ethereum/issues." + "The error was : %s" return fmt.Errorf(msg, tmpName, err) &#125; &#125; return os.Rename(tmpName, filename)&#125; 第一步加密秘钥，1234567891011121314func EncryptKey(key *Key, auth string, scryptN, scryptP int) ([]byte, error) &#123; keyBytes := math.PaddedBigBytes(key.PrivateKey.D, 32) cryptoStruct, err := EncryptDataV3(keyBytes, []byte(auth), scryptN, scryptP) if err != nil &#123; return nil, err &#125; encryptedKeyJSONV3 := encryptedKeyJSONV3&#123; hex.EncodeToString(key.Address[:]), cryptoStruct, key.Id.String(), version, &#125; return json.Marshal(encryptedKeyJSONV3)&#125; PaddedBigBytes方法是将椭圆加密的私钥中D参数以大端形式表示成一个字节数组。然后加密数据，使用我们给账户指定的密码加密椭圆曲线的私钥中的D参数123456789101112131415161718192021222324252627282930313233343536373839404142func EncryptDataV3(data, auth []byte, scryptN, scryptP int) (CryptoJSON, error) &#123; salt := make([]byte, 32) if _, err := io.ReadFull(rand.Reader, salt); err != nil &#123; panic("reading from crypto/rand failed: " + err.Error()) &#125; derivedKey, err := scrypt.Key(auth, salt, scryptN, scryptR, scryptP, scryptDKLen) if err != nil &#123; return CryptoJSON&#123;&#125;, err &#125; encryptKey := derivedKey[:16] iv := make([]byte, aes.BlockSize) // 16 if _, err := io.ReadFull(rand.Reader, iv); err != nil &#123; panic("reading from crypto/rand failed: " + err.Error()) &#125; cipherText, err := aesCTRXOR(encryptKey, data, iv) if err != nil &#123; return CryptoJSON&#123;&#125;, err &#125; mac := crypto.Keccak256(derivedKey[16:32], cipherText) scryptParamsJSON := make(map[string]interface&#123;&#125;, 5) scryptParamsJSON["n"] = scryptN scryptParamsJSON["r"] = scryptR scryptParamsJSON["p"] = scryptP scryptParamsJSON["dklen"] = scryptDKLen scryptParamsJSON["salt"] = hex.EncodeToString(salt) cipherParamsJSON := cipherparamsJSON&#123; IV: hex.EncodeToString(iv), &#125; cryptoStruct := CryptoJSON&#123; Cipher: "aes-128-ctr", CipherText: hex.EncodeToString(cipherText), CipherParams: cipherParamsJSON, KDF: keyHeaderKDF, KDFParams: scryptParamsJSON, MAC: hex.EncodeToString(mac), &#125; return cryptoStruct, nil&#125; 这一段逻辑是这样的，首先生成一个salt，然后利用scrypt算法生成一个导出秘钥，scrypt算法是可以抗暴力破解的，我们利用得到的导出秘钥的前16位作为真正的加密秘钥encryptKey，然后使用CTR模式的AES加密算法，用encryptKey加密私钥的餐数D，最后得到密文。为了能正确解密，我们需要记录一些内容，如scrypt算法的参数N、R、P，导出秘钥的长度dklen，随机变量salt，CTR模式的初始化向量IV（实际是空数组），加密算法，密文，秘钥导出算法名称，最后还有一个mac用来验证数据完整及正确性，它是用导出秘钥的第16到第32字节以及密文经过Keccak256运算后的结果。 最后返回一个cryptoStruct对象，他没有包含我们设定的密码。获得最后私钥的关键是获得导出秘钥，若没有密码，只能暴力破解，但是scrypt算法是可以抵抗暴力破解的，所以是比较安全的保存私钥方法。 回到EncryptKey中，我们最后构建一个encryptedKeyJSONV3对象，他除了包含我们刚才与加密有关的cryptoStruct对象，还包含账户地址，ID以及版本号。最后将encryptedKeyJSONV3序列化位Json数据。 回到StoreKey，经过EncryptKey方法我们已经得到了json数据，此时现将其写入一个临时文件中，然后根据需求进行解密测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798func (ks keyStorePassphrase) GetKey(addr common.Address, filename, auth string) (*Key, error) &#123; keyjson, err := ioutil.ReadFile(filename) if err != nil &#123; return nil, err &#125; key, err := DecryptKey(keyjson, auth) if err != nil &#123; return nil, err &#125; if key.Address != addr &#123; return nil, fmt.Errorf("key content mismatch: have account %x, want %x", key.Address, addr) &#125; return key, nil&#125;func DecryptKey(keyjson []byte, auth string) (*Key, error) &#123; m := make(map[string]interface&#123;&#125;) if err := json.Unmarshal(keyjson, &amp;m); err != nil &#123; return nil, err &#125; var ( keyBytes, keyId []byte err error ) if version, ok := m["version"].(string); ok &amp;&amp; version == "1" &#123; k := new(encryptedKeyJSONV1) if err := json.Unmarshal(keyjson, k); err != nil &#123; return nil, err &#125; keyBytes, keyId, err = decryptKeyV1(k, auth) &#125; else &#123; k := new(encryptedKeyJSONV3) if err := json.Unmarshal(keyjson, k); err != nil &#123; return nil, err &#125; keyBytes, keyId, err = decryptKeyV3(k, auth) &#125; if err != nil &#123; return nil, err &#125; key := crypto.ToECDSAUnsafe(keyBytes) return &amp;Key&#123; Id: uuid.UUID(keyId), Address: crypto.PubkeyToAddress(key.PublicKey), PrivateKey: key, &#125;, nil&#125;func decryptKeyV3(keyProtected *encryptedKeyJSONV3, auth string) (keyBytes []byte, keyId []byte, err error) &#123; if keyProtected.Version != version &#123; return nil, nil, fmt.Errorf("Version not supported: %v", keyProtected.Version) &#125; keyId = uuid.Parse(keyProtected.Id) plainText, err := DecryptDataV3(keyProtected.Crypto, auth) if err != nil &#123; return nil, nil, err &#125; return plainText, keyId, err&#125;func DecryptDataV3(cryptoJson CryptoJSON, auth string) ([]byte, error) &#123; if cryptoJson.Cipher != "aes-128-ctr" &#123; return nil, fmt.Errorf("Cipher not supported: %v", cryptoJson.Cipher) &#125; mac, err := hex.DecodeString(cryptoJson.MAC) if err != nil &#123; return nil, err &#125; iv, err := hex.DecodeString(cryptoJson.CipherParams.IV) if err != nil &#123; return nil, err &#125; cipherText, err := hex.DecodeString(cryptoJson.CipherText) if err != nil &#123; return nil, err &#125; derivedKey, err := getKDFKey(cryptoJson, auth) if err != nil &#123; return nil, err &#125; calculatedMAC := crypto.Keccak256(derivedKey[16:32], cipherText) if !bytes.Equal(calculatedMAC, mac) &#123; return nil, ErrDecrypt &#125; plainText, err := aesCTRXOR(derivedKey[:16], cipherText, iv) if err != nil &#123; return nil, err &#125; return plainText, err&#125; 实际上就是加密的逆过程，先读取json数据，然后先根据版本号执行不同的解密算法，我们只看V3版本的。在decryptKeyV3中，先验证版本号，然后解析出ID，之后利用DecryptDataV3解密，解密过程是先判断加密方法是否正确，然后解析出mac、iv和密文。先利用getKDFKey方法获取导出秘钥，只有提供的密码正确才能得到正确结果，然后验证mac，在进行解密获得明文。根据明文获得秘钥，再根据秘钥获得公钥，最后组装一个Key对象。然后回到GetKey中，比较提供的地址和我们解密计算出的地址是否一样，一样的话返回key，没有错误表示解密验证成功。 最后回到StoreKey将临时文件重命名为正式文件。这样新建一个账户的工作完成。回顾一下，实际上主要是随机生成了一对椭圆曲线秘钥，然后将私钥用我们提供的密码加密并保存成文件，生成秘钥的时候生成了地址。 回到accountCreate中，StoreKey方法返回了账户地址，最后打印出来即可。 update这是用来更新一个账户，所谓的更新是用新版本的存储为新版本的加密文件。有三个flag，分别是DataDirFlag，KeyStoreDirFlag以及LightKDFFlag，前面都介绍过了，注意该命令还要指定地址。使用格式如下：geth account update [options] &lt;address&gt;,我们看他的action12345678910111213141516func accountUpdate(ctx *cli.Context) error &#123; if len(ctx.Args()) == 0 &#123; utils.Fatalf("No accounts specified to update") &#125; stack, _ := makeConfigNode(ctx) ks := stack.AccountManager().Backends(keystore.KeyStoreType)[0].(*keystore.KeyStore) for _, addr := range ctx.Args() &#123; account, oldPassword := unlockAccount(ctx, ks, addr, 0, nil) newPassword := getPassPhrase("Please give a new password. Do not forget this password.", true, 0, nil) if err := ks.Update(account, oldPassword, newPassword); err != nil &#123; utils.Fatalf("Could not update the account: %v", err) &#125; &#125; return nil&#125; 首先判断我们是否制定了地址参数，没有的话报错，接着获取了一个节点，然后从节点的账户管理者那里获取了一个keystore类型的backend。有可能我们指定了多个地址，所以遍历所有地址，首先对每个地址执行解锁操作12345678910111213141516171819202122232425func unlockAccount(ctx *cli.Context, ks *keystore.KeyStore, address string, i int, passwords []string) (accounts.Account, string) &#123; account, err := utils.MakeAddress(ks, address) if err != nil &#123; utils.Fatalf("Could not list accounts: %v", err) &#125; for trials := 0; trials &lt; 3; trials++ &#123; prompt := fmt.Sprintf("Unlocking account %s | Attempt %d/%d", address, trials+1, 3) password := getPassPhrase(prompt, false, i, passwords) err = ks.Unlock(account, password) if err == nil &#123; log.Info("Unlocked account", "address", account.Address.Hex()) return account, password &#125; if err, ok := err.(*keystore.AmbiguousAddrError); ok &#123; log.Info("Unlocked account", "address", account.Address.Hex()) return ambiguousAddrRecovery(ks, err, password), password &#125; if err != keystore.ErrDecrypt &#123; break &#125; &#125; utils.Fatalf("Failed to unlock account %s (%v)", address, err) return accounts.Account&#123;&#125;, ""&#125; 第一步通过给定的字符串地址获取一个账户对象。123456789101112131415161718192021func MakeAddress(ks *keystore.KeyStore, account string) (accounts.Account, error) &#123; if common.IsHexAddress(account) &#123; return accounts.Account&#123;Address: common.HexToAddress(account)&#125;, nil &#125; // Otherwise try to interpret the account as a keystore index index, err := strconv.Atoi(account) if err != nil || index &lt; 0 &#123; return accounts.Account&#123;&#125;, fmt.Errorf("invalid account address or index %q", account) &#125; log.Warn("-------------------------------------------------------------------") log.Warn("Referring to accounts by order in the keystore folder is dangerous!") log.Warn("This functionality is deprecated and will be removed in the future!") log.Warn("Please use explicit addresses! (can search via `geth account list`)") log.Warn("-------------------------------------------------------------------") accs := ks.Accounts() if len(accs) &lt;= index &#123; return accounts.Account&#123;&#125;, fmt.Errorf("index %d higher than number of accounts %d", index, len(accs)) &#125; return accs[index], nil&#125; 首先判断是否是16进制格式，是的话直接构造一个Account对象返回。否则的话我们指定的地址可能是地址的索引，所以先尝试转为整数，然后获取所有账户，取对应索引的账户返回即可。 回到unlockAccount中，接下来进行至多三次尝试，每次都是先利用getPassPhrase获取我们指定的密码，这个方法在前面创建新账户时提过。然后调用Unlock解锁账户。1234567891011121314151617181920212223242526272829func (ks *KeyStore) Unlock(a accounts.Account, passphrase string) error &#123; return ks.TimedUnlock(a, passphrase, 0)&#125;func (ks *KeyStore) TimedUnlock(a accounts.Account, passphrase string, timeout time.Duration) error &#123; a, key, err := ks.getDecryptedKey(a, passphrase) if err != nil &#123; return err &#125; ks.mu.Lock() defer ks.mu.Unlock() u, found := ks.unlocked[a.Address] if found &#123; if u.abort == nil &#123; zeroKey(key.PrivateKey) return nil &#125; close(u.abort) &#125; if timeout &gt; 0 &#123; u = &amp;unlocked&#123;Key: key, abort: make(chan struct&#123;&#125;)&#125; go ks.expire(a.Address, u, timeout) &#125; else &#123; u = &amp;unlocked&#123;Key: key&#125; &#125; ks.unlocked[a.Address] = u return nil&#125; 相关代码上面已经给出，Unlock中直接调用TimedUnlock方法，TimedUnlock中先用getDecryptedKey方法获取Key，这个在前面介绍新建账户是提到过，这里会得到一个Key对象，其中包含账户的地址及私钥。接着从unlocked中查找是否已解锁，unlocked中键就是账户地址，值是一个unlocked对象，其中存着账户的key。如果能从unlocked中找到对应地址的unlocked对象，则先判断unlocked对象的abort变量是否为空，是的话将私钥置为0，然后返回，否则关闭abort通道。如果找不到的话，先看参数中是否设置了timeout，是的话构造一个unlocked对象，之后执行expire，没有设置timeout时也只是简单构造一个unlocked对象，但不初始化其中的abort变量。最后将新建的unlocked对象放入unlocked中。expire的作用是设定一个定时器，在一段时间后将对应地址的unlocked对象从unlocked中删除，表示账户重新进入锁定状态。 回到unlockAccount中，如果解锁成功，则返回账户对象和密码。回到accountUpdate中，这时要求提供一个新密码，然后执行update方法1234567func (ks *KeyStore) Update(a accounts.Account, passphrase, newPassphrase string) error &#123; a, key, err := ks.getDecryptedKey(a, passphrase) if err != nil &#123; return err &#125; return ks.storage.StoreKey(a.URL.Path, key, newPassphrase)&#125; 相关逻辑都以分析过，只是先获取旧的Key然后用新的Key加密并保存密钥。 import这个方法是导入一个密钥从而生成一个账户，他有4个flag前面都介绍过，这里不再介绍，他需要指定keyfile路径，执行的逻辑如下1234567891011121314151617181920func accountImport(ctx *cli.Context) error &#123; keyfile := ctx.Args().First() if len(keyfile) == 0 &#123; utils.Fatalf("keyfile must be given as argument") &#125; key, err := crypto.LoadECDSA(keyfile) if err != nil &#123; utils.Fatalf("Failed to load the private key: %v", err) &#125; stack, _ := makeConfigNode(ctx) passphrase := getPassPhrase("Your new account is locked with a password. Please give a password. Do not forget this password.", true, 0, utils.MakePasswordList(ctx)) ks := stack.AccountManager().Backends(keystore.KeyStoreType)[0].(*keystore.KeyStore) acct, err := ks.ImportECDSA(key, passphrase) if err != nil &#123; utils.Fatalf("Could not create the account: %v", err) &#125; fmt.Printf("Address: &#123;%x&#125;\n", acct.Address) return nil&#125; 首先从我们提供的文件中读取椭圆加密的私钥信息，然后构建一个节点，并取得我们给的密码，然后执行ImportECDSA123456789101112131415161718192021222324252627func (ks *KeyStore) ImportECDSA(priv *ecdsa.PrivateKey, passphrase string) (accounts.Account, error) &#123; key := newKeyFromECDSA(priv) if ks.cache.hasAddress(key.Address) &#123; return accounts.Account&#123;&#125;, fmt.Errorf("account already exists") &#125; return ks.importKey(key, passphrase)&#125;func newKeyFromECDSA(privateKeyECDSA *ecdsa.PrivateKey) *Key &#123; id := uuid.NewRandom() key := &amp;Key&#123; Id: id, Address: crypto.PubkeyToAddress(privateKeyECDSA.PublicKey), PrivateKey: privateKeyECDSA, &#125; return key&#125;func (ks *KeyStore) importKey(key *Key, passphrase string) (accounts.Account, error) &#123; a := accounts.Account&#123;Address: key.Address, URL: accounts.URL&#123;Scheme: KeyStoreScheme, Path: ks.storage.JoinPath(keyFileName(key.Address))&#125;&#125; if err := ks.storage.StoreKey(a.URL.Path, key, passphrase); err != nil &#123; return accounts.Account&#123;&#125;, err &#125; ks.cache.add(a) ks.refreshWallets() return a, nil&#125; 获得私钥后先构建一个key，这里自然也就生成了地址。先检查该地址是否已存在，是的话报错，否则执行importKey。importKey就是直接创建一个账户对象然后保存密钥文件。 题图来自unsplash：https://unsplash.com/photos/lu5uhEAy2lI]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中geth启动流程分析]]></title>
    <url>%2F2019%2F06%2F08%2Fgo-ethereum%E4%B8%ADgeth%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[geth是go-ethereum的一个重要工具，根据官方文档的说明，他是进入Ethereum网络的入口，也就是Ethereum的一个节点程序。如果直接输入geth运行，则会默认启动一个全节点，并以fast模式同步数据。我们从这个命令入手，学习一下geth的启动流程。 main.go通过对geth命令的分析，我们了解到geth是一个CLI程序，程序的定义主要在go-ethereum\cmd\geth\main.go里面，在init函数中定义了大量子命令，用于实现下图所示的功能： 但是如果我们不指定任何子命令，直接输入geth并运行，则会执行app.Action指定的内容：12345678910111213// go-ethereum\cmd\geth\main.goapp.Action = gethfunc geth(ctx *cli.Context) error &#123; if args := ctx.Args(); len(args) &gt; 0 &#123; return fmt.Errorf("invalid command: %q", args[0]) &#125; node := makeFullNode(ctx) defer node.Close() startNode(ctx, node) node.Wait() return nil&#125; geth的逻辑很简单，执行geth时不能有其他未解析的命令。之后调用makeFullNode创建一个全节点，然后启动节点，最后调用wait阻塞。 创建节点123456789101112131415161718192021222324252627282930313233343536373839404142// go-ethereum\cmd\geth\config.gofunc makeFullNode(ctx *cli.Context) *node.Node &#123; stack, cfg := makeConfigNode(ctx) if ctx.GlobalIsSet(utils.ConstantinopleOverrideFlag.Name) &#123; cfg.Eth.ConstantinopleOverride = new(big.Int).SetUint64(ctx.GlobalUint64(utils.ConstantinopleOverrideFlag.Name)) &#125; utils.RegisterEthService(stack, &amp;cfg.Eth) if ctx.GlobalBool(utils.DashboardEnabledFlag.Name) &#123; utils.RegisterDashboardService(stack, &amp;cfg.Dashboard, gitCommit) &#125; shhEnabled := enableWhisper(ctx) shhAutoEnabled := !ctx.GlobalIsSet(utils.WhisperEnabledFlag.Name) &amp;&amp; ctx.GlobalIsSet(utils.DeveloperFlag.Name) if shhEnabled || shhAutoEnabled &#123; if ctx.GlobalIsSet(utils.WhisperMaxMessageSizeFlag.Name) &#123; cfg.Shh.MaxMessageSize = uint32(ctx.Int(utils.WhisperMaxMessageSizeFlag.Name)) &#125; if ctx.GlobalIsSet(utils.WhisperMinPOWFlag.Name) &#123; cfg.Shh.MinimumAcceptedPOW = ctx.Float64(utils.WhisperMinPOWFlag.Name) &#125; if ctx.GlobalIsSet(utils.WhisperRestrictConnectionBetweenLightClientsFlag.Name) &#123; cfg.Shh.RestrictConnectionBetweenLightClients = true &#125; utils.RegisterShhService(stack, &amp;cfg.Shh) &#125; if ctx.GlobalIsSet(utils.GraphQLEnabledFlag.Name) &#123; if err := graphql.RegisterGraphQLService(stack, cfg.Node.GraphQLEndpoint(), cfg.Node.GraphQLCors, cfg.Node.GraphQLVirtualHosts, cfg.Node.HTTPTimeouts); err != nil &#123; utils.Fatalf("Failed to register the Ethereum service: %v", err) &#125; &#125; if cfg.Ethstats.URL != "" &#123; utils.RegisterEthStatsService(stack, cfg.Ethstats.URL) &#125; return stack&#125; 这里首先调用了makeConfigNode方法配置出一个节点，详见后文。节点对象生成后，利用RegisterEthService方法注册eth服务。接着根据需要注册dashboard服务，一般情况不开启此服务，需要额外启动。再往下判断是否启动whisper，条件时使用shh、shh.maxmessagesize、shh.pow或shh.restrict-light任意一个选项，或者没有显式设置shh但是启用了开发者模式（使用了–dev选项），此时配置shh然后注册shh服务。在往下如果使用了–graphql选项，则注册GraphQL服务，随后如果需要注册ethstats服务。 最后回顾可知makeFullNode主要做了这样几件事：加载配置，创建节点，注册服务。关于注册服务，默认只注册了eth服务。 makeConfigNode1234567891011121314151617181920212223242526272829303132func makeConfigNode(ctx *cli.Context) (*node.Node, gethConfig) &#123; cfg := gethConfig&#123; Eth: eth.DefaultConfig, Shh: whisper.DefaultConfig, Node: defaultNodeConfig(), Dashboard: dashboard.DefaultConfig, &#125; if file := ctx.GlobalString(configFileFlag.Name); file != "" &#123; if err := loadConfig(file, &amp;cfg); err != nil &#123; utils.Fatalf("%v", err) &#125; &#125; utils.SetULC(ctx, &amp;cfg.Eth) go-ethereum\cmd\utils\flags.go utils.SetNodeConfig(ctx, &amp;cfg.Node) stack, err := node.New(&amp;cfg.Node) if err != nil &#123; utils.Fatalf("Failed to create the protocol stack: %v", err) &#125; utils.SetEthConfig(ctx, stack, &amp;cfg.Eth) if ctx.GlobalIsSet(utils.EthStatsURLFlag.Name) &#123; cfg.Ethstats.URL = ctx.GlobalString(utils.EthStatsURLFlag.Name) &#125; utils.SetShhConfig(ctx, stack, &amp;cfg.Shh) utils.SetDashboardConfig(ctx, &amp;cfg.Dashboard) return stack, cfg&#125; 第一步加载默认配置，创建了一个gethConfig对象，包含了eth、shh（即whisper）、node和dashboard的配置。如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667//eth的默认配置如下var DefaultConfig = Config&#123; SyncMode: downloader.FastSync, Ethash: ethash.Config&#123; CacheDir: "ethash", CachesInMem: 2, CachesOnDisk: 3, DatasetsInMem: 1, DatasetsOnDisk: 2, &#125;, NetworkId: 1, LightPeers: 100, DatabaseCache: 512, TrieCleanCache: 256, TrieDirtyCache: 256, TrieTimeout: 60 * time.Minute, MinerGasFloor: 8000000, MinerGasCeil: 8000000, MinerGasPrice: big.NewInt(params.GWei), MinerRecommit: 3 * time.Second, TxPool: core.DefaultTxPoolConfig, GPO: gasprice.Config&#123; Blocks: 20, Percentile: 60, &#125;,&#125;//shh配置var DefaultConfig = Config&#123; MaxMessageSize: DefaultMaxMessageSize, MinimumAcceptedPOW: DefaultMinimumPoW, RestrictConnectionBetweenLightClients: true,&#125;//node配置func defaultNodeConfig() node.Config &#123; cfg := node.DefaultConfig //节点默认设置 cfg.Name = clientIdentifier //节点名，"geth" cfg.Version = params.VersionWithCommit(gitCommit) //节点版本号 cfg.HTTPModules = append(cfg.HTTPModules, "eth", "shh") //httprpc默认提供的接口 cfg.WSModules = append(cfg.WSModules, "eth", "shh") //websocketrpc默认提供的接口 cfg.IPCPath = "geth.ipc" //ipcrpc文件名 return cfg&#125;var DefaultConfig = Config&#123; DataDir: DefaultDataDir(), //默认节点目录 /home/.ethereum HTTPPort: DefaultHTTPPort, //httprpc默认端口 8545 HTTPModules: []string&#123;"net", "web3"&#125;, //httprpc默认提供的接口 HTTPVirtualHosts: []string&#123;"localhost"&#125;, //httpcrpc默认服务地址 HTTPTimeouts: rpc.DefaultHTTPTimeouts, //httprpc默认超时时间,读超时30秒，写超时30秒，空闲超时120秒 WSPort: DefaultWSPort, //wsrpc默认端口，8546 WSModules: []string&#123;"net", "web3"&#125;,//wscrpc默认服务地址 P2P: p2p.Config&#123; ListenAddr: ":30303", //p2p网络默认端口30303 MaxPeers: 25, //默认最大连接数 25 NAT: nat.Any(), //默认端口映射 &#125;,&#125;//dashboard配置var DefaultConfig = Config&#123; Host: "localhost", Port: 8080, Refresh: 5 * time.Second,&#125; 加载完默认配置后，再加载外部配置文件，就是–config指定的文件，toml格式。 接着就是架子我们给定配置。首先设置eth，之后设置node。这都是我们在执行geth命令时指定的选项，只与能设置那些值，详见这里。 再往下使用node的new方法创建了一个节点对象。如果没有错的话，利用了几个set方法进一步配置了配置信息。 node.New1234567891011121314151617181920212223242526272829303132333435363738394041func New(conf *Config) (*Node, error) &#123; confCopy := *conf conf = &amp;confCopy if conf.DataDir != "" &#123; absdatadir, err := filepath.Abs(conf.DataDir) if err != nil &#123; return nil, err &#125; conf.DataDir = absdatadir &#125; if strings.ContainsAny(conf.Name, `/\`) &#123; return nil, errors.New(`Config.Name must not contain '/' or '\'`) &#125; if conf.Name == datadirDefaultKeyStore &#123; //"keystore" return nil, errors.New(`Config.Name cannot be "` + datadirDefaultKeyStore + `"`) &#125; if strings.HasSuffix(conf.Name, ".ipc") &#123; //不含.ipc后缀 return nil, errors.New(`Config.Name cannot end in ".ipc"`) &#125; am, ephemeralKeystore, err := makeAccountManager(conf) if err != nil &#123; return nil, err &#125; if conf.Logger == nil &#123; conf.Logger = log.New() &#125; return &amp;Node&#123; accman: am, ephemeralKeystore: ephemeralKeystore, config: conf, serviceFuncs: []ServiceConstructor&#123;&#125;, ipcEndpoint: conf.IPCEndpoint(), httpEndpoint: conf.HTTPEndpoint(), wsEndpoint: conf.WSEndpoint(), eventmux: new(event.TypeMux), log: conf.Logger, &#125;, nil&#125; 首先得到节点目录的绝对路径。然后检查了节点名，确保节点名中不包含“/\”这些特殊符号，以及不能等于“keystore”（密钥存储路径），还有不能有.ipc后缀。接着创建了账户管理者。makeAccountManager方法主要是创建了密钥存储路径以及创建了accountmanager对象。接着配置了log对象，然后创建了Node对象。 RegisterEthService1234567891011121314151617181920func RegisterEthService(stack *node.Node, cfg *eth.Config) &#123; var err error if cfg.SyncMode == downloader.LightSync &#123; err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) &#123; return les.New(ctx, cfg) &#125;) &#125; else &#123; err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) &#123; fullNode, err := eth.New(ctx, cfg) if fullNode != nil &amp;&amp; cfg.LightServ &gt; 0 &#123; ls, _ := les.NewLesServer(fullNode, cfg) fullNode.AddLesServer(ls) &#125; return fullNode, err &#125;) &#125; if err != nil &#123; Fatalf("Failed to register the Ethereum service: %v", err) &#125;&#125; 这里根据不同的同步模式创建不同的服务。如果是LightSync，创建Light Ethereum Subprotocol的服务；如果是其他模式则创建正常的eth服务。 服务注册的逻辑都是调用节点的Register方法123456789101112func (n *Node) Register(constructor ServiceConstructor) error &#123; n.lock.Lock() defer n.lock.Unlock() if n.server != nil &#123; return ErrNodeRunning &#125; n.serviceFuncs = append(n.serviceFuncs, constructor) return nil&#125;type ServiceConstructor func(ctx *ServiceContext) (Service, error) 该方法需要提供一个ServiceConstructor对象，他实际是一个方法，执行后返回一个Service对象，Register方法就是将ServiceConstructor添加到node的serviceFuncs数组。 不管什么模式注册的服务方法都是简单的新建一个eth服务。 启动节点创建完节点后就开始启动了。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101func startNode(ctx *cli.Context, stack *node.Node) &#123; debug.Memsize.Add("node", stack) utils.StartNode(stack) if keystores := stack.AccountManager().Backends(keystore.KeyStoreType); len(keystores) &gt; 0 &#123; ks := keystores[0].(*keystore.KeyStore) passwords := utils.MakePasswordList(ctx) unlocks := strings.Split(ctx.GlobalString(utils.UnlockedAccountFlag.Name), ",") for i, account := range unlocks &#123; if trimmed := strings.TrimSpace(account); trimmed != "" &#123; unlockAccount(ctx, ks, trimmed, i, passwords) &#125; &#125; &#125; events := make(chan accounts.WalletEvent, 16) stack.AccountManager().Subscribe(events) go func() &#123; rpcClient, err := stack.Attach() if err != nil &#123; utils.Fatalf("Failed to attach to self: %v", err) &#125; stateReader := ethclient.NewClient(rpcClient) for _, wallet := range stack.AccountManager().Wallets() &#123; if err := wallet.Open(""); err != nil &#123; log.Warn("Failed to open wallet", "url", wallet.URL(), "err", err) &#125; &#125; for event := range events &#123; switch event.Kind &#123; case accounts.WalletArrived: if err := event.Wallet.Open(""); err != nil &#123; log.Warn("New wallet appeared, failed to open", "url", event.Wallet.URL(), "err", err) &#125; case accounts.WalletOpened: status, _ := event.Wallet.Status() log.Info("New wallet appeared", "url", event.Wallet.URL(), "status", status) derivationPath := accounts.DefaultBaseDerivationPath if event.Wallet.URL().Scheme == "ledger" &#123; derivationPath = accounts.DefaultLedgerBaseDerivationPath &#125; event.Wallet.SelfDerive(derivationPath, stateReader) case accounts.WalletDropped: log.Info("Old wallet dropped", "url", event.Wallet.URL()) event.Wallet.Close() &#125; &#125; &#125;() if ctx.GlobalBool(utils.ExitWhenSyncedFlag.Name) &#123; go func() &#123; sub := stack.EventMux().Subscribe(downloader.DoneEvent&#123;&#125;) defer sub.Unsubscribe() for &#123; event := &lt;-sub.Chan() if event == nil &#123; continue &#125; done, ok := event.Data.(downloader.DoneEvent) if !ok &#123; continue &#125; if timestamp := time.Unix(done.Latest.Time.Int64(), 0); time.Since(timestamp) &lt; 10*time.Minute &#123; log.Info("Synchronisation completed", "latestnum", done.Latest.Number, "latesthash", done.Latest.Hash(), "age", common.PrettyAge(timestamp)) stack.Stop() &#125; &#125; &#125;() &#125; if ctx.GlobalBool(utils.MiningEnabledFlag.Name) || ctx.GlobalBool(utils.DeveloperFlag.Name) &#123; if ctx.GlobalString(utils.SyncModeFlag.Name) == "light" &#123; utils.Fatalf("Light clients do not support mining") &#125; var ethereum *eth.Ethereum if err := stack.Service(&amp;ethereum); err != nil &#123; utils.Fatalf("Ethereum service not running: %v", err) &#125; gasprice := utils.GlobalBig(ctx, utils.MinerLegacyGasPriceFlag.Name) if ctx.IsSet(utils.MinerGasPriceFlag.Name) &#123; gasprice = utils.GlobalBig(ctx, utils.MinerGasPriceFlag.Name) &#125; ethereum.TxPool().SetGasPrice(gasprice) threads := ctx.GlobalInt(utils.MinerLegacyThreadsFlag.Name) if ctx.GlobalIsSet(utils.MinerThreadsFlag.Name) &#123; threads = ctx.GlobalInt(utils.MinerThreadsFlag.Name) &#125; if err := ethereum.StartMining(threads); err != nil &#123; utils.Fatalf("Failed to start mining: %v", err) &#125; &#125;&#125; 在startNode首先调用了utils.StartNode(stack)区启动节点。调用完毕后一个节点正式启动。接着根据需求解锁我们指定的账户使用–unlock和–password指定要解锁的账户和密钥。接着注册了账户事件，是一个WalletEvent类型容量为16的channel。 接着启动了一个goroutine，在这个goroutine中先连接了节点使用Attach方法，实际上就是连接InProcRPC服务，然后获取了所有钱包，当接收到事件时触发对应逻辑。 再往下就是根据情况启动一些辅助逻辑，首先是同步完成监听，其次是根据需求启动挖矿。 utils.StartNode12345678910111213141516171819202122// go-ethereum\cmd\utils\cmd.gofunc StartNode(stack *node.Node) &#123; if err := stack.Start(); err != nil &#123; Fatalf("Error starting protocol stack: %v", err) &#125; go func() &#123; sigc := make(chan os.Signal, 1) signal.Notify(sigc, syscall.SIGINT, syscall.SIGTERM) defer signal.Stop(sigc) &lt;-sigc log.Info("Got interrupt, shutting down...") go stack.Stop() for i := 10; i &gt; 0; i-- &#123; &lt;-sigc if i &gt; 1 &#123; log.Warn("Already shutting down, interrupt more to panic.", "times", i-1) &#125; &#125; debug.Exit() // ensure trace and CPU profile data is flushed. debug.LoudPanic("boom") &#125;()&#125; 这个方法中，先调用了stack.Start()去启动节点，之后启动了一个goroutine，这个goroutine的作用是接收到终端停止信息后，正确停止程序。利用的是Signal包，关于这个包的用法见这里。这个goroutine会一直阻塞直到收到退出信号，调用stop关闭节点。 Node.Start()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func (n *Node) Start() error &#123; n.lock.Lock() defer n.lock.Unlock() if n.server != nil &#123; return ErrNodeRunning &#125; if err := n.openDataDir(); err != nil &#123; return err &#125; n.serverConfig = n.config.P2P n.serverConfig.PrivateKey = n.config.NodeKey() n.serverConfig.Name = n.config.NodeName() n.serverConfig.Logger = n.log if n.serverConfig.StaticNodes == nil &#123; n.serverConfig.StaticNodes = n.config.StaticNodes() &#125; if n.serverConfig.TrustedNodes == nil &#123; n.serverConfig.TrustedNodes = n.config.TrustedNodes() &#125; if n.serverConfig.NodeDatabase == "" &#123; n.serverConfig.NodeDatabase = n.config.NodeDB() &#125; running := &amp;p2p.Server&#123;Config: n.serverConfig&#125; n.log.Info("Starting peer-to-peer node", "instance", n.serverConfig.Name) services := make(map[reflect.Type]Service) for _, constructor := range n.serviceFuncs &#123; ctx := &amp;ServiceContext&#123; config: n.config, services: make(map[reflect.Type]Service), EventMux: n.eventmux, AccountManager: n.accman, &#125; for kind, s := range services &#123; ctx.services[kind] = s &#125; service, err := constructor(ctx) if err != nil &#123; return err &#125; kind := reflect.TypeOf(service) if _, exists := services[kind]; exists &#123; return &amp;DuplicateServiceError&#123;Kind: kind&#125; &#125; services[kind] = service &#125; for _, service := range services &#123; running.Protocols = append(running.Protocols, service.Protocols()...) &#125; if err := running.Start(); err != nil &#123; return convertFileLockError(err) &#125; started := []reflect.Type&#123;&#125; for kind, service := range services &#123; if err := service.Start(running); err != nil &#123; for _, kind := range started &#123; services[kind].Stop() &#125; running.Stop() return err &#125; started = append(started, kind) &#125; if err := n.startRPC(services); err != nil &#123; for _, service := range services &#123; service.Stop() &#125; running.Stop() return err &#125; n.services = services n.server = running n.stop = make(chan struct&#123;&#125;) return nil&#125; 首先检查是否启动过，之后调用openDataDir尝试打开节点目录1234567891011121314151617func (n *Node) openDataDir() error &#123; if n.config.DataDir == "" &#123; return nil &#125; instdir := filepath.Join(n.config.DataDir, n.config.name()) if err := os.MkdirAll(instdir, 0700); err != nil &#123; return err &#125; release, _, err := flock.New(filepath.Join(instdir, "LOCK")) if err != nil &#123; return convertFileLockError(err) &#125; n.instanceDirLock = release return nil&#125; openDataDir比较简单，首先判断是否设置了节点目录，没有的话直接返回，有的话创建一个以节点名为名字的子目录，默认为geth。之后在子目录geth中创建一个文件锁，名字是LOCK，为的是线程安全，之后用instanceDirLock变量记录文件锁引用，以便后续释放。 回到start中，此时文件目录及文件锁都创建完毕。然后初始化p2p服务，首先配置私钥123456789101112131415161718192021222324252627282930313233func (c *Config) NodeKey() *ecdsa.PrivateKey &#123; if c.P2P.PrivateKey != nil &#123; return c.P2P.PrivateKey &#125; if c.DataDir == "" &#123; key, err := crypto.GenerateKey() if err != nil &#123; log.Crit(fmt.Sprintf("Failed to generate ephemeral node key: %v", err)) &#125; return key &#125; keyfile := c.ResolvePath(datadirPrivateKey) if key, err := crypto.LoadECDSA(keyfile); err == nil &#123; return key &#125; key, err := crypto.GenerateKey() if err != nil &#123; log.Crit(fmt.Sprintf("Failed to generate node key: %v", err)) &#125; instanceDir := filepath.Join(c.DataDir, c.name()) if err := os.MkdirAll(instanceDir, 0700); err != nil &#123; log.Error(fmt.Sprintf("Failed to persist node key: %v", err)) return key &#125; keyfile = filepath.Join(instanceDir, datadirPrivateKey) if err := crypto.SaveECDSA(keyfile, key); err != nil &#123; log.Error(fmt.Sprintf("Failed to persist node key: %v", err)) &#125; return key&#125; 第一步检查是否加载过私钥。没有的话，如果节点目录为空，直接生成一个，是椭圆曲线加密的秘钥。如果配置节点目录的话，则先尝试从目录中加载秘钥文件，之后读取私钥，秘钥文件是在geth子目录下的nodekey文件。若没有秘钥文件，则生成一个秘钥，之后存储到文件中，还是geth目录下的nodekey文件。 配置为秘钥后，又配置了服务名，使用NodeName方法，这个方法是一系列字符串组合，不在叙述。之后配置了静态节点123456789101112131415161718192021222324252627282930313233func (c *Config) StaticNodes() []*enode.Node &#123; return c.parsePersistentNodes(&amp;c.staticNodesWarning, c.ResolvePath(datadirStaticNodes))&#125;func (c *Config) parsePersistentNodes(w *bool, path string) []*enode.Node &#123; if c.DataDir == "" &#123; return nil &#125; if _, err := os.Stat(path); err != nil &#123; return nil &#125; c.warnOnce(w, "Found deprecated node list file %s, please use the TOML config file instead.", path) var nodelist []string if err := common.LoadJSON(path, &amp;nodelist); err != nil &#123; log.Error(fmt.Sprintf("Can't load node list file: %v", err)) return nil &#125; var nodes []*enode.Node for _, url := range nodelist &#123; if url == "" &#123; continue &#125; node, err := enode.ParseV4(url) if err != nil &#123; log.Error(fmt.Sprintf("Node URL %s: %v\n", url, err)) continue &#125; nodes = append(nodes, node) &#125; return nodes&#125; 这里直接调用了parsePersistentNodes方法，包括后面加载可信节点也是这个方法，只是传入的参数不同。以静态节点为例，首先通过ResolvePath方法构造出静态节点文件的路径，对于静态节点是datadir/static-nodes.json,对于可信节点是datadir/trusted-nodes.json。之后在parsePersistentNodes中，如果没有配置节点路径，则返回空，否则判断文件是否存在，存在的话解析json文件，实际就是一个字符串数据。每个字符串代表一个节点，之后对于每个字符串解析为一个node节点，最后返回所有节点。 加载完静态节点和可信节点后，有配置了数据库路径，默认是datadir/geth/nodes，这里用了NodeDB方法123456func (c *Config) NodeDB() string &#123; if c.DataDir == "" &#123; return "" // ephemeral &#125; return c.ResolvePath(datadirNodeDatabase)&#125; 关键是ResolvePath，这个方法被多次用到，这里分析一下123456789101112131415161718192021222324252627282930var isOldGethResource = map[string]bool&#123; "chaindata": true, "nodes": true, "nodekey": true, "static-nodes.json": false, "trusted-nodes.json": false, &#125;func (c *Config) ResolvePath(path string) string &#123; if filepath.IsAbs(path) &#123; return path &#125; if c.DataDir == "" &#123; return "" &#125; if warn, isOld := isOldGethResource[path]; isOld &#123; oldpath := "" if c.name() == "geth" &#123; oldpath = filepath.Join(c.DataDir, path) &#125; if oldpath != "" &amp;&amp; common.FileExist(oldpath) &#123; if warn &#123; c.warnOnce(&amp;c.oldGethResourceWarning, "Using deprecated resource file %s, please move this file to the 'geth' subdirectory of datadir.", oldpath) &#125; return oldpath &#125; &#125; return filepath.Join(c.instanceDir(), path)&#125; 这里传入一个路径，一般是文件名，然后先判断是否是绝对路径，是的话直接返回，不是的话再判断datadir是否被设置，没有的话返回空。接着从isOldGethResource中查找以path为键的值，warn表示对应的值，isold表示是否有该键。如果有该键且节点名为geth时，设置目录为datadir/path。接着如果该文件已经存在表示有旧的数据，如果warn位true的话打印log并返回路径。如果节点名不是geth或者没有该键，或者文件不存在，则返回新的路径:datadir/节点名/path 回到start中，最后新建一个p2p服务。接着构建服务集合，遍历我们再注册服务时创建的serviceFuncs对象（默认时只有eth服务），每次遍历是都先创建一个ServiceContext，然后利用我们注册服务时提供的公共构造服务，然后反射服务的类型放到services中，但是不能重复。按照服务创建的先后顺序，后创建的服务在其ServiceContext中都持有先前服务的引用。 接着变量已创建的服务，将其协议添加到p2p服务的协议字段。最后先启动p2p服务，然后再启动之前注册的各个服务，注意在某个服务启动失败后，将终止所有服务，包括p2p服务。最后返回错误。 紧接着，调用startRPC方法启动rpc服务12345678910111213141516171819202122232425262728func (n *Node) startRPC(services map[reflect.Type]Service) error &#123; apis := n.apis() for _, service := range services &#123; apis = append(apis, service.APIs()...) &#125; if err := n.startInProc(apis); err != nil &#123; return err &#125; if err := n.startIPC(apis); err != nil &#123; n.stopInProc() return err &#125; if err := n.startHTTP(n.httpEndpoint, apis, n.config.HTTPModules, n.config.HTTPCors, n.config.HTTPVirtualHosts, n.config.HTTPTimeouts); err != nil &#123; n.stopIPC() n.stopInProc() return err &#125; if err := n.startWS(n.wsEndpoint, apis, n.config.WSModules, n.config.WSOrigins, n.config.WSExposeAll); err != nil &#123; n.stopHTTP() n.stopIPC() n.stopInProc() return err &#125; n.rpcAPIs = apis return nil&#125; 首先收集所有可以提供的api，然后依次调用startInProc、startIPC、startHTTP和startWS来根据需求启动各种rpc服务。注意其中任何一个rpc开启失败的话，都会关闭之前开启的rpc服务，并返回错误。 总结geth的启动流程主要是就是先构造一个节点，然后启动各种服务。最先被启动的是p2p服务，然后在启动我们之前注册的各种服务，默认情况下只有Ethereum服务，最后启动各种RPC服务。 题图来自unsplash：https://unsplash.com/photos/DuBNA1QMpPA]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中txpool源码学习]]></title>
    <url>%2F2019%2F06%2F08%2Fgo-ethereum%E4%B8%ADtxpool%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[TxPool有许多辅助的数据类型，不先介绍一下将会很难理解txpool的实现，这里先介绍与之先关的数据类型 nonceHeap这是一个uint64数组类型，他实现的是heap接口(container/heap)，heap又实现了sort接口，这是一个最小堆。 Push123func (h *nonceHeap) Push(x interface&#123;&#125;) &#123; *h = append(*h, x.(uint64))&#125; 就是简单的把一个uint64类型数据放入数组末尾 Pop1234567func (h *nonceHeap) Pop() interface&#123;&#125; &#123; old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x&#125; 从末尾弹出一个数据 txSortedMap这是一个nonce到交易的映射12345type txSortedMap struct &#123; items map[uint64]*types.Transaction index *nonceHeap cache types.Transactions &#125; 他有一个map类型成员，键是uint64位数据。即nonce，值就是一个个交易。123456func newTxSortedMap() *txSortedMap &#123; return &amp;txSortedMap&#123; items: make(map[uint64]*types.Transaction), index: new(nonceHeap), &#125;&#125; 构造方法就是初始化两个成员变量 Get &amp; Put1234567891011func (m *txSortedMap) Get(nonce uint64) *types.Transaction &#123; return m.items[nonce]&#125;func (m *txSortedMap) Put(tx *types.Transaction) &#123; nonce := tx.Nonce() if m.items[nonce] == nil &#123; heap.Push(m.index, nonce) &#125; m.items[nonce], m.cache = tx, nil&#125; get方法就是按照nonce取值，put方法就是将交易按期nonce值存储。 Forward这个方法用来删除存储的所有nonce小于threshold的交易1234567891011121314func (m *txSortedMap) Forward(threshold uint64) types.Transactions &#123; var removed types.Transactions for m.index.Len() &gt; 0 &amp;&amp; (*m.index)[0] &lt; threshold &#123; nonce := heap.Pop(m.index).(uint64) removed = append(removed, m.items[nonce]) delete(m.items, nonce) &#125; if m.cache != nil &#123; m.cache = m.cache[len(removed):] &#125; return removed&#125; 很简单，由于index是一个nonceHeap类型数据，他从小到大排序，所有每次取第一个也就是最小值，进行判断并删除。 Filter过滤并删除功能1234567891011121314151617181920func (m *txSortedMap) Filter(filter func(*types.Transaction) bool) types.Transactions &#123; var removed types.Transactions for nonce, tx := range m.items &#123; if filter(tx) &#123; removed = append(removed, tx) delete(m.items, nonce) &#125; &#125; if len(removed) &gt; 0 &#123; *m.index = make([]uint64, 0, len(m.items)) for nonce := range m.items &#123; *m.index = append(*m.index, nonce) &#125; heap.Init(m.index) m.cache = nil &#125; return removed&#125; 先遍历所有的item，然后删除所有满足filter函数的交易。注意删除完要重构堆。 Cap这个方法限制存储的交易数量1234567891011121314151617181920func (m *txSortedMap) Cap(threshold int) types.Transactions &#123; if len(m.items) &lt;= threshold &#123; return nil &#125; var drops types.Transactions sort.Sort(*m.index) for size := len(m.items); size &gt; threshold; size-- &#123; drops = append(drops, m.items[(*m.index)[size-1]]) delete(m.items, (*m.index)[size-1]) &#125; *m.index = (*m.index)[:threshold] heap.Init(m.index) if m.cache != nil &#123; m.cache = m.cache[:len(m.cache)-len(drops)] &#125; return drops&#125; 如果已有的交易数量大于指定值，则先对index排序，然后将index从后向前删除，知道满足条件，最后还要重构堆。 Remove1234567891011121314151617func (m *txSortedMap) Remove(nonce uint64) bool &#123; _, ok := m.items[nonce] if !ok &#123; return false &#125; for i := 0; i &lt; m.index.Len(); i++ &#123; if (*m.index)[i] == nonce &#123; heap.Remove(m.index, i) break &#125; &#125; delete(m.items, nonce) m.cache = nil return true&#125; 删除方法，先从items中找到对应的交易，然后先从堆中删除给定的nonce，之后再从itmes中删除 Ready返回一组连续交易，并将其从中删除，这一组交易中第一个交易的nonce要小于给定的值。123456789101112131415func (m *txSortedMap) Ready(start uint64) types.Transactions &#123; if m.index.Len() == 0 || (*m.index)[0] &gt; start &#123; return nil &#125; var ready types.Transactions for next := (*m.index)[0]; m.index.Len() &gt; 0 &amp;&amp; (*m.index)[0] == next; next++ &#123; ready = append(ready, m.items[next]) delete(m.items, next) heap.Pop(m.index) &#125; m.cache = nil return ready&#125; 由于index是一个最小堆，所以根节点也就是数组的第一个值时堆的最小值，如果这个最小值比我们给定的值要大则直接返回。接下来开始一个循环，从堆得最小值开始，寻找连续的交易，每找到一个就将其从items中删除，直到下一个值不连续为止。 Flatten这个方法是返回一个基于nonce排序的交易集合123456789101112func (m *txSortedMap) Flatten() types.Transactions &#123; if m.cache == nil &#123; m.cache = make(types.Transactions, 0, len(m.items)) for _, tx := range m.items &#123; m.cache = append(m.cache, tx) &#125; sort.Sort(types.TxByNonce(m.cache)) &#125; txs := make(types.Transactions, len(m.cache)) copy(txs, m.cache) return txs&#125; 首先从cache中查找，没有的话将所有交易放入cache中，并按Nonce排序，最后返回一个Transactions类型数据。TxByNonce是一个可排序的Transactions类型。 txListtxList 是属于同一个账号的交易列表，按照nonce排序。1234567type txList struct &#123; strict bool txs *txSortedMap costcap *big.Int gascap uint64 &#125; 可见其中封装了txSortedMap，实际存储还是在txSortedMap中。1234567func newTxList(strict bool) *txList &#123; return &amp;txList&#123; strict: strict, txs: newTxSortedMap(), costcap: new(big.Int), &#125;&#125; strict是规定nonce是由要求连续的。 Overlaps123func (l *txList) Overlaps(tx *types.Transaction) bool &#123; return l.txs.Get(tx.Nonce()) != nil&#125; 检查给定的交易是否在txList中，实际上是借助txSortedMap的get方法按nonce查询。 Add1234567891011121314151617func (l *txList) Add(tx *types.Transaction, priceBump uint64) (bool, *types.Transaction) &#123; old := l.txs.Get(tx.Nonce()) if old != nil &#123; threshold := new(big.Int).Div(new(big.Int).Mul(old.GasPrice(), big.NewInt(100+int64(priceBump))), big.NewInt(100)) if old.GasPrice().Cmp(tx.GasPrice()) &gt;= 0 || threshold.Cmp(tx.GasPrice()) &gt; 0 &#123; return false, nil &#125; &#125; l.txs.Put(tx) if cost := tx.Cost(); l.costcap.Cmp(cost) &lt; 0 &#123; l.costcap = cost &#125; if gas := tx.Gas(); l.gascap &lt; gas &#123; l.gascap = gas &#125; return true, old&#125; 这是添加或替换方法。首先根据交易的nonce从已存储的集合中尝试获取，如果有的话表示有旧的交易。此时安装下面公式计算：(old_price * (100+priceBump))/100.只有如果旧的交易的GasPrice大于新的交易，或者刚才那个值大于新的交易的GasPrice则不进行任何处理。否则将新的交易放入txlist中。接着按情况更新costcap，他代表所有交易中的最高花费，以及gascap，表示所有交易中的最高gas用量。 Forward123func (l *txList) Forward(threshold uint64) types.Transactions &#123; return l.txs.Forward(threshold)&#125; 直接调用txSortedMap方法，删除并返回比指定值小的交易 Filter12345678910111213141516171819202122func (l *txList) Filter(costLimit *big.Int, gasLimit uint64) (types.Transactions, types.Transactions) &#123; if l.costcap.Cmp(costLimit) &lt;= 0 &amp;&amp; l.gascap &lt;= gasLimit &#123; return nil, nil &#125; l.costcap = new(big.Int).Set(costLimit) l.gascap = gasLimit removed := l.txs.Filter(func(tx *types.Transaction) bool &#123; return tx.Cost().Cmp(costLimit) &gt; 0 || tx.Gas() &gt; gasLimit &#125;) var invalids types.Transactions if l.strict &amp;&amp; len(removed) &gt; 0 &#123; lowest := uint64(math.MaxUint64) for _, tx := range removed &#123; if nonce := tx.Nonce(); lowest &gt; nonce &#123; lowest = nonce &#125; &#125; invalids = l.txs.Filter(func(tx *types.Transaction) bool &#123; return tx.Nonce() &gt; lowest &#125;) &#125; return removed, invalids&#125; 给定两个参数一个是花费限制，一个是gas限制，所有大于这两个值其中之一的交易都会被删除并返回。 第一步先判断我们已有的交易中是否有符合条件的交易。有的话先更新costcap和gascap。之后利用txSortedMap的filter进行过滤。如果实在严格模式下，先获取刚才过滤出的交易集合中改的最小nonce，返回在获取大于次nonce的所有交易。主要是为了保持连续性 Remove12345678910func (l *txList) Remove(tx *types.Transaction) (bool, types.Transactions) &#123; nonce := tx.Nonce() if removed := l.txs.Remove(nonce); !removed &#123; return false, nil &#125; if l.strict &#123; return true, l.txs.Filter(func(tx *types.Transaction) bool &#123; return tx.Nonce() &gt; nonce &#125;) &#125; return true, nil&#125; 删除一个交易，但是在严格模式下，还要过滤出所有nonce大于给定交易的nonce的所有交易。主要是为了保持连续性 txLookup12345678910type txLookup struct &#123; all map[common.Hash]*types.Transaction lock sync.RWMutex&#125;func newTxLookup() *txLookup &#123; return &amp;txLookup&#123; all: make(map[common.Hash]*types.Transaction), &#125;&#125; 只是封装了一个map，键是交易的hash，值就是交易本身。另外还有一个读写锁 Range12345678910func (t *txLookup) Range(f func(hash common.Hash, tx *types.Transaction) bool) &#123; t.lock.RLock() defer t.lock.RUnlock() for key, value := range t.all &#123; if !f(key, value) &#123; break &#125; &#125;&#125; 需要指定一个方法，会用这个方法处理txLookup例那个map中的所有键值对，当返回false时终止。 Get &amp; Add123456789101112131415161718192021222324252627func (t *txLookup) Get(hash common.Hash) *types.Transaction &#123; t.lock.RLock() defer t.lock.RUnlock() return t.all[hash]&#125;func (t *txLookup) Add(tx *types.Transaction) &#123; t.lock.Lock() defer t.lock.Unlock() t.all[tx.Hash()] = tx&#125;func (t *txLookup) Remove(hash common.Hash) &#123; t.lock.Lock() defer t.lock.Unlock() delete(t.all, hash)&#125;func (t *txLookup) Count() int &#123; t.lock.RLock() defer t.lock.RUnlock() return len(t.all)&#125; 都是直接调用map实现的增删查方法。 accountSet123456789101112type accountSet struct &#123; accounts map[common.Address]struct&#123;&#125; signer types.Signer cache *[]common.Address&#125;func newAccountSet(signer types.Signer) *accountSet &#123; return &amp;accountSet&#123; accounts: make(map[common.Address]struct&#123;&#125;), signer: signer, &#125;&#125; 简单来说就是一个账号的集合，由于封装了Singer对象，所以还可以用来处理签名，Signer是一个接口，提供了从交易中获取发送人地址，获取交易hash以及交易原始签名值的功能 contains1234func (as *accountSet) contains(addr common.Address) bool &#123; _, exist := as.accounts[addr] return exist&#125; 判断给定的地址是否在集合内 containsTx123456func (as *accountSet) containsTx(tx *types.Transaction) bool &#123; if addr, err := types.Sender(as.signer, tx); err == nil &#123; return as.contains(addr) &#125; return false&#125; 给定一个交易，先用Sender方法获取到发送人地址，在判断该地址是否在集合内 add1234func (as *accountSet) add(addr common.Address) &#123; as.accounts[addr] = struct&#123;&#125;&#123;&#125; as.cache = nil&#125; 给定一个地址放入集合内 flatten12345678910func (as *accountSet) flatten() []common.Address &#123; if as.cache == nil &#123; accounts := make([]common.Address, 0, len(as.accounts)) for account := range as.accounts &#123; accounts = append(accounts, account) &#125; as.cache = &amp;accounts &#125; return *as.cache&#125; 以数组的形式返回存储的所有地址，先从cache中取，没有值的话在遍历accounts。 priceHeap首先实际上他是一个Transaction类型的数组，但是实现了堆接口，也是一个最小堆，按照gas价格排序，若gas价格一样则按nonce排序123456789101112131415161718192021222324252627type priceHeap []*types.Transactionfunc (h priceHeap) Len() int &#123; return len(h) &#125;func (h priceHeap) Swap(i, j int) &#123; h[i], h[j] = h[j], h[i] &#125;func (h priceHeap) Less(i, j int) bool &#123; switch h[i].GasPrice().Cmp(h[j].GasPrice()) &#123; case -1: return true case 1: return false &#125; return h[i].Nonce() &gt; h[j].Nonce()&#125;func (h *priceHeap) Push(x interface&#123;&#125;) &#123; *h = append(*h, x.(*types.Transaction))&#125;func (h *priceHeap) Pop() interface&#123;&#125; &#123; old := *h n := len(old) x := old[n-1] *h = old[0 : n-1] return x&#125; txPricedList123456789101112type txPricedList struct &#123; all *txLookup items *priceHeap stales int &#125;func newTxPricedList(all *txLookup) *txPricedList &#123; return &amp;txPricedList&#123; all: all, items: new(priceHeap), &#125;&#125; 类似于txList的功能，构造时会传入txloopup对象，其中包含一系列的交易 Put123func (l *txPricedList) Put(tx *types.Transaction) &#123; heap.Push(l.items, tx)&#125; 注意这里是将交易放在那个最小堆中 Cap123456789101112131415161718192021222324252627func (l *txPricedList) Cap(threshold *big.Int, local *accountSet) types.Transactions &#123; drop := make(types.Transactions, 0, 128) save := make(types.Transactions, 0, 64) for len(*l.items) &gt; 0 &#123; tx := heap.Pop(l.items).(*types.Transaction) if l.all.Get(tx.Hash()) == nil &#123; l.stales-- continue &#125; if tx.GasPrice().Cmp(threshold) &gt;= 0 &#123; save = append(save, tx) break &#125; if local.containsTx(tx) &#123; save = append(save, tx) &#125; else &#123; drop = append(drop, tx) &#125; &#125; for _, tx := range save &#123; heap.Push(l.items, tx) &#125; return drop&#125; 给定两个参数，第一个参数是一个阈值，第二个是一个accountSet集合local。这里会遍历所有item中存储的交易，对于gasprice小于阈值的交易如果不属于local，则放入drop中返回，否则还放回items中。 Underpriced12345678910111213141516171819202122func (l *txPricedList) Underpriced(tx *types.Transaction, local *accountSet) bool &#123; if local.containsTx(tx) &#123; return false &#125; for len(*l.items) &gt; 0 &#123; head := []*types.Transaction(*l.items)[0] if l.all.Get(head.Hash()) == nil &#123; l.stales-- heap.Pop(l.items) continue &#125; break &#125; if len(*l.items) == 0 &#123; log.Error("Pricing query for empty pool") return false &#125; cheapest := []*types.Transaction(*l.items)[0] return cheapest.GasPrice().Cmp(tx.GasPrice()) &gt;= 0&#125; 这个方法是给定一个交易，然后检查这个交易的GasPrice是否比集合中存储的GasPrice的最小值还要小，由于是按GasPrice排序，所以items中第一个元素就是GasPrice最小值。 Discard123456789101112131415161718192021222324func (l *txPricedList) Discard(count int, local *accountSet) types.Transactions &#123; drop := make(types.Transactions, 0, count) save := make(types.Transactions, 0, 64) for len(*l.items) &gt; 0 &amp;&amp; count &gt; 0 &#123; // Discard stale transactions if found during cleanup tx := heap.Pop(l.items).(*types.Transaction) if l.all.Get(tx.Hash()) == nil &#123; l.stales-- continue &#125; // Non stale transaction found, discard unless local if local.containsTx(tx) &#123; save = append(save, tx) &#125; else &#123; drop = append(drop, tx) count-- &#125; &#125; for _, tx := range save &#123; heap.Push(l.items, tx) &#125; return drop&#125; 这个是取集合中GasPrice最小的count个交易从中删除并返回，前提是不在local中，若在则需要再放回 Removed123456789101112131415func (l *txPricedList) Removed() &#123; l.stales++ if l.stales &lt;= len(*l.items)/4 &#123; return &#125; reheap := make(priceHeap, 0, l.all.Count()) l.stales, l.items = 0, &amp;reheap l.all.Range(func(hash common.Hash, tx *types.Transaction) bool &#123; *l.items = append(*l.items, tx) return true &#125;) heap.Init(l.items)&#125; 用来通知有旧的交易被删除，该方法每调用一次，stales加一，当达到items个数的四分之一时，从新调整堆，集体方法是新建一个堆，让后将原来items中改的元素依次放入然后初始化该堆即可。 txJournal这是一个交易的循环日志对象，目的是存储本地创建的交易，使未执行的交易能在节点启动时得到执行12345678910type txJournal struct &#123; path string writer io.WriteCloser &#125;func newTxJournal(path string) *txJournal &#123; return &amp;txJournal&#123; path: path, &#125;&#125; path就是存储交易的目录 load123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051func (journal *txJournal) load(add func([]*types.Transaction) []error) error &#123; if _, err := os.Stat(journal.path); os.IsNotExist(err) &#123; return nil &#125; input, err := os.Open(journal.path) if err != nil &#123; return err &#125; defer input.Close() journal.writer = new(devNull) defer func() &#123; journal.writer = nil &#125;() stream := rlp.NewStream(input, 0) total, dropped := 0, 0 loadBatch := func(txs types.Transactions) &#123; for _, err := range add(txs) &#123; if err != nil &#123; log.Debug("Failed to add journaled transaction", "err", err) dropped++ &#125; &#125; &#125; var ( failure error batch types.Transactions ) for &#123; tx := new(types.Transaction) if err = stream.Decode(tx); err != nil &#123; if err != io.EOF &#123; failure = err &#125; if batch.Len() &gt; 0 &#123; loadBatch(batch) &#125; break &#125; total++ if batch = append(batch, tx); batch.Len() &gt; 1024 &#123; loadBatch(batch) batch = batch[:0] &#125; &#125; log.Info("Loaded local transaction journal", "transactions", total, "dropped", dropped) return failure&#125; 加载并解析磁盘存储的交易。首先判断路径所指的文件是否存在，然后打开该文件。devNull是一个虚拟写的对象，它的write不产生任何写动作，直接返回要写数据的长度，它的close永远返回nil。 打开文件后，根据input获取一个rlp的流，之后进入一个循环，每次解码出一个交易，如果没错的话，计数器total加一，然后将刚才解码出的交易放入batch中，这是一个交易集合。若batch中交易数量大于1024或者刚才解码出错都调用loadBatch方法。 loadBatch方法线用add方法处理刚才得到了交易集合，add方法是我们调用load方法是指定的，之后遍历add返回的error数组，对于有错的交易打印log并使计数器dropped加一。 insert123456789func (journal *txJournal) insert(tx *types.Transaction) error &#123; if journal.writer == nil &#123; return errNoActiveJournal &#125; if err := rlp.Encode(journal.writer, tx); err != nil &#123; return err &#125; return nil&#125; 这里是将一个交易放入日志中，直接使用rlp编码，接入写入writer中。 rotate123456789101112131415161718192021222324252627282930313233343536func (journal *txJournal) rotate(all map[common.Address]types.Transactions) error &#123; if journal.writer != nil &#123; if err := journal.writer.Close(); err != nil &#123; return err &#125; journal.writer = nil &#125; replacement, err := os.OpenFile(journal.path+".new", os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0755) if err != nil &#123; return err &#125; journaled := 0 for _, txs := range all &#123; for _, tx := range txs &#123; if err = rlp.Encode(replacement, tx); err != nil &#123; replacement.Close() return err &#125; &#125; journaled += len(txs) &#125; replacement.Close() if err = os.Rename(journal.path+".new", journal.path); err != nil &#123; return err &#125; sink, err := os.OpenFile(journal.path, os.O_WRONLY|os.O_APPEND, 0755) if err != nil &#123; return err &#125; journal.writer = sink log.Info("Regenerated local transaction journal", "transactions", journaled, "accounts", len(all)) return nil&#125; 这个是用来重新生成交易日志的。第一步先把原来的writer关闭，之后新建一个日志文件，在原来path基础上加.new后缀，然后遍历所有给定的交易，参数中给的是一个map，指的是对应地址的所有交易。对于每个交易先经过rlp编码后写入文件中。最后将新建的文件重命名为原来给定的名字。最后重新打开新的文件，然后设置writer为新文件对象。 txSenderCacher这是一个帮助了，为的是并发的从一组交易中恢复出每个交易的发送人地址1234567891011121314151617181920212223var senderCacher = newTxSenderCacher(runtime.NumCPU())type txSenderCacher struct &#123; threads int tasks chan *txSenderCacherRequest&#125;type txSenderCacherRequest struct &#123; signer types.Signer txs []*types.Transaction inc int&#125;func newTxSenderCacher(threads int) *txSenderCacher &#123; cacher := &amp;txSenderCacher&#123; tasks: make(chan *txSenderCacherRequest, threads), threads: threads, &#125; for i := 0; i &lt; threads; i++ &#123; go cacher.cache() &#125; return cacher&#125; 构造参数需要指定并发数，一般都是cpu核数。然后启动若干个goroutine去执行cache方法 cache1234567func (cacher *txSenderCacher) cache() &#123; for task := range cacher.tasks &#123; for i := 0; i &lt; len(task.txs); i += task.inc &#123; types.Sender(task.signer, task.txs[i]) &#125; &#125;&#125; tasks是一个channel，其中数据时txSenderCacherRequest，在cache中会在for循环中阻塞，知道通道中有数据来临，然后调用Sender方法去恢复地址，并将地址写入对应交易的from字段 recover1234567891011121314151617func (cacher *txSenderCacher) recover(signer types.Signer, txs []*types.Transaction) &#123; if len(txs) == 0 &#123; return &#125; tasks := cacher.threads if len(txs) &lt; tasks*4 &#123; tasks = (len(txs) + 3) / 4 &#125; for i := 0; i &lt; tasks; i++ &#123; cacher.tasks &lt;- &amp;txSenderCacherRequest&#123; signer: signer, txs: txs[i:], inc: tasks, &#125; &#125;&#125; 我们说刚才cache方法在没有数据时会被阻塞，这个方法就是用来发送数据的，现将给定的交易集合分为若干份，每一份都封装为一个txSenderCacherRequest对象，然后发送到通道中，这样激活了cache去解析地址。 recoverFromBlocks1234567891011func (cacher *txSenderCacher) recoverFromBlocks(signer types.Signer, blocks []*types.Block) &#123; count := 0 for _, block := range blocks &#123; count += len(block.Transactions()) &#125; txs := make([]*types.Transaction, 0, count) for _, block := range blocks &#123; txs = append(txs, block.Transactions()...) &#125; cacher.recover(signer, txs)&#125; 我们知道一个区块中也保存了大量交易，所以这里也封装了一个方法去直接处理一个区块中的所有交易，主要是将区块中的交易封装为一个Transactions然后用recover方法处理。 TxPool1234567891011121314151617181920212223242526272829type TxPool struct &#123; config TxPoolConfig chainconfig *params.ChainConfig chain blockChain gasPrice *big.Int txFeed event.Feed scope event.SubscriptionScope chainHeadCh chan ChainHeadEvent chainHeadSub event.Subscription signer types.Signer mu sync.RWMutex currentState *state.StateDB pendingState *state.ManagedState currentMaxGas uint64 locals *accountSet journal *txJournal pending map[common.Address]*txList queue map[common.Address]*txList beats map[common.Address]time.Time all *txLookup priced *txPricedList wg sync.WaitGroup homestead bool&#125; 这里面有几个重要的成员，后面的方法大多都是围绕这几个成员操作的。pending指所有当前可以处理的交易，按照发送人地址归类。queue指当前还不能处理的交易，也是按发送人地址归类。beats指每一个相关账户最后一次心跳时间。all指所有可以查找到的交易。priced是将交易按GasPrice排序的集合。gasPrice指最小gas价格。currentMaxGas指当前最大gas使用量。默认的txpool配置如下1234567891011121314var DefaultTxPoolConfig = TxPoolConfig&#123; Journal: "transactions.rlp", Rejournal: time.Hour, PriceLimit: 1, PriceBump: 10, AccountSlots: 16, GlobalSlots: 4096, AccountQueue: 64, GlobalQueue: 1024, Lifetime: 3 * time.Hour,&#125; 构造txpool包含所有当前已知交易。当从网络收到交易或本地提交交易后，交易会被放入txpool中，当交易已经被包含在区块链中时，会被删除。1234567891011121314151617181920212223242526272829303132333435363738394041func NewTxPool(config TxPoolConfig, chainconfig *params.ChainConfig, chain blockChain) *TxPool &#123; config = (&amp;config).sanitize() pool := &amp;TxPool&#123; config: config, chainconfig: chainconfig, chain: chain, signer: types.NewEIP155Signer(chainconfig.ChainID), pending: make(map[common.Address]*txList), queue: make(map[common.Address]*txList), beats: make(map[common.Address]time.Time), all: newTxLookup(), chainHeadCh: make(chan ChainHeadEvent, chainHeadChanSize), gasPrice: new(big.Int).SetUint64(config.PriceLimit), &#125; pool.locals = newAccountSet(pool.signer) for _, addr := range config.Locals &#123; log.Info("Setting new local account", "address", addr) pool.locals.add(addr) &#125; pool.priced = newTxPricedList(pool.all) pool.reset(nil, chain.CurrentBlock().Header()) if !config.NoLocals &amp;&amp; config.Journal != "" &#123; pool.journal = newTxJournal(config.Journal) if err := pool.journal.load(pool.AddLocals); err != nil &#123; log.Warn("Failed to load transaction journal", "err", err) &#125; if err := pool.journal.rotate(pool.local()); err != nil &#123; log.Warn("Failed to rotate transaction journal", "err", err) &#125; &#125; pool.chainHeadSub = pool.chain.SubscribeChainHeadEvent(pool.chainHeadCh) pool.wg.Add(1) go pool.loop() return pool&#125; 第一步调用的TxPoolConfig的sanitize方法主要是检查配置是否合法。剩余的都是在给txpool的成员赋值，新建了许多我们刚才介绍过的数据类型，其中注册了ChainHead事件。还有就是初始化了Locals，他从config中加载一些账户，这些账户的交易被标记为本地交易，以免在后面的操作中被移除。在构造方法中还调用了rest方法，最后还在一个单独的goroutine中执行了loop方法 resetreset方法检索区块链的当前状态并且确保交易池的内容关于当前的区块链状态是有效的。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970func (pool *TxPool) reset(oldHead, newHead *types.Header) &#123; var reinject types.Transactions if oldHead != nil &amp;&amp; oldHead.Hash() != newHead.ParentHash &#123; oldNum := oldHead.Number.Uint64() newNum := newHead.Number.Uint64() if depth := uint64(math.Abs(float64(oldNum) - float64(newNum))); depth &gt; 64 &#123; log.Debug("Skipping deep transaction reorg", "depth", depth) &#125; else &#123; var discarded, included types.Transactions var ( rem = pool.chain.GetBlock(oldHead.Hash(), oldHead.Number.Uint64()) add = pool.chain.GetBlock(newHead.Hash(), newHead.Number.Uint64()) ) for rem.NumberU64() &gt; add.NumberU64() &#123; discarded = append(discarded, rem.Transactions()...) if rem = pool.chain.GetBlock(rem.ParentHash(), rem.NumberU64()-1); rem == nil &#123; log.Error("Unrooted old chain seen by tx pool", "block", oldHead.Number, "hash", oldHead.Hash()) return &#125; &#125; for add.NumberU64() &gt; rem.NumberU64() &#123; included = append(included, add.Transactions()...) if add = pool.chain.GetBlock(add.ParentHash(), add.NumberU64()-1); add == nil &#123; log.Error("Unrooted new chain seen by tx pool", "block", newHead.Number, "hash", newHead.Hash()) return &#125; &#125; for rem.Hash() != add.Hash() &#123; discarded = append(discarded, rem.Transactions()...) if rem = pool.chain.GetBlock(rem.ParentHash(), rem.NumberU64()-1); rem == nil &#123; log.Error("Unrooted old chain seen by tx pool", "block", oldHead.Number, "hash", oldHead.Hash()) return &#125; included = append(included, add.Transactions()...) if add = pool.chain.GetBlock(add.ParentHash(), add.NumberU64()-1); add == nil &#123; log.Error("Unrooted new chain seen by tx pool", "block", newHead.Number, "hash", newHead.Hash()) return &#125; &#125; reinject = types.TxDifference(discarded, included) &#125; &#125; if newHead == nil &#123; newHead = pool.chain.CurrentBlock().Header() &#125; statedb, err := pool.chain.StateAt(newHead.Root) if err != nil &#123; log.Error("Failed to reset txpool state", "err", err) return &#125; pool.currentState = statedb pool.pendingState = state.ManageState(statedb) pool.currentMaxGas = newHead.GasLimit log.Debug("Reinjecting stale transactions", "count", len(reinject)) senderCacher.recover(pool.signer, reinject) pool.addTxsLocked(reinject, false) pool.demoteUnexecutables() for addr, list := range pool.pending &#123; txs := list.Flatten() pool.pendingState.SetNonce(addr, txs[len(txs)-1].Nonce()+1) &#125; pool.promoteExecutables(nil)&#125; 参数中传入两个区块头，表示一新一旧两个区块。首先如果旧区块不是新区快的父区块的话，需要重构。但是如果二者高度相差太多则不执行重构，这里的界线是64。如果需要重构，首先要找到二者的公共祖先节点，逻辑和BlockChain插入区块时主要需要调整的逻辑类似。两个区块在回溯时，经过的区块中包含交易都分别保存在discarded和included中，discarded表示要删除的交易，included表示要添加的交易。最后用TxDifference方法寻找二者区别，也就是discarded有的而included没有的。 接着获取新区快的状态树，并设置pool的currentState、pendingState和currentMaxGas。接下来调用recover方法将要添加的交易恢复出发送人地址。 再往下调用了addTxsLocked方法，这里有效交易放到相应队列中。后面的demoteUnexecutables方法将pending中一些不能执行的交易放入queue中。之后有一个循环更新交易账号的nonce，最后调用promoteExecutables方法见将一些可以执行的交易放到pending中。 之所以调用demoteUnexecutables方法是因为currentMaxGas等信息的改变，有一些交易将变得无法执行。调用promoteExecutables是因为账户的nonce发送改变，有一些交易变得可以执行 loop123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172func (pool *TxPool) loop() &#123; defer pool.wg.Done() var prevPending, prevQueued, prevStales int report := time.NewTicker(statsReportInterval) defer report.Stop() evict := time.NewTicker(evictionInterval) defer evict.Stop() journal := time.NewTicker(pool.config.Rejournal) defer journal.Stop() head := pool.chain.CurrentBlock() for &#123; select &#123; case ev := &lt;-pool.chainHeadCh: if ev.Block != nil &#123; pool.mu.Lock() if pool.chainconfig.IsHomestead(ev.Block.Number()) &#123; pool.homestead = true &#125; pool.reset(head.Header(), ev.Block.Header()) head = ev.Block pool.mu.Unlock() &#125; case &lt;-pool.chainHeadSub.Err(): return case &lt;-report.C: pool.mu.RLock() pending, queued := pool.stats() stales := pool.priced.stales pool.mu.RUnlock() if pending != prevPending || queued != prevQueued || stales != prevStales &#123; log.Debug("Transaction pool status report", "executable", pending, "queued", queued, "stales", stales) prevPending, prevQueued, prevStales = pending, queued, stales &#125; case &lt;-evict.C: pool.mu.Lock() for addr := range pool.queue &#123; // Skip local transactions from the eviction mechanism if pool.locals.contains(addr) &#123; continue &#125; // Any non-locals old enough should be removed if time.Since(pool.beats[addr]) &gt; pool.config.Lifetime &#123; for _, tx := range pool.queue[addr].Flatten() &#123; pool.removeTx(tx.Hash(), true) &#125; &#125; &#125; pool.mu.Unlock() case &lt;-journal.C: if pool.journal != nil &#123; pool.mu.Lock() if err := pool.journal.rotate(pool.local()); err != nil &#123; log.Warn("Failed to rotate local tx journal", "err", err) &#125; pool.mu.Unlock() &#125; &#125; &#125;&#125; 这就是txloop的事件循环。开始设置了三个定时器，report每8秒触发一次，evict每分钟触发一次，journal可以自己设置，最低每秒触发一次，默认是1小时。 journal每次触发时会调用local方法获取pending和queue中的所有键值对，然后生成新的日志文件。 report触发时就是打印日志。 evict触发时会遍历queue中的超时交易并将其删除，默认超时时间是3小时。 chainHeadCh触发时表示收到新区快，此时调用reset方法。 addTxsLocked123456789101112131415161718192021func (pool *TxPool) addTxsLocked(txs []*types.Transaction, local bool) []error &#123; dirty := make(map[common.Address]struct&#123;&#125;) errs := make([]error, len(txs)) for i, tx := range txs &#123; var replace bool if replace, errs[i] = pool.add(tx, local); errs[i] == nil &amp;&amp; !replace &#123; from, _ := types.Sender(pool.signer, tx) dirty[from] = struct&#123;&#125;&#123;&#125; &#125; &#125; if len(dirty) &gt; 0 &#123; addrs := make([]common.Address, 0, len(dirty)) for addr := range dirty &#123; addrs = append(addrs, addr) &#125; pool.promoteExecutables(addrs) &#125; return errs&#125; 这个方法尝试将交易放到相应队列中。 这里给定一组交易，首先遍历这些交易，对于每个交易执行add方法将其添加到对应队列。replace表示是否替换了旧的交易，没有的话还原出交易的发送者，然后在dirty中添加值。处理完所有交易后如果dirty长度不为零，则读出其中存储的所有交易发送人地址，并执行promoteExecutables方法。 demoteUnexecutables123456789101112131415161718192021222324252627282930313233343536373839func (pool *TxPool) demoteUnexecutables() &#123; for addr, list := range pool.pending &#123; nonce := pool.currentState.GetNonce(addr) for _, tx := range list.Forward(nonce) &#123; hash := tx.Hash() log.Trace("Removed old pending transaction", "hash", hash) pool.all.Remove(hash) pool.priced.Removed() &#125; drops, invalids := list.Filter(pool.currentState.GetBalance(addr), pool.currentMaxGas) for _, tx := range drops &#123; hash := tx.Hash() log.Trace("Removed unpayable pending transaction", "hash", hash) pool.all.Remove(hash) pool.priced.Removed() pendingNofundsCounter.Inc(1) &#125; for _, tx := range invalids &#123; hash := tx.Hash() log.Trace("Demoting pending transaction", "hash", hash) pool.enqueueTx(hash, tx) &#125; if list.Len() &gt; 0 &amp;&amp; list.txs.Get(nonce) == nil &#123; for _, tx := range list.Cap(0) &#123; hash := tx.Hash() log.Error("Demoting invalidated transaction", "hash", hash) pool.enqueueTx(hash, tx) &#125; &#125; if list.Empty() &#123; delete(pool.pending, addr) delete(pool.beats, addr) &#125; &#125;&#125; 这个方法是从pending中删除无效交易 这里首先遍历pending这个map，取出每个地址当前的nonce，然后从对应的list中移除所有nonce小于当前值的交易，并将这些交易移除all和priced。之后在滤除所有花费大于当前地址余额或者、gaslimite大于currentMaxGas的交易。Filter返回两部分，drops是符合条件被滤除的，接下来这些交易需要被删除。invalids是由于要保持连续性被滤除的这些交易需要通过enqueueTx方法进入queue中。 再往下，经过刚才操作后，如果pending中账户对应的list中还有值，但是取不到对应nonce的交易，表示剩下的交易都是nonce大于账户当前nonce的交易，这些交易也需要被拿出来放入queue中。此时如果对应的list为空这删除该地址的相关信息。 promoteExecutables123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153func (pool *TxPool) promoteExecutables(accounts []common.Address) &#123; var promoted []*types.Transaction if accounts == nil &#123; accounts = make([]common.Address, 0, len(pool.queue)) for addr := range pool.queue &#123; accounts = append(accounts, addr) &#125; &#125; for _, addr := range accounts &#123; list := pool.queue[addr] if list == nil &#123; continue &#125; for _, tx := range list.Forward(pool.currentState.GetNonce(addr)) &#123; hash := tx.Hash() log.Trace("Removed old queued transaction", "hash", hash) pool.all.Remove(hash) pool.priced.Removed() &#125; drops, _ := list.Filter(pool.currentState.GetBalance(addr), pool.currentMaxGas) for _, tx := range drops &#123; hash := tx.Hash() log.Trace("Removed unpayable queued transaction", "hash", hash) pool.all.Remove(hash) pool.priced.Removed() queuedNofundsCounter.Inc(1) &#125; for _, tx := range list.Ready(pool.pendingState.GetNonce(addr)) &#123; hash := tx.Hash() if pool.promoteTx(addr, hash, tx) &#123; log.Trace("Promoting queued transaction", "hash", hash) promoted = append(promoted, tx) &#125; &#125; if !pool.locals.contains(addr) &#123; for _, tx := range list.Cap(int(pool.config.AccountQueue)) &#123; hash := tx.Hash() pool.all.Remove(hash) pool.priced.Removed() queuedRateLimitCounter.Inc(1) log.Trace("Removed cap-exceeding queued transaction", "hash", hash) &#125; &#125; if list.Empty() &#123; delete(pool.queue, addr) &#125; &#125; if len(promoted) &gt; 0 &#123; go pool.txFeed.Send(NewTxsEvent&#123;promoted&#125;) &#125; pending := uint64(0) for _, list := range pool.pending &#123; pending += uint64(list.Len()) &#125; if pending &gt; pool.config.GlobalSlots &#123; pendingBeforeCap := pending spammers := prque.New(nil) for addr, list := range pool.pending &#123; if !pool.locals.contains(addr) &amp;&amp; uint64(list.Len()) &gt; pool.config.AccountSlots &#123; spammers.Push(addr, int64(list.Len())) &#125; &#125; offenders := []common.Address&#123;&#125; for pending &gt; pool.config.GlobalSlots &amp;&amp; !spammers.Empty() &#123; offender, _ := spammers.Pop() offenders = append(offenders, offender.(common.Address)) if len(offenders) &gt; 1 &#123; threshold := pool.pending[offender.(common.Address)].Len() for pending &gt; pool.config.GlobalSlots &amp;&amp; pool.pending[offenders[len(offenders)-2]].Len() &gt; threshold &#123; for i := 0; i &lt; len(offenders)-1; i++ &#123; list := pool.pending[offenders[i]] for _, tx := range list.Cap(list.Len() - 1) &#123; hash := tx.Hash() pool.all.Remove(hash) pool.priced.Removed() if nonce := tx.Nonce(); pool.pendingState.GetNonce(offenders[i]) &gt; nonce &#123; pool.pendingState.SetNonce(offenders[i], nonce) &#125; log.Trace("Removed fairness-exceeding pending transaction", "hash", hash) &#125; pending-- &#125; &#125; &#125; &#125; if pending &gt; pool.config.GlobalSlots &amp;&amp; len(offenders) &gt; 0 &#123; for pending &gt; pool.config.GlobalSlots &amp;&amp; uint64(pool.pending[offenders[len(offenders)-1]].Len()) &gt; pool.config.AccountSlots &#123; for _, addr := range offenders &#123; list := pool.pending[addr] for _, tx := range list.Cap(list.Len() - 1) &#123; hash := tx.Hash() pool.all.Remove(hash) pool.priced.Removed() if nonce := tx.Nonce(); pool.pendingState.GetNonce(addr) &gt; nonce &#123; pool.pendingState.SetNonce(addr, nonce) &#125; log.Trace("Removed fairness-exceeding pending transaction", "hash", hash) &#125; pending-- &#125; &#125; &#125; pendingRateLimitCounter.Inc(int64(pendingBeforeCap - pending)) &#125; queued := uint64(0) for _, list := range pool.queue &#123; queued += uint64(list.Len()) &#125; if queued &gt; pool.config.GlobalQueue &#123; addresses := make(addressesByHeartbeat, 0, len(pool.queue)) for addr := range pool.queue &#123; if !pool.locals.contains(addr) &#123; addresses = append(addresses, addressByHeartbeat&#123;addr, pool.beats[addr]&#125;) &#125; &#125; sort.Sort(addresses) for drop := queued - pool.config.GlobalQueue; drop &gt; 0 &amp;&amp; len(addresses) &gt; 0; &#123; addr := addresses[len(addresses)-1] list := pool.queue[addr.address] addresses = addresses[:len(addresses)-1] if size := uint64(list.Len()); size &lt;= drop &#123; for _, tx := range list.Flatten() &#123; pool.removeTx(tx.Hash(), true) &#125; drop -= size queuedRateLimitCounter.Inc(int64(size)) continue &#125; txs := list.Flatten() for i := len(txs) - 1; i &gt;= 0 &amp;&amp; drop &gt; 0; i-- &#123; pool.removeTx(txs[i].Hash(), true) drop-- queuedRateLimitCounter.Inc(1) &#125; &#125; &#125;&#125; 这里是将queue中可执行的交易放到pending中。 参数中给定一组地址，表示其所对应的交易需要修改状态。如果参数为空，则默认为queue中所有地址。 之后遍历所有账户，取其在queue中对应的list，首先移除list中交易的nonce低于账户当前nonce的，将其从all和priced中移除。之后再滤除所有交易花费大于账户余额的或者gas用量大于当前gas限制的所有交易，也将其从all和priced中移除。之后利用ready方法得到可执行的交易，ready方法需要指定一个nonce，如果存储的最小值小于这个nonce，这从起开始取一系列连续的交易。由于之前已经删除了nonce小于当前账户值的交易，所以这里是从nonce等于账户当前值的交易开始取，取出的一些列交易nonce是递增的。对于这些交易使用promoteTx方法将其放入pending中，若放入成功，则在promoted中存一份。 之后如果该放手地址不在locals中，限制list数量为最大64（默认值）。经过上面处理后如果queue中对应地址的list为空，则将其从queue中删除。 循环完所有给定的地址后，如果有交易需要放到pending中时，发送消息。 下面是处理pending溢出的问题。首先添加pending中给所有交易处理。如果大于给定值（默认4096）则需要进一步处理。首先新建一个优先级队列spammers。然后遍历pending中所有键值对，如果不属于locals而且其对应list长度大于给定值（默认16），则将其地址放入spammers，优先级就是list长度。 接着开启一个循环，直到pending中交易数量满足要求或者spammers为空为止。每次循环都从spammers获取优先级最高的地址，放入offenders，直到offenders数量大于1时，循环删除数组中每个地址的list的最后一个交易，前提是保证各个地址的优先级顺序。如果还超过指定数量，则继续循环删除，要保证list长度不小于16（默认值）. 接着处理queue溢出问题，也是先统计数量，默认的最大值是1024。将queue中所有不属于locals的地址放入addresses中，这是一个addressesByHeartbeat数组，可以按心跳时间排序。接着按心跳时间从就到新依次删除，直到总数满足要求。 add123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566func (pool *TxPool) add(tx *types.Transaction, local bool) (bool, error) &#123; hash := tx.Hash() if pool.all.Get(hash) != nil &#123; log.Trace("Discarding already known transaction", "hash", hash) return false, fmt.Errorf("known transaction: %x", hash) &#125; if err := pool.validateTx(tx, local); err != nil &#123; log.Trace("Discarding invalid transaction", "hash", hash, "err", err) invalidTxCounter.Inc(1) return false, err &#125; if uint64(pool.all.Count()) &gt;= pool.config.GlobalSlots+pool.config.GlobalQueue &#123; if !local &amp;&amp; pool.priced.Underpriced(tx, pool.locals) &#123; log.Trace("Discarding underpriced transaction", "hash", hash, "price", tx.GasPrice()) underpricedTxCounter.Inc(1) return false, ErrUnderpriced &#125; drop := pool.priced.Discard(pool.all.Count()-int(pool.config.GlobalSlots+pool.config.GlobalQueue-1), pool.locals) for _, tx := range drop &#123; log.Trace("Discarding freshly underpriced transaction", "hash", tx.Hash(), "price", tx.GasPrice()) underpricedTxCounter.Inc(1) pool.removeTx(tx.Hash(), false) &#125; &#125; from, _ := types.Sender(pool.signer, tx) if list := pool.pending[from]; list != nil &amp;&amp; list.Overlaps(tx) &#123; inserted, old := list.Add(tx, pool.config.PriceBump) if !inserted &#123; pendingDiscardCounter.Inc(1) return false, ErrReplaceUnderpriced &#125; if old != nil &#123; pool.all.Remove(old.Hash()) pool.priced.Removed() pendingReplaceCounter.Inc(1) &#125; pool.all.Add(tx) pool.priced.Put(tx) pool.journalTx(from, tx) log.Trace("Pooled new executable transaction", "hash", hash, "from", from, "to", tx.To()) go pool.txFeed.Send(NewTxsEvent&#123;types.Transactions&#123;tx&#125;&#125;) return old != nil, nil &#125; replace, err := pool.enqueueTx(hash, tx) if err != nil &#123; return false, err &#125; if local &#123; if !pool.locals.contains(from) &#123; log.Info("Setting new local account", "address", from) pool.locals.add(from) &#125; &#125; pool.journalTx(from, tx) log.Trace("Pooled new future transaction", "hash", hash, "from", from, "to", tx.To()) return replace, nil&#125; 这里主要是验证交易并根据情况插入到相应队列。 首先给定一个交易，首先判断是否在all中，是的话表示已经知道该交易直接返回。之后调用validateTx验证交易是否有效。有效的话，看all中的交易数量是否满了，满的话，检查要插入的交易是否比priced中所有交易的GasPrice都要小，是的话抛弃新交易，否则，抛弃priced中一定数量的交易，对于要抛弃的交易调用removeTx方法将其从一些集合中删除。 如果all没有满，或已满但处理过之后，从交易中还原出发送人地址。接着从pending中取出对应地址的交易集合，如果集合不为空且有相同nonce的交易，则尝试替换，如果不需要替换则直接返回，若需要替换，则将旧的交易从all和priced中删除。并将新的交易放入all和priced中。 若该交易的发送人在pending中没有交易列表或列表内没旧的交易，则将调用enqueueTx将其放入queue中。若是本地模式则检查locals是否包含该地址，若没有则加入进去。之后将交易放入日志中，最后返回。 validateTx123456789101112131415161718192021222324252627282930313233343536373839func (pool *TxPool) validateTx(tx *types.Transaction, local bool) error &#123; if tx.Size() &gt; 32*1024 &#123; return ErrOversizedData &#125; if tx.Value().Sign() &lt; 0 &#123; return ErrNegativeValue &#125; if pool.currentMaxGas &lt; tx.Gas() &#123; return ErrGasLimit &#125; from, err := types.Sender(pool.signer, tx) if err != nil &#123; return ErrInvalidSender &#125; local = local || pool.locals.contains(from) // account may be local even if the transaction arrived from the network if !local &amp;&amp; pool.gasPrice.Cmp(tx.GasPrice()) &gt; 0 &#123; return ErrUnderpriced &#125; if pool.currentState.GetNonce(from) &gt; tx.Nonce() &#123; return ErrNonceTooLow &#125; if pool.currentState.GetBalance(from).Cmp(tx.Cost()) &lt; 0 &#123; return ErrInsufficientFunds &#125; intrGas, err := IntrinsicGas(tx.Data(), tx.To() == nil, pool.homestead) if err != nil &#123; return err &#125; if tx.Gas() &lt; intrGas &#123; return ErrIntrinsicGas &#125; return nil&#125; 首先判断交易的大小，所谓交易的大小是指交易数据（如发送人、接收人、GasPrice、value等数据）经rlp编码后的大小，最大不得超过32KB。 之后传输的金额不得小于0，并且交易的GasLimit不得超过当前txpool设置的值（在reset中根据区块设置），也就是区块的限制。接着恢复出交易的发送人地址，这里不能有错。然后对于非本地交易，其gasprice不得小于txpool设定的和。另外还要验证发送者的nonce和交易中标记的nonce是否符合要求，并且发送者还要有足够的余额。最后计算出消耗的固定gas，不能超过gaslimit。 removeTx12345678910111213141516171819202122232425262728293031323334func (pool *TxPool) removeTx(hash common.Hash, outofbound bool) &#123; tx := pool.all.Get(hash) if tx == nil &#123; return &#125; addr, _ := types.Sender(pool.signer, tx) pool.all.Remove(hash) if outofbound &#123; pool.priced.Removed() &#125; if pending := pool.pending[addr]; pending != nil &#123; if removed, invalids := pending.Remove(tx); removed &#123; if pending.Empty() &#123; delete(pool.pending, addr) delete(pool.beats, addr) &#125; for _, tx := range invalids &#123; pool.enqueueTx(tx.Hash(), tx) &#125; if nonce := tx.Nonce(); pool.pendingState.GetNonce(addr) &gt; nonce &#123; pool.pendingState.SetNonce(addr, nonce) &#125; return &#125; &#125; if future := pool.queue[addr]; future != nil &#123; future.Remove(tx) if future.Empty() &#123; delete(pool.queue, addr) &#125; &#125;&#125; 这是删除一个交易的操作。首先从all中获取对应交易，没有的话直接返回。有的话从交易中恢复出地址，然后从all中删除交易，如果第二个参数为true的话，priced中的也要对应删除。之后获取pending中对应地址的txlist，将交易从中删除，若删除之后对应txlist为空则还要删除对应的txlist。txlist的remove的第二个方法是在严格模式下删除的那些不连续的交易，对于这些交易要通过enqueueTx放入未执行队列中。最后如果发送地址的nonce大于交易的nonce，要修改发送地址的nonce。 最后删除queue中对应地址下的txlist中的相应交易。 enqueueTx12345678910111213141516171819202122func (pool *TxPool) enqueueTx(hash common.Hash, tx *types.Transaction) (bool, error) &#123; from, _ := types.Sender(pool.signer, tx) if pool.queue[from] == nil &#123; pool.queue[from] = newTxList(false) &#125; inserted, old := pool.queue[from].Add(tx, pool.config.PriceBump) if !inserted &#123; queuedDiscardCounter.Inc(1) return false, ErrReplaceUnderpriced &#125; if old != nil &#123; pool.all.Remove(old.Hash()) pool.priced.Removed() queuedReplaceCounter.Inc(1) &#125; if pool.all.Get(hash) == nil &#123; pool.all.Add(tx) pool.priced.Put(tx) &#125; return old != nil, nil&#125; 这是将一个交易插入queue中，首先获取交易的发送人地址，之后如果queue中对应地址的值为空，则新建一个txlist（非严格模式）。之后调用add方法插入，add方法会返回有相同nonce的旧交易，若有旧交易则需要将其从all删除。对于新交易如果all中没有则添加进去，同样也要在priced中添加一份。 journalTx12345678func (pool *TxPool) journalTx(from common.Address, tx *types.Transaction) &#123; if pool.journal == nil || !pool.locals.contains(from) &#123; return &#125; if err := pool.journal.insert(tx); err != nil &#123; log.Warn("Failed to journal local transaction", "err", err) &#125;&#125; 这个操作主要是讲交易放入日志中，但事先会检查地址是否在locals中 promoteTx12345678910111213141516171819202122232425262728293031func (pool *TxPool) promoteTx(addr common.Address, hash common.Hash, tx *types.Transaction) bool &#123; if pool.pending[addr] == nil &#123; pool.pending[addr] = newTxList(true) &#125; list := pool.pending[addr] inserted, old := list.Add(tx, pool.config.PriceBump) if !inserted &#123; pool.all.Remove(hash) pool.priced.Removed() pendingDiscardCounter.Inc(1) return false &#125; if old != nil &#123; pool.all.Remove(old.Hash()) pool.priced.Removed() pendingReplaceCounter.Inc(1) &#125; if pool.all.Get(hash) == nil &#123; pool.all.Add(tx) pool.priced.Put(tx) &#125; pool.beats[addr] = time.Now() pool.pendingState.SetNonce(addr, tx.Nonce()+1) return true&#125; 这是将某个交易放入pending中 首先将交易放入pending中对应的list中，如果没有出现替换，则将新的交易从all中移除，若出现替换则将旧的交易从all中移除。最后还要讲新的交易放入all和priced中，并记录改地址心跳时间，并更新地址的nonce。 题图来自unsplash：https://unsplash.com/photos/eWFdaPRFjwE]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中Processor源码学习]]></title>
    <url>%2F2019%2F06%2F08%2Fgo-ethereum%E4%B8%ADProcessor%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[这是对交易进行处理的地方 NewStateProcessor先从BlockChain的构造方法中开始看，在创建了验证器之后，就创建了Processor123456789bc.SetProcessor(NewStateProcessor(chainConfig, bc, engine))func NewStateProcessor(config *params.ChainConfig, bc *BlockChain, engine consensus.Engine) *StateProcessor &#123; return &amp;StateProcessor&#123; config: config, bc: bc, engine: engine, &#125;&#125; 可见直接创建了一个StateProcessor并返回，StateProcessor实现了Processor接口，这个接口只有一个方法：Process Process在插入区块时，对每个要插入的区块都执行了该方法123456789101112131415161718192021222324252627func (p *StateProcessor) Process(block *types.Block, statedb *state.StateDB, cfg vm.Config) (types.Receipts, []*types.Log, uint64, error) &#123; var ( receipts types.Receipts usedGas = new(uint64) header = block.Header() allLogs []*types.Log gp = new(GasPool).AddGas(block.GasLimit()) ) if p.config.DAOForkSupport &amp;&amp; p.config.DAOForkBlock != nil &amp;&amp; p.config.DAOForkBlock.Cmp(block.Number()) == 0 &#123; misc.ApplyDAOHardFork(statedb) &#125; for i, tx := range block.Transactions() &#123; statedb.Prepare(tx.Hash(), block.Hash(), i) receipt, _, err := ApplyTransaction(p.config, p.bc, nil, gp, statedb, header, tx, usedGas, cfg) if err != nil &#123; return nil, nil, 0, err &#125; receipts = append(receipts, receipt) allLogs = append(allLogs, receipt.Logs...) &#125; p.engine.Finalize(p.bc, header, statedb, block.Transactions(), block.Uncles(), receipts) return receipts, allLogs, *usedGas, nil&#125; 首先初始化了一系列的变量，其中比较特殊的是gp，它是一个GasPool对象，用于追踪交易执行过程中gas的使用，实际上是一个uint64类型，封装了一些加减方法，初始值时区块的最大gas量。 接着对DAO分叉进行了特殊处理，然后遍历区块中的每个交易，对于每个交易，先执行statedb的Prepare方法，表示准备处理交易，主要是存入交易hash和区块hash以及交易编号。接着调用ApplyTransaction处理交易，最后返回收据。并将每一个交易处理完之后的数据和日志收集起来在最后返回。处理完所有交易后调用engine的Finalize方法发放奖励。 ApplyTransaction123456789101112131415161718192021222324252627282930313233343536func ApplyTransaction(config *params.ChainConfig, bc ChainContext, author *common.Address, gp *GasPool, statedb *state.StateDB, header *types.Header, tx *types.Transaction, usedGas *uint64, cfg vm.Config) (*types.Receipt, uint64, error) &#123; msg, err := tx.AsMessage(types.MakeSigner(config, header.Number)) if err != nil &#123; return nil, 0, err &#125; context := NewEVMContext(msg, header, bc, author) vmenv := vm.NewEVM(context, statedb, config, cfg) _, gas, failed, err := ApplyMessage(vmenv, msg, gp) if err != nil &#123; return nil, 0, err &#125; var root []byte if config.IsByzantium(header.Number) &#123; statedb.Finalise(true) &#125; else &#123; root = statedb.IntermediateRoot(config.IsEIP158(header.Number)).Bytes() &#125; *usedGas += gas receipt := types.NewReceipt(root, failed, *usedGas) receipt.TxHash = tx.Hash() receipt.GasUsed = gas if msg.To() == nil &#123; receipt.ContractAddress = crypto.CreateAddress(vmenv.Context.Origin, tx.Nonce()) &#125; receipt.Logs = statedb.GetLogs(tx.Hash()) receipt.Bloom = types.CreateBloom(types.Receipts&#123;receipt&#125;) return receipt, gas, err&#125; 第一行调用了transaction的AsMessage方法。这是将一个交易以message的形式表示。接着构建了EVM上下文环境和EVM。然后调用了ApplyMessage方法，这是真正执行交易的地方，详见后文，执行完成后返回了gas的使用数量以及成功与否。如果没有错误，表示交易执行完毕。接着更新了状态树，然后创建了一个收据，存储着状态树中间状态的根值，使用的gas，交易hash，另外如果是创建合约的交易还存储合约地址等信息。 ApplyMessage123func ApplyMessage(evm *vm.EVM, msg Message, gp *GasPool) ([]byte, uint64, bool, error) &#123; return NewStateTransition(evm, msg, gp).TransitionDb()&#125; 这里先利用NewStateTransition构造了StateTransition对象1234567891011func NewStateTransition(evm *vm.EVM, msg Message, gp *GasPool) *StateTransition &#123; return &amp;StateTransition&#123; gp: gp, evm: evm, msg: msg, gasPrice: msg.GasPrice(), value: msg.Value(), data: msg.Data(), state: evm.StateDB, &#125;&#125; 然后调用了TransitionDb方法1234567891011121314151617181920212223242526272829303132333435363738func (st *StateTransition) TransitionDb() (ret []byte, usedGas uint64, failed bool, err error) &#123; if err = st.preCheck(); err != nil &#123; return &#125; msg := st.msg sender := vm.AccountRef(msg.From()) homestead := st.evm.ChainConfig().IsHomestead(st.evm.BlockNumber) contractCreation := msg.To() == nil gas, err := IntrinsicGas(st.data, contractCreation, homestead) if err != nil &#123; return nil, 0, false, err &#125; if err = st.useGas(gas); err != nil &#123; return nil, 0, false, err &#125; var ( evm = st.evm vmerr error ) if contractCreation &#123; ret, _, st.gas, vmerr = evm.Create(sender, st.data, st.gas, st.value) &#125; else &#123; st.state.SetNonce(msg.From(), st.state.GetNonce(sender.Address())+1) ret, st.gas, vmerr = evm.Call(sender, st.to(), st.data, st.gas, st.value) &#125; if vmerr != nil &#123; log.Debug("VM returned with error", "err", vmerr) if vmerr == vm.ErrInsufficientBalance &#123; return nil, 0, false, vmerr &#125; &#125; st.refundGas() st.state.AddBalance(st.evm.Coinbase, new(big.Int).Mul(new(big.Int).SetUint64(st.gasUsed()), st.gasPrice)) return ret, st.gasUsed(), vmerr != nil, err&#125; 第一步进行的预检查：1234567891011121314151617181920212223242526func (st *StateTransition) preCheck() error &#123; if st.msg.CheckNonce() &#123; nonce := st.state.GetNonce(st.msg.From()) if nonce &lt; st.msg.Nonce() &#123; return ErrNonceTooHigh &#125; else if nonce &gt; st.msg.Nonce() &#123; return ErrNonceTooLow &#125; &#125; return st.buyGas()&#125;func (st *StateTransition) buyGas() error &#123; mgval := new(big.Int).Mul(new(big.Int).SetUint64(st.msg.Gas()), st.gasPrice) if st.state.GetBalance(st.msg.From()).Cmp(mgval) &lt; 0 &#123; return errInsufficientBalanceForGas &#125; if err := st.gp.SubGas(st.msg.Gas()); err != nil &#123; return err &#125; st.gas += st.msg.Gas() st.initialGas = st.msg.Gas() st.state.SubBalance(st.msg.From(), mgval) return nil&#125; 这里主要是检查nonce。然后利用buyGas购买了gas，这里首先计算总共的金额，然后判断账户金额是否足够，然后在gp中记录所用的gas，并更新StateTransition的gas和initialGas字段，最后从账户中减去对应的金额。这里的gas是指gasLimit，也就是需要保证账户中至少有gasLimit*gasPrice余额，才能继续交易。之后在StateTransition的gas字段记录最大gas量 接下来记录了交易的发送者，并根据接受者是否为空判断是否是合约创建交易。接着计算需要消耗的gas1234567891011121314151617181920212223242526272829func IntrinsicGas(data []byte, contractCreation, homestead bool) (uint64, error) &#123; if contractCreation &amp;&amp; homestead &#123; gas = params.TxGasContractCreation &#125; else &#123; gas = params.TxGas &#125; if len(data) &gt; 0 &#123; // Zero and non-zero bytes are priced differently var nz uint64 for _, byt := range data &#123; if byt != 0 &#123; nz++ &#125; &#125; if (math.MaxUint64-gas)/params.TxDataNonZeroGas &lt; nz &#123; return 0, vm.ErrOutOfGas &#125; gas += nz * params.TxDataNonZeroGas z := uint64(len(data)) - nz if (math.MaxUint64-gas)/params.TxDataZeroGas &lt; z &#123; return 0, vm.ErrOutOfGas &#125; gas += z * params.TxDataZeroGas &#125; return gas, nil&#125; 接着，如果是创建合约的交易并且是家园版本，基础费用为53000gas，否则基础费用是21000。往下再计算交易中附带数据所消耗的gas，遍历所有字节数组，对于非0的数据，每字节支付68gas，为0的数据每字节支付4gas。最后计算出总gas。关于这个固有费用的计算是按照黄皮书6.2节的说明实现的。 回到TransitionDb，计算完需要的gas后，使用useGas方法减去对应的gas数，这里主要是用StateTransition的gas字段减去刚才的固有gas量。 接着，如果是创建合约的话调用evm的create方法创建合约。否则的话就是一般交易，这时将发送者的nonce递增一，然后调用call方法对账户转账或调用合约。接着，如果有错误的而且是金额不足的错误则返回错误。否则调用refundGas退回gas12345678910111213141516func (st *StateTransition) refundGas() &#123; refund := st.gasUsed() / 2 if refund &gt; st.state.GetRefund() &#123; refund = st.state.GetRefund() &#125; st.gas += refund remaining := new(big.Int).Mul(new(big.Int).SetUint64(st.gas), st.gasPrice) st.state.AddBalance(st.msg.From(), remaining) st.gp.AddGas(st.gas)&#125;func (st *StateTransition) gasUsed() uint64 &#123; return st.initialGas - st.gas&#125; 首先计算已用的gas，gasUsed中initialGas是初始的gas，也就是交易允许的最大gas数，而gas是剩余的gas，在交易执行中会一直变化。二者相减就是已用的gas。先设refund的值为已用gas的一般，然后将其和statedb的refund相比，若比他大，则以statedb的refund为标准。然后将gas加上refund的值，这样在计算出实际需要退换的余额。注意这里的逻辑是花费的金额要小于实际金额。 回到TransitionDb最后，退款完毕后，将所用的gas费用发送给Coinbase，也就是矿工，当做奖励。这样一个交易执行完毕。 题图来自unsplash：https://unsplash.com/photos/3P3NHLZGCp8]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中evm源码学习]]></title>
    <url>%2F2019%2F06%2F08%2Fgo-ethereum%E4%B8%ADevm%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[首先关于EVM的基础知识情参考这里。另外推荐一个EVM操作码介绍网站 Stack我们都知道EVM是基于栈结构的，我们这里先看一下他的栈实现。123type Stack struct &#123; data []*big.Int&#125; 首先结构体很简单，就是一个big.Int类型的数组。构造方法如下123func newstack() *Stack &#123; return &amp;Stack&#123;data: make([]*big.Int, 0, 1024)&#125;&#125; 构造方法就是初始化了一个长度为1024的数组，也就是栈最大深度是1024. push &amp; pop &amp; peek &amp; back123456789101112131415161718192021func (st *Stack) push(d *big.Int) &#123; st.data = append(st.data, d)&#125;func (st *Stack) pushN(ds ...*big.Int) &#123; st.data = append(st.data, ds...)&#125;func (st *Stack) pop() (ret *big.Int) &#123; ret = st.data[len(st.data)-1] st.data = st.data[:len(st.data)-1] return&#125;func (st *Stack) peek() *big.Int &#123; return st.data[st.len()-1]&#125;func (st *Stack) Back(n int) *big.Int &#123; return st.data[st.len()-n-1]&#125; push就向数组添加内容，pop就是取出数组最后一个数据，也就是栈顶元素。peek访问栈顶元素。Back是从栈顶开始取第n个元素 swap123func (st *Stack) swap(n int) &#123; st.data[st.len()-n], st.data[st.len()-1] = st.data[st.len()-1], st.data[st.len()-n]&#125; 将栈顶元素和指定位置元素交换，对于虚拟机中的SWAP操作码 dup123func (st *Stack) dup(pool *intPool, n int) &#123; st.push(pool.get().Set(st.data[st.len()-n]))&#125; 参数中intPool封装了一个stack对象，为的是实现big.Int复用。他的get方法就是获得栈顶元素，这里复用一个对象，将其设为栈中某个元素并放到栈顶，为的是复制元素到栈顶。 require123456func (st *Stack) require(n int) error &#123; if st.len() &lt; n &#123; return fmt.Errorf("stack underflow (%d &lt;=&gt; %d)", len(st.data), n) &#125; return nil&#125; 这个方法作用是检查是否能取出要求个数的元素 stack_table这里面放着检测栈的几个方法，这几个方法都是用在后面定义operation时的validateStack字段 makeStackFunc123456789101112func makeStackFunc(pop, push int) stackValidationFunc &#123; return func(stack *Stack) error &#123; if err := stack.require(pop); err != nil &#123; return err &#125; if stack.len()+push-pop &gt; int(params.StackLimit) &#123; return fmt.Errorf("stack limit reached %d (%d)", stack.len(), params.StackLimit) &#125; return nil &#125;&#125; 这个方法节后两个变量，第一个表示要执行几次pop操作，第二个表示要执行几次push操作，这个方法目的是检查一个栈是否能执行这样一组pop和push操作。首先调用require检测是否能pop对应数量的元素。然后在检查在pop与push操作之后栈是否超过最大深度。 makeDupStackFunc123func makeDupStackFunc(n int) stackValidationFunc &#123; return makeStackFunc(n, n+1)&#125; 这个表示复制操作的检测，就是要pop出n个值，然后push进n+1个值 makeSwapStackFunc123func makeSwapStackFunc(n int) stackValidationFunc &#123; return makeStackFunc(n, n)&#125; 这是检查交换操作的，就是看能否弹出以及压入n个值。 intPool前面见过这种类型，它内部封装了一个栈对象，为的是存储复用bigInt对象1234567type intPool struct &#123; pool *Stack&#125;func newIntPool() *intPool &#123; return &amp;intPool&#123;pool: newstack()&#125;&#125; get123456func (p *intPool) get() *big.Int &#123; if p.pool.len() &gt; 0 &#123; return p.pool.pop() &#125; return new(big.Int)&#125; 这是取出一个bigInt对象供我们使用，不必每次都重新创建对象，但是前提是intPool中有数据，不然还是需要创建123456func (p *intPool) getZero() *big.Int &#123; if p.pool.len() &gt; 0 &#123; return p.pool.pop().SetUint64(0) &#125; return new(big.Int)&#125; 特别的给我们提供了值为0的bigInt对象获取方法 put1234567891011func (p *intPool) put(is ...*big.Int) &#123; if len(p.pool.data) &gt; poolLimit &#123; return &#125; for _, i := range is &#123; if verifyPool &#123; i.Set(checkVal) &#125; p.pool.push(i) &#125;&#125; 首先不能超过pool的最大容量–256.其次根据需要在存入前将每个值设为默认值：-42 intPoolPool这是intPool的缓存池，最大容量为25，12345678type intPoolPool struct &#123; pools []*intPool lock sync.Mutex&#125;var poolOfIntPools = &amp;intPoolPool&#123; pools: make([]*intPool, 0, poolDefaultCap),&#125; get与put方法都很简单，这里不再详述 memory这个实现了EVM的内存模型12345678type Memory struct &#123; store []byte lastGasCost uint64&#125;func NewMemory() *Memory &#123; return &amp;Memory&#123;&#125;&#125; 包含了一个字节数组，用于存储东西，一个整数存储gas的消耗。 Resize123456789func (m *Memory) Resize(size uint64) &#123; if uint64(m.Len()) &lt; size &#123; m.store = append(m.store, make([]byte, size-uint64(m.Len()))...) &#125;&#125;func (m *Memory) Len() int &#123; return len(m.store)&#125; 使用Resize空间，注意这个方法设计的可以在使用过程中动态调整内存空间，只有当要赋予的空间大于已有的时，在对store数组进行扩展，其中的数据保持不变。 Set123456789func (m *Memory) Set(offset, size uint64, value []byte) &#123; if size &gt; 0 &#123; if offset+size &gt; uint64(len(m.store)) &#123; panic("invalid memory: store empty") &#125; copy(m.store[offset:offset+size], value) &#125;&#125; 由于是模仿内存模型，所以存储数据时要指定偏移量，数据长度以及数据本体。首先检查是否能存下，可以的话按照给定的偏移即长度存储数据。12345678910func (m *Memory) Set32(offset uint64, val *big.Int) &#123; if offset+32 &gt; uint64(len(m.store)) &#123; panic("invalid memory: store empty") &#125; copy(m.store[offset:offset+32], []byte&#123;0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0&#125;) math.ReadBits(val, m.store[offset:offset+32])&#125; 由于EVM的栈宽度是32字节，所以特别给出了存储一个32字节数据的方法，第一步还是检查是否放的下，然后先存储32字节的灵数据，这是因为我们要存储的是bigInt类型，先用0占位后，然后再用math包中的ReadBits方法写入字节数据。 Get1234567891011121314func (m *Memory) Get(offset, size int64) (cpy []byte) &#123; if size == 0 &#123; return nil &#125; if len(m.store) &gt; int(offset) &#123; cpy = make([]byte, size) copy(cpy, m.store[offset:offset+size]) return &#125; return&#125; 同样也是根据偏移量和大小取一组字节数据，但这个方法是获得数据副本1234567891011func (m *Memory) GetPtr(offset, size int64) []byte &#123; if size == 0 &#123; return nil &#125; if len(m.store) &gt; int(offset) &#123; return m.store[offset : offset+size] &#125; return nil&#125; 这个方法则是获取数据的引用，可以修改元数据 memory_table.go这里面的方法是获取某个操作会占用的memory大小，如1234567891011func memorySha3(stack *Stack) *big.Int &#123; return calcMemSize(stack.Back(0), stack.Back(1))&#125;func calcMemSize(off, l *big.Int) *big.Int &#123; if l.Sign() == 0 &#123; return common.Big0 &#125; return new(big.Int).Add(off, l)&#125; 这个方法对于sha3操作，他需要从栈中弹出两个值，第一个值是在memory中的偏移量，第二个值是数据的长度，所以memorySha3调用了calcMemSize，第一个参数就是栈顶元素，第二个参数就是栈顶倒数第二个参数，该操作所需要的memory最小长度是offset+length。 jump_table.go这里面定义了operation，表示一个个操作符1234567891011121314type operation struct &#123; execute executionFunc gasCost gasFunc validateStack stackValidationFunc memorySize memorySizeFunc halts bool jumps bool writes bool valid bool reverts bool returns bool &#125; 解释一下每个成员的含义： execute：表示要执行的函数 gasCost：表示gas消耗函数 validateStack：表示堆栈大小验证函数 memorySize：表示需要的内存大小 halts：表示是否停止 jumps：表示程序计数器是否不应该递增 writes：表示是否是一个状态修改操作 valid：表示检索到的操作是否有效且已知 reverts：确定操作是否已经恢复状态 returns：表示操作是否设置了返回内容 EVM最多有256个操作符，但许多都未定义。不同的版本有不同的操作符集合123456var ( frontierInstructionSet = newFrontierInstructionSet() homesteadInstructionSet = newHomesteadInstructionSet() byzantiumInstructionSet = newByzantiumInstructionSet() constantinopleInstructionSet = newConstantinopleInstructionSet()) 基本上都是新版本包含了旧版本的操作符，同时又添加了新的操作符。 instruction.gojump_table中定义了全部的operation，每个operation的execute实现在这里定义，如： opAdd1234567func opAdd(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) &#123; x, y := stack.pop(), stack.peek() math.U256(y.Add(x, y)) interpreter.intPool.put(x) return nil, nil&#125; 这是基于栈的加法，首先弹出栈顶元素x，然后获取新的栈顶元素y（该元素并不出栈），然后将x，并赋值到y，最后结果用补码表示。还有一点是，刚才出栈的数在用完后放入intPool中以便后面进行复用。 opLt12345678910func opLt(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) &#123; x, y := stack.pop(), stack.peek() if x.Cmp(y) &lt; 0 &#123; y.SetUint64(1) &#125; else &#123; y.SetUint64(0) &#125; interpreter.intPool.put(x) return nil, nil&#125; 这是小于比较的方法，也是先出栈一个元素x，再获取栈顶元素，然后二者相减进行比较，结果写入y，最后x放入intPool复用。 opCallDataLoad1234567891011121314151617181920212223func opCallDataLoad(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) &#123; stack.push(interpreter.intPool.get().SetBytes(getDataBig(contract.Input, stack.pop(), big32))) return nil, nil&#125;func getDataBig(data []byte, start *big.Int, size *big.Int) []byte &#123; dlen := big.NewInt(int64(len(data))) s := math.BigMin(start, dlen) e := math.BigMin(new(big.Int).Add(s, size), dlen) return common.RightPadBytes(data[s.Uint64():e.Uint64()], int(size.Uint64()))&#125;func RightPadBytes(slice []byte, l int) []byte &#123; if l &lt;= len(slice) &#123; return slice &#125; padded := make([]byte, l) copy(padded, slice) return padded&#125; 这是一个常用的获取输入参数的操作符，注意看，第一步利用getDataBig从合约的输入中从某个偏移开始读取32字节输入数据，有时未必能读够32字节，这时还需要RightPadBytes方法在右侧补零。获取完数据后放入栈顶 opMstore1234567func opMstore(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) &#123; mStart, val := stack.pop(), stack.pop() memory.Set32(mStart.Uint64(), val) interpreter.intPool.put(mStart, val) return nil, nil&#125; 从栈顶获取代表偏移量和数据的两个值，然后放入内存模型中。 opSstore12345678func opSstore(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) &#123; loc := common.BigToHash(stack.pop()) val := stack.pop() interpreter.evm.StateDB.SetState(contract.Address(), loc, common.BigToHash(val)) interpreter.intPool.put(val) return nil, nil&#125; 这个也就是我们说的持久化存储操作符，可见他实际存储到状态树中，最后放入数据库。其存储位置就是键。 opJump1234567891011func opJump(pc *uint64, interpreter *EVMInterpreter, contract *Contract, memory *Memory, stack *Stack) ([]byte, error) &#123; pos := stack.pop() if !contract.validJumpdest(pos) &#123; nop := contract.GetOp(pos.Uint64()) return nil, fmt.Errorf("invalid jump destination (%v) %v", nop, pos) &#125; *pc = pos.Uint64() interpreter.intPool.put(pos) return nil, nil&#125; 这是程序跳转操作，首先从栈顶获取跳转的位置，然后验证是否是有效的跳转目的地，是的话修改程序计数器实现跳转，否则返回错误。 gas_table.go这里面定义了每种操作符的gas消耗。在jump_table中定义operation的gasCost字段时定义了gas消耗计算方法。对于一些基础操作都是constGasFunc方法12345func constGasFunc(gas uint64) gasFunc &#123; return func(gt params.GasTable, evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySize uint64) (uint64, error) &#123; return gas, nil &#125;&#125; 这里指定的gas就是该操作消耗的gas，对于一些基本操作符如ADD，SUB等都是消耗固定的gas，一般分以下几种123456789101112const ( GasQuickStep uint64 = 2 GasFastestStep uint64 = 3 GasFastStep uint64 = 5 GasMidStep uint64 = 8 GasSlowStep uint64 = 10 GasExtStep uint64 = 20 GasReturn uint64 = 0 GasStop uint64 = 0 GasContractByte uint64 = 200) 可见基本是根据步骤执行快慢决定的，如调用ADDRESS、ORIGIN都消耗GasQuickStep也就是2Gas。ADD、SUB等都是GasFastestStep。 除此之外，还有许多操作符是单独定义了，如MSTORE1234567891011121314151617181920212223242526272829303132333435363738func gasMStore(gt params.GasTable, evm *EVM, contract *Contract, stack *Stack, mem *Memory, memorySize uint64) (uint64, error) &#123; var overflow bool gas, err := memoryGasCost(mem, memorySize) if err != nil &#123; return 0, errGasUintOverflow &#125; if gas, overflow = math.SafeAdd(gas, GasFastestStep); overflow &#123; return 0, errGasUintOverflow &#125; return gas, nil&#125;func memoryGasCost(mem *Memory, newMemSize uint64) (uint64, error) &#123; if newMemSize == 0 &#123; return 0, nil &#125; if newMemSize &gt; 0xffffffffe0 &#123; return 0, errGasUintOverflow &#125; newMemSizeWords := toWordSize(newMemSize) newMemSize = newMemSizeWords * 32 if newMemSize &gt; uint64(mem.Len()) &#123; square := newMemSizeWords * newMemSizeWords linCoef := newMemSizeWords * params.MemoryGas quadCoef := square / params.QuadCoeffDiv newTotalFee := linCoef + quadCoef fee := newTotalFee - mem.lastGasCost mem.lastGasCost = newTotalFee return fee, nil &#125; return 0, nil&#125; 对于从memory中读取数据的操作，主要是根据要取的数据大小计算gas，借助了memoryGasCost方法。 memoryGasCost中，首先如果要取的数据为0，则直接返回0。另外如果大于0xffffffffe0则报错。对于正常情况，首先按32字节一个字计算，看有多少个字，借助toWordSize方法（相当于除以32并向上取整），之后再乘以32，表示按32字节一个字取的话要多少字节。之后如果取值大于memory的长度，则首先按每个字3Gas计算出linCoef，然后对字数取平方在除以512计算出quadCoef。此时总费用newTotalFee就是linCoef + quadCoef，但是还要减去memory的lastGasCost字段，最后将lastGasCost字段更新为newTotalFee。如果计算出的实际字节数没有超过memory长度则直接返回零。 回到gasMStore中，如果前一步没有错，则实际费用就是memoryGasCost返回值加上基础费用3。这里我们也可以知道如果从memory取值时如果没有超出当前memory返回，费用只有基础费用3Gas Contract这就是表示一个合约的对象12345678910111213141516type Contract struct &#123; CallerAddress common.Address caller ContractRef self ContractRef jumpdests map[common.Hash]bitvec analysis bitvec Code []byte CodeHash common.Hash CodeAddr *common.Address Input []byte Gas uint64 value *big.Int&#125; 包含了合约创建者地址，合约地址，合约代码以及输入等许多基本要素 NewContract1234567891011121314func NewContract(caller ContractRef, object ContractRef, value *big.Int, gas uint64) *Contract &#123; c := &amp;Contract&#123;CallerAddress: caller.Address(), caller: caller, self: object&#125; if parent, ok := caller.(*Contract); ok &#123; c.jumpdests = parent.jumpdests &#125; else &#123; c.jumpdests = make(map[common.Hash]bitvec) &#125; c.Gas = gas c.value = value return c&#125; 构造方法最后返回一个Contract对象，需要传入创建者的地址，如果创建者是一个合约的话，则继承其的jumpdests。 interpreter前面在instruction中每个操作符函数参数中都有一个interpreter参数，这是一个接口表示解释器，解释器是用来执行智能合约的12345type Interpreter interface &#123; Run(contract *Contract, input []byte, static bool) ([]byte, error) CanRun([]byte) bool&#125; 实际使用的EVMInterpreter12345678910111213type EVMInterpreter struct &#123; evm *EVM cfg Config gasTable params.GasTable intPool *intPool hasher keccakState hasherBuf common.Hash readOnly bool returnData []byte &#125; 构造函数如下1234567891011121314151617181920func NewEVMInterpreter(evm *EVM, cfg Config) *EVMInterpreter &#123; if !cfg.JumpTable[STOP].valid &#123; switch &#123; case evm.ChainConfig().IsConstantinople(evm.BlockNumber): cfg.JumpTable = constantinopleInstructionSet case evm.ChainConfig().IsByzantium(evm.BlockNumber): cfg.JumpTable = byzantiumInstructionSet case evm.ChainConfig().IsHomestead(evm.BlockNumber): cfg.JumpTable = homesteadInstructionSet default: cfg.JumpTable = frontierInstructionSet &#125; &#125; return &amp;EVMInterpreter&#123; evm: evm, cfg: cfg,CanRun gasTable: evm.ChainConfig().GasTable(evm.BlockNumber), &#125;&#125; 首先根据JumpTable的STOP指令的有效性判断JumpTable是否初始化，没有的话根据具体版本加载不同的指令集。然后新建EVMInterpreter对象。 CanRun123func (in *EVMInterpreter) CanRun(code []byte) bool &#123; return true&#125; 这个方法作用是检查代码是否可以运行，但是这里直接返回true，表示都可以执行。 Run这是运行合约的核心方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113func (in *EVMInterpreter) Run(contract *Contract, input []byte, readOnly bool) (ret []byte, err error) &#123; if in.intPool == nil &#123; in.intPool = poolOfIntPools.get() defer func() &#123; poolOfIntPools.put(in.intPool) in.intPool = nil &#125;() &#125; in.evm.depth++ defer func() &#123; in.evm.depth-- &#125;() if readOnly &amp;&amp; !in.readOnly &#123; in.readOnly = true defer func() &#123; in.readOnly = false &#125;() &#125; in.returnData = nil if len(contract.Code) == 0 &#123; return nil, nil &#125; var ( op OpCode mem = NewMemory() stack = newstack() pc = uint64(0) cost uint64 pcCopy uint64 gasCopy uint64 logged bool res []byte ) contract.Input = input defer func() &#123; in.intPool.put(stack.data...) &#125;() if in.cfg.Debug &#123; defer func() &#123; if err != nil &#123; if !logged &#123; in.cfg.Tracer.CaptureState(in.evm, pcCopy, op, gasCopy, cost, mem, stack, contract, in.evm.depth, err) &#125; else &#123; in.cfg.Tracer.CaptureFault(in.evm, pcCopy, op, gasCopy, cost, mem, stack, contract, in.evm.depth, err) &#125; &#125; &#125;() &#125; for atomic.LoadInt32(&amp;in.evm.abort) == 0 &#123; if in.cfg.Debug &#123; logged, pcCopy, gasCopy = false, pc, contract.Gas &#125; op = contract.GetOp(pc) operation := in.cfg.JumpTable[op] if !operation.valid &#123; return nil, fmt.Errorf("invalid opcode 0x%x", int(op)) &#125; if err = operation.validateStack(stack); err != nil &#123; return nil, err &#125; if err = in.enforceRestrictions(op, operation, stack); err != nil &#123; return nil, err &#125; var memorySize uint64 if operation.memorySize != nil &#123; memSize, overflow := bigUint64(operation.memorySize(stack)) if overflow &#123; return nil, errGasUintOverflow &#125; if memorySize, overflow = math.SafeMul(toWordSize(memSize), 32); overflow &#123; return nil, errGasUintOverflow &#125; &#125; cost, err = operation.gasCost(in.gasTable, in.evm, contract, stack, mem, memorySize) if err != nil || !contract.UseGas(cost) &#123; return nil, ErrOutOfGas &#125; if memorySize &gt; 0 &#123; mem.Resize(memorySize) &#125; if in.cfg.Debug &#123; in.cfg.Tracer.CaptureState(in.evm, pc, op, gasCopy, cost, mem, stack, contract, in.evm.depth, err) logged = true &#125; res, err = operation.execute(&amp;pc, in, contract, mem, stack) if verifyPool &#123; verifyIntegerPool(in.intPool) &#125; if operation.returns &#123; in.returnData = res &#125; switch &#123; case err != nil: return nil, err case operation.reverts: return res, errExecutionReverted case operation.halts: return res, nil case !operation.jumps: pc++ &#125; &#125; return nil, nil&#125; 第一步如果intPool为空，则从poolOfIntPools中取一个，poolOfIntPools是intPoolPool类型，就是intPool的缓存池。这里还定义了一个defer，是在run执行完之后回收解释器的intPool 接着调用栈深度加一，也就是每执行一次Run方法调用栈深度加一。但是调用结束后会减一。接着初始化一些变量用于执行代码，如栈、内存模型、程序计数器等。然后将输入赋给合约的Input字段。中间有一步，如果传入的合约对象的代码为空的话则直接结束，对应evm的call方法中指定的合约地址不存在的情况。 再往下开始了一个循环，每次都要先判断evm的abort字段是否为0，为1的话要终止操作。进入循环，首先通过合约的GetOp方法获取pc所指的操作符，再根据操作符获取JumpTable对应的operation对象。获得operation后，先检查有效性，再检测当前栈的大小是否符合操作符要求，利用的validateStack方法。如果通过检查，则调用enforceRestrictions方法12345678910func (in *EVMInterpreter) enforceRestrictions(op OpCode, operation operation, stack *Stack) error &#123; if in.evm.chainRules.IsByzantium &#123; if in.readOnly &#123; if operation.writes || (op == CALL &amp;&amp; stack.Back(2).BitLen() &gt; 0) &#123; return errWriteProtection &#125; &#125; &#125; return nil&#125; 这个主要是针对拜占庭版本下只读模式时，操作符是否进行写操作，在evm的StaticCall的方法会进行只读操作，是的话触发写保护错误。 一切正常的话，检查memory是否符合操作符要求，主要借助operation的memorySize获取期望的memory大小。接着又计算了gas的消耗，利用contract.UseGas检查gas是否够用。经过上面的检测，都通过的话，先对memory大小进行调整，然后执行操作符的execute方法，得到返回值和错误信息。之后，如果操作符需要返回值，则将刚才执行完后的返回值res赋给解释器的returnData字段。 最后还有一个switch字段，根据operation的一些条件返回不同的值。这样一次循环结束，接着下一次循环，根据pc执行下一个操作符。 evm这个就是EVM的对象，他主要是运行智能合约的。123456789101112131415161718192021type EVM struct &#123; Context StateDB StateDB depth int chainConfig *params.ChainConfig chainRules params.Rules. vmConfig Config interpreters []Interpreter interpreter Interpreter abort int32 callGasTemp uint64&#125; 其中Context提供了区块链的相关上下文信息。StateDB是一个接口，实际上就是state包中stateDB，用于对合约账户操作。1234567891011121314type Context struct &#123; CanTransfer CanTransferFunc Transfer TransferFunc GetHash GetHashFunc Origin common.Address GasPrice *big.Int Coinbase common.Address GasLimit uint64 BlockNumber *big.Int Time *big.Int Difficulty *big.Int &#125; NewEVM12345678910111213141516171819func NewEVM(ctx Context, statedb StateDB, chainConfig *params.ChainConfig, vmConfig Config) *EVM &#123; evm := &amp;EVM&#123; Context: ctx, StateDB: statedb, vmConfig: vmConfig, chainConfig: chainConfig, chainRules: chainConfig.Rules(ctx.BlockNumber), interpreters: make([]Interpreter, 0, 1), &#125; if chainConfig.IsEWASM(ctx.BlockNumber) &#123; panic("No supported ewasm interpreter yet.") &#125; evm.interpreters = append(evm.interpreters, NewEVMInterpreter(evm, vmConfig)) evm.interpreter = evm.interpreters[0] return evm&#125; 主要是对evm的成员进行赋值。chainConfig.Rules方法主要是记录区块链的ID和以太坊版本。之后新建了一个解释器。 Create123456789func (evm *EVM) Create(caller ContractRef, code []byte, gas uint64, value *big.Int) (ret []byte, contractAddr common.Address, leftOverGas uint64, err error) &#123; contractAddr = crypto.CreateAddress(caller.Address(), evm.StateDB.GetNonce(caller.Address())) return evm.create(caller, &amp;codeAndHash&#123;code: code&#125;, gas, value, contractAddr)&#125;func CreateAddress(b common.Address, nonce uint64) common.Address &#123; data, _ := rlp.EncodeToBytes([]interface&#123;&#125;&#123;b, nonce&#125;) return common.BytesToAddress(Keccak256(data)[12:])&#125; 这是创建一个合约的方法，在StateTransition处理交易时，如果接收人地址为空则调用该方法创建合约。传入的参数中caller是交易发起人的地址（ContractRef类型）、code是交易中附带的数据、gas是交易最大gas量减去固有费用后剩余的gas、value是交易中需要交易的金额。 首先第一步构造合约地址，这里我们知道合约地址实际上就是发起者的地址拼接上发起者的nonce经过rlp编码后再做keccak256散列后取后20字节。接下来调用了create方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func (evm *EVM) create(caller ContractRef, codeAndHash *codeAndHash, gas uint64, value *big.Int, address common.Address) ([]byte, common.Address, uint64, error) &#123; if evm.depth &gt; int(params.CallCreateDepth) &#123; return nil, common.Address&#123;&#125;, gas, ErrDepth &#125; if !evm.CanTransfer(evm.StateDB, caller.Address(), value) &#123; return nil, common.Address&#123;&#125;, gas, ErrInsufficientBalance &#125; nonce := evm.StateDB.GetNonce(caller.Address()) evm.StateDB.SetNonce(caller.Address(), nonce+1) contractHash := evm.StateDB.GetCodeHash(address) if evm.StateDB.GetNonce(address) != 0 || (contractHash != (common.Hash&#123;&#125;) &amp;&amp; contractHash != emptyCodeHash) &#123; return nil, common.Address&#123;&#125;, 0, ErrContractAddressCollision &#125; snapshot := evm.StateDB.Snapshot() evm.StateDB.CreateAccount(address) if evm.ChainConfig().IsEIP158(evm.BlockNumber) &#123; evm.StateDB.SetNonce(address, 1) &#125; evm.Transfer(evm.StateDB, caller.Address(), address, value) contract := NewContract(caller, AccountRef(address), value, gas) contract.SetCodeOptionalHash(&amp;address, codeAndHash) if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 &#123; return nil, address, gas, nil &#125; if evm.vmConfig.Debug &amp;&amp; evm.depth == 0 &#123; evm.vmConfig.Tracer.CaptureStart(caller.Address(), address, true, codeAndHash.code, gas, value) &#125; start := time.Now() ret, err := run(evm, contract, nil, false) maxCodeSizeExceeded := evm.ChainConfig().IsEIP158(evm.BlockNumber) &amp;&amp; len(ret) &gt; params.MaxCodeSize if err == nil &amp;&amp; !maxCodeSizeExceeded &#123; createDataGas := uint64(len(ret)) * params.CreateDataGas if contract.UseGas(createDataGas) &#123; evm.StateDB.SetCode(address, ret) &#125; else &#123; err = ErrCodeStoreOutOfGas &#125; &#125; if maxCodeSizeExceeded || (err != nil &amp;&amp; (evm.ChainConfig().IsHomestead(evm.BlockNumber) || err != ErrCodeStoreOutOfGas)) &#123; evm.StateDB.RevertToSnapshot(snapshot) if err != errExecutionReverted &#123; contract.UseGas(contract.Gas) &#125; &#125; if maxCodeSizeExceeded &amp;&amp; err == nil &#123; err = errMaxCodeSizeExceeded &#125; if evm.vmConfig.Debug &amp;&amp; evm.depth == 0 &#123; evm.vmConfig.Tracer.CaptureEnd(ret, gas-contract.Gas, time.Since(start), err) &#125; return ret, address, contract.Gas, err&#125; 首先检测调用深度不得超过1024。之后利用CanTransfer检测账户余额是否足够123func CanTransfer(db vm.StateDB, addr common.Address, amount *big.Int) bool &#123; return db.GetBalance(addr).Cmp(amount) &gt;= 0&#125; 接着获取了发起者账户的Nonce，之后将其Nonce自增一。接下来检测该合约是否被创建过。一切检测完毕后，创建一个StateDB的快照。 接下来首先调用StateDB的CreateAccount，在statedb中的表现是创建了一个stateObject并记录相应事件，这个stateObject就代表新建的合约账户。接着如果处于EIP158版本，则将合约账户nonce初始化为1。再往下执行了Transfer方法。1234func Transfer(db vm.StateDB, sender, recipient common.Address, amount *big.Int) &#123; db.SubBalance(sender, amount) db.AddBalance(recipient, amount)&#125; 到此处表示合约账户创建成功了，此时要将创建人的账户减去他给合约发送的金额，而合约账户要相应的增加对应的金额。 接着调用NewContract创建一个新的合约对象，并利用SetCodeOptionalHash设置合约代码以代码hash值等数据。此时如果配置了NoRecursion（也就是不允许解释器执行call、callcode、delegate call和create）并且调用深度大于0，则直接返回。否则如果调用深度为0但是Debug模式则开始抓取信息。接下来运行run方法进行合约初始化，返回值ret是合约的代码。之后检查代码是否超过最大长度（24567）。如果没有的话存储代码，首先计算存储代码所需的gas，每字节200Gas。然后调用Contract的UseGas方法判断gas是否够用，够用的话使用statedb存储代码。如果前面代码过长或者Gas不足则回滚。最后方法结束，返回合约代码，合约地址以及合约剩余Gas。 除了Create方法可以创建合约外，还有一个Create2方法，唯一区别就是合约账户地址的生成不一样，123456789func (evm *EVM) Create2(caller ContractRef, code []byte, gas uint64, endowment *big.Int, salt *big.Int) (ret []byte, contractAddr common.Address, leftOverGas uint64, err error) &#123; codeAndHash := &amp;codeAndHash&#123;code: code&#125; contractAddr = crypto.CreateAddress2(caller.Address(), common.BigToHash(salt), codeAndHash.Hash().Bytes()) return evm.create(caller, codeAndHash, gas, endowment, contractAddr)&#125;func CreateAddress2(b common.Address, salt [32]byte, inithash []byte) common.Address &#123; return common.BytesToAddress(Keccak256([]byte&#123;0xff&#125;, b.Bytes(), salt[:], inithash)[12:])&#125; Create2中地址为keccak256(0xff + 发起人地址 + salt + 代码的hash值)，取最后20字节。 Call123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354func (evm *EVM) Call(caller ContractRef, addr common.Address, input []byte, gas uint64, value *big.Int) (ret []byte, leftOverGas uint64, err error) &#123; if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 &#123; return nil, gas, nil &#125; if evm.depth &gt; int(params.CallCreateDepth) &#123; return nil, gas, ErrDepth &#125; if !evm.Context.CanTransfer(evm.StateDB, caller.Address(), value) &#123; return nil, gas, ErrInsufficientBalance &#125; var ( to = AccountRef(addr) snapshot = evm.StateDB.Snapshot() ) if !evm.StateDB.Exist(addr) &#123; precompiles := PrecompiledContractsHomestead if evm.ChainConfig().IsByzantium(evm.BlockNumber) &#123; precompiles = PrecompiledContractsByzantium &#125; if precompiles[addr] == nil &amp;&amp; evm.ChainConfig().IsEIP158(evm.BlockNumber) &amp;&amp; value.Sign() == 0 &#123; if evm.vmConfig.Debug &amp;&amp; evm.depth == 0 &#123; evm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value) evm.vmConfig.Tracer.CaptureEnd(ret, 0, 0, nil) &#125; return nil, gas, nil &#125; evm.StateDB.CreateAccount(addr) &#125; evm.Transfer(evm.StateDB, caller.Address(), to.Address(), value) contract := NewContract(caller, to, value, gas) contract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr)) start := time.Now() if evm.vmConfig.Debug &amp;&amp; evm.depth == 0 &#123; evm.vmConfig.Tracer.CaptureStart(caller.Address(), addr, false, input, gas, value) defer func() &#123; evm.vmConfig.Tracer.CaptureEnd(ret, gas-contract.Gas, time.Since(start), err) &#125;() &#125; ret, err = run(evm, contract, input, false) if err != nil &#123; evm.StateDB.RevertToSnapshot(snapshot) if err != errExecutionReverted &#123; contract.UseGas(contract.Gas) &#125; &#125; return ret, contract.Gas, err&#125; 与Create方法类似，这个方法在一般交易中或者调用合约是会用到。在StateTransition中如果是一般交易的话会调用该方法。传入的参数依次是交易的发起人，交易的接受者，交易附带数据（这里解释为调用合约的输入值），交易剩余的可用gas，交易传输的金额。 开始时也是先进行检测，第一步如果配置了NoRecursion且调用深度大于0，则直接返回。第二如果调用深度大于1024报错返回。第三步检测调用账户余额是否足够。 之后记录交易的目标地址以及创建快照。接着使用stateDB的Exist方法判断该地址是否存在，如果不存在，也就说明该账户尚未创建，则首先加载一系列预编译的代码，然后检查所谓的目标地址是否和这些预编译的代码编号对应，如果对应不上且是EIP158版本且发送的value为0，则返回，本次没有实际的调用。 否则，则是前面的几种情况有满足的，调用StateDB的CreateAccount创建一个账户对应的stateObject。接下来调用Transfer转移金额。再往下创建一个新的合约对象并设置代码及代码hash。这里只是创建一个Contract对象，提供后面执行的上下文环境，并没有实际的创建合约账户，而且Contract的代码字段也仅仅是通过给定的合约地址获取的，如果刚才这个合约地址不存在的话，这个GetCode方法取到的只能为nil，当code为空时后面的run方法会自动退出，这时表示对一个账户单纯的转账。 接着如果是debug模式而且调用深度为0，开始捕获信息。然后调用run方法执行，此时有输入信息，如果前面创建的合约对象code不为空的话。这里就表示调用合约的代码。执行完之后，如果有错则进行回滚。 Callcode123456789101112131415161718192021222324252627282930func (evm *EVM) CallCode(caller ContractRef, addr common.Address, input []byte, gas uint64, value *big.Int) (ret []byte, leftOverGas uint64, err error) &#123; if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 &#123; return nil, gas, nil &#125; if evm.depth &gt; int(params.CallCreateDepth) &#123; return nil, gas, ErrDepth &#125; if !evm.CanTransfer(evm.StateDB, caller.Address(), value) &#123; return nil, gas, ErrInsufficientBalance &#125; var ( snapshot = evm.StateDB.Snapshot() to = AccountRef(caller.Address()) ) contract := NewContract(caller, to, value, gas) contract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr)) ret, err = run(evm, contract, input, false) if err != nil &#123; evm.StateDB.RevertToSnapshot(snapshot) if err != errExecutionReverted &#123; contract.UseGas(contract.Gas) &#125; &#125; return ret, contract.Gas, err&#125; 这个方法和call类似，最大的区别是使用的是调用者的上下文，体现在创建Contract对象时，第二个参数to是一个用AccountRef包装的调用者地址，这个参数最后影响Contract对象的self字段，表示的是合约的地址，这样设置为调用者的地址后也就相当于调用者自己。回顾call，那里面的to参数就是合约的地址。最后还有一点，call方法会给目标地址转移金额，而callcode不会。 DelegateCall123456789101112131415161718192021222324252627282930313233func (evm *EVM) DelegateCall(caller ContractRef, addr common.Address, input []byte, gas uint64) (ret []byte, leftOverGas uint64, err error) &#123; if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 &#123; return nil, gas, nil &#125; if evm.depth &gt; int(params.CallCreateDepth) &#123; return nil, gas, ErrDepth &#125; var ( snapshot = evm.StateDB.Snapshot() to = AccountRef(caller.Address()) ) contract := NewContract(caller, to, nil, gas).AsDelegate() contract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr)) ret, err = run(evm, contract, input, false) if err != nil &#123; evm.StateDB.RevertToSnapshot(snapshot) if err != errExecutionReverted &#123; contract.UseGas(contract.Gas) &#125; &#125; return ret, contract.Gas, err&#125;func (c *Contract) AsDelegate() *Contract &#123; parent := c.caller.(*Contract) c.CallerAddress = parent.CallerAddress c.value = parent.value return c&#125; 这个和callcode方法类似，唯一的区别还是创建合约的形式不同，这里和callcode一样将Contract对象的self字段设为调用者地址，另外还使用AsDelegate对合约进行转化。主要修改的是这个合约的调用者不再是DelegateCall传入的调用者，而是DelegateCall方法给的调用者的调用者。注意这里有两层关系，这样创建出的合约实际上调用者类似，自己的地址是caller，调用者则是caller.CallerAddress。这就相当于将两个合约合为一体，效果就类似将另一个合约的代码拿来放在自己合约内执行，当然上下文环境也是自己的。 实际上call、callcode、delegatecall这三个方法就相当于solidity中对应名称的三个低级调用。 StaticCall12345678910111213141516171819202122232425262728func (evm *EVM) StaticCall(caller ContractRef, addr common.Address, input []byte, gas uint64) (ret []byte, leftOverGas uint64, err error) &#123; if evm.vmConfig.NoRecursion &amp;&amp; evm.depth &gt; 0 &#123; return nil, gas, nil &#125; if evm.depth &gt; int(params.CallCreateDepth) &#123; return nil, gas, ErrDepth &#125; var ( to = AccountRef(addr) snapshot = evm.StateDB.Snapshot() ) contract := NewContract(caller, to, new(big.Int), gas) contract.SetCallCode(&amp;addr, evm.StateDB.GetCodeHash(addr), evm.StateDB.GetCode(addr)) evm.StateDB.AddBalance(addr, bigZero) ret, err = run(evm, contract, input, true) if err != nil &#123; evm.StateDB.RevertToSnapshot(snapshot) if err != errExecutionReverted &#123; contract.UseGas(contract.Gas) &#125; &#125; return ret, contract.Gas, err&#125; 这类似于前面的call方法，但是他不允许修改状态，原因是调用run方法时最后一个readOnly变量为true，而前几个都为false。 runevm中多次调用了该方法，这是运行给定合约1234567891011121314151617181920212223func run(evm *EVM, contract *Contract, input []byte, readOnly bool) ([]byte, error) &#123; if contract.CodeAddr != nil &#123; precompiles := PrecompiledContractsHomestead if evm.ChainConfig().IsByzantium(evm.BlockNumber) &#123; precompiles = PrecompiledContractsByzantium &#125; if p := precompiles[*contract.CodeAddr]; p != nil &#123; return RunPrecompiledContract(p, input, contract) &#125; &#125; for _, interpreter := range evm.interpreters &#123; if interpreter.CanRun(contract.Code) &#123; if evm.interpreter != interpreter &#123; defer func(i Interpreter) &#123; evm.interpreter = i &#125;(evm.interpreter) evm.interpreter = interpreter &#125; return interpreter.Run(contract, input, readOnly) &#125; &#125; return nil, ErrNoCompatibleInterpreter&#125; 第一步如果合约中的CodeAddr不为空，则先加载预编译的代码，然后看合约地址是否是这些预编译代码的编号，是的话执行对应的预编译代码1234567func RunPrecompiledContract(p PrecompiledContract, input []byte, contract *Contract) (ret []byte, err error) &#123; gas := p.RequiredGas(input) if contract.UseGas(gas) &#123; return p.Run(input) &#125; return nil, ErrOutOfGas&#125; 基本就是调用了这些预编译合约的RequiredGas和Run方法，一个获取所需的gas，一个执行逻辑。我们以最简单的dataCopy为例12345678type dataCopy struct&#123;&#125;func (c *dataCopy) RequiredGas(input []byte) uint64 &#123; return uint64(len(input)+31)/32*params.IdentityPerWordGas + params.IdentityBaseGas&#125;func (c *dataCopy) Run(in []byte) ([]byte, error) &#123; return in, nil&#125; 它的RequiredGas就是根据输入数据的长度按每32字节一个字（向上取整）消耗3Gas在加上基础消耗15Gas计算。Run方法则是直接返回输入数据，实现copy功能。 类似的还有sha256hash，实现SHA256计算123456789type sha256hash struct&#123;&#125;func (c *sha256hash) RequiredGas(input []byte) uint64 &#123; return uint64(len(input)+31)/32*params.Sha256PerWordGas + params.Sha256BaseGas&#125;func (c *sha256hash) Run(input []byte) ([]byte, error) &#123; h := sha256.Sum256(input) return h[:], nil&#125; 还回到run中，如果不是预编译的代码，则遍历evm中的所有解释器，对每个解释器执行canRun方法，检查是否可以执行，可以的话则调用解释器的Run方法去执行，并返回结果。Run方法参见前面解释器的源码分析。 题图来自unsplash：https://unsplash.com/photos/X0OoHrPvgXE]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中ethash源码分析]]></title>
    <url>%2F2019%2F05%2F30%2Fgo-ethereum%E4%B8%ADethash%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[本文代码大部分集中在consensus目录下 EngineEngine就是以太坊中共识引擎，在构建Ethereum时被创建使用CreateConsensusEngine方法1234567891011121314151617181920212223242526272829CreateConsensusEngine(ctx, chainConfig, &amp;config.Ethash, config.MinerNotify, config.MinerNoverify, chainDb),func CreateConsensusEngine(ctx *node.ServiceContext, chainConfig *params.ChainConfig, config *ethash.Config, notify []string, noverify bool, db ethdb.Database) consensus.Engine &#123; if chainConfig.Clique != nil &#123; return clique.New(chainConfig.Clique, db) &#125; switch config.PowMode &#123; case ethash.ModeFake: log.Warn("Ethash used in fake mode") return ethash.NewFaker() case ethash.ModeTest: log.Warn("Ethash used in test mode") return ethash.NewTester(nil, noverify) case ethash.ModeShared: log.Warn("Ethash used in shared mode") return ethash.NewShared() default: engine := ethash.New(ethash.Config&#123; CacheDir: ctx.ResolvePath(config.CacheDir), CachesInMem: config.CachesInMem, CachesOnDisk: config.CachesOnDisk, DatasetDir: config.DatasetDir, DatasetsInMem: config.DatasetsInMem, DatasetsOnDisk: config.DatasetsOnDisk, &#125;, notify, noverify) engine.SetThreads(-1) // Disable CPU mining return engine &#125;&#125; 首先如果需要PoA共识的话，创建clique对象。对于PoW共识的话根据不同模式创建不同的ethash对象。 对于CreateConsensusEngine是返回的一个Engine类型对象，它是一个接口，定义如下123456789101112131415161718192021222324252627// go-ethereum\consensus\consensus.gotype Engine interface &#123; Author(header *types.Header) (common.Address, error) VerifyHeader(chain ChainReader, header *types.Header, seal bool) error VerifyHeaders(chain ChainReader, headers []*types.Header, seals []bool) (chan&lt;- struct&#123;&#125;, &lt;-chan error) VerifyUncles(chain ChainReader, block *types.Block) error VerifySeal(chain ChainReader, header *types.Header) error Prepare(chain ChainReader, header *types.Header) error Finalize(chain ChainReader, header *types.Header, state *state.StateDB, txs []*types.Transaction, uncles []*types.Header, receipts []*types.Receipt) (*types.Block, error) Seal(chain ChainReader, block *types.Block, results chan&lt;- *types.Block, stop &lt;-chan struct&#123;&#125;) error SealHash(header *types.Header) common.Hash CalcDifficulty(chain ChainReader, time uint64, parent *types.Header) *big.Int APIs(chain ChainReader) []rpc.API Close() error&#125; Author是返回挖出该区块的地址，接下来几个Verify开头的方法是用来验证对错的。Prepare用于填充区块头的难度字段。Finalize是发放奖励和组装区块。Seal用来打包区块。SealHash返回打包区块的hash。CalcDifficulty计算新区快的应有难度。 与Engine一起定义的还有一个PoW接口，它除了继承了Engine接口内容，还多一个Hashrate方法用于返回当前挖矿的hash率。 New本文主要介绍Ethash源码，先看其New方法：123456789101112131415161718192021222324252627func New(config Config, notify []string, noverify bool) *Ethash &#123; if config.CachesInMem &lt;= 0 &#123; log.Warn("One ethash cache must always be in memory", "requested", config.CachesInMem) config.CachesInMem = 1 &#125; if config.CacheDir != "" &amp;&amp; config.CachesOnDisk &gt; 0 &#123; log.Info("Disk storage enabled for ethash caches", "dir", config.CacheDir, "count", config.CachesOnDisk) &#125; if config.DatasetDir != "" &amp;&amp; config.DatasetsOnDisk &gt; 0 &#123; log.Info("Disk storage enabled for ethash DAGs", "dir", config.DatasetDir, "count", config.DatasetsOnDisk) &#125; ethash := &amp;Ethash&#123; config: config, caches: newlru("cache", config.CachesInMem, newCache), datasets: newlru("dataset", config.DatasetsInMem, newDataset), update: make(chan struct&#123;&#125;), hashrate: metrics.NewMeterForced(), workCh: make(chan *sealTask), fetchWorkCh: make(chan *sealWork), submitWorkCh: make(chan *mineResult), fetchRateCh: make(chan chan uint64), submitRateCh: make(chan *hashrate), exitCh: make(chan chan error), &#125; go ethash.remote(notify, noverify) return ethash&#125; 主要就是根据config信息构建一个ethash对象，我们简单回顾一下ethash的配置，首先在eth.DefaultConfig中加载了一部分默认配置信息123456789101112131415161718192021222324252627// go-ethereum\eth\config.govar DefaultConfig = Config&#123; SyncMode: downloader.FastSync, Ethash: ethash.Config&#123; CacheDir: "ethash", CachesInMem: 2, CachesOnDisk: 3, DatasetsInMem: 1, DatasetsOnDisk: 2, &#125;, NetworkId: 1, LightPeers: 100, DatabaseCache: 512, TrieCleanCache: 256, TrieDirtyCache: 256, TrieTimeout: 60 * time.Minute, MinerGasFloor: 8000000, MinerGasCeil: 8000000, MinerGasPrice: big.NewInt(params.GWei), MinerRecommit: 3 * time.Second, TxPool: core.DefaultTxPoolConfig, GPO: gasprice.Config&#123; Blocks: 20, Percentile: 60, &#125;,&#125; 这里给出了构建ethash的几个关键参数，还有一个config.DatasetDir是在go-ethereum\eth\config.go的init中初始化，默认是在/home/.ethash。除此之外还有一些列用户可以设定的参数，需要在启动以太坊节点后根据固定参数设置，在go-ethereum\cmd\utils\flags.go的SetEthConfig中加载参数，一般我们都没有指定特殊参数。new方法最后启动了一个goroutine运行remote方法，我们稍后再讲 Author123func (ethash *Ethash) Author(header *types.Header) (common.Address, error) &#123; return header.Coinbase, nil&#125; 这个很简单就是返回区块头的Coinbase字段 VerifyHeader12345678910111213141516func (ethash *Ethash) VerifyHeader(chain consensus.ChainReader, header *types.Header, seal bool) error &#123; if ethash.config.PowMode == ModeFullFake &#123; return nil &#125; number := header.Number.Uint64() if chain.GetHeader(header.Hash(), number) != nil &#123; return nil &#125; parent := chain.GetHeader(header.ParentHash, number-1) if parent == nil &#123; return consensus.ErrUnknownAncestor &#125; return ethash.verifyHeader(chain, header, parent, false, seal)&#125; 首先对于ModeFullFake模式下的共识对任何区块头都予以放行，不进行检测。对于需要检测的区块头，首先获取可区块的高度，接着从本地尝试获取对应高度和hash的区块头，如果能获取到，说明该区块正确。之后在本地检查了父块，如果找不到返回ErrUnknownAncestor错误。 接下来如果能找到父块，则调用verifyHeader方法进行检测 verifyHeader12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (ethash *Ethash) verifyHeader(chain consensus.ChainReader, header, parent *types.Header, uncle bool, seal bool) error &#123; if uint64(len(header.Extra)) &gt; params.MaximumExtraDataSize &#123; return fmt.Errorf("extra-data too long: %d &gt; %d", len(header.Extra), params.MaximumExtraDataSize) &#125; if uncle &#123; if header.Time.Cmp(math.MaxBig256) &gt; 0 &#123; return errLargeBlockTime &#125; &#125; else &#123; if header.Time.Cmp(big.NewInt(time.Now().Add(allowedFutureBlockTime).Unix())) &gt; 0 &#123; return consensus.ErrFutureBlock &#125; &#125; if header.Time.Cmp(parent.Time) &lt;= 0 &#123; return errZeroBlockTime &#125; expected := ethash.CalcDifficulty(chain, header.Time.Uint64(), parent) if expected.Cmp(header.Difficulty) != 0 &#123; return fmt.Errorf("invalid difficulty: have %v, want %v", header.Difficulty, expected) &#125; cap := uint64(0x7fffffffffffffff) if header.GasLimit &gt; cap &#123; return fmt.Errorf("invalid gasLimit: have %v, max %v", header.GasLimit, cap) &#125; if header.GasUsed &gt; header.GasLimit &#123; return fmt.Errorf("invalid gasUsed: have %d, gasLimit %d", header.GasUsed, header.GasLimit) &#125; diff := int64(parent.GasLimit) - int64(header.GasLimit) if diff &lt; 0 &#123; diff *= -1 &#125; limit := parent.GasLimit / params.GasLimitBoundDivisor if uint64(diff) &gt;= limit || header.GasLimit &lt; params.MinGasLimit &#123; return fmt.Errorf("invalid gas limit: have %d, want %d += %d", header.GasLimit, parent.GasLimit, limit) &#125; if diff := new(big.Int).Sub(header.Number, parent.Number); diff.Cmp(big.NewInt(1)) != 0 &#123; return consensus.ErrInvalidNumber &#125; if seal &#123; if err := ethash.VerifySeal(chain, header); err != nil &#123; return err &#125; &#125; if err := misc.VerifyDAOHeaderExtraData(chain.Config(), header); err != nil &#123; return err &#125; if err := misc.VerifyForkHashes(chain.Config(), header, uncle); err != nil &#123; return err &#125; return nil&#125; 这个是区块头验证的主要地方，基本遵循黄皮书4.3.4的所述。分以下几步： 验证额外数据长度度：在区块头有一个额外数据的字段Extra，它的长度要小于32字节 验证时间戳：时间戳最基本的要求是要大于父块的时间戳。其次对于如果是一个叔块，时间戳不能太大，代码中要求不大于2的256次方。对于普通区块，不能为未来15秒之外的区块。 验证总难度：首先调用CalcDifficulty计算应该难度，然后判断是否相等，关于难度的计算稍后介绍。 验证gas限制：首先要求不大于2^63-1，但不能小于5000。其次gaslimit还和父块中的gaslimit相关，先关公式如下： 验证gas用量：要求小于gasLimit即可 验证区块高度：要求等于父块高度加一 其他验证：如果方法参数seal为true，执行VerifySeal方法，稍后介绍 验证分叉 VerifyHeaders123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func (ethash *Ethash) VerifyHeaders(chain consensus.ChainReader, headers []*types.Header, seals []bool) (chan&lt;- struct&#123;&#125;, &lt;-chan error) &#123; if ethash.config.PowMode == ModeFullFake || len(headers) == 0 &#123; abort, results := make(chan struct&#123;&#125;), make(chan error, len(headers)) for i := 0; i &lt; len(headers); i++ &#123; results &lt;- nil &#125; return abort, results &#125; workers := runtime.GOMAXPROCS(0) if len(headers) &lt; workers &#123; workers = len(headers) &#125; var ( inputs = make(chan int) done = make(chan int, workers) errors = make([]error, len(headers)) abort = make(chan struct&#123;&#125;) ) for i := 0; i &lt; workers; i++ &#123; go func() &#123; for index := range inputs &#123; errors[index] = ethash.verifyHeaderWorker(chain, headers, seals, index) done &lt;- index &#125; &#125;() &#125; errorsOut := make(chan error, len(headers)) go func() &#123; defer close(inputs) var ( in, out = 0, 0 checked = make([]bool, len(headers)) inputs = inputs ) for &#123; select &#123; case inputs &lt;- in: if in++; in == len(headers) &#123; inputs = nil &#125; case index := &lt;-done: for checked[index] = true; checked[out]; out++ &#123; errorsOut &lt;- errors[out] if out == len(headers)-1 &#123; return &#125; &#125; case &lt;-abort: return &#125; &#125; &#125;() return abort, errorsOut&#125; 这个是批量验证。首先还是对ModeFullFake模式不进行实质的验证，直接放行。接着利用一个循环，并发的执行verifyHeaderWorker方法：123456789101112131415func (ethash *Ethash) verifyHeaderWorker(chain consensus.ChainReader, headers []*types.Header, seals []bool, index int) error &#123; var parent *types.Header if index == 0 &#123; parent = chain.GetHeader(headers[0].ParentHash, headers[0].Number.Uint64()-1) &#125; else if headers[index-1].Hash() == headers[index].ParentHash &#123; parent = headers[index-1] &#125; if parent == nil &#123; return consensus.ErrUnknownAncestor &#125; if chain.GetHeader(headers[index].Hash(), headers[index].Number.Uint64()) != nil &#123; return nil // known block &#125; return ethash.verifyHeader(chain, headers[index], parent, false, seals[index])&#125; 这里逻辑很简单，根据index验证相应的区块头，首先获取父区块，然后要验证的区块在本地是否存在，之后调用verifyHeader方法。 回到VerifyHeaders，前面的那个并发程序后河面这个匿名方法是组合使用。手下前面的for循环启动了workers个goroutine，workers表示目前可用的cpu核心数，这样做是为了尽量满负荷运行，加速验证过程。但是每个线程都在从inputs这个channel读数据的时候阻塞，这时第二个匿名函数开始执行，首先他向inputs中写入数据，写入的是要验证的区块头的index，这样前面的验证线程可以结束阻塞执行verifyHeaderWorker方法。在验证完成后，将结果写入errors中，并向done赋值，这样又触发匿名方法中select中的逻辑，这里讲错误放入errorsOut，并由errorsOut最终返回。 VerifyUncles123456789101112131415161718192021222324252627282930313233343536373839404142434445func (ethash *Ethash) VerifyUncles(chain consensus.ChainReader, block *types.Block) error &#123; if ethash.config.PowMode == ModeFullFake &#123; return nil &#125; if len(block.Uncles()) &gt; maxUncles &#123; return errTooManyUncles &#125; uncles, ancestors := mapset.NewSet(), make(map[common.Hash]*types.Header) number, parent := block.NumberU64()-1, block.ParentHash() for i := 0; i &lt; 7; i++ &#123; ancestor := chain.GetBlock(parent, number) if ancestor == nil &#123; break &#125; ancestors[ancestor.Hash()] = ancestor.Header() for _, uncle := range ancestor.Uncles() &#123; uncles.Add(uncle.Hash()) &#125; parent, number = ancestor.ParentHash(), number-1 &#125; ancestors[block.Hash()] = block.Header() uncles.Add(block.Hash()) for _, uncle := range block.Uncles() &#123; hash := uncle.Hash() if uncles.Contains(hash) &#123; return errDuplicateUncle &#125; uncles.Add(hash) if ancestors[hash] != nil &#123; return errUncleIsAncestor &#125; if ancestors[uncle.ParentHash] == nil || uncle.ParentHash == block.ParentHash() &#123; return errDanglingUncle &#125; if err := ethash.verifyHeader(chain, uncle, ancestors[uncle.ParentHash], true, true); err != nil &#123; return err &#125; &#125; return nil&#125; 这是验证叔块的。首先也是对于ModeFullFake模式直接放行。然后检查该块的叔块数量，如果大于2报错。接着寻找了该块的父块高度和hash。之后收集了该块的祖先，最高7代。ancestors是一个map，key是hash类型，value是header类型，它存储着从该块的父块开始连续寻找7个祖先块的区块头，最后将自己也放入在内。uncles存储着每一代祖先的所有叔块hash以及该块自己的hash。 之后遍历该块的所有叔块，对于每个叔块，首先验证是否已经在uncles内，uncles存的是该块祖先的叔块，所以他的叔块不应包含在内。在之后验证是否在ancestors，因为ancestors是其直接祖先块，所以也不能成为其叔块。在之后叔块的父块时候包含在ancestors内，或者叔块的父块等于该块的父块，这都是不和逻辑的。最后校验每个叔块是否正确，调用verifyHeader方法 VerifySeal12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (ethash *Ethash) VerifySeal(chain consensus.ChainReader, header *types.Header) error &#123; return ethash.verifySeal(chain, header, false)&#125;func (ethash *Ethash) verifySeal(chain consensus.ChainReader, header *types.Header, fulldag bool) error &#123; if ethash.config.PowMode == ModeFake || ethash.config.PowMode == ModeFullFake &#123; time.Sleep(ethash.fakeDelay) if ethash.fakeFail == header.Number.Uint64() &#123; return errInvalidPoW &#125; return nil &#125; if ethash.shared != nil &#123; return ethash.shared.verifySeal(chain, header, fulldag) &#125; if header.Difficulty.Sign() &lt;= 0 &#123; return errInvalidDifficulty &#125; number := header.Number.Uint64() var ( digest []byte result []byte ) if fulldag &#123; dataset := ethash.dataset(number, true) if dataset.generated() &#123; digest, result = hashimotoFull(dataset.dataset, ethash.SealHash(header).Bytes(), header.Nonce.Uint64()) runtime.KeepAlive(dataset) &#125; else &#123; // Dataset not yet generated, don't hang, use a cache instead fulldag = false &#125; &#125; if !fulldag &#123; cache := ethash.cache(number) size := datasetSize(number) if ethash.config.PowMode == ModeTest &#123; size = 32 * 1024 &#125; digest, result = hashimotoLight(size, cache.cache, ethash.SealHash(header).Bytes(), header.Nonce.Uint64()) runtime.KeepAlive(cache) &#125; if !bytes.Equal(header.MixDigest[:], digest) &#123; return errInvalidMixDigest &#125; target := new(big.Int).Div(two256, header.Difficulty) if new(big.Int).SetBytes(result).Cmp(target) &gt; 0 &#123; return errInvalidPoW &#125; return nil&#125; 这个方法用来检测区块是否满足PoW的难度要求，主要是验证nonce。首先对于ModeFake和ModeFullFake不进行检测。另外如果是shared模式，则采用对应的verifySeal方法。接下来检测区块头的难度值必须大于0.接下来根据fulldag的具体情况执行不同逻辑。 如果fullgdag为true，则先加载对应数据集，如果数据集已经产生则使用hashimotoFull进行验证，否则fulldag置为false。如果fullgad为false，则加载对应的随机数集cache，然后计算数据集大小，之后用hashimotoLight进行验证。这两处都用了KeepAlive方法，这是告诉编译器不要回收给定代码的内存。 验证之后返回两个结果digest和result，按照下面公式进行验证： 。 其中的n就是result，m就是digest。Hd表示该区块的难度；Hm表示该区块头的mixHash字段，是一个256位的哈希值，用来与nonce一起证明当前区块已经承载了足够的计算量。上图中的PoW函数的第一个参数表示不包含nonce和mixHash的区块头，也就是SealHash方法所产生的。 Prepare12345678func (ethash *Ethash) Prepare(chain consensus.ChainReader, header *types.Header) error &#123; parent := chain.GetHeader(header.ParentHash, header.Number.Uint64()-1) if parent == nil &#123; return consensus.ErrUnknownAncestor &#125; header.Difficulty = ethash.CalcDifficulty(chain, header.Time.Uint64(), parent) return nil&#125; 这个方法首先查找了给定区块头的父区块，然后计算了难度。 Finalize123456func (ethash *Ethash) Finalize(chain consensus.ChainReader, header *types.Header, state *state.StateDB, txs []*types.Transaction, uncles []*types.Header, receipts []*types.Receipt) (*types.Block, error) &#123; accumulateRewards(chain.Config(), state, header, uncles) header.Root = state.IntermediateRoot(chain.Config().IsEIP158(header.Number)) return types.NewBlock(header, txs, uncles, receipts), nil&#125; 首先调用accumulateRewards发放奖励：1234567891011121314151617181920212223func accumulateRewards(config *params.ChainConfig, state *state.StateDB, header *types.Header, uncles []*types.Header) &#123; blockReward := FrontierBlockReward if config.IsByzantium(header.Number) &#123; blockReward = ByzantiumBlockReward &#125; if config.IsConstantinople(header.Number) &#123; blockReward = ConstantinopleBlockReward &#125; reward := new(big.Int).Set(blockReward) r := new(big.Int) for _, uncle := range uncles &#123; r.Add(uncle.Number, big8) r.Sub(r, header.Number) r.Mul(r, blockReward) r.Div(r, big8) state.AddBalance(uncle.Coinbase, r) r.Div(blockReward, big32) reward.Add(reward, r) &#125; state.AddBalance(header.Coinbase, reward)&#125; 先根据区块高度决定基本的区块奖励，详细奖励发放的细节见黄皮书11.3节描述。如果是拜占庭版本也就是区块高度大于4370000，每个区块基本奖励为3以太币。如果是君士坦丁堡版本，也就是区块高度大于7280000，每个区块基本奖励为2以太币。如果区块高度低于4370000，则是5以太币。之后遍历所有叔块，每多一个叔块，奖励提高三十二分之一的基本区块奖励。对于每个叔块也有其相应奖励，公式如下： 上面公式用Ui表示叔块高度，BHi表示当前区块高度，Rblock表示表示基本区块奖励。每计算一个叔块用state的AddBalance修改对应地址的余额。最后修改该区块头的coinbase余额，奖励发放完毕。 回到Finalize，计算新状态的状态树根hash，然后染回一个新的区块。 CalcDifficulty这是一个计算难度的方法，用于计算一个区块应有的难度。1234567891011121314151617func (ethash *Ethash) CalcDifficulty(chain consensus.ChainReader, time uint64, parent *types.Header) *big.Int &#123; return CalcDifficulty(chain.Config(), time, parent)&#125;func CalcDifficulty(config *params.ChainConfig, time uint64, parent *types.Header) *big.Int &#123; next := new(big.Int).Add(parent.Number, big1) switch &#123; case config.IsConstantinople(next): return calcDifficultyConstantinople(time, parent) case config.IsByzantium(next): return calcDifficultyByzantium(time, parent) case config.IsHomestead(next): return calcDifficultyHomestead(time, parent) default: return calcDifficultyFrontier(time, parent) &#125;&#125; 这里首先计算该区块多对应的版本号，简单说一下不同版本的划分，高度在7280000以上的为君士坦丁堡版本；高度在4370000以上的为拜占庭版本；高度在1150000以上的为家园(Homestead)版本；最后高度在1150000一下的为前沿(Frontier)版本。其中君士坦丁堡版本和拜占庭版本都调用了makeDifficultyCalculator方法，区别是其中的参数不同，这个参数为了推迟难度炸弹的来临，关于难度计算是根据黄皮书中的公式计算的，这里讲一下公式，公式如下： 公式(41)描述了难度的计算，首先创世区块为131072，转为16进制表示就是0x‭20000，这就是官网给的创世区块json示例中的难度值。对于非创世区块则在两个值中取一个最大值。第一个值就是创世区块的难度。第二个值由三部分组成： P(H)Hd表示父区块难度 x表示父区块的难度除以2048并向下取整。与x相乘的有一个系数，由公式(44)计算。这个公式中y有父区块的叔块数量决定，如果叔块数量为0则取1，否则取2.公式(44)中的Hs表示当前区块的时间戳，P(H)Hs表示父区块的时间戳。 第三部分由公式(45)(46)联合计算，这里在以太坊初始版本中没有公式(46)，直接是用区块高度除以100000，由于是做指数运算，会使第三部分的值每十万个区块指数增长一次，难度值会越来越夸张，所以从拜占庭版本开始对区块高度减去一个值，拜占庭版本是3000000，君士坦丁堡版本是5000000。公式中的Hi就是区块高度。 区块的难度就由上面的公式计算的，代码也都是一些数学运算，这里不再叙述了。 关于难度计算通过公式可以看到也是动态调整的，首先它是基于父块的难度，然后难度的第二部分，当两个区块时间间隔过近时，x的系数为正，加大难度；当两个区块时间间隔过远时，x的系数为负数，减小难度值。最后一部分则会根据区块高度稳定增加一定的难度。 Seal这个方法就是尝试找到一个nonce去满足PoW要求，然后封装一个区块12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273func (ethash *Ethash) Seal(chain consensus.ChainReader, block *types.Block, results chan&lt;- *types.Block, stop &lt;-chan struct&#123;&#125;) error &#123; if ethash.config.PowMode == ModeFake || ethash.config.PowMode == ModeFullFake &#123; header := block.Header() header.Nonce, header.MixDigest = types.BlockNonce&#123;&#125;, common.Hash&#123;&#125; select &#123; case results &lt;- block.WithSeal(header): default: log.Warn("Sealing result is not read by miner", "mode", "fake", "sealhash", ethash.SealHash(block.Header())) &#125; return nil &#125; if ethash.shared != nil &#123; return ethash.shared.Seal(chain, block, results, stop) &#125; abort := make(chan struct&#123;&#125;) ethash.lock.Lock() threads := ethash.threads if ethash.rand == nil &#123; seed, err := crand.Int(crand.Reader, big.NewInt(math.MaxInt64)) if err != nil &#123; ethash.lock.Unlock() return err &#125; ethash.rand = rand.New(rand.NewSource(seed.Int64())) &#125; ethash.lock.Unlock() if threads == 0 &#123; threads = runtime.NumCPU() &#125; if threads &lt; 0 &#123; threads = 0 // Allows disabling local mining without extra logic around local/remote &#125; if ethash.workCh != nil &#123; ethash.workCh &lt;- &amp;sealTask&#123;block: block, results: results&#125; &#125; var ( pend sync.WaitGroup locals = make(chan *types.Block) ) for i := 0; i &lt; threads; i++ &#123; pend.Add(1) go func(id int, nonce uint64) &#123; defer pend.Done() ethash.mine(block, id, nonce, abort, locals) &#125;(i, uint64(ethash.rand.Int63())) &#125; go func() &#123; var result *types.Block select &#123; case &lt;-stop: close(abort) case result = &lt;-locals: select &#123; case results &lt;- result: default: log.Warn("Sealing result is not read by miner", "mode", "local", "sealhash", ethash.SealHash(block.Header())) &#125; close(abort) case &lt;-ethash.update: close(abort) if err := ethash.Seal(chain, block, results, stop); err != nil &#123; log.Error("Failed to restart sealing after update", "err", err) &#125; &#125; pend.Wait() &#125;() return nil&#125; 首先对于ModeFake或ModeFullFake模式，直接打包一个区块，nonce为0。另外如果为shared模式则调用对应的Seal方法。 接下来ethash.threads获取挖矿线程数，如果为0的话表示线程数等于cpu核数，如果小于0则禁用。接着如果随机数种子为空，则生成一个。接着启动threads个goroutine去执行mine方法。另外在外面还有一个独立的goroutine执行一个匿名方法，用于接受信号执行响应逻辑。stop读到信号表示终止操作；locals读到信号表示有线程找到了合法值；update收到信号表示进行重启。最后这个方法会等待前面执行mine的goroutine都结束才会退出。 mine123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func (ethash *Ethash) mine(block *types.Block, id int, seed uint64, abort chan struct&#123;&#125;, found chan *types.Block) &#123; var ( header = block.Header() hash = ethash.SealHash(header).Bytes() target = new(big.Int).Div(two256, header.Difficulty) number = header.Number.Uint64() dataset = ethash.dataset(number, false) ) var ( attempts = int64(0) nonce = seed ) logger := log.New("miner", id) logger.Trace("Started ethash search for new nonces", "seed", seed)search: for &#123; select &#123; case &lt;-abort: logger.Trace("Ethash nonce search aborted", "attempts", nonce-seed) ethash.hashrate.Mark(attempts) break search default: attempts++ if (attempts % (1 &lt;&lt; 15)) == 0 &#123; ethash.hashrate.Mark(attempts) attempts = 0 &#125; digest, result := hashimotoFull(dataset.dataset, hash, nonce) if new(big.Int).SetBytes(result).Cmp(target) &lt;= 0 &#123; header = types.CopyHeader(header) header.Nonce = types.EncodeNonce(nonce) header.MixDigest = common.BytesToHash(digest) select &#123; case found &lt;- block.WithSeal(header): logger.Trace("Ethash nonce found and reported", "attempts", nonce-seed, "nonce", nonce) case &lt;-abort: logger.Trace("Ethash nonce found but discarded", "attempts", nonce-seed, "nonce", nonce) &#125; break search &#125; nonce++ &#125; &#125; runtime.KeepAlive(dataset)&#125; 这个方法才是实际上寻找nonce的方法，基本逻辑从后面的for循环开始，从给定的seed开始，每次加一，利用hashimotoFull计算digest和result，就和前面的VerifySeal方法一样，只要result小于target即可。target等于2^256除以区块的难度。 如果找到的话给区块头补充nonce和misdigest字段，并通过WithSeal产生一个区块赋值给found，found就是前面Seal中的locals。 Ethash算法官方文档有详细的叙述，这里简单描述一下。 Ethash是以太坊中PoW的主要算法，基本流程如下： 根据区块高度计算出一个seed 根据seed产生一个16MB伪随机数据集cache 根据cache产生一个1GB大小的数据集DAG，一般完全节点需要DAG，轻客户端只需要cache 从DAG中随机选出元素，对其进行hash运算，看是否满足要求 数据集30000个区块更新一次，约100小时，并且会线性增长，DAG每次增长8MB，cache每次128KB。（之所以是100小时，目的是为了在18月左右增长一倍，符合摩尔定律） 数据结构12345678910111213141516type cache struct &#123; epoch uint64 // Epoch for which this cache is relevant dump *os.File // File descriptor of the memory mapped cache mmap mmap.MMap // Memory map itself to unmap before releasing cache []uint32 // The actual cache data content (may be memory mapped) once sync.Once // Ensures the cache is generated only once&#125;type dataset struct &#123; epoch uint64 // Epoch for which this cache is relevant dump *os.File // File descriptor of the memory mapped cache mmap mmap.MMap // Memory map itself to unmap before releasing dataset []uint32 // The actual cache data content once sync.Once // Ensures the cache is generated only once done uint32 // Atomic flag to determine generation status&#125; cache生成前面在verifySeal方法中就通过cache获取了对应的cache1234567891011121314func (ethash *Ethash) cache(block uint64) *cache &#123; epoch := block / epochLength currentI, futureI := ethash.caches.get(epoch) current := currentI.(*cache) current.generate(ethash.config.CacheDir, ethash.config.CachesOnDisk, ethash.config.PowMode == ModeTest) if futureI != nil &#123; future := futureI.(*cache) go future.generate(ethash.config.CacheDir, ethash.config.CachesOnDisk, ethash.config.PowMode == ModeTest) &#125; return current&#125; 第一步计算了代数，就是区块高度除以30000，然后从caches从尝试获取cache，caches的get获取所需代数及下一代的cache。1234567891011121314151617181920212223func (lru *lru) get(epoch uint64) (item, future interface&#123;&#125;) &#123; lru.mu.Lock() defer lru.mu.Unlock() item, ok := lru.cache.Get(epoch) if !ok &#123; if lru.future &gt; 0 &amp;&amp; lru.future == epoch &#123; item = lru.futureItem &#125; else &#123; log.Trace("Requiring new ethash "+lru.what, "epoch", epoch) item = lru.new(epoch) &#125; lru.cache.Add(epoch, item) &#125; if epoch &lt; maxEpoch-1 &amp;&amp; lru.future &lt; epoch+1 &#123; log.Trace("Requiring new future ethash "+lru.what, "epoch", epoch+1) future = lru.new(epoch + 1) lru.future = epoch + 1 lru.futureItem = future &#125; return item, future&#125; lru.cache是一个lru类型的缓存，先从中获取指定代数的，如果没有尝试从futureItem中获取，futureItem永远存储着下一代的cache，当然最开始为空。如果都没有新建一个。不管从哪里取到的话，如果代数低于最大代数，而且future需要更新的话，就更新future与futureItem。 我们再看新建方法：123func newCache(epoch uint64) interface&#123;&#125; &#123; return &amp;cache&#123;epoch: epoch&#125;&#125; 就是新建一个cache对象。回到cache方法，调用了generate方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849func (c *cache) generate(dir string, limit int, test bool) &#123; c.once.Do(func() &#123; size := cacheSize(c.epoch*epochLength + 1) seed := seedHash(c.epoch*epochLength + 1) if test &#123; size = 1024 &#125; if dir == "" &#123; c.cache = make([]uint32, size/4) generateCache(c.cache, c.epoch, seed) return &#125; var endian string if !isLittleEndian() &#123; endian = ".be" &#125; path := filepath.Join(dir, fmt.Sprintf("cache-R%d-%x%s", algorithmRevision, seed[:8], endian)) logger := log.New("epoch", c.epoch) runtime.SetFinalizer(c, (*cache).finalizer) var err error c.dump, c.mmap, c.cache, err = memoryMap(path) if err == nil &#123; logger.Debug("Loaded old ethash cache from disk") return &#125; logger.Debug("Failed to load old ethash cache", "err", err) c.dump, c.mmap, c.cache, err = memoryMapAndGenerate(path, size, func(buffer []uint32) &#123; generateCache(buffer, c.epoch, seed) &#125;) if err != nil &#123; logger.Error("Failed to generate mapped ethash cache", "err", err) c.cache = make([]uint32, size/4) generateCache(c.cache, c.epoch, seed) &#125; for ep := int(c.epoch) - limit; ep &gt;= 0; ep-- &#123; seed := seedHash(uint64(ep)*epochLength + 1) path := filepath.Join(dir, fmt.Sprintf("cache-R%d-%x%s", algorithmRevision, seed[:8], endian)) os.Remove(path) &#125; &#125;)&#125; 首先计算了cache大小，使用cacheSize方法，如果代数小于2048（按30000块一代，2048代有61440000个区块，需要二十几年才能生成）则根据预先计算好的表查找，否则先计算size = 初始值(128MB) + 128KB * 代数 - 64B，然后验证size/64取整后是否为质数，否则size减去128在验证，循环递减直到size/64取整后为质数。对于测试模式直接设为1024. 第二步计算了seed，如果是第零代区块，直接返回一个空的长度为32的字节数组。否则对那个空字节数组循环做n次keccak256哈希运算，n就是区块所在代数。总之seed是一个256位的数据 接着组装了本地的存储文件，接下来的runtime.SetFinalizer方法是设置cache被回收时执行的方法。接着调用memoryMap将加载文件并在内存中映射，这个方法如果不报错说明之前在磁盘有旧文件，可以直接用。否则需要生成cache文件。12345678910111213141516171819202122232425262728293031323334func memoryMapAndGenerate(path string, size uint64, generator func(buffer []uint32)) (*os.File, mmap.MMap, []uint32, error) &#123; if err := os.MkdirAll(filepath.Dir(path), 0755); err != nil &#123; return nil, nil, nil, err &#125; temp := path + "." + strconv.Itoa(rand.Int()) dump, err := os.Create(temp) if err != nil &#123; return nil, nil, nil, err &#125; if err = dump.Truncate(int64(len(dumpMagic))*4 + int64(size)); err != nil &#123; return nil, nil, nil, err &#125; mem, buffer, err := memoryMapFile(dump, true) if err != nil &#123; dump.Close() return nil, nil, nil, err &#125; copy(buffer, dumpMagic) data := buffer[len(dumpMagic):] generator(data) if err := mem.Unmap(); err != nil &#123; return nil, nil, nil, err &#125; if err := dump.Close(); err != nil &#123; return nil, nil, nil, err &#125; if err := os.Rename(temp, path); err != nil &#123; return nil, nil, nil, err &#125; return memoryMap(path)&#125; 首先创建目录，然后创建一个临时文件，接着调用Truncate方法修改临时文件大小，大小为8+size。接着映射该临时文件到内存，用的是memoryMapFile方法，我们具体看一下：1234567891011121314151617func memoryMapFile(file *os.File, write bool) (mmap.MMap, []uint32, error) &#123; flag := mmap.RDONLY if write &#123; flag = mmap.RDWR &#125; mem, err := mmap.Map(file, flag, 0) if err != nil &#123; return nil, nil, err &#125; header := *(*reflect.SliceHeader)(unsafe.Pointer(&amp;mem)) header.Len /= 4 header.Cap /= 4 return mem, *(*[]uint32)(unsafe.Pointer(&amp;header)), nil&#125; 首先设置模式，只读或是可读写。接着调用mmap.Map方法，这是”github.com/edsrzf/mmap-go”的库。mmap将一个文件或者其它对象映射进内存，让用户程序直接访问设备内存，这种机制，相比较在用户空间和内核空间互相拷贝数据，效率更高。Map方法返回一个MMap对象，翻阅源码实际就是字节数组。接下来将MMap转为一个切片（切片实际就是SliceHeader类型），这里将切片的长度和容器都缩减到原来四分之一，这是因为原来是字节数组，后面要改为uin32数组，之后有将修改过的切片转为32位无符号整形数组连同MMap一起返回。 回到memoryMapAndGenerate中，这里将dumpMagic拷贝到刚才返回的那个uint32数组中，dumpMagic是预置的一个含有两个魔法数的数组。接着调用generator生成数据，实际上是generateCache方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768func generateCache(dest []uint32, epoch uint64, seed []byte) &#123; logger := log.New("epoch", epoch) start := time.Now() defer func() &#123; elapsed := time.Since(start) logFn := logger.Debug if elapsed &gt; 3*time.Second &#123; logFn = logger.Info &#125; logFn("Generated ethash verification cache", "elapsed", common.PrettyDuration(elapsed)) &#125;() header := *(*reflect.SliceHeader)(unsafe.Pointer(&amp;dest)) header.Len *= 4 header.Cap *= 4 cache := *(*[]byte)(unsafe.Pointer(&amp;header)) size := uint64(len(cache)) rows := int(size) / hashBytes var progress uint32 done := make(chan struct&#123;&#125;) defer close(done) go func() &#123; for &#123; select &#123; case &lt;-done: return case &lt;-time.After(3 * time.Second): logger.Info("Generating ethash verification cache", "percentage", atomic.LoadUint32(&amp;progress)*100/uint32(rows)/4, "elapsed", common.PrettyDuration(time.Since(start))) &#125; &#125; &#125;() keccak512 := makeHasher(sha3.NewLegacyKeccak512()) keccak512(cache, seed) for offset := uint64(hashBytes); offset &lt; size; offset += hashBytes &#123; keccak512(cache[offset:], cache[offset-hashBytes:offset]) atomic.AddUint32(&amp;progress, 1) &#125; temp := make([]byte, hashBytes) for i := 0; i &lt; cacheRounds; i++ &#123; for j := 0; j &lt; rows; j++ &#123; var ( srcOff = ((j - 1 + rows) % rows) * hashBytes dstOff = j * hashBytes xorOff = (binary.LittleEndian.Uint32(cache[dstOff:]) % uint32(rows)) * hashBytes ) bitutil.XORBytes(temp, cache[srcOff:srcOff+hashBytes], cache[xorOff:xorOff+hashBytes]) keccak512(cache[dstOff:], temp) atomic.AddUint32(&amp;progress, 1) &#125; &#125; if !isLittleEndian() &#123; swap(cache) &#125;&#125; 传入的参数有三个。第一个就是生成的数据要填充的数组，也就是前面映射文件时返回的一个数组，第二个是区块所在代数，第三个是开始计算的种子。cache生成流程如下： 第一步将传进来的数组转为切片，然后长度和容量都乘以4。这里有几个大小需要注意，首先创建临时文件时大小是8+size，映射完返回的buffer容量是2+cap/4，之后前两个字节被写入固定值，之后剩余cap/4容量被传过来，这里又乘以4，进行了恢复，目的是为了将uint32数组转为字节数组，一个uint32等于4个字节长度。之后再将切片转为字节数组。然后计算大小size和轮数rows。接着启动一个goroutine，里面有一个for-select结构，每3秒打印一个log，显示cache生成进度。 第二步，准备一个hash函数–keccak512，keccak512(cache, seed)方法表示对seed计算hash值并写入cache中。此时cache的前512位也就是前64个字节 第三步开始一个循环，对cache进行预填充，每512位一组即64字节，第一组是对seed进行hash后的结果，之后每一组都是对前一组的hash。 第四步开始主循环，外循环有3轮，内循环轮数为第一步计算的rows。这一步连同上一步合起来是一种叫RandMemoHash的函数，是一种内存困难型的计算，详细内容参见原文或者译文。这里不再叙述，只是说一下几个方法的作用，XORBytes接受三个参数，作用是将第二个和第三个参数异或后的结果放入第一个参数中。keccak512是对第二个参数做hash运算，结果放入第一个参数。 经过上面第四步的循环后，cache被填满，最后还要保证cache中的数据时小端模式。注意cache是由header转换类型而来的，header则是的dest转换类型而来的，所以最后dest中也填满了数据。 最后cache中是若干组数据，每组有64个字节，也就是512位数据。 再回到memoryMapAndGenerate中，经过generator方法后，data填充了数据，data是buffer从2开始的切片，buffer前两个索引被放入的魔法数字，此时buffer也是有数据的。接着解除映射，这一步会将刚才内存中的数据写入文件，但注意此时还是那个temp临时文件，这里对其重命名，然后调用memoryMap12345678910111213141516171819func memoryMap(path string) (*os.File, mmap.MMap, []uint32, error) &#123; file, err := os.OpenFile(path, os.O_RDONLY, 0644) if err != nil &#123; return nil, nil, nil, err &#125; mem, buffer, err := memoryMapFile(file, false) if err != nil &#123; file.Close() return nil, nil, nil, err &#125; for i, magic := range dumpMagic &#123; if buffer[i] != magic &#123; mem.Unmap() file.Close() return nil, nil, nil, ErrInvalidDumpMagic &#125; &#125; return file, mem, buffer[len(dumpMagic):], err&#125; 这里再次对文件进行映射，只不过这次时只读模式，然后检查开头两个魔法数字来判断格式是否正确，然后返回文件句柄，映射对象，实际数据。 再往前回到cache的generate方法，memoryMapAndGenerate结束后，返回的几个值分别赋给了cache的几个成员，其中cache就是实际数据。接着判断前一步是否有错，有错的话则不映射文件直接生成数据。最后删除之前一些旧的文件。 最后回到Ethash的cache方法，此时我们只是生成的当前代的cache，接下来，为了方便，我们在生成下一代的cache，不过是在一个独立的goroutine中生成，方法一样，最后返回当前代的cache。 dataset生成同样在verifySeal方法中也有获取dateset的方法，用的是ethash的dataset方法123456789101112131415161718192021222324func (ethash *Ethash) dataset(block uint64, async bool) *dataset &#123; epoch := block / epochLength currentI, futureI := ethash.datasets.get(epoch) current := currentI.(*dataset) if async &amp;&amp; !current.generated() &#123; go func() &#123; current.generate(ethash.config.DatasetDir, ethash.config.DatasetsOnDisk, ethash.config.PowMode == ModeTest) if futureI != nil &#123; future := futureI.(*dataset) future.generate(ethash.config.DatasetDir, ethash.config.DatasetsOnDisk, ethash.config.PowMode == ModeTest) &#125; &#125;() &#125; else &#123; current.generate(ethash.config.DatasetDir, ethash.config.DatasetsOnDisk, ethash.config.PowMode == ModeTest) if futureI != nil &#123; future := futureI.(*dataset) go future.generate(ethash.config.DatasetDir, ethash.config.DatasetsOnDisk, ethash.config.PowMode == ModeTest) &#125; &#125; return current&#125; 前三行和cache一样，都尝试获取当前和下一代的数据集，接着判断当前代的dataset是否已经生成，没有的话调用generate123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func (d *dataset) generate(dir string, limit int, test bool) &#123; d.once.Do(func() &#123; defer atomic.StoreUint32(&amp;d.done, 1) csize := cacheSize(d.epoch*epochLength + 1) dsize := datasetSize(d.epoch*epochLength + 1) seed := seedHash(d.epoch*epochLength + 1) if test &#123; csize = 1024 dsize = 32 * 1024 &#125; if dir == "" &#123; cache := make([]uint32, csize/4) generateCache(cache, d.epoch, seed) d.dataset = make([]uint32, dsize/4) generateDataset(d.dataset, d.epoch, cache) return &#125; var endian string if !isLittleEndian() &#123; endian = ".be" &#125; path := filepath.Join(dir, fmt.Sprintf("full-R%d-%x%s", algorithmRevision, seed[:8], endian)) logger := log.New("epoch", d.epoch) runtime.SetFinalizer(d, (*dataset).finalizer) d.dump, d.mmap, d.dataset, err = memoryMap(path) if err == nil &#123; logger.Debug("Loaded old ethash dataset from disk") return &#125; logger.Debug("Failed to load old ethash dataset", "err", err) cache := make([]uint32, csize/4) generateCache(cache, d.epoch, seed) d.dump, d.mmap, d.dataset, err = memoryMapAndGenerate(path, dsize, func(buffer []uint32) &#123; generateDataset(buffer, d.epoch, cache) &#125;) if err != nil &#123; logger.Error("Failed to generate mapped ethash dataset", "err", err) d.dataset = make([]uint32, dsize/2) generateDataset(d.dataset, d.epoch, cache) &#125; for ep := int(d.epoch) - limit; ep &gt;= 0; ep-- &#123; seed := seedHash(uint64(ep)*epochLength + 1) path := filepath.Join(dir, fmt.Sprintf("full-R%d-%x%s", algorithmRevision, seed[:8], endian)) os.Remove(path) &#125; &#125;)&#125; 这里首先计算了对应代的cache大小和种子seed，和前面cache中一样，不在叙述。除此之外还计算了dateset大小：123456789101112131415func datasetSize(block uint64) uint64 &#123; epoch := int(block / epochLength) if epoch &lt; maxEpoch &#123; return datasetSizes[epoch] &#125; return calcDatasetSize(epoch)&#125;func calcDatasetSize(epoch int) uint64 &#123; size := datasetInitBytes + datasetGrowthBytes*uint64(epoch) - mixBytes for !new(big.Int).SetUint64(size / mixBytes).ProbablyPrime(1) &#123; // Always accurate for n &lt; 2^64 size -= 2 * mixBytes &#125; return size&#125; 和计算cachesize一样，对于2048代以内是查表，超过2048代是size=1GB+8MB*代数-128B，同样还是要求size除以128为质数，否则减去256在判断，如此循环直到为质数为止。 回到generate中，如果是测试模式，则设置cache的大小为1024，dateset大小为32*1024。接着如果没有指定目录的话，则不用文件映射，直接先生成一个cache，之后再生成dateset123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func generateDataset(dest []uint32, epoch uint64, cache []uint32) &#123; logger := log.New("epoch", epoch) start := time.Now() defer func() &#123; elapsed := time.Since(start) logFn := logger.Debug if elapsed &gt; 3*time.Second &#123; logFn = logger.Info &#125; logFn("Generated ethash verification cache", "elapsed", common.PrettyDuration(elapsed)) &#125;() swapped := !isLittleEndian() header := *(*reflect.SliceHeader)(unsafe.Pointer(&amp;dest)) header.Len *= 4 header.Cap *= 4 dataset := *(*[]byte)(unsafe.Pointer(&amp;header)) threads := runtime.NumCPU() size := uint64(len(dataset)) var pend sync.WaitGroup pend.Add(threads) var progress uint32 for i := 0; i &lt; threads; i++ &#123; go func(id int) &#123; defer pend.Done() keccak512 := makeHasher(sha3.NewLegacyKeccak512()) batch := uint32((size + hashBytes*uint64(threads) - 1) / (hashBytes * uint64(threads))) first := uint32(id) * batch limit := first + batch if limit &gt; uint32(size/hashBytes) &#123; limit = uint32(size / hashBytes) &#125; percent := uint32(size / hashBytes / 100) for index := first; index &lt; limit; index++ &#123; item := generateDatasetItem(cache, index, keccak512) if swapped &#123; swap(item) &#125; copy(dataset[index*hashBytes:], item) if status := atomic.AddUint32(&amp;progress, 1); status%percent == 0 &#123; logger.Info("Generating DAG in progress", "percentage", uint64(status*100)/(size/hashBytes), "elapsed", common.PrettyDuration(time.Since(start))) &#125; &#125; &#125;(i) &#125; pend.Wait()&#125; 这里首先对传入的dest也就是要存放数据的数组进行处理，先转为切片，修改其长度和容量，都是扩大4倍，之后再转为字节数组类型。接着获取cpu核数记为threads，获取数据集大小，然后启动threads个独立的goroutine。 首先dataset的整体数据结构和cache类似，都是按64字节也就是512位为一组，这里为了实现多线程并行计算，在每个goroutine中计算了需要计算的组数，然后循环调用generateDatasetItem生成每一组数据：123456789101112131415161718192021222324252627func generateDatasetItem(cache []uint32, index uint32, keccak512 hasher) []byte &#123; rows := uint32(len(cache) / hashWords) mix := make([]byte, hashBytes) binary.LittleEndian.PutUint32(mix, cache[(index%rows)*hashWords]^index) for i := 1; i &lt; hashWords; i++ &#123; binary.LittleEndian.PutUint32(mix[i*4:], cache[(index%rows)*hashWords+uint32(i)]) &#125; keccak512(mix, mix) intMix := make([]uint32, hashWords) for i := 0; i &lt; len(intMix); i++ &#123; intMix[i] = binary.LittleEndian.Uint32(mix[i*4:]) &#125; for i := uint32(0); i &lt; datasetParents; i++ &#123; parent := fnv(index^i, intMix[i%16]) % rows fnvHash(intMix, cache[parent*hashWords:]) &#125; for i, val := range intMix &#123; binary.LittleEndian.PutUint32(mix[i*4:], val) &#125; keccak512(mix, mix) return mix&#125; 首先把cache中的数据每16个视作一行，计算cache的总行数，由于cache每个元素时32位，16个也即是512位，也就是cache中的一组。这里初始化了一个含有64字节的数组mix，总长度也就是512位。接着按照一定规则计算mix，基本原则是充分利用cache中足够多的数据。 接着把mix中的数据放入一个长度为16的32位整型数组intmix，总长度也是512位。然后有一个循环，每次循环都利用了所谓的fnv和fnvhash函数，总循环为256次，目的还是尽可能多的使用cache中数据。每次循环的结果还是放在intmix中。（fnv全称Fowler–Noll–Vo，也是一种hash函数，他计算速度非常快，冲突率较低，也就是对于相似的数据也能产生大量的差别，其分散性较好，之所以用它是为了能较为随机的从数据集中取数据，避免数据间的使用率差别较大） 最后将intmix的数据写入mix中，再对mix做一次哈希运算，最后得到一个512位的数据，就是dataset中一组数据。 数据集的生成算法借鉴了Hashimoto算法，要想了解更多请参考Hashimoto算法，译文见这里 回到generateDataset中，调用generateDatasetItem之后，获取了一组数据，将其放到dateset对应位置，经过若干次上面过程后一个完整的dataset得以生成。 回到dataset的generate方法中，刚才我们分析的是没有指定数据存储路径的流程，接下来我们在看一下有数据路径的流程。 首先构建文件的最终路径，然后调用memoryMap进行映射，这一步和cache相同，如果没有错误说明原本就有，直接返回，读取的数据放入dataset相应字段中。如果读不到数据或有错，则先用generateCache生成cache数据，在使用memoryMapAndGenerate生成空文件，并进行映射然后生成dataset数据进行填充，流程和cache一样，不在叙述。只不过和前面直接生成数据不同的是，这里在数据开头写入了64位的魔法数字，和cache一样。最后尝试旧的数据文件，和cache一样的流程。 最后回到ethash的dataset方法，在这里主要是分了同步还是异步，逻辑都还是一样，只不过异步的是在一个单独的goroutine中执行的。最后生成完当代的dateset后，又根据具体需要生成了下一代数据。 hashimotoFull1234567func hashimotoFull(dataset []uint32, hash []byte, nonce uint64) ([]byte, []byte) &#123; lookup := func(index uint32) []uint32 &#123; offset := index * hashWords return dataset[offset : offset+hashWords] &#125; return hashimoto(hash, nonce, uint64(len(dataset))*4, lookup)&#125; 这是在全节点中节点有完整dateset数据集时的验证方法，直接调用了hashimoto方法 hashimotoLight1234567891011121314func hashimotoLight(size uint64, cache []uint32, hash []byte, nonce uint64) ([]byte, []byte) &#123; keccak512 := makeHasher(sha3.NewLegacyKeccak512()) lookup := func(index uint32) []uint32 &#123; rawData := generateDatasetItem(cache, index, keccak512) data := make([]uint32, len(rawData)/4) for i := 0; i &lt; len(data); i++ &#123; data[i] = binary.LittleEndian.Uint32(rawData[i*4:]) &#125; return data &#125; return hashimoto(hash, nonce, size, lookup)&#125; 这是没有完整dataset之后cache的轻节点的验证方法，也是直接调用了hashimoto方法，和hashimotoFull的区别是lookup的差别 hashimoto1234567891011121314151617181920212223242526272829303132333435363738func hashimoto(hash []byte, nonce uint64, size uint64, lookup func(index uint32) []uint32) ([]byte, []byte) &#123; rows := uint32(size / mixBytes) seed := make([]byte, 40) copy(seed, hash) binary.LittleEndian.PutUint64(seed[32:], nonce) seed = crypto.Keccak512(seed) seedHead := binary.LittleEndian.Uint32(seed) mix := make([]uint32, mixBytes/4) for i := 0; i &lt; len(mix); i++ &#123; mix[i] = binary.LittleEndian.Uint32(seed[i%16*4:]) &#125; temp := make([]uint32, len(mix)) for i := 0; i &lt; loopAccesses; i++ &#123; parent := fnv(uint32(i)^seedHead, mix[i%len(mix)]) % rows for j := uint32(0); j &lt; mixBytes/hashBytes; j++ &#123; copy(temp[j*hashWords:], lookup(2*parent+j)) &#125; fnvHash(mix, temp) &#125; for i := 0; i &lt; len(mix); i += 4 &#123; mix[i/4] = fnv(fnv(fnv(mix[i], mix[i+1]), mix[i+2]), mix[i+3]) &#125; mix = mix[:len(mix)/4] digest := make([]byte, common.HashLength) for i, val := range mix &#123; binary.LittleEndian.PutUint32(digest[i*4:], val) &#125; return digest, crypto.Keccak256(append(seed, digest...))&#125; 首先根据给定的头部hash和nonce计算seed，头部hash是32字节，nonce是8字节，将其拼接后做一次keccak512哈希运算，得到一个长度为64的字节数组。接着创建了一个无符号32位整型数组，长度是32。然后将seed中的数据数据放入mix中，由于mix总位数是seed的两倍，所以mix先后放置了两个seed的数据内容。 继续向下，设置一个和mix大小一样的临时数组。开始了64次循环，每次循环还是fnv和fnvhash进行运算，其中循环中fnv即其后的那个循环是为了对temp进行填充，fnvhash是为了利用temp对mix进行运算，最后结果放入mix中。关键一点是在lookup中。对于节点有完整dataset时，lookup实现如下1234lookup := func(index uint32) []uint32 &#123; offset := index * hashWords return dataset[offset : offset+hashWords] &#125; 很简单就是输入一个索引，然后从dateset中取一组数据（16个uint32数据，共512位）。对于没有完整dateset时，实现如下：123456789lookup := func(index uint32) []uint32 &#123; rawData := generateDatasetItem(cache, index, keccak512) data := make([]uint32, len(rawData)/4) for i := 0; i &lt; len(data); i++ &#123; data[i] = binary.LittleEndian.Uint32(rawData[i*4:]) &#125; return data &#125; 由于没有完整的数据，我们要根据索引去临时计算一个数据，调用的是generateDatasetItem方法，这个计算量以及内存占用都是比较少的。 回到hshimoto中，之所以用fnv以及lookup只是为了能随机的从dateset中取一个数据，这样对于挖矿节点，最优的方法是在内存中完整保留dataset数据副本，这就是内存困难型工作证明函数。经过64轮的fnv、lookup及fnvhash运算，最后得到的还是mix数组，接着对mix进行压缩，压缩为之前的四分之一，也就是128位，这就是区块头的MixDigest字段。最后将seed（512位）和digest拼接进行一次keccak256运算得到一个256位的值，挖矿也就是将这个值和难度值比较。 这里我们简要分析一下，从dataset中取数据的索引由parent和j构成，parent由seedhead（seed的前四个字节按小端序组成）和mix（mix由seed经过简单的操作生成），j则是0或1。而seed是由头结点hash和nonce组成。所以对于验证节点，只需一个完整的cache数据，然后在那64轮循环中，每次循环根据索引从cache中计算0dateset的某组数据。而对于挖矿节点，虽然也可以和验证节点一样每次都计算一组，但是由于每次是从整个dataset中随机选一组数据，虽然是伪随机的，但是也难以预测，所以最好的方法是能是保存整个数据集副本，这样就实现了内存困难型计算。 最后在验证过程中既要小于难度值，又要等于digest，所以也就强迫挖矿节点按照刚才流程来进行计算。因为最后和难度值比较的数只是seed和某个128位的值拼接后hash的结果，所以如果不比较digest，挖矿节点只用不断尝试nonce，然后计算出seed即可，digest就是使用dateset的一个证明。 geth生成数据集为了方便我们测试，geth提供了生成数据集的命令，只用指定区块号即可12geth makecache 36000 ethash/geth makedag 36000 ethash/ 关于大小端无论是cache还是dateset中的数据都是按照小端模式存储的。所谓小端模式就是在低地址中存放低位，相反低地址存放高位就是大端模式。对于0x01020304这个数，04就是低位，01就是高位。源码中也给出了测试我们的机器是大端还是小端的代码：1234func isLittleEndian() bool &#123; n := uint32(0x01020304) return *(*byte)(unsafe.Pointer(&amp;n)) == 0x04&#125; 很简单，就是存一个数，然后取低地址看是否是低位即可，这里的取低地址就是通过指针转为字节类型，由于32位整型转为8位字节，只保留的低位数据。 关于为什么要使用小端模式，实际上无论大小端都可以，但是在计算数据集的时候存在多次uin32与[]byte的转换，如果不统一一下格式，在不同机器上就会有不同结果。同样源码也给出了转为小端模式的代码12345678910func swap(buffer []byte) &#123; for i := 0; i &lt; len(buffer); i += 4 &#123; binary.BigEndian.PutUint32(buffer[i:], binary.LittleEndian.Uint32(buffer[i:])) &#125;&#125;func (littleEndian) Uint32(b []byte) uint32 &#123; _ = b[3] // bounds check hint to compiler; see golang.org/issue/14808 return uint32(b[0]) | uint32(b[1])&lt;&lt;8 | uint32(b[2])&lt;&lt;16 | uint32(b[3])&lt;&lt;24&#125; 实际就是利用了littleEndian中的方法翻一下顺序即可。 题图来自unsplash：https://unsplash.com/photos/kDJ4i77UPe0]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang文件锁]]></title>
    <url>%2F2019%2F05%2F30%2Fgolang%E6%96%87%E4%BB%B6%E9%94%81%2F</url>
    <content type="text"><![CDATA[在程序并发运行时，有时会限制多个线程操作同一个文件，这是就需要文件锁，类似于线程中的锁。不同的系统平台有不同的实现，这里以Linux为例。 先来说一下锁的集中情况，在go语言的syscall包中定义了下面几个常量1234LOCK_EX = 0x2LOCK_NB = 0x4LOCK_SH = 0x1LOCK_UN = 0x8 LOCK_EX指排他锁，也就是同时只允许一个线程使用 LOCK_NB指其他线程遇到一个排他锁会直接返回error，而不加该参数时线程会等待锁释放，利用这个参数可以简单的检测一个文件是否被占用 LOCK_SH指共享锁，多个线程都可以使用 LOCK_UN指释放一个锁 而在go语言中对一个文件锁的操作主要借助syscall的Flock方法1234567func Flock(fd int, how int) (err error) &#123; _, _, e1 := Syscall(SYS_FLOCK, uintptr(fd), uintptr(how), 0) if e1 != 0 &#123; err = errnoErr(e1) &#125; return&#125; 这里我们只要传入文件标识符fd和锁的操作参数how即可，如：12f, err := os.OpenFile(fileName, os.O_RDWR|os.O_CREATE, 0644)syscall.Flock(int(l.f.Fd()), syscall.LOCK_EX|syscall.LOCK_NB) 由于对于不同平台有不同实现，上面只适用于linux，为了解决各种平台的适配，在Prometheus的tsdb中有一套文件锁的实现，可以直接拿过来用或参考其相关实现。 题图来自unsplash：https://unsplash.com/photos/sUIrV6z9JCs]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dagger算法]]></title>
    <url>%2F2019%2F05%2F28%2FDagger%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文地址 从过去五年比特币以及其他加密货币的经验来看，工作证明的一个重要属性是内存困难，计算有效的工作证明不仅需要大量的计算，而且需要大量的内存。目前存在两大类内存困难型函数:scrypt和Primecoin，但都不完善;这两种方法都不像理想的内存困难型函数那样需要那么多内存，而且都面临着时间-内存权衡攻击，在这种情况下，函数的计算内存都比预期的少很多，代价是牺牲了一些计算效率。本文介绍了Dagger，一种基于适度连接的有向无环图（DAG，因此得名）的内存困难型的工作证明，虽然远非最优，但具有比当今使用的任何其他东西更强的内存困难特性 为什么要内存困难？内存困难之所以重要的主要原因是使工作证明不受专用硬件的影响。比特币的挖矿算法仅仅需要简单的sha256计算，创建特殊的“专用集成电路(ASICs)”公司已经出现了一年多，这种通过特殊设计和配置芯片的机器，目的是仅仅为了数十亿次的哈希运行，从而找到有效的比特币区块。这种芯片除了比特币挖矿和密码破解外没有任何应用，这些芯片的存在，使得在计算哈希值时每美元和千瓦时的效率是普通cpu的数千倍，这使得使用通用CPU和GPU硬件的普通用户无法与之竞争。 专业硬件的这种优势有几个不利的影响： 它否定了加密货币挖掘的去中心化方面。在通用硬件主导的生态系统中，每个人都拥有计算机的这个事实保证至少每个人都有平等的机会获得一些初始货币供应。对于专用硬件，这种情况不再存在;每个经济主体的矿业潜力与其现有资本数量上之比是线性的(事实上，略微超线性)，这可能加剧现有的财富不平等。 它增加了资源浪费。在有效的市场中，边际收入接近边际成本。由于采矿收入与采矿的硬件成本及电费支出是呈线性的，这也意味着总收入接近总成本。因此，在专用硬件主导的生态系统中，资源浪费量接近网络安全级别的100%。在CPU和gpu主导的生态系统中，因为每个人都已经有了一台计算机，所以人们不需要购买专门的硬件来获得每秒几哈希值的挖掘能力。因此，收入在成本上是次线性的——每个人都“免费”获得一点收入。这意味着网络所浪费的资源数量可能大大低于其安全参数。 它将采矿集中在几个参与者手中，这使得51%的攻击更有可能发生，并有可能使网络面临监管压力。 专门的硬件是如此强大，因为它包含了成千上万个专门为计算工作证明函数而设计的电路，允许硬件并行地计算函数的成千上万次。内存困难通过使主要限制因素不是CPU功率而是内存来缓解这个问题。人们也可以通过以CPU时钟速度为目标进行适度的改进，但是由于技术考虑，这种优化的程度上限非常低。因此，通过改进是得并行化遇到这样一个障碍:并行运行10个内存困难型计算需要10倍的内存。专业的硬件制造商当然可以将数TB的内存打包到他们的设备中，但这可以通过两个因素来减轻这种影响。首先，业余爱好者可以通过购买许多现成的存储卡来达到同样的效果。其次，与SHA256散列芯片相比，存储器的生产成本要高得多（如果用笔记本电脑等价物测量）;普通计算机中使用的RAM已基本上是最佳的。 算法详述本质上，Dagger算法的工作原理是创建一个有向无环图（树的技术术语，其中每个节点允许有多个父节点），其中包含根节点总共有10层，2^25 -1个值。在级别1到8中，每个节点的值取决于它上一级的三个节点，并且每一级的节点数是前一级别的8倍。在第9层中，每个节点的值取决于其父节点中的16个，并且该级别仅是前一级的两倍;这样做的目的是使自然时间-内存权衡攻击在第一级实现高的人工成本，因此根本不可能实现任何时间-内存权衡优化。最后，该算法使用这些数据与nonce一起伪随机地选择图中的八个底层节点，并放在一起计算所有的这些节点的散列。如果矿工发现一个随机数，使得此结果散列低于2^256除以难度参数，则结果是有效的工作证明。 设D是基础数据（例如，在比特币的情况下是块头），N是nonce，||是字符串连接运算符(‘foo’ || ‘bar’ == ‘foobar’)。算法的整个代码如下：1234567891011spread(L) = 16 if L == 9 else 3node(D,xn,0,0) = Dnode(D,xn,L,i) = with m = spread(L) p[k] = sha256(D || xn || L || i || k) mod 8^(L-1) for k in [0 ...m-1]eval(D,N) = with xn = floor(n/2^26) p[k] = sha256(D || xn || i || k) mod 8^8*2 for k in [0...m-1] sha256(node(D,xn,9,p[0]) || node(D,xn,9,p[1]) ...||node(D,xn,9,p[3]) 目标：发现一个k使得eval(D,k) &lt; 2^256/diff 性能 使用2^ 25内存（即512MB，因为每个内存单元是32字节哈希），最佳算法是预先计算2^ 24个叶子节点,运行eval时有2^ 25种可能性。主要的计算困难是计算SHA256哈希,1到8层的的每个节点需要两次哈希，所以需要2^ 25-4次哈希(因为根节点不需要散列，所以不是-2)。在第9层每个节点需要16个哈希，增加2^ 28次哈希，之外每个nonce占用8次哈希，在增加2^28次哈希。因此运行2^ 26个nonce需要2^ 29+2^ 25-4次哈希。 一个潜在的问题是延迟评估：为了减少所需的哈希数，树的一部分可以被估计。然而，由于2^ 25个节点中有一个(伪)随机节点被取了2^ 28次，我们可以统计估计每个节点剩余未使用的变化量为1/e^ 8—只有0.03%左右。因此，延迟评估的好处是微不足道的。 可以用很少的内存运行算法，但是必须重新计算工作证明每个nonce上依赖的8个底部叶子节点。这是一个指数计算，计算一个nonce需要3^ 8*16(104976)步。实际上，很多值都是重用的，所以平均只需要6000个哈希值，但是这仍然是一个非常大的量——基于内存的算法每nonce只管理8个计算，这使得低内存硬件的代价是750倍 验证需要在没有预先计算的情况下计算一个nonce，因此它还需要6000个哈希值和大约160 KB的内存。 由于最后一层中的每个节点都有16个父节点，而不是3个，因此时间-内存权衡攻击被严重削弱，试图存储8层而不是9层会减少2倍的内存使用量，但会降低16倍的计算速度。因此，不存在实际的时间权衡攻击;任何合理的效率水平都需要接近完整的512 MB。 结论该算法提供了一个工作证明挖矿函数，其内存困难特性并不理想，但与以前的任何方法相比，这是一个巨大的改进。计算需要512MB，验证需要112KB内存和4078哈希，而且由于底层的分支调整，即使是最小的时间-内存折衷也不值得实现。这些参数允许Dagger在内存需求方面比Primecoin或scrypt大胆得多，后者要求为单个线程提供512MB的RAM。决定难度的主要因素是内存，而不是计算，专有硬件只有很少的优势。即使在这样的均衡状态下，使用普通cpu进行开采也很依然是可行的。 题图来自unsplash：https://unsplash.com/photos/ttw2EsTM8VI]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EVM介绍]]></title>
    <url>%2F2019%2F05%2F28%2FEVM%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[原文地址 这是一个了解EVM及其与Solidity关系以及如何使用某些调试工具的指南。 安全性EVM是面向安全的虚拟机，旨在允许不受信任的代码由全球计算机网络执行。为安全起见，它规定了以下限制 程序执行中的每个计算步骤都必须预先支付金额，从而防止拒绝服务攻击。 程序只能通过发送单个任意长度的字节数组来进行交互;但是他们无法访问彼此的状态。 程序是在沙盒中执行的;EVM程序仅可以访问和修改自己的内部状态，或者触发其他EVM程序的执行。 程序执行是完全确定的，对于从相同状态开始的任何情况都产生相同的状态转换 概述EVM是一个基于堆栈的虚拟机，它具有临时的内存字节数组存储和持久的键值存储（持久的存储在Merkle树中）。堆栈上的元素是32字节长度，并且所有键和值都是以32字节存储的。有超过100个操作码，按十六进制分类。以下是pyethereum客户端的操作符列表，使用粗略的类别名称进行注释。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100# schema: [opcode, ins, outs, gas]opcodes = &#123; # arithmetic 0x00: ['STOP', 0, 0, 0], 0x01: ['ADD', 2, 1, 3], 0x02: ['MUL', 2, 1, 5], 0x03: ['SUB', 2, 1, 3], 0x04: ['DIV', 2, 1, 5], 0x05: ['SDIV', 2, 1, 5], 0x06: ['MOD', 2, 1, 5], 0x07: ['SMOD', 2, 1, 5], 0x08: ['ADDMOD', 3, 1, 8], 0x09: ['MULMOD', 3, 1, 8], 0x0a: ['EXP', 2, 1, 10], 0x0b: ['SIGNEXTEND', 2, 1, 5], # boolean 0x10: ['LT', 2, 1, 3], 0x11: ['GT', 2, 1, 3], 0x12: ['SLT', 2, 1, 3], 0x13: ['SGT', 2, 1, 3], 0x14: ['EQ', 2, 1, 3], 0x15: ['ISZERO', 1, 1, 3], 0x16: ['AND', 2, 1, 3], 0x17: ['OR', 2, 1, 3], 0x18: ['XOR', 2, 1, 3], 0x19: ['NOT', 1, 1, 3], 0x1a: ['BYTE', 2, 1, 3], # crypto 0x20: ['SHA3', 2, 1, 30], # contract context 0x30: ['ADDRESS', 0, 1, 2], 0x31: ['BALANCE', 1, 1, 20], 0x32: ['ORIGIN', 0, 1, 2], 0x33: ['CALLER', 0, 1, 2], 0x34: ['CALLVALUE', 0, 1, 2], 0x35: ['CALLDATALOAD', 1, 1, 3], 0x36: ['CALLDATASIZE', 0, 1, 2], 0x37: ['CALLDATACOPY', 3, 0, 3], 0x38: ['CODESIZE', 0, 1, 2], 0x39: ['CODECOPY', 3, 0, 3], 0x3a: ['GASPRICE', 0, 1, 2], 0x3b: ['EXTCODESIZE', 1, 1, 20], 0x3c: ['EXTCODECOPY', 4, 0, 20], # blockchain context 0x40: ['BLOCKHASH', 1, 1, 20], 0x41: ['COINBASE', 0, 1, 2], 0x42: ['TIMESTAMP', 0, 1, 2], 0x43: ['NUMBER', 0, 1, 2], 0x44: ['DIFFICULTY', 0, 1, 2], 0x45: ['GASLIMIT', 0, 1, 2], # storage and execution 0x50: ['POP', 1, 0, 2], 0x51: ['MLOAD', 1, 1, 3], 0x52: ['MSTORE', 2, 0, 3], 0x53: ['MSTORE8', 2, 0, 3], 0x54: ['SLOAD', 1, 1, 50], 0x55: ['SSTORE', 2, 0, 0], 0x56: ['JUMP', 1, 0, 8], 0x57: ['JUMPI', 2, 0, 10], 0x58: ['PC', 0, 1, 2], 0x59: ['MSIZE', 0, 1, 2], 0x5a: ['GAS', 0, 1, 2], 0x5b: ['JUMPDEST', 0, 0, 1], # logging 0xa0: ['LOG0', 2, 0, 375], 0xa1: ['LOG1', 3, 0, 750], 0xa2: ['LOG2', 4, 0, 1125], 0xa3: ['LOG3', 5, 0, 1500], 0xa4: ['LOG4', 6, 0, 1875], # arbitrary length storage (proposal for metropolis hardfork) 0xe1: ['SLOADBYTES', 3, 0, 50], 0xe2: ['SSTOREBYTES', 3, 0, 0], 0xe3: ['SSIZE', 1, 1, 50], # closures 0xf0: ['CREATE', 3, 1, 32000], 0xf1: ['CALL', 7, 1, 40], 0xf2: ['CALLCODE', 7, 1, 40], 0xf3: ['RETURN', 2, 0, 0], 0xf4: ['DELEGATECALL', 6, 0, 40], 0xff: ['SUICIDE', 1, 0, 0],&#125;# pushfor i in range(1, 33): opcodes[0x5f + i] = ['PUSH' + str(i), 0, 1, 3]# duplicate and swapfor i in range(1, 17): opcodes[0x7f + i] = ['DUP' + str(i), i, i + 1, 3] opcodes[0x8f + i] = ['SWAP' + str(i), i + 1, i + 1, 3] 该表告诉我们每个操作码从堆栈中弹出多少个参数并压回几个参数，以及消耗了多少Gas。大多数操作码从堆栈中取出一些参数，并将一个或零个结压回栈。但是有些像GAS和PC一样的操作符，并不会从堆栈中取出任何参数，但是会将剩余的气体和程序计数器分别压入堆栈。许多操作码，如SHA3，CREATE和RETURN，从堆栈中获取引用内存中位置和大小的参数，允许它们对一个连续的内存数组进行操作。 所有的运算都是使用栈上的元素对大整数进行的（如32字节大端整数）。目前，唯一的加密操作是SHA3散列函数，它从内存中获取任意长度的字节数组(由内存中的初始位置和长度指定)，并在堆栈上输出散列值。智能合约和区块链的上下文允许访问各种有用的环境信息，例如，CALLDATACOPY将发送到合约的数据(称为call-data)复制到内存中，NUMBER可以根据区块编号执行时间锁定。 EVM通过MLOAD和MSTORE对其内存进行操作，并通过SLOAD和SSTORE对其持久存储进行操作。JUMP可用于跳转到程序中的任意点，其中这些点必须是JUMPDEST。PUSH1-PUSH32操作码将1-32字节的任何数据压入堆栈。DUP1-DUP16操作码将堆栈顶部16个元素之一的副本放到栈顶。SWAP1-SWAP16操作码将栈顶元素与栈中前16个元素的某一个交换。 LOG操作码支持事件日志记录，它在区块中进行记录，并且能够被轻量级客户机有效地验证。最后，CALL和CREATE允许合约调用和创建其他合约，RETURN用于从一个调用中返回一块内存。SUICIDE导致合约被销毁，并将所有资金发送到指定的地址。 每个操作码的规范可以在黄皮书上找到源代码在Github上，或者从EVM的实现中寻找。 注意，EVM是图灵完全的：它既有图灵机的基本结构(用于管理内存和跳转到程序中的任意点的操作)，也有基于代理的消息传递系统，其中代理可能是任意代码(用于调用和创建其他合约以及返回值的操作)。为了确保每个操作都能终止，所有操作都带有明确的成本标记，以gas表示。执行必须指定一个最大的Gas量，这样当超过这个量就会抛出一个OutOfGas异常。操作码列表指定每个操作码消耗多少气体。 此外，某些操作消耗的气体量可通过下表参数化(详细信息请参阅黄皮书):123456789101112131415161718192021222324252627282930# Non-opcode gas pricesGDEFAULT = 1GMEMORY = 3GQUADRATICMEMDENOM = 512 # 1 gas per 512 quadwordsGSTORAGEREFUND = 15000GSTORAGEKILL = 5000GSTORAGEMOD = 5000GSTORAGEADD = 20000GEXPONENTBYTE = 10 # cost of EXP exponent per byteGCOPY = 3 # cost to copy one 32 byte wordGCONTRACTBYTE = 200 # one byte of code in contract creationGCALLVALUETRANSFER = 9000 # non-zero-valued callGLOGBYTE = 8 # cost of a byte of logdataGTXCOST = 21000 # TX BASE GAS COSTGTXDATAZERO = 4 # TX DATA ZERO BYTE GAS COSTGTXDATANONZERO = 68 # TX DATA NON ZERO BYTE GAS COSTGSHA3WORD = 6 # Cost of SHA3 per wordGSHA256BASE = 60 # Base c of SHA256GSHA256WORD = 12 # Cost of SHA256 per wordGRIPEMD160BASE = 600 # Base cost of RIPEMD160GRIPEMD160WORD = 120 # Cost of RIPEMD160 per wordGIDENTITYBASE = 15 # Base cost of indentityGIDENTITYWORD = 3 # Cost of identity per wordGECRECOVER = 3000 # Cost of ecrecover opGSTIPEND = 2300GCALLNEWACCOUNT = 25000GSUICIDEREFUND = 24000 除Gas耗尽异常外，还包括无效的操作符、堆栈下溢和无效的跳转目的地等。栈的大小也有限制，而且调用深度也有限制，这样从一个合约到另一个合约的链式调用不能太长。例如，尽管提供了大量的Gas，递归调用合约终止也会停止。以太坊交易和原子性的，一旦抛出异常，交易状态会被回滚。唯一例外的是gas的支付在OutOfGas异常之前使用的任何Gas都将被扣除并发送给矿工。请注意，这样的交易仍然包含在块中，以便他们可以支付费用，如果不是这样，这将为矿工提供一个重要的DoS攻击载体。 执行让我们看一些简单的执行。为此，我在一个repo中收集了一些有用的工具，包括go-ethereum提供的一些不错的工具的分支。安装这些工具请参考安装指南 下面是我写的一些非常简单的字节码:16005600401 运行 echo 6005600401 | disasm 执行反汇编, 结果如下:1230 PUSH1 =&gt; 052 PUSH1 =&gt; 044 ADD 这是一个简单的程序，它将数字 05 和 04放入栈内然后相加。 我们也可以通过 evm --debug --code 6005600401 在EVM中执行, 得到的结果如下123456789101112131415161718192021222324VM STAT 4 OPsPC 00000000: PUSH1 GAS: 9999999997 COST: 3STACK = 0MEM = 0STORAGE = 0PC 00000002: PUSH1 GAS: 9999999994 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000004: ADD GAS: 9999999991 COST: 3STACK = 20000: 00000000000000000000000000000000000000000000000000000000000000040001: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000005: STOP GAS: 9999999991 COST: 0STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000009MEM = 0STORAGE = 0 其中--debug debug标志在每个步骤中为我们打印堆栈、内存和存储的当前状态，并显示每个操作码和Gas用量。注意0x04和0x05是如何被压入栈(填充为32字节)并由ADD使用的，这使得结果0x09留在堆栈上。如果要返回值，而不是简单地留在栈上，我们需要修改字节码，以便将值复制到内存中，然后返回:12345678910$ echo 60056004016000526001601ff3 | disasm60056004016000526001601ff30 PUSH1 =&gt; 052 PUSH1 =&gt; 044 ADD5 PUSH1 =&gt; 007 MSTORE8 PUSH1 =&gt; 0110 PUSH1 =&gt; 1f12 RETURN 值(0x09)存储在0x0位置。然而，由于存储的元素来自堆栈，所以它是一个32字节的元素，使用大端字节编码(即左填充0)的0x09。因此，为了只返回一个字节0x09，我们从内存0x1f位置开始返回长度为0x01的字节数组。或者，我们可以从位置0x00开始返回长度为0x20的字节数组，返回值是用零填充的32字节数据。 通过 evm --debug --code 60056004016000526001601ff3 执行上面逻辑:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859VM STAT 8 OPsPC 00000000: PUSH1 GAS: 9999999997 COST: 3STACK = 0MEM = 0STORAGE = 0PC 00000002: PUSH1 GAS: 9999999994 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000004: ADD GAS: 9999999991 COST: 3STACK = 20000: 00000000000000000000000000000000000000000000000000000000000000040001: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000005: PUSH1 GAS: 9999999988 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000009MEM = 0STORAGE = 0PC 00000007: MSTORE GAS: 9999999982 COST: 6STACK = 20000: 00000000000000000000000000000000000000000000000000000000000000000001: 0000000000000000000000000000000000000000000000000000000000000009MEM = 320000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................0016: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................STORAGE = 0PC 00000008: PUSH1 GAS: 9999999979 COST: 3STACK = 0MEM = 320000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................0016: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 09 ...............?STORAGE = 0PC 00000010: PUSH1 GAS: 9999999976 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000001MEM = 320000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................0016: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 09 ...............?STORAGE = 0PC 00000012: RETURN GAS: 9999999976 COST: 0STACK = 20000: 000000000000000000000000000000000000000000000000000000000000001f0001: 0000000000000000000000000000000000000000000000000000000000000001MEM = 320000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................0016: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 09 ...............?STORAGE = 0OUT: 0x09 注意32字节的大端字节0x09如何存储在内存中，以及程序最终如何输出0x09。 如果我们添加的参数大于一个字节，我们可以使用不同的PUSH操作符。例如，要添加像257 (0x0101)和258 (0x0102)这样的双字节数，我们使用PUSH2 (0x61): 12345$ echo 61010161010201 | disasm610101610102010 PUSH2 =&gt; 01013 PUSH2 =&gt; 01026 ADD 执行 evm --debug --code 61010161010201 结果如下123456789101112131415161718192021222324VM STAT 4 OPsPC 00000000: PUSH2 GAS: 9999999997 COST: 3STACK = 0MEM = 0STORAGE = 0PC 00000003: PUSH2 GAS: 9999999994 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000101MEM = 0STORAGE = 0PC 00000006: ADD GAS: 9999999991 COST: 3STACK = 20000: 00000000000000000000000000000000000000000000000000000000000001020001: 0000000000000000000000000000000000000000000000000000000000000101MEM = 0STORAGE = 0PC 00000007: STOP GAS: 9999999991 COST: 0STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000203MEM = 0STORAGE = 0 其中 0x0203 = 515 = 257 + 258 如果我们想将参数作为调用数据传递，而不是硬编码它们，该怎么办?为了方便起见，我们需要首先就格式规则达成一致。例如，所有输入值都左填充为32字节。然后我们可以这样做: 1234567$ echo 60003560203501 | disasm600035602035010 PUSH1 =&gt; 002 CALLDATALOAD3 PUSH1 =&gt; 205 CALLDATALOAD6 ADD 要正确执行，我们必须传递正确的填充输入: 1234567891011121314151617181920212223242526272829303132333435363738$ evm --debug --code 60003560203501 --input 00000000000000000000000000000000000000000000000000000000000000050000000000000000000000000000000000000000000000000000000000000004VM STAT 6 OPsPC 00000000: PUSH1 GAS: 9999999997 COST: 3STACK = 0MEM = 0STORAGE = 0PC 00000002: CALLDATALOAD GAS: 9999999994 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000000MEM = 0STORAGE = 0PC 00000003: PUSH1 GAS: 9999999991 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000005: CALLDATALOAD GAS: 9999999988 COST: 3STACK = 20000: 00000000000000000000000000000000000000000000000000000000000000200001: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000006: ADD GAS: 9999999985 COST: 3STACK = 20000: 00000000000000000000000000000000000000000000000000000000000000040001: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000007: STOP GAS: 9999999985 COST: 0STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000009MEM = 0STORAGE = 0 如果你想让你的程序有多个可能的函数呢?结合调用数据的格式化和调用函数等问题，产生了应用程序二进制接口(ABI)标准，并被高级语言如Solidity或serpent接受。我们稍后再讨论这个问题 首先，我们如何控制流程? 当然是使用布尔表达式和跳转!下面是一个简单的循环: 1234567891011121314151617$ echo 6000356000525b600160005103600052600051600657 | disasm6000356000525b6001600051036000526000516006570 PUSH1 =&gt; 002 CALLDATALOAD3 PUSH1 =&gt; 005 MSTORE6 JUMPDEST7 PUSH1 =&gt; 019 PUSH1 =&gt; 0011 MLOAD12 SUB13 PUSH1 =&gt; 0015 MSTORE16 PUSH1 =&gt; 0018 MLOAD19 PUSH1 =&gt; 0621 JUMPI 这里我们从call-data中加载一些值，然后通过多次循环将计数器的值存到内存中，并在每次循环是递减。这个循环实际上是从JUMPDEST地方开始的.最后一个操作码JUMPI接受一个值和一个位置，如果该值非零，则跳转到程序中的位置。如果跳转位置不是JUMPDEST，则抛出异常。在本例中，JUMPDEST的位置是0x06，它检查的值是计数器变量，从内存中加载。 通过执行evm --debug --code 6000356000525b600160005103600052600051600657 --input 0000000000000000000000000000000000000000000000000000000000000005 来循环五次。看看您是否能够破译代码——查找内存中递减的计数器变量。 如果我们运行的代码没有任何输入，或者输入为零，会发生什么? 循环会运行0次吗?为什么或为什么不(EVM没有负数的概念, 所以-1实际是 2^256 - 1 或 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff). 要解决这个问题，在进入循环之前检查输入值是否为零(提示:使用ISZERO)。 注意，我们在内存的使用上非常低效，因为我们不断地在内存中多次从同一个位置加载，然后存储到该位置。我们可以使用DUP和SWAP操作码将需要的内容保存在堆栈上，而不是访问内存字节数组。Solidity编译器一直在进行这种优化。下面是不使用内存的循环: 1234567891011$ echo 6000355b6001900380600357 | disasm6000355b60019003806003570 PUSH1 =&gt; 002 CALLDATALOAD3 JUMPDEST4 PUSH1 =&gt; 016 SWAP17 SUB8 DUP19 PUSH1 =&gt; 0311 JUMPI 非常简单! SWAP操作确保计数器(要递减的值)位于堆栈的顶部，这正是SUB操作码所期望的。DUP1用于复制堆栈上的计数器，因此JUMPI可以使用它，并且下一次通过循环时仍然可以使用它进行减法。除此之外，循环的工作方式完全相同。还要注意，由于在循环开始之前我们没有将计数器存储到内存中，所以JUMPDEST的位置是0x03而不是0x06。 通过下面操作执行五次循环evm --debug --code 6000355b6001900380600357 --input 0000000000000000000000000000000000000000000000000000000000000005观察计数器在堆栈上而不是在内存中保持和递减。 在继续之前还有一个改进。传递一个32字节填充的字符串是很糟糕的;调用数据的大小应该是它需要的大小在本例中，我们希望使用—input 05调用5次循环，并使用—input 0101运行257次循环。问题是, CALLDATALOAD加载32字节大端数, 所以 --input 05 在栈中变成了 0500000000000000000000000000000000000000000000000000000000000000由于EVM中没有字节移位操作符，我们必须使用除法。在本例中，我们要除以256^(32-L)其中L是调用数据的长度。这具有字节右移(32-L)字节的效果。更新后的字节码如下:1234567891011121314151617$ echo 366020036101000a600035045b6001900380600c57 | disasm366020036101000a600035045b6001900380600c570 CALLDATASIZE1 PUSH1 =&gt; 203 SUB4 PUSH2 =&gt; 01007 EXP8 PUSH1 =&gt; 0010 CALLDATALOAD11 DIV12 JUMPDEST13 PUSH1 =&gt; 0115 SWAP116 SUB17 DUP118 PUSH1 =&gt; 0c20 JUMPI 我们可以通过 evm --debug --code 366020036101000a600035045b6001900380600c57 --input 05 执行五次循环或者通过 evm --debug --code 366020036101000a600035045b6001900380600c57 --input 0101执行257次循环。确保您了解如何使用EXP和DIV来实现移位，这是高级语言广泛使用的一种非常常见的范例。 合约到目前为止，我们只研究了EVM的基本执行环境。但是EVM嵌入了区块链账户状态。以太坊中所有的账户都存储在一个Merkle基数树中。EVM中的程序位于称为合约的帐户中。除了地址、余额和序列号(等于帐户发送的事务数——也称为nonce)之外，合约还保留其EVM字节码的散列和内部存储树的Merkle根。一个账户最多可以有一个与之关联的程序，通过一个交易可以再任何时候创建一个合约。或者使用CALL操作符从另外一个合约中触发来创建。注意，一旦部署，合约的代码可能不会更改。帐户/合约存储的Merkle根将在任何交易成功之后更新，其中SSTORE操作码的执行将导致一个值存储在一个新键上，或者对存储在现有键上的值进行更改。 合约的创建以一种特殊的方式进行，将交易发送到空地址，并将合约代码作为数据。以太坊的状态转移函数或通过创建一个新账户来创建合约，并运行调用数据中指定的程序，之后将EVM返回的内容设置为新合约的代码。也就是说，在创建过程中发送的代码与存储在合约中的代码不一样——相反，它是所谓的“部署代码”，其中包含包装在某些操作中的实际合约代码，这些操作将把它复制到内存中并返回。 例如，如果我们编写的一个程序(它不返回任何东西)，并将其作为数据发送到空地址，程序将执行，但是生成的帐户将没有代码，因此对该帐户的任何事务将导致没有代码运行。 以简单的加法程序6005600401为例，我们可以使用evm-deploy工具生成部署代码: 123456789101112$ echo 6005600401 | evm-deploy | disasm 600580600b6000396000f360056004010 PUSH1 =&gt; 052 DUP13 PUSH1 =&gt; 0b5 PUSH1 =&gt; 007 CODECOPY8 PUSH1 =&gt; 0010 RETURN11 PUSH1 =&gt; 0513 PUSH1 =&gt; 0415 ADD 在这里，我们知道程序的长度是0x05，并且我们知道它嵌入到部署代码中，从位置11 (0x0b)开始。因此，我们将这段代码复制到内存中(位置0x00)并返回它。注意，使用DUP1可以使代码的长度(在本例中是0x05)在栈上，用于CODECOPY和返回。当部署代码运行时，返回值应该是目标代码，即：6005600401 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455$ evm --debug --code 600580600b6000396000f36005600401VM STAT 7 OPsPC 00000000: PUSH1 GAS: 9999999997 COST: 3STACK = 0MEM = 0STORAGE = 0PC 00000002: DUP1 GAS: 9999999994 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000003: PUSH1 GAS: 9999999991 COST: 3STACK = 20000: 00000000000000000000000000000000000000000000000000000000000000050001: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000005: PUSH1 GAS: 9999999988 COST: 3STACK = 30000: 000000000000000000000000000000000000000000000000000000000000000b0001: 00000000000000000000000000000000000000000000000000000000000000050002: 0000000000000000000000000000000000000000000000000000000000000005MEM = 0STORAGE = 0PC 00000007: CODECOPY GAS: 9999999979 COST: 9STACK = 40000: 00000000000000000000000000000000000000000000000000000000000000000001: 000000000000000000000000000000000000000000000000000000000000000b0002: 00000000000000000000000000000000000000000000000000000000000000050003: 0000000000000000000000000000000000000000000000000000000000000005MEM = 320000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................0016: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................STORAGE = 0PC 00000008: PUSH1 GAS: 9999999976 COST: 3STACK = 10000: 0000000000000000000000000000000000000000000000000000000000000005MEM = 320000: 60 05 60 04 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................STORAGE = 0PC 00000010: RETURN GAS: 9999999976 COST: 0STACK = 20000: 00000000000000000000000000000000000000000000000000000000000000000001: 0000000000000000000000000000000000000000000000000000000000000005MEM = 320000: 60 05 60 04 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................STORAGE = 0OUT: 0x6005600401 有状态的EVM我对evm工具做了一些修改，以便它可以在调用之间保持状态。只需使用datadir标志。例如，让我们使用返回0x5和0x4之和的合约。我们可以运行部署代码，因此实际上部署了合约(用正确的代码创建的帐户)，然后我们可以与它交互: 123456$ evm --code $(echo &quot;60056004016000526001601ff3&quot; | evm-deploy) --datadir evm-dataLoading databaseLoading root hash 0000000000000000000000000000000000000000000000000000000000000000Contract Address: 1F2A98889594024BFFDA3311CBE69728D392C06DVM STAT 0 OPsOUT: 0x60056004016000526001601ff3 他给我们返回了合约地址：(1F2A98889594024BFFDA3311CBE69728D392C06D).这个地址是从哪儿来的?它是列表[发送者地址,发送者序列号]的RLP编码的sha3散列值。默认的发送者是 0x000000000000000000000000000073656e646572 ，序列号从0x0开始。python代码如下: 123&gt;&gt;&gt; import rlp, sha3&gt;&gt;&gt; sha3.sha3_256(rlp.encode([&quot;000000000000000000000000000073656e646572&quot;.decode(&apos;hex&apos;), 0])).hexdigest()[24:]&apos;1f2a98889594024bffda3311cbe69728d392c06d&apos; 注意，这意味着地址从相同的状态开始是严格确定的。如果我们再次部署合同，发送者的序列号将是0x1: 1234567$ evm --code $(echo &quot;60056004016000526001601ff3&quot; | evm-deploy) --datadir evm-dataDatadir already existsLoading databaseLoading root hash BFDDB19821CE2BFAB71C4BA9E8ADC6CF083DAE0EF9206AA506BC88B0F9064182Contract Address: 14F6D12ECEBB7606C528880AD8B97C25AB7D4AD9VM STAT 0 OPsOUT: 0x60056004016000526001601ff3 对于相同的输出产生不同的地址： 123&gt;&gt;&gt; import rlp, sha3&gt;&gt;&gt; sha3.sha3_256(rlp.encode([&quot;000000000000000000000000000073656e646572&quot;.decode(&apos;hex&apos;), 1])).hexdigest()[24:]&apos;14f6d12ecebb7606c528880ad8b97c25ab7d4ad9&apos; 现在我们可以发送一个交易给合约 12345678$ evm --to 14F6D12ECEBB7606C528880AD8B97C25AB7D4AD9 --datadir evm-dataDatadir already existsLoading databaseLoading root hash 60209E93FEFD3DD5CF1D6B3FBDC33DA1B020C5B880A51E8306A3F5FDF269122ALoaded account for receiver 14F6D12ECEBB7606C528880AD8B97C25AB7D4AD9CODE: 60056004016000526001601FF3VM STAT 0 OPsOUT: 0x09 注意它是如何返回0x09的 异常这里有一些异常的例子。 无效操作符 (5f 是一个无效的操作符): 1evm --debug --code 5f 栈下溢 (JUMP (0x56) 只要要求一个参数): 1evm --debug --code 56 无效的跳转目的地 (0x0不是一个 JUMPDEST, 在本例它是一个 PUSH): 1evm --debug --code 600056 这是一个out-of-gas异常 (PUSH 要求3个gas): 1evm --debug --gas 1 --code 6000 更多说明参见evm –help 内存和存储除了堆栈之外，EVM还附带一个临时内存字节数组和持久存储树。对内存字节数组的访问是相对便宜的，内存越界访问也不例外;当您访问内存时，内存会根据需要增长，您只需为大小的变化支付相应的费用。 例如，第一次访问内存位置0x1000花费了我们很多钱，因为内存的大小从0增长到4096，而第二次几乎没有，因为内存的大小没有变化: 1evm --debug --code 611000805151 存储空间实际上是无限的，或者说是2^256，但是相对来说比较昂贵，将一个非零的区域赋值需要消耗20000个Gas，相反则需要5000个气体。例如，我们将0x2存储在0x0位置，然后用0x1覆盖它: 1evm --debug --code 60026000556001600055 Solidity最后我们讨论一下Solidity。solability是一种高级的、类似javascript的、面向合约的语言，可以编译为EVM。他有许多EVM没有的高级特性，如type、arrays和函数调用。它还符合Ethereum ABI，这是一个关于参数和函数调用如何在调用数据中编码的规范。总之，调用数据的前四个字节是函数标识符，对应于函数签名规范版本的sha3散列的前四个字节。其余参数以32字节形式填充并传递。 首先，我们需要Solidity编译器,solc。因为它是用c++编写的，所以安装起来很麻烦。幸运的是，您可以使用docker和Eris Industries提供好的镜像。 首先，我们创建一个工作目录: 12export SOLC_WORKSPACE=$HOME/solidity_workspacemkdir $SOLC_WORKSPACE 现在我们运行docker容器(如果你还没有eris/compiler的镜像，这个会进行下载): 1docker run --name solc -v $SOLC_WORKSPACE:/home/eris/.eris -it quay.io/eris/compilers /bin/bash 这个命令会让您进入Solidity编译器的容器，$SOLC_WORKSPACE目录会被挂载到容器的 /home/eris/.eris目录下，$SOLC_WORKSPACE目录中的任何文件改动都会立即在容器中得到体现。运行 solc --help确保编译器已被安装。 使用docker通常涉及两个终端会话，一个在容器中，另一个在主机上。容器会话允许交互访问所需的任何二进制文件(在本例中是solc)，而主机会话允许文件正常地在主机进行更改，并立即反映在容器中。 打开另一个窗口作为主机会话, 设置 SOLC_WORKSPACE 通过 export SOLC_WORKSPACE=$HOME/solidity_workspace,并存储下面的合约为：$SOLC_WORKSPACE/add.sol: 123456contract Addition&#123; int x; function add(int a, int b)&#123; x = a + b; &#125;&#125; 这个合约运行用户调用 add 函数, 传递两个参数 a 和 b ，他们相加的结果存储在变量x中。注意，定义在合约顶部的变量被持久化到合约存储树中(使用SSTORE)。 回到容器会话, 使用cd /home/eris/.eris和ls,你会发现一个目录和合约文件 编译合约: 1solc --bin-runtime --optimize -o . add.sol 在主机会话, 你会发现合约在 $SOLC_WORKSPACE/Addition.bin-runtime目录. 通过使用 --bin-runtime,我们将得到与部署后合同中一样的代码——我们可以使用evm工具进行测试。如果使用 --bin 代替 --bin-runtime, 并通过 evm运行, 将得到和--bin-runtime一样的输出,使用—bin编译的合约的返回值是使用—bin-runtime编译的合约。 让我们反编译solidity合约: 12345678910111213141516171819202122232425262728$ echo $(cat MyContract.bin-runtime) | disasm 606060405260e060020a6000350463a5f3c23b8114601a575b005b602435600435016000556018560 PUSH1 =&gt; 602 PUSH1 =&gt; 404 MSTORE5 PUSH1 =&gt; e07 PUSH1 =&gt; 029 EXP10 PUSH1 =&gt; 0012 CALLDATALOAD13 DIV14 PUSH4 =&gt; a5f3c23b19 DUP220 EQ21 PUSH1 =&gt; 1a23 JUMPI24 JUMPDEST25 STOP26 JUMPDEST27 PUSH1 =&gt; 2429 CALLDATALOAD30 PUSH1 =&gt; 0432 CALLDATALOAD33 ADD34 PUSH1 =&gt; 0036 SSTORE37 PUSH1 =&gt; 1839 JUMP ：加法本身发生在底部。注意，就在ADD之前，使用CALLDATALOADs，我们从调用数据的0x04和0x24位置加载32字节的参数，而不是0x00和0x20，以便在函数标识符的前四个字节中留出空间。在本例中，您可能已经猜到，我们唯一的函数的函数标识符是a5f3c23b。26行之前所有的代码都是为了检测调用数据的前四个字节是否是a5f3c23b。因为CALLDATALOAD会获取一个32字节的数据，而我们只需要4个字节，所以我们必须通过除以一个大整数来进行字节移位，因此需要EXP和DIV。如果调用数据的前四个字节匹配a5f3c23b，则加载参数，添加它们，并存储在0x00位置。否则,我们停止。 注意，我们可以通过运行solc --hashes add.sol来验证函数标识符 , 或者在python如下操作 123&gt;&gt;&gt; import sha3&gt;&gt;&gt; sha3.sha3_256(&quot;add(int256,int256)&quot;).hexdigest()[:8]&apos;a5f3c23b&apos; 为了正确调用函数, 我们可以如下操作 evm --debug --code $(cat Addition.bin-runtime) --input a5f3c23b00000000000000000000000000000000000000000000000000000000000000050000000000000000000000000000000000000000000000000000000000000004 一个更有趣的合约将有一个get函数，所以我们可以找出最后存储的值: 1234567891011contract Addition&#123; int x; function add(int a, int b)&#123; x = a + b; &#125; function get() returns (int)&#123; return x; &#125;&#125; 使用我们的evm工具，我们可以部署此合约，添加两个值，然后检索存储的值。将合约存储为add.sol. 现在，从容器内部编译合同： 1solc --bin --optimize -o . add.sol 这回创建一个 Addition.bin文件, 在容器外面的的目录为 $SOLC_WORKSPACE.在主机的 $SOLC_WORKSPACE 目录，我们可以部署合约： 123456$ evm --code $(cat Addition.bin) --datadir evm-dataLoading databaseLoading root hash 0000000000000000000000000000000000000000000000000000000000000000Contract Address: 1F2A98889594024BFFDA3311CBE69728D392C06DVM STAT 0 OPsOUT: 0x606060405260e060020a60003504636d4ce63c81146024578063a5f3c23b146031575b005b6000546060908152602090f35b60243560043501600055602256 现在我们调用 add 函数, 并存储 5+4的结果: 1evm --datadir evm-data --to 0x1F2A98889594024BFFDA3311CBE69728D392C06D --input a5f3c23b00000000000000000000000000000000000000000000000000000000000000050000000000000000000000000000000000000000000000000000000000000004 最后让我们调用 get 函数. 首先我们获取函数标识: 12345$ solc --hashes add.sol======= Addition =======Function signatures: 6d4ce63c: get()a5f3c23b: add(int256,int256) 现在我们可以进行调用 12345678$ evm --datadir evm-data --to 0x1F2A98889594024BFFDA3311CBE69728D392C06D --input 6d4ce63cDatadir already existsLoading databaseLoading root hash F3C30A7CD9769C45590C236816F2714E96198DBD7FEC33AE892E861816F548B2Loaded account for receiver 1F2A98889594024BFFDA3311CBE69728D392C06DCODE: 606060405260E060020A60003504636D4CE63C81146024578063A5F3C23B146031575B005B6000546060908152602090F35B60243560043501600055602256VM STAT 0 OPsOUT: 0x0000000000000000000000000000000000000000000000000000000000000009 总结以上就是对Ethereum虚拟机的介绍。希望您现在能够更深入地了解它的工作原理，并将这些知识传授给其他人，使更多的人了解以太坊底层工作原理，从而促进更多的分析和处理以太坊合约的工具出现。 题图来自unsplash：https://unsplash.com/photos/H1SOELwNtTw]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hashimoto：IO限制的工作证明]]></title>
    <url>%2F2019%2F05%2F23%2FHashimoto%EF%BC%9AIO%E9%99%90%E5%88%B6%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%AF%81%E6%98%8E%2F</url>
    <content type="text"><![CDATA[原文地址 摘要使用加密哈希函数并不是为了工作证明，而是作为一个指向共享数据集的生成器，成为一个受IO约束的工作证明。这种工作证明方法很难通过ASIC设计进行优化，并且在没有完整数据集的情况下很难外包给节点。该名称基于包含算法的三个操作:散列、移位和模运算 证明这个操作是很难优化与外包的加密货币开发中的一个常见挑战是保持网络的去中心化。使用工作证明来达成去中心化的共识，最显著的例子就是比特币，它使用了与sha256的零数量类似的部分冲突，与hashcash类似。由于比特币受欢迎程度日益高涨，已经生成了专用硬件来快速迭代基于哈希的工作证明函数（当前应用的是特点集成电路或ASICs）。与比特币类似的新项目通常使用不同的算法来证明工作，并且通常以抗ASIC为目标。对于比特币这样的算法，ASICs的改进因素意味着商用计算机硬件无法有效使用。 工作的证明也可以“外包”，或者由专用机器(“矿工”)执行，而不知道正在验证什么。在比特币的“矿池”中，情况往往如此。工作证明算法难以外包是十分有利的，他能促进去中心化，并鼓励所有参与工作证明过程的节点也对事务进行验证。考虑到这些目标，我们提出Hashimoto，一个I/O限制的工作证明算法，我们相信他可以抵抗ASIC和外包。 抵抗ASIC的最初尝试包括改变比特币的sha256算法，使之成为一种不同的、内存更密集的算法，即Percival的基于密钥推导功能的“scrypt”密码算法。许多实现将scrypt参数设置为低内存需求，这违背了密钥派生算法的大部分目的。在切换到新算法时，再加上各种基于scryptt的加密货币运行有一定延迟，目前已经有基于scrypt优化的ASICs。类似的，尝试各种变体或异构的hash函数也仅仅是推迟ASIC的实现 利用共享数据集创建I/O绑定证明 超级计算机是一种将受计算量限制的问题转换为受IO限制的问题 –Ken Batcher. 相反，如果一种算法在普通商业计算机系统以已经优化过的方式工作，那么他在一个新的设备上就不会有太大的提升。 由于I/O限制是数十年来计算机研究所致力于解决的问题，所以对挖币这种动机而言不太可能在缓存层次结构中的有技术水平的提升。如果取得进展，它们很可能会影响整个计算机硬件行业。 幸运的是，参与当前加密货币实现的所有节点都有一组彼此同意的数据，事实上，这种“区块链”也是是加密货币的基础。使用这种大型数据集既限制了专用硬件的优势，又要求工作节点拥有整个数据集。 Hashimoto是基于比特币的工作证明。就像Hashimoto一样，在比特币中成功的证明满足以下不平等条件:1hash_output &lt; target 对于比特币，hash_output由以下公式得出1hash_output = sha256(prev_hash, merkle_root, nonce) 其中prev_hash是前一个块的哈希值，不能更改。merkle_root基于块中包含的事务，对于每个节点都是不同的。当计算hash_output时，如果不满足不等式，nonce会快速增加。因此，证明的瓶颈是sha256函数，提高sha256的速度或并行化是asic可以非常有效地做的事情。 Hashimoto使用这个哈希输出作为起点，用于生成第二个哈希函数的输入。我们称原始哈希为hash_output_A，以及证明的最终结果为final_output。 Hash_output_A可以从共享区块链中选择许多事务得出，然后将其用作第二个散列的输入。为了将事务组织成块，按顺序组织所有事务比较简单。例如，第815块的第47个事务可以称为事务141,918。我们将使用64个事务，尽管较高和较低的数字都可以使用，但具有不同的访问属性。我们定义了以下函数：123nonce 64位。每次尝试都会创建一个新的nonce。get_txid(T) 从B块返回编号为T的事务的txid(事务的哈希)block_height 区块链的当前高度，会在每个新块上增长 Hashimoto通过以下操作选择事务:12345678hash_output_A = sha256(prev_hash, merkle_root, nonce)for:=0 to 60 do shifted_A = hash_output_A &gt;&gt; i transaction = shifited_A mod total_transactions txid[i] = get_txid(transaction) &lt;&lt; iend fortxid_mix = txid[0] xor txid[1]...xor txid[63]final_ouput = txidmix xor (nonce &lt;&lt; 192) 然后将目标与final_output进行比较，并接受较小的值作为证明。 初始哈希输出用于独立且一致地从区块链中选择64个事务。在这64步中的每一步，hash_outputA都会右移一位，以获得一个新的数字shifted_A。通过计算shifted_A模总块数选择一个区块，通过计算shifted_A模该块的总事务数选择一个事务。这些txid的偏移量也与选择它们的shifted_A相同。一旦检索到64个txid，它们就会一起进行异或，并与原始的nonce一起用作最终哈希函数的输入。在最后的异或函数中需要原来的nonce，因为非常小的事务集可能没有包含足够多的txid排列来满足工作不平等的证明。事实上，这个算法只在区块链扩展时才成为I/O限制的。在只有一个块和一个事务的区块链的极端情况下，可以省略整个64次迭代过程，并且可以快速迭代用于计算final_output的nonce，因为txid总是相同的。对于较大的区块链，在最后的散列中包含nonce可能不再是必要的，但也不是有害的。 瓶颈分析这种方法在哈希操作和内存访问之间进行了指数级的权衡。给定一个包含100个块的区块链，如果一个挖掘节点缺少一个块，那么每个初始哈希都有0.5的概率成为第二个哈希计算的输入。因此减少百分之一的IO需求就要付出两倍的哈希计算。百分之二的减少会付出四倍的计算。显然，采矿者需要整个区块链才能开采。 对于所有节点，这也很容易验证。接收节点只需要执行1个sha256操作，128个移位操作、64个XORs和几百个I/O操作。与块验证期间还需要的签名验证相比，验证此工作证明的成本要低得多。 这种方法不能有效地外包。如果服务器要为远程挖掘节点托管区块链，那么网络延迟将完全超过每次哈希操作的时间。在这个场景中，矿工将持有每个块中事务数量的查询表，这样他们就可以计算散列、移位、模，并找到他们需要的每个事务的txid。发送到区块链主机服务器最多需要几kb。区块链托管服务器的响应也将是2KB或稍多一点。如果将这些请求序列化，每个传输的延迟为毫秒级，这将创建每秒1000哈希数以下的限制。相反，如果矿工创建了大量txid请求，那么每个可能的散列都需要2Kb的数据通过网络。每秒运行10亿个sha256操作(用当前的硬件很容易实现)将需要每秒几tb的网络吞吐量。如果区块链小于1tb，那么整个区块链每秒需要传输多次。显然，对于每个挖掘节点来说，维护它所需的所有数据的本地副本，以便尽可能地证明工作，这样会快得多。 为这种算法开发ASIC不太可能比普通计算机硬件带来显著的改进。从比特币网络难度的增加可以看出，sha256可以通过专用硬件进行优化。然而，Hashimoto每次尝试只使用1个sha256操作，对于当前CPU，每个操作的时间都是微秒。尽管在定制硬件中，可以在低成本快速的情况下实现移位，但在通用cpu上，移位操作也非常迅速，而不是瓶颈。同样，虽然模块化操作也可以优化，但在cpu上也非常快。，Hashimoto的瓶颈是get_txid(T)函数，它需要对磁盘或RAM执行读取操作。不能有效地缓存这些I/O操作，因为每个hash_output_A指向一组完全不同的事务。 进行这种工作证明的最有效方法是由高速内存。由于哈希、移位和模操作非常快，因此可以计算和排列许多(block、tx)对，并按顺序或并行检索它们。虽然区块链很小，cpu将能够在芯片上缓存整个区块链，但是随着它的增长，将它移动到DRAM将是必要的。将txid移动到磁盘上会慢得多，并且可能会导致矿商无法与能够在DRAM中存储整个区块链的矿商竞争。如果区块链比DRAM存储增长得更快，那么会有使用无限带宽或其他低延迟、高吞吐量网络系统的多服务器。这种访问模式在许多高性能计算应用程序中很常见，几十年的研究已经为此优化了计算机硬件。 结论通过利用加密货币区块链固有的大型共享数据存储，可以创建抗ASIC、不可外包的工作证明算法。使用加密哈希算法伪随机地从大型共享数据集中选择元素，使得哈希能力证明成为I/O能力证明，这是当前计算机硬件已经优化过的。这种I/O绑定算法还确保每个节点包含整个数据集，从而限制了集中的外包池。Hashimoto可以推出一种新的加密货币，以公平和区中心化的方式在商业计算机硬件上出现。 题图来自unsplash: https://unsplash.com/photos/Q_ffjo0m3hE]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[严格的内存困难型哈希函数]]></title>
    <url>%2F2019%2F05%2F22%2F%E4%B8%A5%E6%A0%BC%E7%9A%84%E5%86%85%E5%AD%98%E5%9B%B0%E9%9A%BE%E5%9E%8B%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[原文地址 摘要本文介绍严格内存困难型函数的概念。严格内存困难型函数是内存困难性函数的一个扩展，当用于实际计算的内存比预定义的最优内存略微减少时，会使函数的计算指数级变慢或根本不可行。严格内存困难型函数的主要应用是证明在一定的时间间隔内或在一定的计算中使用了一定的内存。这反过来可以用来证明设备的内存区域不包含隐藏数据。其他应用场景包括密码散列和工作证明。我们提供了SeqMemoHash和RandMemoHash两个在随机预测模型下的连续内存困难函数 介绍加密哈希函数易于计算，但很难反推，同时保留了大量源熵。加密哈希函数称为许多其他函数的基石，比如密钥生成函数（KDF）。密钥生成函数使用伪随机函数从密钥(如主密钥)中派生一个或多个密钥。基于密码的KDFs(PKDF)(也称为密码散列函数)使用密码或密码短语作为主密钥。PKDFs通常用于密钥扩展。密钥扩展是用来在网站中实现更安全的密码认证。该网站不存储原始密码，而是利用PKDF产生一个散列密钥。如果攻击者能够访问所有网站用户的派生密钥列表，他可能尝试执行字典攻击或暴力攻击。这需要为每个密码候选项计算PKDF，并将结果与散列值进行比较。为了降低这些攻击的有用性，于是设计了密钥扩展函数，使它们要么需要昂贵的计算，要么需要大量的RAM。通过对密钥进行递归哈希产生的摘要和一个随机变量异或可以实现这种昂贵计算，比如PBKDF2体制（异或是为了尽可能少的减少熵）。scrypt算法是密钥扩展算法的一个例子，该算法可以配置为需要使用一定数量的RAM才能有效地计算，并且每个内存访问都依赖于前一个内存访问。这使得破解机的硬件实现不那么吸引人，因为这种内存访问模式既不能并行化，也不能流水线化。尽管如此，即使计算期间使用的内存小于最优值，scrypt函数仍然可以快速计算。密码散列函数不需要防止用更少的内存计算该函数：它所期望的性能是，用小于最优内存的函数计算会使计算速度足够慢，因此创建具有这种特性的破译机器没有经济效益。在scrypt中，计算时间随着内存减少的数量线性增长，直到剩下一个非常小的内存时，计算将变得不可能。相比之下，在严格的内存困难型函数(SMHF)中，如果从最优值中删除超过一个常数的少量内存，计算会立即变得不可行，甚至不可能。在随机预测模型下，我们给出了SeqMemoHash和RandMemoHash这两个严格的内存困难型函数。这些函数可以用作密码散列函数，但它们可能达不到高的吞吐量，因为它们需要哈希函数来支持严格属性，而scrypt只需要一个一致的强序函数(一种如果按不同的顺序计算运算，其输出很可能不同的函数)。不过可以修改我们的方案，在不影响实际安全性的前提下通过减少哈希函数的轮数来实现更高的吞吐量。例如SHA-256减少到16轮回比比Salsa20/8快4倍。 在软件认证中的应用假设验证者希望在目标计算机上验证软件，并且已经有一个验证方法来验证正在运行或已安装的软件是否与预定义的条件相同（比如通过哈希）。但是认证过程还必须验证空闲内存中没有隐藏任何内容，无论是在易失性存储还是非易失性存储中。一个简单的但不是最优的方案的是，验证者发送一个真正的随机数序列来填充未使用的内存，然后执行已知的软件验证阶段，最后检查内存中是否存在相同的序列。SMHF可以在没有网络传输随机值的情况下提供相同的功能，这可能会造成非常高的开销。验证器向认证计算机提供种子，然后计算机计算一个伪随机数序列，该伪随机数序列使用多轮SMHF填充未使用的内存。此填充过程将花费比通信延迟更高的量时间。然后目标计算机返回上一轮SMHF的散列摘要，由验证器进行验证。在已知的软件认证阶段结束后，验证者向目标计算机发送一个挑战。计算机必须使用与SMHF的最后一轮输出相连接的挑战的散列进行响应（应该存储在内存中）。如果内存中没有填充此数据，并且目标计算机试图重新计算的话，这种行为将被探测到，因为这样做的延迟会非常大。 严格内存困难型函数定义1： 针对内存大小为n的随机存取机，如果他在执行T(n)操作时T(n)=O(n)，提出了一种RAM-fast算法 定义2： 如果一个函数可以用随机存取机的RAM-fast算法来计算，那么它就是RAM-fast。 定义3： 随机存取机器上的内存困难型算法是这样一种算法：他使用大小为n的空间和T(n)操作，n=Ω(T(n)^1−ϵ) 定义3： 如果一个函数是RAM-fast而且可以在随机存取机上一n的空间通过内存困难型算法执行，但是不能在并行随机存储机上以小于n-x的空间运行，那么他是一个内存困难型函数。 SeqMemoHashSeqMemoHash是我们第一个SMHF提议。设H为单向压缩函数。设D为哈希摘要大小。设s是一个大小等于D的主秘密。设M[i]为为内存数组(0≤i&lt; N)，其中内存单元包含D个字节。设R是函数的轮数。该算法就地计算，输出为内存数组M。对于PoW或密码散列，取内存的最后z块(M[N-z]..M[N-1])，再用一个安全的加密哈希函数进行哈希，得到最终结果。 123456SeqMemoHash(s,R,N): Set M[0]:=s For i:=1 to N-1 do set M[i]:=H(M[i-1]) For r:=1 to R do For b:=0 to N-1 do M[b]:=H(M[(b-1+N) mod N] || M[b]) //注：||表示拼接 如果设置R≥N+1，那么SeqMemoHash是严格内存困难型函数。现在我们尝试一个非正式的证明。设c为压缩函数的工作状态空间。如果可用内存低于N*D+c，则计算最后一轮时需要存储一个大小为D的临时状态，而且至少计算前一轮两次。第二次计算必须要n*D+c-D的空间。同样的参数也可以随着内存减少应用到前一轮。经过N轮后，由于没有足够的暂存空间来计算压缩函数的工作状态，使得计算变得不可行的。更仔细的分析表明，每轮执行的回溯调用的数量随着回溯深度的增加而增加，因为每轮都需要存储临时散列摘要，从而减少了调用方的轮临时存储空间。这个问题类似于寄存器分配问题，作者找不到求最优解所需哈希数的精确递归式。 RandMemoHash,添加不可预测的内存访问SeqMemoHash的每个散列步骤的输入都是预先知道的，因此可以使用最优寄存器分配算法重用尽可能多的中间结果。事实上，一个总是删除链中最老块的贪婪算法似乎是最优的。在本节中，我们建议对前面的函数进行一些轻微的修改，以防止任何寄存器分配算法提前知道将来需要哪些寄存器(或内存块)。：我们强制其中一个块的索引依赖于链的最后一个散列。这给出了一个高度均匀的随机分布的索引。当需要重新计算并执行回溯时，仍然有可能将当前块索引预先存储并作为参数传递给回溯子例程，以便在回溯函数返回后动态优化内存状态。然而，下面的问题似乎是np完全的，所以对于一个足够大的N，可能只找到一个次优解。仿真结果表明，当所提供的内存小于最优内存时，贪婪算法执行的哈希步数随着轮数的阶乘增加而增加。如果我们能够证明这对于任何算法都是正确的，那么这就意味着当R≥35，计算对于128位等效安全变得不可行的。 我们定义RandMemoHash如下:123456789RandMemoHash(s,R,N)： Set M[0]:=s For i:=1 to N-1 do set M[i]:=H(M[i-1]) For r:=1 to R do: For b:=0 to N-1 do: p:=(b-1+N) mod N q:=AsInteger(M[p]) mod (N-1) j:=(b+q) mod N M[b]:=H(M[p] || M[j]) 注意，如果输入是按随机顺序而不是按顺序执行的，它会降低CPU缓存的效用，这通常是一个优势。 若要使用RandMemoHash作为密码散列函数，如果最终结果是完全哈希的话可以使用一个降低轮数的版本替换函数H（如SHA-256使用16轮）。此外，种子应该使用一个标准的快速密钥推导函数从密码中得出，而且结果M应该通过另一个密钥推导函数来输出更短的密钥。 性能优化当使用RandMemoHash作为工作证明时，它可以防止使用gpu或asic发送垃圾邮件或获得比标准计算机更快的速度。通过要求1mb内存，在一个最先进的gpu上计算SeqMemoHash(从2013年开始)会比使用标准电脑要慢。内部哈希函数可以按轮数减少，只需为减少的轮函数找到一个pre-image比完全计算RandMemoHash要困难。 使用RandMemoHash作为PoW的建议配置如下: RandMemoHash使用4轮(R=4) 内部哈希函数是SHA-256，减少到16个循环 N = 2^16，所以需要2mb的内存来优化计算SeqMemoHash。 计算SeqMemoHash至少需要2^18次被减少的哈希计算，这相当于2^16次完整的SHA-256计算，在标准计算机中大约需要30毫秒。 假设每个SHA-256轮需要4个步骤，那么RandMemoHash计算的总步骤数为2^24。 对于这种配置，估计用一半内存计算RandMemoHash需要重新计算大约2^60个散列摘要。 在PoW中也不需要隐藏初始种子，不需要隐藏任何中间状态。使用完整的SHA-256哈希最后一个块，可以防止完整的SeqMemoHash原像攻击。：攻击者不会愿意每次都破坏一个内部约简版哈希函数，即使它在计算上是可行的。例如，打破减少到16轮的SHA-2的原像抵抗需要2^32步。然后是计算成本，如果内存比最优内存少32字节的RandMemoHash至少需要执行这2^32个额外步骤，因此RandMemoHash需要的时间比以前多256倍。 逐步验证当SeqMemoHash或RandMemoHash被用作PoW时，攻击者可以通过欺骗PoW的难度来尝试DoS攻击，并迫使验证者在计算(无效的)MemoHash摘要时投入CPU资源。防止这种攻击的一种方法是创建一个PoW，该PoW由在两个幂为2的步骤中(在哈希步骤1,2,4,8，..)生成的所有中间结果的串联组成最后的结果。对于上一节给出的配置，这需要17个中间散列摘要和最终散列摘要。验证者必须在计算过程中根据给定的值检查每个中间状态。此保护确保攻击者必须执行验证者执行的至少一半操作。 结论介绍了严格内存困难函数(SMHF)的概念，和现在的两个SMHF候选SeqMemoHash和RandMemoHash，而且我们推测，他们在随机预测模型下是内存困难的。 题图来自unsplash: https://unsplash.com/photos/TAm2z1TOges]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中core-blockchain源码学习]]></title>
    <url>%2F2019%2F05%2F19%2Fgo-ethereum%E4%B8%ADcore-blockchain%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[数据结构在BlockChain的数据结构定义前面有一段注释，解释了BlockChain功能，大致意思是BlockChain提供了规范链，也可以理解为主链的定义，同时提供了一系列区块链的操作。数据结构如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546// go-ethereum\core\blockchain.gotype BlockChain struct &#123; chainConfig *params.ChainConfig // Chain &amp; network configuration cacheConfig *CacheConfig // Cache configuration for pruning db ethdb.Database // Low level persistent database to store final content in triegc *prque.Prque // Priority queue mapping block numbers to tries to gc gcproc time.Duration // Accumulates canonical block processing for trie dumping hc *HeaderChain rmLogsFeed event.Feed chainFeed event.Feed chainSideFeed event.Feed chainHeadFeed event.Feed logsFeed event.Feed scope event.SubscriptionScope genesisBlock *types.Block chainmu sync.RWMutex // blockchain insertion lock procmu sync.RWMutex // block processor lock checkpoint int // checkpoint counts towards the new checkpoint currentBlock atomic.Value // Current head of the block chain currentFastBlock atomic.Value // Current head of the fast-sync chain (may be above the block chain!) stateCache state.Database // State database to reuse between imports (contains state cache) bodyCache *lru.Cache // Cache for the most recent block bodies bodyRLPCache *lru.Cache // Cache for the most recent block bodies in RLP encoded format receiptsCache *lru.Cache // Cache for the most recent receipts per block blockCache *lru.Cache // Cache for the most recent entire blocks futureBlocks *lru.Cache // future blocks are blocks added for later processing quit chan struct&#123;&#125; // blockchain quit channel running int32 // running must be called atomically // procInterrupt must be atomically called procInterrupt int32 // interrupt signaler for block processing wg sync.WaitGroup // chain processing wait group for shutting down engine consensus.Engine processor Processor // block processor interface validator Validator // block and state validator interface vmConfig vm.Config badBlocks *lru.Cache // Bad block cache shouldPreserve func(*types.Block) bool // Function used to determine whether should preserve the given block.&#125; NewBlockChain区块链的初始化方法是NewBlockChain，他在eth\backend.go中的New方法里会被调用。也就是创建一个Ethereum时会创建BlockChain对象并赋值到Ethereum的blockchain中。实现如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// go-ethereum\core\blockchain.gofunc NewBlockChain(db ethdb.Database, cacheConfig *CacheConfig, chainConfig *params.ChainConfig, engine consensus.Engine, vmConfig vm.Config, shouldPreserve func(block *types.Block) bool) (*BlockChain, error) &#123; if cacheConfig == nil &#123; cacheConfig = &amp;CacheConfig&#123; TrieCleanLimit: 256, TrieDirtyLimit: 256, TrieTimeLimit: 5 * time.Minute, &#125; &#125; bodyCache, _ := lru.New(bodyCacheLimit) bodyRLPCache, _ := lru.New(bodyCacheLimit) receiptsCache, _ := lru.New(receiptsCacheLimit) blockCache, _ := lru.New(blockCacheLimit) futureBlocks, _ := lru.New(maxFutureBlocks) badBlocks, _ := lru.New(badBlockLimit) bc := &amp;BlockChain&#123; chainConfig: chainConfig, cacheConfig: cacheConfig, db: db, triegc: prque.New(nil), stateCache: state.NewDatabaseWithCache(db, cacheConfig.TrieCleanLimit), quit: make(chan struct&#123;&#125;), shouldPreserve: shouldPreserve, bodyCache: bodyCache, bodyRLPCache: bodyRLPCache, receiptsCache: receiptsCache, blockCache: blockCache, futureBlocks: futureBlocks, engine: engine, vmConfig: vmConfig, badBlocks: badBlocks, &#125; bc.SetValidator(NewBlockValidator(chainConfig, bc, engine)) bc.SetProcessor(NewStateProcessor(chainConfig, bc, engine)) var err error bc.hc, err = NewHeaderChain(db, chainConfig, engine, bc.getProcInterrupt) if err != nil &#123; return nil, err &#125; bc.genesisBlock = bc.GetBlockByNumber(0) if bc.genesisBlock == nil &#123; return nil, ErrNoGenesis &#125; if err := bc.loadLastState(); err != nil &#123; return nil, err &#125; for hash := range BadHashes &#123; if header := bc.GetHeaderByHash(hash); header != nil &#123; headerByNumber := bc.GetHeaderByNumber(header.Number.Uint64()) if headerByNumber != nil &amp;&amp; headerByNumber.Hash() == header.Hash() &#123; log.Error("Found bad hash, rewinding chain", "number", header.Number, "hash", header.ParentHash) bc.SetHead(header.Number.Uint64() - 1) log.Error("Chain rewind was successful, resuming normal operation") &#125; &#125; &#125; go bc.update() return bc, nil&#125; 首先检查了cacheConfig是否为空，若为空则初始化一个默认配置。随后初始化了一系列的lru缓存实例。然后构造了BlockChain的实例，其中triegc是一个prque，也就是优先级队列的数据结构；stateCache在前面介绍state是分析过，NewDatabaseWithCache返回一个database类型对象，用于后面构建StateDB。 随后设置了Validator和Processor。Validator是区块链验证器，Processor是用来对交易进行处理。 接下来调用了NewHeaderChain创建了一个HeaderChain对象赋值给bc的hc。HeaderChain是一个只包含区块头的链。然后去取编号为0的区块，也就是创世区块并赋值给genesisBlock字段，如果取不到则报错。接下来调用loadLastState去加载最新状态，最后遍历BadHashes，所谓的BadHashes就是一组散列值，用于检测硬分叉，首先根据hash检测我们的区块链上是否有对应的区块，如果有的话在检测对应编号的区块是否相同，相同的话表示有坏区块，这时需要回滚到坏区块的编号减一的位置。 最后启动一个goroutine运行update，然后返回构建的区块链对象。 update这个方法实现如下123456789101112func (bc *BlockChain) update() &#123; futureTimer := time.NewTicker(5 * time.Second) defer futureTimer.Stop() for &#123; select &#123; case &lt;-futureTimer.C: bc.procFutureBlocks() case &lt;-bc.quit: return &#125; &#125;&#125; 主要就是启动一个ticker，每5秒触发一次，去执行procFutureBlocks方法123456789101112131415func (bc *BlockChain) procFutureBlocks() &#123; blocks := make([]*types.Block, 0, bc.futureBlocks.Len()) for _, hash := range bc.futureBlocks.Keys() &#123; if block, exist := bc.futureBlocks.Peek(hash); exist &#123; blocks = append(blocks, block.(*types.Block)) &#125; &#125; if len(blocks) &gt; 0 &#123; types.BlockBy(types.Number).Sort(blocks) for i := range blocks &#123; bc.InsertChain(blocks[i : i+1]) &#125; &#125;&#125; 这个方法主要是遍历futureBlocks这个lru缓存的key，futureBlocks存储着将要插入的区块，然后取出对应的block，并将block插入区块链。 loadLastState刚才NewBlockChain方法中的loadLastState是用来更新区块链到最新状态，主要是更新三个变量：currentBlock，currentHeader和currentFastBlock。currentBlock表示区块链中最新的区块；currentHeader表示那个只保存区块头的链的最新内容，这个头部的编号可能大于currentBlock；currentFastBlock表示快速同步模式下的最新内容，也可能大于currentBlock。实现如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546func (bc *BlockChain) loadLastState() error &#123; head := rawdb.ReadHeadBlockHash(bc.db) if head == (common.Hash&#123;&#125;) &#123; log.Warn("Empty database, resetting chain") return bc.Reset() &#125; currentBlock := bc.GetBlockByHash(head) if currentBlock == nil &#123; log.Warn("Head block missing, resetting chain", "hash", head) return bc.Reset() &#125; if _, err := state.New(currentBlock.Root(), bc.stateCache); err != nil &#123; log.Warn("Head state missing, repairing chain", "number", currentBlock.Number(), "hash", currentBlock.Hash()) if err := bc.repair(&amp;currentBlock); err != nil &#123; return err &#125; &#125; bc.currentBlock.Store(currentBlock) currentHeader := currentBlock.Header() if head := rawdb.ReadHeadHeaderHash(bc.db); head != (common.Hash&#123;&#125;) &#123; if header := bc.GetHeaderByHash(head); header != nil &#123; currentHeader = header &#125; &#125; bc.hc.SetCurrentHeader(currentHeader) bc.currentFastBlock.Store(currentBlock) if head := rawdb.ReadHeadFastBlockHash(bc.db); head != (common.Hash&#123;&#125;) &#123; if block := bc.GetBlockByHash(head); block != nil &#123; bc.currentFastBlock.Store(block) &#125; &#125; currentFastBlock := bc.CurrentFastBlock() headerTd := bc.GetTd(currentHeader.Hash(), currentHeader.Number.Uint64()) blockTd := bc.GetTd(currentBlock.Hash(), currentBlock.NumberU64()) fastTd := bc.GetTd(currentFastBlock.Hash(), currentFastBlock.NumberU64()) log.Info("Loaded most recent local header", "number", currentHeader.Number, "hash", currentHeader.Hash(), "td", headerTd, "age", common.PrettyAge(time.Unix(currentHeader.Time.Int64(), 0))) log.Info("Loaded most recent local full block", "number", currentBlock.Number(), "hash", currentBlock.Hash(), "td", blockTd, "age", common.PrettyAge(time.Unix(currentBlock.Time().Int64(), 0))) log.Info("Loaded most recent local fast block", "number", currentFastBlock.Number(), "hash", currentFastBlock.Hash(), "td", fastTd, "age", common.PrettyAge(time.Unix(currentFastBlock.Time().Int64(), 0))) return nil&#125; 在这个方法中首先利用ReadHeadBlockHash读取了数据库中的最新区块hash，也就是数据库key为”LastBlock”的数据，他代表区块链的最高区块的hash值，若为空则表示数据库为空，对应的区块链也要重置，调用Reset。 若不为空，则根据hash值去查找对应区块数据，若找不到也进行重置。若找到对应区块，则确认和这个区块相关的状态树是否正确。这里的主要操作是尝试访问状态树，看是否成功，若不成功尝试进行修复，使用repair。若一切都正确则更新currentBlock。 继续往下是更新currentHeader，逻辑也是一样的，先从数据库中读取key为”LastHeader”的数据，他表示只含头区块的链的最高区块头hash，然后根据hash从数据库查找对应头区块并更新currentHeader，若找不到则以前面的currentBlock的头作为currentHeader。 再往下还是类似的逻辑，这次更新currentFastBlock，也是先从数据库中读取key为”LastFast”的数据，然后寻找对应的区块，并更新currentFastBlock，若找不到就以currentHeader为currentFastBlock。 最后进行了log打印。 reset前面在loadLastState多次出现了reset方法，主要是恢复到创世区块状态12345678910111213141516171819202122232425func (bc *BlockChain) Reset() error &#123; return bc.ResetWithGenesisBlock(bc.genesisBlock)&#125;func (bc *BlockChain) ResetWithGenesisBlock(genesis *types.Block) error &#123; if err := bc.SetHead(0); err != nil &#123; return err &#125; bc.chainmu.Lock() defer bc.chainmu.Unlock() if err := bc.hc.WriteTd(genesis.Hash(), genesis.NumberU64(), genesis.Difficulty()); err != nil &#123; log.Crit("Failed to write genesis block TD", "err", err) &#125; rawdb.WriteBlock(bc.db, genesis) bc.genesisBlock = genesis bc.insert(bc.genesisBlock) bc.currentBlock.Store(bc.genesisBlock) bc.hc.SetGenesis(bc.genesisBlock.Header()) bc.hc.SetCurrentHeader(bc.genesisBlock.Header()) bc.currentFastBlock.Store(bc.genesisBlock) return nil&#125; 这里首先调用SetHead方法，设置头区块为0。SetHead方法主要是指定区块链的某个区块为新的头区块，该区块之后的区块都会被删除，主要用于回滚。这里我们设置为0，也就是清空整个区块链。 接下来根据创世区块重构区块链。首先利用hc上写入总难度，然后向数据库写入创世区块，并将其插入到区块链中，并设置currentBlock、currentFastBlock和CurrentHeader。 SetHead刚才reset以及NewBlockChain都用到了SetHead方法，这里详细看一下12345678910111213141516171819202122232425262728293031323334353637383940414243444546func (bc *BlockChain) SetHead(head uint64) error &#123; log.Warn("Rewinding blockchain", "target", head) bc.chainmu.Lock() defer bc.chainmu.Unlock() delFn := func(db rawdb.DatabaseDeleter, hash common.Hash, num uint64) &#123; rawdb.DeleteBody(db, hash, num) &#125; bc.hc.SetHead(head, delFn) currentHeader := bc.hc.CurrentHeader() bc.bodyCache.Purge() bc.bodyRLPCache.Purge() bc.receiptsCache.Purge() bc.blockCache.Purge() bc.futureBlocks.Purge() if currentBlock := bc.CurrentBlock(); currentBlock != nil &amp;&amp; currentHeader.Number.Uint64() &lt; currentBlock.NumberU64() &#123; bc.currentBlock.Store(bc.GetBlock(currentHeader.Hash(), currentHeader.Number.Uint64())) &#125; if currentBlock := bc.CurrentBlock(); currentBlock != nil &#123; if _, err := state.New(currentBlock.Root(), bc.stateCache); err != nil &#123; bc.currentBlock.Store(bc.genesisBlock) &#125; &#125; if currentFastBlock := bc.CurrentFastBlock(); currentFastBlock != nil &amp;&amp; currentHeader.Number.Uint64() &lt; currentFastBlock.NumberU64() &#123; bc.currentFastBlock.Store(bc.GetBlock(currentHeader.Hash(), currentHeader.Number.Uint64())) &#125; if currentBlock := bc.CurrentBlock(); currentBlock == nil &#123; bc.currentBlock.Store(bc.genesisBlock) &#125; if currentFastBlock := bc.CurrentFastBlock(); currentFastBlock == nil &#123; bc.currentFastBlock.Store(bc.genesisBlock) &#125; currentBlock := bc.CurrentBlock() currentFastBlock := bc.CurrentFastBlock() rawdb.WriteHeadBlockHash(bc.db, currentBlock.Hash()) rawdb.WriteHeadFastBlockHash(bc.db, currentFastBlock.Hash()) return bc.loadLastState()&#125; 首先调用headerchain的SetHead方法：1234567891011121314151617181920212223242526272829303132333435func (hc *HeaderChain) SetHead(head uint64, delFn DeleteCallback) &#123; height := uint64(0) if hdr := hc.CurrentHeader(); hdr != nil &#123; height = hdr.Number.Uint64() &#125; batch := hc.chainDb.NewBatch() for hdr := hc.CurrentHeader(); hdr != nil &amp;&amp; hdr.Number.Uint64() &gt; head; hdr = hc.CurrentHeader() &#123; hash := hdr.Hash() num := hdr.Number.Uint64() if delFn != nil &#123; delFn(batch, hash, num) &#125; rawdb.DeleteHeader(batch, hash, num) rawdb.DeleteTd(batch, hash, num) hc.currentHeader.Store(hc.GetHeader(hdr.ParentHash, hdr.Number.Uint64()-1)) &#125; for i := height; i &gt; head; i-- &#123; rawdb.DeleteCanonicalHash(batch, i) &#125; batch.Write() hc.headerCache.Purge() hc.tdCache.Purge() hc.numberCache.Purge() if hc.CurrentHeader() == nil &#123; hc.currentHeader.Store(hc.genesisHeader) &#125; hc.currentHeaderHash = hc.CurrentHeader().Hash() rawdb.WriteHeadHeaderHash(hc.chainDb, hc.currentHeaderHash)&#125; 在headerchain的SetHead中，首先计算了当前链的高度，然后开启一个循环从链的头部开始遍历到目标区块，每遍历一个区块就执行删除操作，具体来说，是先执行delFn函数，这个函数调用了DeleteBody用来删除区块体，然后又删除了存储在数据库中的区块头和总难度 随后又有一个循环，也是从最高点开始到目标位置，删除规范链的hash。注意这些删除都是借助了批量操作。最后清空几个缓存后，如果最高区块为空，则存入创世区块的头作为最高区块。再存取最高区块的hash，并写入数据库。 回到BlockChain的setHead，在hc回滚完之后，实际上目标点之后的区块已经删除，接下来更新了currentBlock，这里以hc的currentHeader为标准去查找区块，然后验证了状态树是否正确，不正确的话currentBlock设为创世区块。接着又更新了currentFastBlock，也是以currentHeader为标准。下面判断了currentBlock与currentFastBlock是否为空，若为空将二者都设置为创世区块。最后更新了数据库中currentBlock与currentFastBlock，也就是key为”LastBlock”和”LastFast”的数据。最后调用了loadLastState去更新状态。 InsertChain这个是插入一系列区块的，在前面update的procFutureBlocks方法以及外部的downloader的importBlockResults中有调用过，只不过那里一次只插入一个区块，具体实现如下：123456789101112131415161718192021222324func (bc *BlockChain) InsertChain(chain types.Blocks) (int, error) &#123; if len(chain) == 0 &#123; return 0, nil &#125; for i := 1; i &lt; len(chain); i++ &#123; if chain[i].NumberU64() != chain[i-1].NumberU64()+1 || chain[i].ParentHash() != chain[i-1].Hash() &#123; log.Error("Non contiguous block insert", "number", chain[i].Number(), "hash", chain[i].Hash(), "parent", chain[i].ParentHash(), "prevnumber", chain[i-1].Number(), "prevhash", chain[i-1].Hash()) return 0, fmt.Errorf("non contiguous insert: item %d is #%d [%x…], item %d is #%d [%x…] (parent [%x…])", i-1, chain[i-1].NumberU64(), chain[i-1].Hash().Bytes()[:4], i, chain[i].NumberU64(), chain[i].Hash().Bytes()[:4], chain[i].ParentHash().Bytes()[:4]) &#125; &#125; bc.wg.Add(1) bc.chainmu.Lock() n, events, logs, err := bc.insertChain(chain, true) bc.chainmu.Unlock() bc.wg.Done() bc.PostChainEvents(events, logs) return n, err&#125; 前面一部分主要是检查要插入的一系列区块是否合法，如编号是否正确，父子关系是否正确等。实际插入方法在insertChain中实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153func (bc *BlockChain) insertChain(chain types.Blocks, verifySeals bool) (int, []interface&#123;&#125;, []*types.Log, error) &#123; if atomic.LoadInt32(&amp;bc.procInterrupt) == 1 &#123; return 0, nil, nil, nil &#125; senderCacher.recoverFromBlocks(types.MakeSigner(bc.chainConfig, chain[0].Number()), chain) var ( stats = insertStats&#123;startTime: mclock.Now()&#125; events = make([]interface&#123;&#125;, 0, len(chain)) lastCanon *types.Block coalescedLogs []*types.Log ) headers := make([]*types.Header, len(chain)) seals := make([]bool, len(chain)) for i, block := range chain &#123; headers[i] = block.Header() seals[i] = verifySeals &#125; abort, results := bc.engine.VerifyHeaders(bc, headers, seals) defer close(abort) it := newInsertIterator(chain, results, bc.Validator()) block, err := it.next() switch &#123; case err == consensus.ErrPrunedAncestor: return bc.insertSidechain(block, it) case err == consensus.ErrFutureBlock || (err == consensus.ErrUnknownAncestor &amp;&amp; bc.futureBlocks.Contains(it.first().ParentHash())): for block != nil &amp;&amp; (it.index == 0 || err == consensus.ErrUnknownAncestor) &#123; if err := bc.addFutureBlock(block); err != nil &#123; return it.index, events, coalescedLogs, err &#125; block, err = it.next() &#125; stats.queued += it.processed() stats.ignored += it.remaining() return it.index, events, coalescedLogs, err case err == ErrKnownBlock: current := bc.CurrentBlock().NumberU64() for block != nil &amp;&amp; err == ErrKnownBlock &amp;&amp; current &gt;= block.NumberU64() &#123; stats.ignored++ block, err = it.next() &#125; case err != nil: stats.ignored += len(it.chain) bc.reportBlock(block, nil, err) return it.index, events, coalescedLogs, err &#125; for ; block != nil &amp;&amp; err == nil; block, err = it.next() &#123; if atomic.LoadInt32(&amp;bc.procInterrupt) == 1 &#123; log.Debug("Premature abort during blocks processing") break &#125; if BadHashes[block.Hash()] &#123; bc.reportBlock(block, nil, ErrBlacklistedHash) return it.index, events, coalescedLogs, ErrBlacklistedHash &#125; start := time.Now() parent := it.previous() if parent == nil &#123; parent = bc.GetBlock(block.ParentHash(), block.NumberU64()-1) &#125; state, err := state.New(parent.Root(), bc.stateCache) if err != nil &#123; return it.index, events, coalescedLogs, err &#125; t0 := time.Now() receipts, logs, usedGas, err := bc.processor.Process(block, state, bc.vmConfig) t1 := time.Now() if err != nil &#123; bc.reportBlock(block, receipts, err) return it.index, events, coalescedLogs, err &#125; if err := bc.Validator().ValidateState(block, parent, state, receipts, usedGas); err != nil &#123; bc.reportBlock(block, receipts, err) return it.index, events, coalescedLogs, err &#125; t2 := time.Now() proctime := time.Since(start) status, err := bc.writeBlockWithState(block, receipts, state) t3 := time.Now() if err != nil &#123; return it.index, events, coalescedLogs, err &#125; blockInsertTimer.UpdateSince(start) blockExecutionTimer.Update(t1.Sub(t0)) blockValidationTimer.Update(t2.Sub(t1)) blockWriteTimer.Update(t3.Sub(t2)) switch status &#123; case CanonStatTy: log.Debug("Inserted new block", "number", block.Number(), "hash", block.Hash(), "uncles", len(block.Uncles()), "txs", len(block.Transactions()), "gas", block.GasUsed(), "elapsed", common.PrettyDuration(time.Since(start)), "root", block.Root()) coalescedLogs = append(coalescedLogs, logs...) events = append(events, ChainEvent&#123;block, block.Hash(), logs&#125;) lastCanon = block bc.gcproc += proctime case SideStatTy: log.Debug("Inserted forked block", "number", block.Number(), "hash", block.Hash(), "diff", block.Difficulty(), "elapsed", common.PrettyDuration(time.Since(start)), "txs", len(block.Transactions()), "gas", block.GasUsed(), "uncles", len(block.Uncles()), "root", block.Root()) events = append(events, ChainSideEvent&#123;block&#125;) &#125; blockInsertTimer.UpdateSince(start) stats.processed++ stats.usedGas += usedGas dirty, _ := bc.stateCache.TrieDB().Size() stats.report(chain, it.index, dirty) &#125; if block != nil &amp;&amp; err == consensus.ErrFutureBlock &#123; if err := bc.addFutureBlock(block); err != nil &#123; return it.index, events, coalescedLogs, err &#125; block, err = it.next() for ; block != nil &amp;&amp; err == consensus.ErrUnknownAncestor; block, err = it.next() &#123; if err := bc.addFutureBlock(block); err != nil &#123; return it.index, events, coalescedLogs, err &#125; stats.queued++ &#125; &#125; stats.ignored += it.remaining() if lastCanon != nil &amp;&amp; bc.CurrentBlock().Hash() == lastCanon.Hash() &#123; events = append(events, ChainHeadEvent&#123;lastCanon&#125;) &#125; return it.index, events, coalescedLogs, err&#125; 在这个方法里，首先验证了头部的正确性。之后创建了两个数组分别存储要插入的区块头和该区块是否需要验证。然后创建了一个迭代器：123456789// go-ethereum\core\blockchain_insert.gofunc newInsertIterator(chain types.Blocks, results &lt;-chan error, validator Validator) *insertIterator &#123; return &amp;insertIterator&#123; chain: chain, results: results, index: -1, validator: validator, &#125;&#125; 这个迭代器有一组迭代方法，next用于获取下一个区块，previous用于获取上一个区块，first获取第一个区块，remaining返回还有多少区块未便利，processed返回已经遍历了多少区块。它是借助于数组操作的，实现也很简单，唯一特别的是在获取下一个区块时会对区块进行验证。 这里首先取了第一个区块，然后根据不同的错误执行不同的逻辑，若没有错误则进入循环遍历所有要插入的区块。 首先检测每个区块是否是BadHash中元素，若不是，先取出其父区块，对于第一个区块的父区块要在本地区块链中根据其指定的父区块hash查找，其余区块就是通过迭代器的previous方法取上一个区块。接着新建一个状态树，然后利用processor处理交易，生成收据日志等信息。接着又验证了状态树，若通过，则利用writeBlockWithState写入区块和状态。最后根据写入的结果执行不同逻辑：CanonStatTy表示插入了新区快，SideStatTy表示插入了分叉区块。 在循环结束后，判断是否还有区块，这种情况主要是之前循环过程中procInterrupt等于1，也就是被中断了，在调用stop函数后会出现这种情况。若有剩余的，而且err为ErrFutureBlock，表示区块是未来的区块时会将其添加到futureBlocks缓存中，并迭代其后的区块，注意添加的时候最多添加未来30s以内的区块。 writeBlockWithStateinsertChain的主要插入操作是在writeBlockWithState完成的，实现如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107func (bc *BlockChain) writeBlockWithState(block *types.Block, receipts []*types.Receipt, state *state.StateDB) (status WriteStatus, err error) &#123; bc.wg.Add(1) defer bc.wg.Done() ptd := bc.GetTd(block.ParentHash(), block.NumberU64()-1) if ptd == nil &#123; return NonStatTy, consensus.ErrUnknownAncestor &#125; currentBlock := bc.CurrentBlock() localTd := bc.GetTd(currentBlock.Hash(), currentBlock.NumberU64()) externTd := new(big.Int).Add(block.Difficulty(), ptd) if err := bc.hc.WriteTd(block.Hash(), block.NumberU64(), externTd); err != nil &#123; return NonStatTy, err &#125; rawdb.WriteBlock(bc.db, block) root, err := state.Commit(bc.chainConfig.IsEIP158(block.Number())) if err != nil &#123; return NonStatTy, err &#125; triedb := bc.stateCache.TrieDB() if bc.cacheConfig.Disabled &#123; if err := triedb.Commit(root, false); err != nil &#123; return NonStatTy, err &#125; &#125; else &#123; triedb.Reference(root, common.Hash&#123;&#125;) bc.triegc.Push(root, -int64(block.NumberU64())) if current := block.NumberU64(); current &gt; triesInMemory &#123; var ( nodes, imgs = triedb.Size() limit = common.StorageSize(bc.cacheConfig.TrieDirtyLimit) * 1024 * 1024 ) if nodes &gt; limit || imgs &gt; 4*1024*1024 &#123; triedb.Cap(limit - ethdb.IdealBatchSize) &#125; chosen := current - triesInMemory if bc.gcproc &gt; bc.cacheConfig.TrieTimeLimit &#123; header := bc.GetHeaderByNumber(chosen) if header == nil &#123; log.Warn("Reorg in progress, trie commit postponed", "number", chosen) &#125; else &#123; if chosen &lt; lastWrite+triesInMemory &amp;&amp; bc.gcproc &gt;= 2*bc.cacheConfig.TrieTimeLimit &#123; log.Info("State in memory for too long, committing", "time", bc.gcproc, "allowance", bc.cacheConfig.TrieTimeLimit, "optimum", float64(chosen-lastWrite)/triesInMemory) &#125; triedb.Commit(header.Root, true) lastWrite = chosen bc.gcproc = 0 &#125; &#125; for !bc.triegc.Empty() &#123; root, number := bc.triegc.Pop() if uint64(-number) &gt; chosen &#123; bc.triegc.Push(root, number) break &#125; triedb.Dereference(root.(common.Hash)) &#125; &#125; &#125; batch := bc.db.NewBatch() rawdb.WriteReceipts(batch, block.Hash(), block.NumberU64(), receipts) reorg := externTd.Cmp(localTd) &gt; 0 currentBlock = bc.CurrentBlock() if !reorg &amp;&amp; externTd.Cmp(localTd) == 0 &#123; if block.NumberU64() &lt; currentBlock.NumberU64() &#123; reorg = true &#125; else if block.NumberU64() == currentBlock.NumberU64() &#123; var currentPreserve, blockPreserve bool if bc.shouldPreserve != nil &#123; currentPreserve, blockPreserve = bc.shouldPreserve(currentBlock), bc.shouldPreserve(block) &#125; reorg = !currentPreserve &amp;&amp; (blockPreserve || mrand.Float64() &lt; 0.5) &#125; &#125; if reorg &#123; if block.ParentHash() != currentBlock.Hash() &#123; if err := bc.reorg(currentBlock, block); err != nil &#123; return NonStatTy, err &#125; &#125; rawdb.WriteTxLookupEntries(batch, block) rawdb.WritePreimages(batch, state.Preimages()) status = CanonStatTy &#125; else &#123; status = SideStatTy &#125; if err := batch.Write(); err != nil &#123; return NonStatTy, err &#125; if status == CanonStatTy &#123; bc.insert(block) &#125; bc.futureBlocks.Remove(block.Hash()) return status, nil&#125; 首先计算了几个区块链的难度值，ptd表示要插入区块的父区块的总难度，localTd表示本地最高区块的总难度，externTd表示要插入区块的难度加上ptd，也就是可能的新的总难度。计算完之后将externTd写入数据库，随后又写入了区块体，然后又提交了state，之前在处理交易时状态可能改变了，这里将其提交持久化到数据库中。再往下写入了收据信息。 接下来需要根据reorg的真假决定后面的逻辑，这其实也对应了区块插入的几种情况。 第一种情况，如果新区块插入后总难度并不比主链的总难度高，该区块插入后不产生实际影响，则reorg置为false，对应的后面status写为SideStatTy，表示区块插入到了分支上了。 第二种情况，如果新区快插入后总难度比我们主链的难度高，但是新区块又不能放在主链后，表示有分叉而且主流也要调整，此时reorg置为true，并且执行reorg方法，最后status写为CanonStatTy，表示规范链也就是主链有变动。 第三种情况，如果新区块插入后总难度和我们目前主链相等，但是新区块的高度比我们目前主链要小。说明出现更优的主链，此时新区快必定不能放在主链后，所以和第二种情况一样，reorg置为true，并且执行reorg方法，最后status写为CanonStatTy，表示主链有变动。 第四种情况，如果新区块插入后总难度和我们目前主链相等，同时高度有相等，这是一种在主链顶端分叉的情况，具体选哪一个为主链，这就要具体判断了，这里要避免私自挖矿的情况。这里调用shouldPreserve方法，这个方法主要是检测区块是不是自己挖的。如果本地最新区块是自己挖的，则reorg置为false，表示不分叉。如果本地最高区块不是自己挖的，新区快是自己挖的，则reorg置为true，表示主链要更改。如果两个都不是自己挖的，则有50%的概率reorg为true，也就是50%概率修改主链。另外，这种情况下，如果reorg为true，必能触发后面的reorg方法重构主链。 在判断reorg的if中，如果新插入区块的父区块不等于当前本地最新区块的，则表示新区快不能放主链后，则表示主链要从新定义，所以执行reorg方法。对于能接在主链后的区块，只是简单调用WriteTxLookupEntries和WritePreimages写入一些信息。 再接着，如果status为CanonStatTy，调用insert来设置新的区块链信息。最后把该区块从futureBlocks中移除。 reorg123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102func (bc *BlockChain) reorg(oldBlock, newBlock *types.Block) error &#123; var ( newChain types.Blocks oldChain types.Blocks commonBlock *types.Block deletedTxs types.Transactions deletedLogs []*types.Log collectLogs = func(hash common.Hash) &#123; // Coalesce logs and set 'Removed'. number := bc.hc.GetBlockNumber(hash) if number == nil &#123; return &#125; receipts := rawdb.ReadReceipts(bc.db, hash, *number) for _, receipt := range receipts &#123; for _, log := range receipt.Logs &#123; del := *log del.Removed = true deletedLogs = append(deletedLogs, &amp;del) &#125; &#125; &#125; ) if oldBlock.NumberU64() &gt; newBlock.NumberU64() &#123; for ; oldBlock != nil &amp;&amp; oldBlock.NumberU64() != newBlock.NumberU64(); oldBlock = bc.GetBlock(oldBlock.ParentHash(), oldBlock.NumberU64()-1) &#123; oldChain = append(oldChain, oldBlock) deletedTxs = append(deletedTxs, oldBlock.Transactions()...) collectLogs(oldBlock.Hash()) &#125; &#125; else &#123; for ; newBlock != nil &amp;&amp; newBlock.NumberU64() != oldBlock.NumberU64(); newBlock = bc.GetBlock(newBlock.ParentHash(), newBlock.NumberU64()-1) &#123; newChain = append(newChain, newBlock) &#125; &#125; if oldBlock == nil &#123; return fmt.Errorf("Invalid old chain") &#125; if newBlock == nil &#123; return fmt.Errorf("Invalid new chain") &#125; for &#123; if oldBlock.Hash() == newBlock.Hash() &#123; commonBlock = oldBlock break &#125; oldChain = append(oldChain, oldBlock) newChain = append(newChain, newBlock) deletedTxs = append(deletedTxs, oldBlock.Transactions()...) collectLogs(oldBlock.Hash()) oldBlock, newBlock = bc.GetBlock(oldBlock.ParentHash(), oldBlock.NumberU64()-1), bc.GetBlock(newBlock.ParentHash(), newBlock.NumberU64()-1) if oldBlock == nil &#123; return fmt.Errorf("Invalid old chain") &#125; if newBlock == nil &#123; return fmt.Errorf("Invalid new chain") &#125; &#125; if len(oldChain) &gt; 0 &amp;&amp; len(newChain) &gt; 0 &#123; logFn := log.Debug if len(oldChain) &gt; 63 &#123; logFn = log.Warn &#125; logFn("Chain split detected", "number", commonBlock.Number(), "hash", commonBlock.Hash(), "drop", len(oldChain), "dropfrom", oldChain[0].Hash(), "add", len(newChain), "addfrom", newChain[0].Hash()) &#125; else &#123; log.Error("Impossible reorg, please file an issue", "oldnum", oldBlock.Number(), "oldhash", oldBlock.Hash(), "newnum", newBlock.Number(), "newhash", newBlock.Hash()) &#125; var addedTxs types.Transactions for i := len(newChain) - 1; i &gt;= 0; i-- &#123; rawdb.WriteTxLookupEntries(bc.db, newChain[i]) addedTxs = append(addedTxs, newChain[i].Transactions()...) &#125; batch := bc.db.NewBatch() for _, tx := range diff &#123; rawdb.DeleteTxLookupEntry(batch, tx.Hash()) &#125; batch.Write() if len(deletedLogs) &gt; 0 &#123; go bc.rmLogsFeed.Send(RemovedLogsEvent&#123;deletedLogs&#125;) &#125; if len(oldChain) &gt; 0 &#123; go func() &#123; for _, block := range oldChain &#123; bc.chainSideFeed.Send(ChainSideEvent&#123;Block: block&#125;) &#125; &#125;() &#125; return nil&#125; 这个方法是重新调整区块链，传入的两个区块代表旧链和新链，在前面writeBlockWithState方法中有调用。 首先如果旧链比新链高，要减少旧链高度，则从旧链头部开始向下遍历，直到等于要插入的区块高度，将遍历得到的区块即区块中的交易分别放入oldChain和deletedTxs，然后对每一个遍历的区块调用collectLogs方法收集日志信息，并将所有日志信息标记为removed。 如果旧链等于或小于新链高度，则向下遍历新链，将遍历得到的区块放入newChain。 到这里新链旧链的高度相等，但是二者的hash未必相等。所以进入循环，同时向下遍历两条链，寻找二者hash值相等的位置，对于不相等的区块也是放入oldChain和newChain，并将旧链上的区块交易放入deletedTxs，同时用collectLogs处理旧链区块。知道二者的hash相等时，此时二者高度与hash都相等，表示找到一个共同点，也就是分叉点，记为commonBlock并退出循环。 接下来，遍历newChain，对每个区块调用insert，表示更新新链为规范链，然后调用WriteTxLookupEntries写入交易信息，并将每个区块的交易信息放入addedTxs。 然后比较deletedTxs和addedTxs的不同，主要是deletedTxs有的但addedTxs没有的交易。addedTxs是从分叉点开始到新链结束所有的交易，deletedTxs表示从分叉点开始到旧链结束所有的交易。对于找出的不同交易将其从数据库中删除。 InsertHeaderChain这个方法在downloader的processHeaders中调用，作用是插入区块头123456789101112131415161718func (bc *BlockChain) InsertHeaderChain(chain []*types.Header, checkFreq int) (int, error) &#123; start := time.Now() if i, err := bc.hc.ValidateHeaderChain(chain, checkFreq); err != nil &#123; return i, err &#125; bc.chainmu.Lock() defer bc.chainmu.Unlock() bc.wg.Add(1) defer bc.wg.Done() whFunc := func(header *types.Header) error &#123; _, err := bc.hc.WriteHeader(header) return err &#125; return bc.hc.InsertHeaderChain(chain, whFunc, start)&#125; 首先验证给的区块头：1234567891011121314151617181920212223242526272829303132333435363738394041func (hc *HeaderChain) ValidateHeaderChain(chain []*types.Header, checkFreq int) (int, error) &#123; for i := 1; i &lt; len(chain); i++ &#123; if chain[i].Number.Uint64() != chain[i-1].Number.Uint64()+1 || chain[i].ParentHash != chain[i-1].Hash() &#123; log.Error("Non contiguous header insert", "number", chain[i].Number, "hash", chain[i].Hash(), "parent", chain[i].ParentHash, "prevnumber", chain[i-1].Number, "prevhash", chain[i-1].Hash()) return 0, fmt.Errorf("non contiguous insert: item %d is #%d [%xâ€¦], item %d is #%d [%xâ€¦] (parent [%xâ€¦])", i-1, chain[i-1].Number, chain[i-1].Hash().Bytes()[:4], i, chain[i].Number, chain[i].Hash().Bytes()[:4], chain[i].ParentHash[:4]) &#125; &#125; seals := make([]bool, len(chain)) if checkFreq != 0 &#123; for i := 0; i &lt; len(seals)/checkFreq; i++ &#123; index := i*checkFreq + hc.rand.Intn(checkFreq) if index &gt;= len(seals) &#123; index = len(seals) - 1 &#125; seals[index] = true &#125; seals[len(seals)-1] = true &#125; abort, results := hc.engine.VerifyHeaders(hc, chain, seals) defer close(abort) for i, header := range chain &#123; if hc.procInterrupt() &#123; log.Debug("Premature abort during headers verification") return 0, errors.New("aborted") &#125; if BadHashes[header.Hash()] &#123; return i, ErrBlacklistedHash &#125; if err := &lt;-results; err != nil &#123; return i, err &#125; &#125; return 0, nil&#125; 第一个for循环是检查给定的一组区块相互依赖是否正确。之后根据checkFreq的值确定哪些区块需要验证，这里并不是固定的每个checkFreq检查一个，而是每checkFreq个区块中间随机选一个。最后根据验证结果以及是否在badhash内返回最终结果。 回到InsertHeaderChain，如果验证无误，则调用InsertHeaderChain方法，这是headerchain的方法123456789101112131415161718192021222324252627282930313233343536func (hc *HeaderChain) InsertHeaderChain(chain []*types.Header, writeHeader WhCallback, start time.Time) (int, error) &#123; stats := struct&#123; processed, ignored int &#125;&#123;&#125; for i, header := range chain &#123; if hc.procInterrupt() &#123; log.Debug("Premature abort during headers import") return i, errors.New("aborted") &#125; if hc.HasHeader(header.Hash(), header.Number.Uint64()) &#123; stats.ignored++ continue &#125; if err := writeHeader(header); err != nil &#123; return i, err &#125; stats.processed++ &#125; last := chain[len(chain)-1] context := []interface&#123;&#125;&#123; "count", stats.processed, "elapsed", common.PrettyDuration(time.Since(start)), "number", last.Number, "hash", last.Hash(), &#125; if timestamp := time.Unix(last.Time.Int64(), 0); time.Since(timestamp) &gt; time.Minute &#123; context = append(context, []interface&#123;&#125;&#123;"age", common.PrettyAge(timestamp)&#125;...) &#125; if stats.ignored &gt; 0 &#123; context = append(context, []interface&#123;&#125;&#123;"ignored", stats.ignored&#125;...) &#125; log.Info("Imported new block headers", context...) return 0, nil&#125; 首先遍历所有要插入的区块头，先判断是否已经有了，没有的话调用writeHeader，这是在BlockChain的InsertHeaderChain定义的，实际调用的headerchain的WriteHeader方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func (hc *HeaderChain) WriteHeader(header *types.Header) (status WriteStatus, err error) &#123; var ( hash = header.Hash() number = header.Number.Uint64() ) ptd := hc.GetTd(header.ParentHash, number-1) if ptd == nil &#123; return NonStatTy, consensus.ErrUnknownAncestor &#125; localTd := hc.GetTd(hc.currentHeaderHash, hc.CurrentHeader().Number.Uint64()) externTd := new(big.Int).Add(header.Difficulty, ptd) if err := hc.WriteTd(hash, number, externTd); err != nil &#123; log.Crit("Failed to write header total difficulty", "err", err) &#125; rawdb.WriteHeader(hc.chainDb, header) if externTd.Cmp(localTd) &gt; 0 || (externTd.Cmp(localTd) == 0 &amp;&amp; mrand.Float64() &lt; 0.5) &#123; batch := hc.chainDb.NewBatch() for i := number + 1; ; i++ &#123; hash := rawdb.ReadCanonicalHash(hc.chainDb, i) if hash == (common.Hash&#123;&#125;) &#123; break &#125; rawdb.DeleteCanonicalHash(batch, i) &#125; batch.Write() var ( headHash = header.ParentHash headNumber = header.Number.Uint64() - 1 headHeader = hc.GetHeader(headHash, headNumber) ) for rawdb.ReadCanonicalHash(hc.chainDb, headNumber) != headHash &#123; rawdb.WriteCanonicalHash(hc.chainDb, headHash, headNumber) headHash = headHeader.ParentHash headNumber = headHeader.Number.Uint64() - 1 headHeader = hc.GetHeader(headHash, headNumber) &#125; rawdb.WriteCanonicalHash(hc.chainDb, hash, number) rawdb.WriteHeadHeaderHash(hc.chainDb, hash) hc.currentHeaderHash = hash hc.currentHeader.Store(types.CopyHeader(header)) status = CanonStatTy &#125; else &#123; status = SideStatTy &#125; hc.headerCache.Add(hash, header) hc.numberCache.Add(hash, number) return&#125; 和插入区块类似，计算localTd与externTd，然后写入总难度即区块头。之后如果外部难度大于本地难度，或者即使相等但仍有50%概率修改规范链。修改的操作如下，首先从要插入的区块头高度开始从本地读取对应高度的规范链hash，每次高度加一，读到一个删一个，知道读不到为止。这样本地规范链的的高度和要插入的区块头高度一样。接着从要插入区块头的高度减一的位置开始，每次减一，读到一个删一个，直到到达某个位置的区块hash等于要插入区块的父hash。经过这两步后，新到的的区块可以正确的插入到规范链中，然后写入规范链hash以及头区块hash，最后改写入状态为CanonStatTy。如果不满足前面的本地难度和外部难度的判断则写入状态为SideStatTy。 回到headerchain的InsertHeaderChain中，在插入所有区块头后，打印了一些日志然后返回，整个InsertHeaderChain结束。 insert123456789101112131415func (bc *BlockChain) insert(block *types.Block) &#123; updateHeads := rawdb.ReadCanonicalHash(bc.db, block.NumberU64()) != block.Hash() rawdb.WriteCanonicalHash(bc.db, block.Hash(), block.NumberU64()) rawdb.WriteHeadBlockHash(bc.db, block.Hash()) bc.currentBlock.Store(block) if updateHeads &#123; bc.hc.SetCurrentHeader(block.Header()) rawdb.WriteHeadFastBlockHash(bc.db, block.Hash()) bc.currentFastBlock.Store(block) &#125;&#125; 这是一个调整主链的方法，在reorg方法中，当遍历到新旧链的公共点之后，开始在新链上遍历区块，每遍历一个区块执行一次insert方法，通过这样改变主链到新链。具体方法如下，首先读取数据库中主链上相应高度的区块hash来决定时候更新CurrentHeader和currentFastBlock。不过首先更新了主链上对应高度的hash，然后修改数据库中最新区块的hash。 通过对新链的每个区块都执行这个方法，使得数据库中规范链的每个位置的区块得到更新，而且currentBlock、currentHeader和currentFastBlock这几个变量也得到更新，从而改变了主链。 题图来自unsplash：https://unsplash.com/photos/HQMyV8a_4_4]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中core-genesis源码学习]]></title>
    <url>%2F2019%2F05%2F18%2Fgo-ethereum%E4%B8%ADcore-genesis%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[genesis就是创世区块，我们在运行一个区块链节点时都要使用创世区块的配置文件对区块链进行初始化，不同的网络又不同的创世区块。 数据结构12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758type Genesis struct &#123; Config *params.ChainConfig `json:"config"` Nonce uint64 `json:"nonce"` Timestamp uint64 `json:"timestamp"` ExtraData []byte `json:"extraData"` GasLimit uint64 `json:"gasLimit" gencodec:"required"` Difficulty *big.Int `json:"difficulty" gencodec:"required"` Mixhash common.Hash `json:"mixHash"` Coinbase common.Address `json:"coinbase"` Alloc GenesisAlloc `json:"alloc" gencodec:"required"` // These fields are used for consensus tests. Please don't use them // in actual genesis blocks. Number uint64 `json:"number"` GasUsed uint64 `json:"gasUsed"` ParentHash common.Hash `json:"parentHash"`&#125;type GenesisAlloc map[common.Address]GenesisAccounttype GenesisAccount struct &#123; Code []byte `json:"code,omitempty"` Storage map[common.Hash]common.Hash `json:"storage,omitempty"` Balance *big.Int `json:"balance" gencodec:"required"` Nonce uint64 `json:"nonce,omitempty"` PrivateKey []byte `json:"secretKey,omitempty"` &#125;type ChainConfig struct &#123; ChainID *big.Int `json:"chainId"` HomesteadBlock *big.Int `json:"homesteadBlock,omitempty"` DAOForkBlock *big.Int `json:"daoForkBlock,omitempty"` DAOForkSupport bool `json:"daoForkSupport,omitempty"` EIP150Block *big.Int `json:"eip150Block,omitempty"` EIP150Hash common.Hash `json:"eip150Hash,omitempty"` EIP155Block *big.Int `json:"eip155Block,omitempty"` EIP158Block *big.Int `json:"eip158Block,omitempty"` ByzantiumBlock *big.Int `json:"byzantiumBlock,omitempty"` ConstantinopleBlock *big.Int `json:"constantinopleBlock,omitempty"` PetersburgBlock *big.Int `json:"petersburgBlock,omitempty"` EWASMBlock *big.Int `json:"ewasmBlock,omitempty"` Ethash *EthashConfig `json:"ethash,omitempty"` Clique *CliqueConfig `json:"clique,omitempty"`&#125;type EthashConfig struct&#123;&#125;type CliqueConfig struct &#123; Period uint64 `json:"period"` Epoch uint64 `json:"epoch"` &#125; 上面给出了创世区块的完整定义，每个字段后面都有json标签，说明可以进行json的序列化和反序列化操作，事实上我们在指定一个创世区块时就是通过json文件配置的，官网给出了一个创世区块json文件的例子1234567891011121314151617181920&#123; "config": &#123; "chainId": 0, "homesteadBlock": 0, "eip155Block": 0, "eip158Block": 0 &#125;, "alloc": &#123; "0x0000000000000000000000000000000000000001": &#123;"balance": "111111111"&#125;, "0x0000000000000000000000000000000000000002": &#123;"balance": "222222222"&#125; &#125;, "coinbase" : "0x0000000000000000000000000000000000000000", "difficulty" : "0x20000", "extraData" : "", "gasLimit" : "0x2fefd8", "nonce" : "0x0000000000000042", "mixhash" : "0x0000000000000000000000000000000000000000000000000000000000000000", "parentHash" : "0x0000000000000000000000000000000000000000000000000000000000000000", "timestamp" : "0x00"&#125; 其中，config中的chainId是网络标识，注意1表示以太坊主网；homesteadBlock、eip155Block和eip158Block是表示几个版本升级时硬分叉的高度，为nil表示不分叉。剩余的基本就是区块中一些固定的内容。 SetupGenesisBlock在初始化区块链的时候就是调用这个方法来配置创世区块1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556func SetupGenesisBlock(db ethdb.Database, genesis *Genesis) (*params.ChainConfig, common.Hash, error) &#123; return SetupGenesisBlockWithOverride(db, genesis, nil)&#125;func SetupGenesisBlockWithOverride(db ethdb.Database, genesis *Genesis, constantinopleOverride *big.Int) (*params.ChainConfig, common.Hash, error) &#123; if genesis != nil &amp;&amp; genesis.Config == nil &#123; return params.AllEthashProtocolChanges, common.Hash&#123;&#125;, errGenesisNoConfig &#125; stored := rawdb.ReadCanonicalHash(db, 0) if (stored == common.Hash&#123;&#125;) &#123; if genesis == nil &#123; log.Info("Writing default main-net genesis block") genesis = DefaultGenesisBlock() &#125; else &#123; log.Info("Writing custom genesis block") &#125; block, err := genesis.Commit(db) return genesis.Config, block.Hash(), err &#125; if genesis != nil &#123; hash := genesis.ToBlock(nil).Hash() if hash != stored &#123; return genesis.Config, hash, &amp;GenesisMismatchError&#123;stored, hash&#125; &#125; &#125; newcfg := genesis.configOrDefault(stored) if constantinopleOverride != nil &#123; newcfg.ConstantinopleBlock = constantinopleOverride newcfg.PetersburgBlock = constantinopleOverride &#125; storedcfg := rawdb.ReadChainConfig(db, stored) if storedcfg == nil &#123; log.Warn("Found genesis block without chain config") rawdb.WriteChainConfig(db, stored, newcfg) return newcfg, stored, nil &#125; if genesis == nil &amp;&amp; stored != params.MainnetGenesisHash &#123; return storedcfg, stored, nil &#125; height := rawdb.ReadHeaderNumber(db, rawdb.ReadHeadHeaderHash(db)) if height == nil &#123; return newcfg, stored, fmt.Errorf("missing block number for head header hash") &#125; compatErr := storedcfg.CheckCompatible(newcfg, *height) if compatErr != nil &amp;&amp; *height != 0 &amp;&amp; compatErr.RewindTo != 0 &#123; return newcfg, stored, compatErr &#125; rawdb.WriteChainConfig(db, stored, newcfg) return newcfg, stored, nil&#125; 传入的参数就是一个已经解析过的Genesis对象。首先判断config字段是否为空，因为这里面至少定义了一个网络ID。接下来调用了ReadCanonicalHash方法，ReadCanonicalHash实际上就是ethdb的get方法封装，这里读取了编号为0的区块hash，也就是尝试从数据库中读取创世区块。 接下来分四种情况，在源码开头已经给出了：12345// genesis == nil genesis != nil// +------------------------------------------// db has no genesis | main-net default | genesis// db has genesis | from DB | genesis (if compatible)// 情况一：外部genesis与数据库中genesis都为空首先如果读取到的为空表示没有初始化过。接下来如果传入的genesis对象也为为空时，符合注释中的第一种情况，就调用DefaultGenesisBlock配置默认的创世区块，也就是主网下创世区块。这一般在默认连接主网时出现12345678910111213141516171819202122232425func DefaultGenesisBlock() *Genesis &#123; return &amp;Genesis&#123; Config: params.MainnetChainConfig, Nonce: 66, ExtraData: hexutil.MustDecode("0x11bbe8db4e347b4e8c937c1c8370e4b5ed33adb3db69cbdb7a38e1e50b1b82fa"), GasLimit: 5000, Difficulty: big.NewInt(17179869184), Alloc: decodePrealloc(mainnetAllocData), &#125;&#125; MainnetChainConfig = &amp;ChainConfig&#123; ChainID: big.NewInt(1), HomesteadBlock: big.NewInt(1150000), DAOForkBlock: big.NewInt(1920000), DAOForkSupport: true, EIP150Block: big.NewInt(2463000), EIP150Hash: common.HexToHash("0x2086799aeebeae135c246c65021c82b4e15a2c451340993aacfd2751886514f0"), EIP155Block: big.NewInt(2675000), EIP158Block: big.NewInt(2675000), ByzantiumBlock: big.NewInt(4370000), ConstantinopleBlock: big.NewInt(7280000), PetersburgBlock: big.NewInt(7280000), Ethash: new(EthashConfig), &#125; 主网的创世区块配置中的Alloc字段是在core/genesis_alloc.go中写的。另外可以看到主网的ID是1，还有几次硬分叉的高度。 情况二：只有数据库中的genesis为空回到SetupGenesisBlock中，如果我们传来的创世区块不为空，但是本地数据库中没有存储过创世区块的话，这一般在指定配置文件时第一次初始化出现，则调用commit方法将我们指定的genesis提交到数据库，commit方法后面再介绍 情况三：外部genesis与数据库中genesis都不为空如果本地数据库存的有genesis数据，外部指定的也有genesis数据，先对二者的区块进行比较，就是对hash比较，不一样的报错返回。只有在一样的情况下继续执行，这时先通过configOrDefault获取我们指定的配置信息，然后利用ReadChainConfig从数据库读取旧的配置信息，然后在获取区块链高度，之后进行兼容性判断，兼容的话利用WriteChainConfig把我们指定的配置信息写入数据库 情况四：只有外部的genesis为空对应这种情况，也是先通过configOrDefault根据本地存储的创世区块hash值获取某个预制的配置信息，在获取的配置信息不是主网配置信息的情况下不做任何改变，也就是说是其他配置信息的话就和有外部Genesis一样进行兼容性检测人后写入。 configOrDefault123456789101112func (g *Genesis) configOrDefault(ghash common.Hash) *params.ChainConfig &#123; switch &#123; case g != nil: return g.Config case ghash == params.MainnetGenesisHash: return params.MainnetChainConfig case ghash == params.TestnetGenesisHash: return params.TestnetChainConfig default: return params.AllEthashProtocolChanges &#125;&#125; commitcommit方法是将我们指定的创世区块写入数据库1234567891011121314151617181920func (g *Genesis) Commit(db ethdb.Database) (*types.Block, error) &#123; block := g.ToBlock(db) if block.Number().Sign() != 0 &#123; return nil, fmt.Errorf("can't commit genesis block with number &gt; 0") &#125; rawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty) rawdb.WriteBlock(db, block) rawdb.WriteReceipts(db, block.Hash(), block.NumberU64(), nil) rawdb.WriteCanonicalHash(db, block.Hash(), block.NumberU64()) rawdb.WriteHeadBlockHash(db, block.Hash()) rawdb.WriteHeadHeaderHash(db, block.Hash()) config := g.Config if config == nil &#123; config = params.AllEthashProtocolChanges &#125; rawdb.WriteChainConfig(db, block.Hash(), config) return block, nil&#125; ToBlock首先调用了ToBlock方法创建了一个区块12345678910111213141516171819202122232425262728293031323334353637383940func (g *Genesis) ToBlock(db ethdb.Database) *types.Block &#123; if db == nil &#123; db = ethdb.NewMemDatabase() &#125; statedb, _ := state.New(common.Hash&#123;&#125;, state.NewDatabase(db)) for addr, account := range g.Alloc &#123; statedb.AddBalance(addr, account.Balance) statedb.SetCode(addr, account.Code) statedb.SetNonce(addr, account.Nonce) for key, value := range account.Storage &#123; statedb.SetState(addr, key, value) &#125; &#125; root := statedb.IntermediateRoot(false) head := &amp;types.Header&#123; Number: new(big.Int).SetUint64(g.Number), Nonce: types.EncodeNonce(g.Nonce), Time: new(big.Int).SetUint64(g.Timestamp), ParentHash: g.ParentHash, Extra: g.ExtraData, GasLimit: g.GasLimit, GasUsed: g.GasUsed, Difficulty: g.Difficulty, MixDigest: g.Mixhash, Coinbase: g.Coinbase, Root: root, &#125; if g.GasLimit == 0 &#123; head.GasLimit = params.GenesisGasLimit //默认为4712388 go-ethereum\params\protocol_params.go &#125; if g.Difficulty == nil &#123; head.Difficulty = params.GenesisDifficulty //默认为131072 &#125; statedb.Commit(false) statedb.Database().TrieDB().Commit(root, true) return types.NewBlock(head, nil, nil, nil)&#125; 在ToBlock，如果传入的数据库对象为空，则建立一个内存数据库，这个我们在分析ethdb源码时分析过，随后调用了state.New方法，关于state见这篇文章,这里返回的StateDB用于操作账户。随后遍历了alloc字段，这是预分配余额，对于每个账户都写入相应的余额、代码、随机数和存储的数据。之后调用IntermediateRoot获取临时的根hash，接着构建了区块头，填入了头部的各项信息，基本都是按照创世区块来的。随后调用statedb.Commit把前面statedb所做的变动进行提交，注意IntermediateRoot只是暂时算出当前状态树的根并没有持久化到数据库。 接着又调用了statedb.Database().TrieDB().Commit(root, true)，我们一段一段分析，statedb.Database()是获取的StateDB的db对象，这个变量我们前面在创建statedb时通过state.NewDatabase方法构建，他返回一个cachingDB对象，而cachingDB的TrieDB返回它自己的db对象，这是一个trie包里的Database对象，这个对象保存了我们最初传入的ethdb.Database对象。它的Commit方法实际上就是将树最后写入数据库中，关于这一部分见前面tire源码分析 回到ToBlock，最后调用NewBlock构建了一个区块对象123456789101112131415161718192021222324252627282930func NewBlock(header *Header, txs []*Transaction, uncles []*Header, receipts []*Receipt) *Block &#123; b := &amp;Block&#123;header: CopyHeader(header), td: new(big.Int)&#125; if len(txs) == 0 &#123; b.header.TxHash = EmptyRootHash &#125; else &#123; b.header.TxHash = DeriveSha(Transactions(txs)) b.transactions = make(Transactions, len(txs)) copy(b.transactions, txs) &#125; if len(receipts) == 0 &#123; b.header.ReceiptHash = EmptyRootHash &#125; else &#123; b.header.ReceiptHash = DeriveSha(Receipts(receipts)) b.header.Bloom = CreateBloom(receipts) &#125; if len(uncles) == 0 &#123; b.header.UncleHash = EmptyUncleHash &#125; else &#123; b.header.UncleHash = CalcUncleHash(uncles) b.uncles = make([]*Header, len(uncles)) for i := range uncles &#123; b.uncles[i] = CopyHeader(uncles[i]) &#125; &#125; return b&#125; 传入的参数有区块头，交易集合、叔块头和收据，我们在这里还要补全交易树和收据树的根，我们看一下根hash如何计算12345678910111213141516// go-ethereum\core\types\derive_sha.gofunc DeriveSha(list DerivableList) common.Hash &#123; keybuf := new(bytes.Buffer) trie := new(trie.Trie) for i := 0; i &lt; list.Len(); i++ &#123; keybuf.Reset() rlp.Encode(keybuf, uint(i)) trie.Update(keybuf.Bytes(), list.GetRlp(i)) &#125; return trie.Hash()&#125;func (s Transactions) GetRlp(i int) []byte &#123; enc, _ := rlp.EncodeToBytes(s[i]) return enc&#125; 首先新建一棵树，要插入的key就是其所在集合中的编号，值时经过rlp编码的数据，最后计算树的根hash即可。 对于叔块的hash计算如下：12345678910func CalcUncleHash(uncles []*Header) common.Hash &#123; return rlpHash(uncles)&#125;func rlpHash(x interface&#123;&#125;) (h common.Hash) &#123; hw := sha3.NewLegacyKeccak256() rlp.Encode(hw, x) hw.Sum(h[:0]) return h&#125; 首先进行rlp编码然后计算sha3-256的值即可。 写数据库回到Genesis中，ToBlock返回了一个区块对象也就是创世区块，接下来调用了rawdb包中的许多方法，rawdb实际上就是一个包装类，封装了一些操作数据库的方法，底层还是使用ethdb的相关方法。首先写入了总难度12345678910111213141516171819202122232425func WriteTd(db DatabaseWriter, hash common.Hash, number uint64, td *big.Int) &#123; data, err := rlp.EncodeToBytes(td) if err != nil &#123; log.Crit("Failed to RLP encode block total difficulty", "err", err) &#125; if err := db.Put(headerTDKey(number, hash), data); err != nil &#123; log.Crit("Failed to store block total difficulty", "err", err) &#125;&#125;func headerTDKey(number uint64, hash common.Hash) []byte &#123; return append(headerKey(number, hash), headerTDSuffix...)&#125;func headerKey(number uint64, hash common.Hash) []byte &#123; return append(append(headerPrefix, encodeBlockNumber(number)...), hash.Bytes()...)&#125;headerPrefix = []byte("h")func encodeBlockNumber(number uint64) []byte &#123; enc := make([]byte, 8) binary.BigEndian.PutUint64(enc, number) return enc&#125; 向数据库中写入总难度时，先对key进行了构造:1byte(&apos;h&apos;) + 区块编号的大端表示（长度8字节） + 区块hash + byte(&apos;t&apos;) 之后开始写入区块1234func WriteBlock(db DatabaseWriter, block *types.Block) &#123; WriteBody(db, block.Hash(), block.NumberU64(), block.Body()) WriteHeader(db, block.Header())&#125; 先写区块体123456789101112131415161718192021func (b *Block) Body() *Body &#123; return &amp;Body&#123;b.transactions, b.uncles&#125; &#125;func WriteBody(db DatabaseWriter, hash common.Hash, number uint64, body *types.Body) &#123; data, err := rlp.EncodeToBytes(body) if err != nil &#123; log.Crit("Failed to RLP encode body", "err", err) &#125; WriteBodyRLP(db, hash, number, data)&#125;func WriteBodyRLP(db DatabaseWriter, hash common.Hash, number uint64, rlp rlp.RawValue) &#123; if err := db.Put(blockBodyKey(number, hash), rlp); err != nil &#123; log.Crit("Failed to store block body", "err", err) &#125;&#125;func blockBodyKey(number uint64, hash common.Hash) []byte &#123; return append(append(blockBodyPrefix, encodeBlockNumber(number)...), hash.Bytes()...)&#125;blockBodyPrefix = []byte("b") 首先所谓的区块体就是一个只包含交易和叔块头的结构体，存储时先对其进行rlp编码，然后存入数据库，存入的key如下构成1byte('b') + 区块编号的大端表示（长度8字节） + 区块hash 写入完区块体后写入区块头123456789101112131415161718192021222324252627282930func WriteHeader(db DatabaseWriter, header *types.Header) &#123; var ( hash = header.Hash() number = header.Number.Uint64() encoded = encodeBlockNumber(number) ) key := headerNumberKey(hash) if err := db.Put(key, encoded); err != nil &#123; log.Crit("Failed to store hash to number mapping", "err", err) &#125; data, err := rlp.EncodeToBytes(header) if err != nil &#123; log.Crit("Failed to RLP encode header", "err", err) &#125; key = headerKey(number, hash) if err := db.Put(key, data); err != nil &#123; log.Crit("Failed to store header", "err", err) &#125;&#125;func headerNumberKey(hash common.Hash) []byte &#123; return append(headerNumberPrefix, hash.Bytes()...)&#125;headerNumberPrefix = []byte("H")func headerKey(number uint64, hash common.Hash) []byte &#123; return append(append(headerPrefix, encodeBlockNumber(number)...), hash.Bytes()...)&#125; 这里首先存储区块编号，构建的key结构如下1byte(&apos;H&apos;) + 区块头hash 之后再存储区块头，先进行rlp编码，再构建key，结构如下1byte(&apos;h&apos;) + 区块编号的大端表示（长度8字节） + 区块头hash 接着又存储了收据信息，区块hash，当前区块（区块头顶部区块）hash以及当前区块头hash。还要写入配置信息，不过如果配置为空则加载一个默认配置1AllEthashProtocolChanges = &amp;ChainConfig&#123;big.NewInt(1337), big.NewInt(0), nil, false, big.NewInt(0), common.Hash&#123;&#125;, big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), big.NewInt(0), nil, new(EthashConfig), nil&#125; 最后commit方法返回开始创建的区块对象。回到SetupGenesisBlock中，此时创世区块配置完毕返回其配置和区块hash。 题图来自unsplash：https://unsplash.com/photos/_aASE0L1I1g]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中core-state源码学习]]></title>
    <url>%2F2019%2F05%2F17%2Fgo-ethereum%E4%B8%ADcore-state%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[core里的state包提供了账户状态的管理，包括状态转换以及回滚等操作。 datebase.go首先提供了数据库的抽象，定义了一个接口：12345678910111213type Database interface &#123; OpenTrie(root common.Hash) (Trie, error) OpenStorageTrie(addrHash, root common.Hash) (Trie, error) CopyTrie(Trie) Trie ContractCode(addrHash, codeHash common.Hash) ([]byte, error) ContractCodeSize(addrHash, codeHash common.Hash) (int, error) TrieDB() *trie.Database&#125; OpenTrie是打开主账号的树，OpenStorageTrie是打开某个账号的数，CopyTrie就是复制，ContractCode是访问合约代码，ContractCodeSize获取合约大小，TrieDB访问底层数据库 new提供了两个创建该数据库的方法，NewDatabase和NewDatabaseWithCache就是一个带缓冲一个不带缓冲1234567891011func NewDatabase(db ethdb.Database) Database &#123; return NewDatabaseWithCache(db, 0)&#125;func NewDatabaseWithCache(db ethdb.Database, cache int) Database &#123; csc, _ := lru.New(codeSizeCacheSize) return &amp;cachingDB&#123; db:trie.NewDatabaseWithCache(db, cache), codeSizeCache: csc, &#125;&#125; 构建了一个cachingDB对象，其中有一个实际的数据库用的是trie的NewDatabaseWithCache方法创建的12345678910111213141516171819// go-ethereum\trie\database.gofunc NewDatabaseWithCache(diskdb ethdb.Database, cache int) *Database &#123; var cleans *bigcache.BigCache if cache &gt; 0 &#123; cleans, _ = bigcache.NewBigCache(bigcache.Config&#123; Shards: 1024, LifeWindow: time.Hour, MaxEntriesInWindow: cache * 1024, MaxEntrySize: 512, HardMaxCacheSize: cache, &#125;) &#125; return &amp;Database&#123; diskdb: diskdb, cleans: cleans, dirties: map[common.Hash]*cachedNode&#123;&#123;&#125;: &#123;&#125;&#125;, preimages: make(map[common.Hash][]byte), &#125;&#125; OpenTrie123456789101112131415func (db *cachingDB) OpenTrie(root common.Hash) (Trie, error) &#123; db.mu.Lock() defer db.mu.Unlock() for i := len(db.pastTries) - 1; i &gt;= 0; i-- &#123; if db.pastTries[i].Hash() == root &#123; return cachedTrie&#123;db.pastTries[i].Copy(), db&#125;, nil &#125; &#125; tr, err := trie.NewSecure(root, db.db, MaxTrieCacheGen) if err != nil &#123; return nil, err &#125; return cachedTrie&#123;tr, db&#125;, nil&#125; 前面说过这个方法是打开主账户的树，这里首先从pastTries中查找，有的话用一个cachedTrie对象包装后返回，没有的话调用NewSecure区创建一个，创建的是一个SecureTrie类型的数，前面我们分析trie源码时听到过，SecureTrie就是trie的包装。前面没有详细分析SecureTrie源码，这里来看一下：1234567891011func NewSecure(root common.Hash, db *Database, cachelimit uint16) (*SecureTrie, error) &#123; if db == nil &#123; panic("trie.NewSecure called without a database") &#125; trie, err := New(root, db) if err != nil &#123; return nil, err &#125; trie.SetCacheLimit(cachelimit) return &amp;SecureTrie&#123;trie: *trie&#125;, nil&#125; 创建很简单，就是用New方法创建一个普通的树，然后构造出一个SecureTrie对象。OpenTrie方法最后返回的是一个cachedTrie对象，里面包装了SecureTrie和cachingDB。 OpenStorageTrie这个很简单直接创建一个SecureTrie123func (db *cachingDB) OpenStorageTrie(addrHash, root common.Hash) (Trie, error) &#123; return trie.NewSecure(root, db.db, 0)&#125; ContractCode &amp; ContractCodeSize1234567func (db *cachingDB) ContractCode(addrHash, codeHash common.Hash) ([]byte, error) &#123; code, err := db.db.Node(codeHash) if err == nil &#123; db.codeSizeCache.Add(codeHash, len(code)) &#125; return code, err&#125; Node实际上就根据hash从数据库中取值，取值完成后我们会将其放入前面创建的缓存中，这是一个lru缓存，便于下次取。1234567func (db *cachingDB) ContractCodeSize(addrHash, codeHash common.Hash) (int, error) &#123; if cached, ok := db.codeSizeCache.Get(codeHash); ok &#123; return cached.(int), nil &#125; code, err := db.ContractCode(addrHash, codeHash) return len(code), err&#125; 也是一个先取后计算长度的过程 CommitCommit就是将树缓存起来1234567func (m cachedTrie) Commit(onleaf trie.LeafCallback) (common.Hash, error) &#123; root, err := m.SecureTrie.Commit(onleaf) if err == nil &#123; m.db.pushTrie(m.SecureTrie) &#125; return root, err&#125; 首先调用了SecureTrie的Commit方法，检查源码实际上调用了其包装的trie的commit方法，之前分析过trie源码，Commit是序列化方法，是将一颗树存储到数据库中，返回的是树根的hash。在cachedTrie的Commit方法中，如果没有错首先将原来的树缓存到pastTries中，然后返回提交的结果。 journal.go先看数据结构1234type journal struct &#123; entries []journalEntry // Current changes tracked by the journal dirties map[common.Address]int // Dirty accounts and the number of changes&#125; 包含了一个journalEntry数组和一个map，journalEntry相当于一条日志，dirties记录了某个账户改动次数。journalEntry是一个接口，如下定义12345type journalEntry interface &#123; revert(*StateDB) dirtied() *common.Address&#125; revert是用于撤销操作的，dirtied返回对应的账户地址。对应接口定义了大量的journalEntry类型对象123456789101112131415161718192021222324252627282930313233343536373839404142434445type ( createObjectChange struct &#123; account *common.Address &#125; resetObjectChange struct &#123; prev *stateObject &#125; suicideChange struct &#123; account *common.Address prev bool // whether account had already suicided prevbalance *big.Int &#125; balanceChange struct &#123; account *common.Address prev *big.Int &#125; nonceChange struct &#123; account *common.Address prev uint64 &#125; storageChange struct &#123; account *common.Address key, prevalue common.Hash &#125; codeChange struct &#123; account *common.Address prevcode, prevhash []byte &#125; refundChange struct &#123; prev uint64 &#125; addLogChange struct &#123; txhash common.Hash &#125; addPreimageChange struct &#123; hash common.Hash &#125; touchChange struct &#123; account *common.Address prev bool prevDirty bool &#125;) 每种struct都对应了不同的事件日志。当然种都有revert和dirtied方法我们后面具体遇到了在分析。 state_object.gostateObject代表了正在修改的以太坊账户，数据结构如下12345678910111213141516171819type stateObject struct &#123; address common.Address addrHash common.Hash data Account db *StateDB dbErr error trie Trie code Code originStorage Storage dirtyStorage Storage dirtyCode bool // true if the code was updated suicided bool deleted bool&#125; 根据源码注释，要想修改账户，需要首先获取stateObject，然后通过这个对象访问修改，最后提交进行持久化存储。 new12345678910111213141516func newObject(db *StateDB, address common.Address, data Account) *stateObject &#123; if data.Balance == nil &#123; data.Balance = new(big.Int) &#125; if data.CodeHash == nil &#123; data.CodeHash = emptyCodeHash &#125; return &amp;stateObject&#123; db: db, address: address, addrHash: crypto.Keccak256Hash(address[:]), data: data, originStorage: make(Storage), dirtyStorage: make(Storage), &#125;&#125; 需要传入地址和账户的对象才能构造一个stateObject对象。 SetStateSetState是更新账户存储中的某个值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253func (self *stateObject) SetState(db Database, key, value common.Hash) &#123; prev := self.GetState(db, key) if prev == value &#123; return &#125; self.db.journal.append(storageChange&#123; account: &amp;self.address, key: key, prevalue: prev, &#125;) self.setState(key, value)&#125;func (self *stateObject) GetState(db Database, key common.Hash) common.Hash &#123; value, dirty := self.dirtyStorage[key] if dirty &#123; return value &#125; return self.GetCommittedState(db, key)&#125;func (self *stateObject) GetCommittedState(db Database, key common.Hash) common.Hash &#123; value, cached := self.originStorage[key] if cached &#123; return value &#125; enc, err := self.getTrie(db).TryGet(key[:]) if err != nil &#123; self.setError(err) return common.Hash&#123;&#125; &#125; if len(enc) &gt; 0 &#123; _, content, _, err := rlp.Split(enc) if err != nil &#123; self.setError(err) &#125; value.SetBytes(content) &#125; self.originStorage[key] = value return value&#125;func (c *stateObject) getTrie(db Database) Trie &#123; if c.trie == nil &#123; var err error c.trie, err = db.OpenStorageTrie(c.addrHash, c.data.Root) if err != nil &#123; c.trie, _ = db.OpenStorageTrie(c.addrHash, common.Hash&#123;&#125;) c.setError(fmt.Errorf("can't create storage trie: %v", err)) &#125; &#125; return c.trie&#125; 首先用了GetState方法去取旧的值，GetState方法中先访问dirtyStorage，这也是一个缓存机制，取不到的话调用GetCommittedState，GetCommittedState也是先访问originStorage这个缓存，originStorage与dirtyStorage的区别是，originStorage是已经持久化过的，dirtyStorage而是未持久化的。还找不到的话就需要访问本地数据库了，调用getTrie获取树。GetCommittedState方法如果是从数据库取值的话就向originStorage从缓存一份。 回到SetState中，如果旧值和新值一样，就直接返回，否则新建一个storageChange类型的journalEntry放入journal的entries中，最后调用setState方法，setState主要是向dirtyStorage中缓存。我们顺便看一下storageChange123456789101112storageChange struct &#123; account *common.Address key, prevalue common.Hash&#125;func (ch storageChange) revert(s *StateDB) &#123; s.getStateObject(*ch.account).setState(ch.key, ch.prevalue)&#125;func (ch storageChange) dirtied() *common.Address &#123; return ch.account&#125; storageChange主要存储了状态改变前后的新旧值和对应地址。所以revert方法就是取对应状态恢复到旧值 SetBalance1234567891011func (self *stateObject) SetBalance(amount *big.Int) &#123; self.db.journal.append(balanceChange&#123; account: &amp;self.address, prev: new(big.Int).Set(self.data.Balance), &#125;) self.setBalance(amount)&#125;func (self *stateObject) setBalance(amount *big.Int) &#123; self.data.Balance = amount&#125; 就是修改账户的余额，给日志添加了balanceChange，还有两个加减方法1234567891011121314151617func (c *stateObject) AddBalance(amount *big.Int) &#123; if amount.Sign() == 0 &#123; if c.empty() &#123; c.touch() &#125; return &#125; c.SetBalance(new(big.Int).Add(c.Balance(), amount))&#125;func (c *stateObject) SubBalance(amount *big.Int) &#123; if amount.Sign() == 0 &#123; return &#125; c.SetBalance(new(big.Int).Sub(c.Balance(), amount))&#125; 都要首先判断加减值是否为0，对于加的情况，如果值为0而且账户也为空（即nonce为0，余额为0,，账户代码也为空）则调用touch方法，touch方法个日志添加了touchChange操作。 下面我们先看一下balanceChange。touchChange没有实际操作1234567891011balanceChange struct &#123; account *common.Address prev *big.Int&#125;func (ch balanceChange) revert(s *StateDB) &#123; s.getStateObject(*ch.account).setBalance(ch.prev)&#125;func (ch balanceChange) dirtied() *common.Address &#123; return ch.account&#125; 也很简单，就是存储了先前的值，然后回滚时设置余额为之前的值。 SetCode123456789101112131415161718192021222324252627282930func (self *stateObject) SetCode(codeHash common.Hash, code []byte) &#123; prevcode := self.Code(self.db.db) self.db.journal.append(codeChange&#123; account: &amp;self.address, prevhash: self.CodeHash(), prevcode: prevcode, &#125;) self.setCode(codeHash, code)&#125;func (self *stateObject) Code(db Database) []byte &#123; if self.code != nil &#123; return self.code &#125; if bytes.Equal(self.CodeHash(), emptyCodeHash) &#123; return nil &#125; code, err := db.ContractCode(self.addrHash, common.BytesToHash(self.CodeHash())) if err != nil &#123; self.setError(fmt.Errorf("can't load code hash %x: %v", self.CodeHash(), err)) &#125; self.code = code return code&#125;func (self *stateObject) setCode(codeHash common.Hash, code []byte) &#123; self.code = code self.data.CodeHash = codeHash[:] self.dirtyCode = true&#125; 首先取之前的code，取得方法还是先从缓存取，取不到再去数据库取，有两集缓存，一级是stateObject的code字段，每次set都会更新，；另一级是Database的ContractCode取的时候会坚持codeSizeCache缓存，都没有再从数据库取。设置code时，也给日志添加了codeChange。123456789101112codeChange struct &#123; account *common.Address prevcode, prevhash []byte&#125; func (ch codeChange) revert(s *StateDB) &#123; s.getStateObject(*ch.account).setCode(common.BytesToHash(ch.prevhash), ch.prevcode)&#125;func (ch codeChange) dirtied() *common.Address &#123; return ch.account&#125; 和storageChange逻辑类似 SetNonce123456789101112131415161718192021222324func (self *stateObject) SetNonce(nonce uint64) &#123; self.db.journal.append(nonceChange&#123; account: &amp;self.address, prev: self.data.Nonce, &#125;) self.setNonce(nonce)&#125;func (self *stateObject) setNonce(nonce uint64) &#123; self.data.Nonce = nonce&#125;nonceChange struct &#123; account *common.Address prev uint64&#125;func (ch nonceChange) revert(s *StateDB) &#123; s.getStateObject(*ch.account).setNonce(ch.prev)&#125;func (ch nonceChange) dirtied() *common.Address &#123; return ch.account&#125; 和balance一样的逻辑，不在多说 CommitTrie刚才的set方法都只是改变了stateObject的值，没有实际的持久化，要持久化需要这个方法12345678910111213141516171819202122232425262728293031func (self *stateObject) CommitTrie(db Database) error &#123; self.updateTrie(db) if self.dbErr != nil &#123; return self.dbErr &#125; root, err := self.trie.Commit(nil) if err == nil &#123; self.data.Root = root &#125; return err&#125;func (self *stateObject) updateTrie(db Database) Trie &#123; tr := self.getTrie(db) for key, value := range self.dirtyStorage &#123; delete(self.dirtyStorage, key) if value == self.originStorage[key] &#123; continue &#125; self.originStorage[key] = value if (value == common.Hash&#123;&#125;) &#123; self.setError(tr.TryDelete(key[:])) continue &#125; v, _ := rlp.EncodeToBytes(bytes.TrimLeft(value[:], "\x00")) self.setError(tr.TryUpdate(key[:], v)) &#125; return tr&#125; 首先调用updateTrie更新树，updateTrie中现获取了树，随后遍历了dirtyStorage，前面说过这是未持久化的值，取出的每个值先和originStorage中的比较，一样的就不操作，随后对于空值记录一个错误，最后先rlp编码，最后调用TryUpdate更新，TryUpdate是SecureTrie中的方法：123456789func (t *SecureTrie) TryUpdate(key, value []byte) error &#123; hk := t.hashKey(key) err := t.trie.TryUpdate(hk, value) if err != nil &#123; return err &#125; t.getSecKeyCache()[string(hk)] = common.CopyBytes(key) return nil&#125; 还是调用trie的TryUpdate方法，TryUpdate方法之前分析trie源码时没有将，不过也很简单1234567891011121314151617func (t *Trie) TryUpdate(key, value []byte) error &#123; k := keybytesToHex(key) if len(value) != 0 &#123; _, n, err := t.insert(t.root, nil, k, valueNode(value)) if err != nil &#123; return err &#125; t.root = n &#125; else &#123; _, n, err := t.delete(t.root, nil, k) if err != nil &#123; return err &#125; t.root = n &#125; return nil&#125; 首先对于key长度不为0的话就进行插入来更新，否则执行删除逻辑。回到stateobject中，在更新完毕后，如果没错，就调用commit方法持久化存储。 statedb.goStateDB负责缓存和存储嵌套状态。主要用于检索合约和账户。1234567891011121314151617181920212223type StateDB struct &#123; db Database trie Trie stateObjects map[common.Address]*stateObject stateObjectsDirty map[common.Address]struct&#123;&#125; dbErr error refund uint64 thash, bhash common.Hash txIndex int logs map[common.Hash][]*types.Log logSize uint preimages map[common.Hash][]byte journal *journal validRevisions []revision nextRevisionId int&#125; 基本包含了前面分析的三种结构体。 new123456789101112131415func New(root common.Hash, db Database) (*StateDB, error) &#123; tr, err := db.OpenTrie(root) if err != nil &#123; return nil, err &#125; return &amp;StateDB&#123; db: db, trie: tr, stateObjects: make(map[common.Address]*stateObject), stateObjectsDirty: make(map[common.Address]struct&#123;&#125;), logs: make(map[common.Hash][]*types.Log), preimages: make(map[common.Hash][]byte), journal: newJournal(), &#125;, nil&#125; 首先调用了OpenTrie打开主账户的树，然后构造了StateDB对象。 AddLog这个log并不是程序log，它代表合约的log事件12345678910func (self *StateDB) AddLog(log *types.Log) &#123; self.journal.append(addLogChange&#123;txhash: self.thash&#125;) log.TxHash = self.thash log.BlockHash = self.bhash log.TxIndex = uint(self.txIndex) log.Index = self.logSize self.logs[self.thash] = append(self.logs[self.thash], log) self.logSize++&#125; 首先补全log信息，然后按交易hash放到logs中，关于thash和bhash是在Prepare中设置的12345func (self *StateDB) Prepare(thash, bhash common.Hash, ti int) &#123; self.thash = thash self.bhash = bhash self.txIndex = ti&#125; 在AddLog开始的时候还向journal添加了addLogChange12345678910111213141516addLogChange struct &#123; txhash common.Hash&#125;func (ch addLogChange) revert(s *StateDB) &#123; logs := s.logs[ch.txhash] if len(logs) == 1 &#123; delete(s.logs, ch.txhash) &#125; else &#123; s.logs[ch.txhash] = logs[:len(logs)-1] &#125; s.logSize--&#125;func (ch addLogChange) dirtied() *common.Address &#123; return nil&#125; addLogChange只有一个字段，它的回滚就是将最后的log删除。此外关于log还有两个方法，都是取的1234567891011func (self *StateDB) GetLogs(hash common.Hash) []*types.Log &#123; return self.logs[hash]&#125;func (self *StateDB) Logs() []*types.Log &#123; var logs []*types.Log for _, lgs := range self.logs &#123; logs = append(logs, lgs...) &#125; return logs&#125; GetXxx &amp; SetXxx有一系列get和set方法，也就体现了statedb作为对外开放接口的作用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func (self *StateDB) GetBalance(addr common.Address) *big.Int &#123; stateObject := self.getStateObject(addr) if stateObject != nil &#123; return stateObject.Balance() &#125; return common.Big0&#125;func (self *StateDB) GetNonce(addr common.Address) uint64 &#123; stateObject := self.getStateObject(addr) if stateObject != nil &#123; return stateObject.Nonce() &#125; return 0&#125;func (self *StateDB) GetCode(addr common.Address) []byte &#123; stateObject := self.getStateObject(addr) if stateObject != nil &#123; return stateObject.Code(self.db) &#125; return nil&#125;func (self *StateDB) GetCodeSize(addr common.Address) int &#123; stateObject := self.getStateObject(addr) if stateObject == nil &#123; return 0 &#125; if stateObject.code != nil &#123; return len(stateObject.code) &#125; size, err := self.db.ContractCodeSize(stateObject.addrHash, common.BytesToHash(stateObject.CodeHash())) if err != nil &#123; self.setError(err) &#125; return size&#125;func (self *StateDB) GetCodeHash(addr common.Address) common.Hash &#123; stateObject := self.getStateObject(addr) if stateObject == nil &#123; return common.Hash&#123;&#125; &#125; return common.BytesToHash(stateObject.CodeHash())&#125;func (self *StateDB) GetState(addr common.Address, hash common.Hash) common.Hash &#123; stateObject := self.getStateObject(addr) if stateObject != nil &#123; return stateObject.GetState(self.db, hash) &#125; return common.Hash&#123;&#125;&#125;func (self *StateDB) GetCommittedState(addr common.Address, hash common.Hash) common.Hash &#123; stateObject := self.getStateObject(addr) if stateObject != nil &#123; return stateObject.GetCommittedState(self.db, hash) &#125; return common.Hash&#123;&#125;&#125;func (self *StateDB) StorageTrie(addr common.Address) Trie &#123; stateObject := self.getStateObject(addr) if stateObject == nil &#123; return nil &#125; cpy := stateObject.deepCopy(self) return cpy.updateTrie(self.db)&#125;func (self *StateDB) HasSuicided(addr common.Address) bool &#123; stateObject := self.getStateObject(addr) if stateObject != nil &#123; return stateObject.suicided &#125; return false&#125; set类方法如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func (self *StateDB) AddBalance(addr common.Address, amount *big.Int) &#123; stateObject := self.GetOrNewStateObject(addr) if stateObject != nil &#123; stateObject.AddBalance(amount) &#125;&#125;func (self *StateDB) SubBalance(addr common.Address, amount *big.Int) &#123; stateObject := self.GetOrNewStateObject(addr) if stateObject != nil &#123; stateObject.SubBalance(amount) &#125;&#125;func (self *StateDB) SetBalance(addr common.Address, amount *big.Int) &#123; stateObject := self.GetOrNewStateObject(addr) if stateObject != nil &#123; stateObject.SetBalance(amount) &#125;&#125;func (self *StateDB) SetNonce(addr common.Address, nonce uint64) &#123; stateObject := self.GetOrNewStateObject(addr) if stateObject != nil &#123; stateObject.SetNonce(nonce) &#125;&#125;func (self *StateDB) SetCode(addr common.Address, code []byte) &#123; stateObject := self.GetOrNewStateObject(addr) if stateObject != nil &#123; stateObject.SetCode(crypto.Keccak256Hash(code), code) &#125;&#125;func (self *StateDB) SetState(addr common.Address, key, value common.Hash) &#123; stateObject := self.GetOrNewStateObject(addr) if stateObject != nil &#123; stateObject.SetState(self.db, key, value) &#125;&#125;func (self *StateDB) Suicide(addr common.Address) bool &#123; stateObject := self.getStateObject(addr) if stateObject == nil &#123; return false &#125; self.journal.append(suicideChange&#123; account: &amp;addr, prev: stateObject.suicided, prevbalance: new(big.Int).Set(stateObject.Balance()), &#125;) stateObject.markSuicided() stateObject.data.Balance = new(big.Int) return true&#125; 基本上都是通过getStateObject先获取stateObject，前面说过stateObject代表正在修改的以太坊账户，通过他也就可以访问各项内容 操作StateObjectget方法：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func (self *StateDB) getStateObject(addr common.Address) (stateObject *stateObject) &#123; if obj := self.stateObjects[addr]; obj != nil &#123; if obj.deleted &#123; return nil &#125; return obj &#125; enc, err := self.trie.TryGet(addr[:]) if len(enc) == 0 &#123; self.setError(err) return nil &#125; var data Account if err := rlp.DecodeBytes(enc, &amp;data); err != nil &#123; log.Error("Failed to decode state object", "addr", addr, "err", err) return nil &#125; obj := newObject(self, addr, data) self.setStateObject(obj) return obj&#125;func (self *StateDB) deleteStateObject(stateObject *stateObject) &#123; stateObject.deleted = true addr := stateObject.Address() self.setError(self.trie.TryDelete(addr[:]))&#125;func (self *StateDB) updateStateObject(stateObject *stateObject) &#123; addr := stateObject.Address() data, err := rlp.EncodeToBytes(stateObject) if err != nil &#123; panic(fmt.Errorf("can't encode object at %x: %v", addr[:], err)) &#125; self.setError(self.trie.TryUpdate(addr[:], data))&#125;func (self *StateDB) setStateObject(object *stateObject) &#123; self.stateObjects[object.Address()] = object&#125;func (self *StateDB) GetOrNewStateObject(addr common.Address) *stateObject &#123; stateObject := self.getStateObject(addr) if stateObject == nil || stateObject.deleted &#123; stateObject, _ = self.createObject(addr) &#125; return stateObject&#125;func (self *StateDB) createObject(addr common.Address) (newobj, prev *stateObject) &#123; prev = self.getStateObject(addr) newobj = newObject(self, addr, Account&#123;&#125;) newobj.setNonce(0) // sets the object to dirty if prev == nil &#123; self.journal.append(createObjectChange&#123;account: &amp;addr&#125;) &#125; else &#123; self.journal.append(resetObjectChange&#123;prev: prev&#125;) &#125; self.setStateObject(newobj) return newobj, prev&#125; 首先尝试stateObjects回去，没有的话用newObject构造一个，同时存入setStateObject中。 快照Snapshot可以创建一个快照，然后通过RevertToSnapshot可以回滚到哪个状态，这个功能是通过journal来做到的。1234567891011121314151617181920212223242526272829303132func (self *StateDB) Snapshot() int &#123; id := self.nextRevisionId self.nextRevisionId++ self.validRevisions = append(self.validRevisions, revision&#123;id, self.journal.length()&#125;) return id&#125;func (self *StateDB) RevertToSnapshot(revid int) &#123; idx := sort.Search(len(self.validRevisions), func(i int) bool &#123; return self.validRevisions[i].id &gt;= revid &#125;) if idx == len(self.validRevisions) || self.validRevisions[idx].id != revid &#123; panic(fmt.Errorf("revision id %v cannot be reverted", revid)) &#125; snapshot := self.validRevisions[idx].journalIndex self.journal.revert(self, snapshot) self.validRevisions = self.validRevisions[:idx]&#125;func (j *journal) revert(statedb *StateDB, snapshot int) &#123; for i := len(j.entries) - 1; i &gt;= snapshot; i-- &#123; j.entries[i].revert(statedb) if addr := j.entries[i].dirtied(); addr != nil &#123; if j.dirties[*addr]--; j.dirties[*addr] == 0 &#123; delete(j.dirties, *addr) &#125; &#125; &#125; j.entries = j.entries[:snapshot]&#125; 可见创建快照是记录了RevisionId和journal中日志数量。恢复则是确定该位置的journal中日志数量snapshot，然后调用revert，将日志集合中snapshot之后的事件全部执行回滚。 commitcommit用于提交更改12345678910111213141516171819202122232425262728293031323334353637383940414243444546func (s *StateDB) Commit(deleteEmptyObjects bool) (root common.Hash, err error) &#123; defer s.clearJournalAndRefund() for addr := range s.journal.dirties &#123; s.stateObjectsDirty[addr] = struct&#123;&#125;&#123;&#125; &#125; for addr, stateObject := range s.stateObjects &#123; _, isDirty := s.stateObjectsDirty[addr] switch &#123; case stateObject.suicided || (isDirty &amp;&amp; deleteEmptyObjects &amp;&amp; stateObject.empty()): s.deleteStateObject(stateObject) case isDirty: if stateObject.code != nil &amp;&amp; stateObject.dirtyCode &#123; s.db.TrieDB().InsertBlob(common.BytesToHash(stateObject.CodeHash()), stateObject.code) stateObject.dirtyCode = false &#125; if err := stateObject.CommitTrie(s.db); err != nil &#123; return common.Hash&#123;&#125;, err &#125; s.updateStateObject(stateObject) &#125; delete(s.stateObjectsDirty, addr) &#125; root, err = s.trie.Commit(func(leaf []byte, parent common.Hash) error &#123; var account Account if err := rlp.DecodeBytes(leaf, &amp;account); err != nil &#123; return nil &#125; if account.Root != emptyState &#123; s.db.TrieDB().Reference(account.Root, parent) &#125; code := common.BytesToHash(account.CodeHash) if code != emptyCode &#123; s.db.TrieDB().Reference(code, parent) &#125; return nil &#125;) log.Debug("Trie cache stats after commit", "misses", trie.CacheMisses(), "unloads", trie.CacheUnloads()) return root, err&#125;func (s *StateDB) clearJournalAndRefund() &#123; s.journal = newJournal() s.validRevisions = s.validRevisions[:0] s.refund = 0&#125; 首先遍历了journal.dirties，他存储着每个地址操作的次数，然后在stateObjectsDirty进行记录，表示相应地址有改动。随后遍历stateObjects，他保存着各个地址的stateObject。 如果某个地址有过操作，首先处理code，如果code有更新则调用InsertBlob进行插入。随后调用stateObject的CommitTrie提交这个签名分析过，最终结果是将树写入数据库，之后更新了StateObject。注意前面只是提交各个stateObject的树，回顾stateObject源码，stateObject成员中的树是通过OpenStorageTrie获取的，其中的root参数是通过StateDB的树种获取的，而StateDB成员中的树是通过OpenTrie获取的。stateObject只是代表一个个以太坊账户，所以还要对StateDB的树进行提交。 题图来自unsplash：https://unsplash.com/photos/1Z2niiBPg5A]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中eth-downloader源码学习（二）]]></title>
    <url>%2F2019%2F05%2F16%2Fgo-ethereum%E4%B8%ADeth-downloader%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A02%2F</url>
    <content type="text"><![CDATA[本文是downloader的源码分析的第二部分，分析peer、queue和statesync这三个辅助部分 peer.gopeer表示了一个节点，封装了一系列有用的方法123456789101112type Peer interface &#123; LightPeer RequestBodies([]common.Hash) error RequestReceipts([]common.Hash) error RequestNodeData([]common.Hash) error&#125;type LightPeer interface &#123; Head() (common.Hash, *big.Int) RequestHeadersByHash(common.Hash, int, int, bool) error RequestHeadersByNumber(uint64, int, int, bool) error&#125; register &amp; Unregister实际使用中，当一个连接建立后，使用pm的handle去处理一个peer时会用RegisterPeer的RegisterPeer方法去注册一个peer，RegisterPeer方法如下1234567891011func (d *Downloader) RegisterPeer(id string, version int, peer Peer) error &#123; logger := log.New("peer", id) logger.Trace("Registering sync peer") if err := d.peers.Register(newPeerConnection(id, version, peer, logger)); err != nil &#123; logger.Error("Failed to register sync peer", "err", err) return err &#125; d.qosReduceConfidence() return nil&#125; 可见实际上是向peers中注册，peers是一个peerSet对象，它的注册的是peerConnection对象12345678910111213141516171819202122232425262728293031323334type peerSet struct &#123; peers map[string]*peerConnection newPeerFeed event.Feed peerDropFeed event.Feed lock sync.RWMutex&#125;type peerConnection struct &#123; id string // Unique identifier of the peer headerIdle int32 // Current header activity state of the peer (idle = 0, active = 1) blockIdle int32 // Current block activity state of the peer (idle = 0, active = 1) receiptIdle int32 // Current receipt activity state of the peer (idle = 0, active = 1) stateIdle int32 // Current node data activity state of the peer (idle = 0, active = 1) headerThroughput float64 // Number of headers measured to be retrievable per second blockThroughput float64 // Number of blocks (bodies) measured to be retrievable per second receiptThroughput float64 // Number of receipts measured to be retrievable per second stateThroughput float64 // Number of node data pieces measured to be retrievable per second rtt time.Duration // Request round trip time to track responsiveness (QoS) headerStarted time.Time // Time instance when the last header fetch was started blockStarted time.Time // Time instance when the last block (body) fetch was started receiptStarted time.Time // Time instance when the last receipt fetch was started stateStarted time.Time // Time instance when the last node data fetch was started lacking map[common.Hash]struct&#123;&#125; // Set of hashes not to request (didn't have previously) peer Peer version int // Eth protocol version number to switch strategies log log.Logger // Contextual logger to add extra infos to peer logs lock sync.RWMutex&#125; peerSet的Register方法如下123456789101112131415161718192021222324252627282930func (ps *peerSet) Register(p *peerConnection) error &#123; p.rtt = ps.medianRTT() ps.lock.Lock() if _, ok := ps.peers[p.id]; ok &#123; ps.lock.Unlock() return errAlreadyRegistered &#125; if len(ps.peers) &gt; 0 &#123; p.headerThroughput, p.blockThroughput, p.receiptThroughput, p.stateThroughput = 0, 0, 0, 0 for _, peer := range ps.peers &#123; peer.lock.RLock() p.headerThroughput += peer.headerThroughput p.blockThroughput += peer.blockThroughput p.receiptThroughput += peer.receiptThroughput p.stateThroughput += peer.stateThroughput peer.lock.RUnlock() &#125; p.headerThroughput /= float64(len(ps.peers)) p.blockThroughput /= float64(len(ps.peers)) p.receiptThroughput /= float64(len(ps.peers)) p.stateThroughput /= float64(len(ps.peers)) &#125; ps.peers[p.id] = p ps.lock.Unlock() ps.newPeerFeed.Send(p) return nil&#125; medianRTT是取ps存储的所有peer的rtt的中位数，RTT即round-trip time，往返时间，可以评估和一个peer的通信质量。medianRTT实现如下：123456789101112131415161718192021222324252627func (ps *peerSet) medianRTT() time.Duration &#123; ps.lock.RLock() defer ps.lock.RUnlock() rtts := make([]float64, 0, len(ps.peers)) for _, p := range ps.peers &#123; p.lock.RLock() rtts = append(rtts, float64(p.rtt)) p.lock.RUnlock() &#125; sort.Float64s(rtts) median := rttMaxEstimate if qosTuningPeers &lt;= len(rtts) &#123; median = time.Duration(rtts[qosTuningPeers/2]) &#125; else if len(rtts) &gt; 0 &#123; median = time.Duration(rtts[len(rtts)/2]) // Median of our connected peers (maintain even like this some baseline qos) &#125; if median &lt; rttMinEstimate &#123; median = rttMinEstimate &#125; if median &gt; rttMaxEstimate &#123; median = rttMaxEstimate &#125; return median&#125; 逻辑很简单，首先取出所有peer的rtt，然后排序，如果序列长度大于5，就只取前5个的中位数，否则就是序列的中位数，获得的时间最后控制在2秒到20秒之间。 回到Register中，先看是否注册过，若没有再判断是否注册过其他peer，则计算headerThroughput、blockThroughput、receiptThroughput和stateThroughput四个值，分别代表：每秒可检索的区块头数量，每秒可检索的区块体数量，每秒可检索的收据数量和每秒可检测的节点数据数量。然后将peer按照其id放入peers中。 有注册就有反注册，Unregister实现如下12345678910111213func (ps *peerSet) Unregister(id string) error &#123; ps.lock.Lock() p, ok := ps.peers[id] if !ok &#123; defer ps.lock.Unlock() return errNotRegistered &#125; delete(ps.peers, id) ps.lock.Unlock() ps.peerDropFeed.Send(p) return nil&#125; 很简单就是先判断在删除。 FetchXxxpeerConnection除了封装一个peer，还有一系列的peer相关的信息，除了前面提到过的headerThroughput、blockThroughput、receiptThroughput和stateThroughput，还有headerIdle、blockIdle、receiptIdle和stateIdle分别用来记录peer对应的工作状态，这几个变量为0时表示对应状态空闲，为1时表示对应状态繁忙。除此之外还有headerStarted、blockStarted、receiptStarted和stateStarted几个时间变量记录对应工作开始的时间。 以head为例介绍一下相关变量的改变，在peerConnection有一个FetchHeaders表示请求区块头，实现如下1234567891011121314func (p *peerConnection) FetchHeaders(from uint64, count int) error &#123; if p.version &lt; 62 &#123; panic(fmt.Sprintf("header fetch [eth/62+] requested on eth/%d", p.version)) &#125; if !atomic.CompareAndSwapInt32(&amp;p.headerIdle, 0, 1) &#123; return errAlreadyFetching &#125; p.headerStarted = time.Now() go p.peer.RequestHeadersByNumber(from, count, 0, false) return nil&#125; 这里先判断了eth协议的版本号，然后将headerIdle置为1，并记录开始时间到headerStarted，真正的请求逻辑在peer的RequestHeadersByNumber方法。这里的peer是ProtocolManager的newPeer方法创建的peer(go-ethereum\eth\peer.go)。 同样还有FetchBodies、FetchReceipts和FetchNodeData等方法。 SetXxxIdle前面的FetchXxx是将对应状态置为忙碌，这里SetXxxIdle则是相反，他们都调用的是setIdle方法。12345678910111213141516171819202122func (p *peerConnection) setIdle(started time.Time, delivered int, throughput *float64, idle *int32) &#123; defer atomic.StoreInt32(idle, 0) p.lock.Lock() defer p.lock.Unlock() if delivered == 0 &#123; *throughput = 0 return &#125; elapsed := time.Since(started) + 1 measured := float64(delivered) / (float64(elapsed) / float64(time.Second)) *throughput = (1-measurementImpact)*(*throughput) + measurementImpact*measured p.rtt = time.Duration((1-measurementImpact)*float64(p.rtt) + measurementImpact*float64(elapsed)) p.log.Trace("Peer throughput measurements updated", "hps", p.headerThroughput, "bps", p.blockThroughput, "rps", p.receiptThroughput, "sps", p.stateThroughput, "miss", len(p.lacking), "rtt", p.rtt)&#125; 首先置0，表示空闲，然后如果delivered为0，表示没有传送到，则该peer的对应throughput置0.否则更新throughput和rtt。 XxxCapacity返回的对应状态的吞吐量，以heads为例123456func (p *peerConnection) HeaderCapacity(targetRTT time.Duration) int &#123; p.lock.RLock() defer p.lock.RUnlock() return int(math.Min(1+math.Max(1, p.headerThroughput*float64(targetRTT)/float64(time.Second)), float64(MaxHeaderFetch)))&#125; XxxIdlePeers用来获取对应状态空闲的peer1234567891011func (ps *peerSet) HeaderIdlePeers() ([]*peerConnection, int) &#123; idle := func(p *peerConnection) bool &#123; return atomic.LoadInt32(&amp;p.headerIdle) == 0 &#125; throughput := func(p *peerConnection) float64 &#123; p.lock.RLock() defer p.lock.RUnlock() return p.headerThroughput &#125; return ps.idlePeers(62, 64, idle, throughput)&#125; 调用的是idlePeers12345678910111213141516171819202122func (ps *peerSet) idlePeers(minProtocol, maxProtocol int, idleCheck func(*peerConnection) bool, throughput func(*peerConnection) float64) ([]*peerConnection, int) &#123; ps.lock.RLock() defer ps.lock.RUnlock() idle, total := make([]*peerConnection, 0, len(ps.peers)), 0 for _, p := range ps.peers &#123; if p.version &gt;= minProtocol &amp;&amp; p.version &lt;= maxProtocol &#123; if idleCheck(p) &#123; idle = append(idle, p) &#125; total++ &#125; &#125; for i := 0; i &lt; len(idle); i++ &#123; for j := i + 1; j &lt; len(idle); j++ &#123; if throughput(idle[i]) &lt; throughput(idle[j]) &#123; idle[i], idle[j] = idle[j], idle[i] &#125; &#125; &#125; return idle, total&#125; 就是简单的遍历，然后将结果按throughput排序。 Reset重置所有变量12345678910111213141516func (p *peerConnection) Reset() &#123; p.lock.Lock() defer p.lock.Unlock() atomic.StoreInt32(&amp;p.headerIdle, 0) atomic.StoreInt32(&amp;p.blockIdle, 0) atomic.StoreInt32(&amp;p.receiptIdle, 0) atomic.StoreInt32(&amp;p.stateIdle, 0) p.headerThroughput = 0 p.blockThroughput = 0 p.receiptThroughput = 0 p.stateThroughput = 0 p.lacking = make(map[common.Hash]struct&#123;&#125;)&#125; queue.go这实际上起到一个调度的作用，配合downloader的fetchParts方法，它用来告诉downloader哪些可以去处理。先看构造方法，在downloader创建时调用了newQueue方法创建了一个queue123456789101112131415161718func newQueue() *queue &#123; lock := new(sync.Mutex) return &amp;queue&#123; headerPendPool: make(map[string]*fetchRequest), headerContCh: make(chan bool), blockTaskPool: make(map[common.Hash]*types.Header), blockTaskQueue: prque.New(nil), blockPendPool: make(map[string]*fetchRequest), blockDonePool: make(map[common.Hash]struct&#123;&#125;), receiptTaskPool: make(map[common.Hash]*types.Header), receiptTaskQueue: prque.New(nil), receiptPendPool: make(map[string]*fetchRequest), receiptDonePool: make(map[common.Hash]struct&#123;&#125;), resultCache: make([]*fetchResult, blockCacheItems), active: sync.NewCond(lock), lock: lock, &#125;&#125; 其中的active变量是一个Cond类型的锁，它有一个锁L可以正常加锁解锁，除此之外还有wait进入阻塞，Signal和Broadcast可以进行唤醒。receiptTaskQueue与blockTaskQueue是两个优先级队列。 Schedule123456789101112131415161718192021222324252627282930313233343536func (q *queue) Schedule(headers []*types.Header, from uint64) []*types.Header &#123; q.lock.Lock() defer q.lock.Unlock() inserts := make([]*types.Header, 0, len(headers)) for _, header := range headers &#123; hash := header.Hash() if header.Number == nil || header.Number.Uint64() != from &#123; log.Warn("Header broke chain ordering", "number", header.Number, "hash", hash, "expected", from) break &#125; if q.headerHead != (common.Hash&#123;&#125;) &amp;&amp; q.headerHead != header.ParentHash &#123; log.Warn("Header broke chain ancestry", "number", header.Number, "hash", hash) break &#125; if _, ok := q.blockTaskPool[hash]; ok &#123; log.Warn("Header already scheduled for block fetch", "number", header.Number, "hash", hash) continue &#125; if _, ok := q.receiptTaskPool[hash]; ok &#123; log.Warn("Header already scheduled for receipt fetch", "number", header.Number, "hash", hash) continue &#125; q.blockTaskPool[hash] = header q.blockTaskQueue.Push(header, -int64(header.Number.Uint64())) if q.mode == FastSync &#123; q.receiptTaskPool[hash] = header q.receiptTaskQueue.Push(header, -int64(header.Number.Uint64())) &#125; inserts = append(inserts, header) q.headerHead = hash from++ &#125; return inserts&#125; 这个方法在downloader的processHeaders方法中出现。传入的参数headers是一组head，from是开始的位置。这个方法的主要作用是申请对一些区块头进行下载的调度。首先创建了一个Header数组，之后遍历了所有传入的head，对每个head进行一系列检查。 首先检测head格式是否正确，即编号是否为空，且是否为正确的编号。在检测区块间是否为父子关系，即检测父区块哈希是否正确且对应。然后在检测是否已经位于blockTaskPool和receiptTaskPool中，是的话直接跳过。 检测完毕后，将head放入blockTaskPool，这个map存储着等待检索区块体的任务。之后再放入blockTaskQueue这个队列，并以区块编号的负数作为优先级，编号越小的区块优先级越高。再接着对于fast模式下，再向receiptTaskPool和receiptTaskQueue添加内容，这也就显示出fast模式的特性。之后将head放入insert中，然后更新headerHead与from，用于下一个区块验证。整个方法的返回值就是要等待请求的区块头集合。 其中的两个TaskPool主要作用是避免重复申请调度，会在请求结束后在DeliverXxx方法中被删除。而这两个TaskQueue则是调度的关键，存储着等待调度的东西，在后面的ReserveXxx方法中会被拿出来构造请求进行处理。 ScheduleSkeleton这个方法出现在downloader的fillHeaderSkeleton方法中，就是在fetchHeaders中对于骨架模式进行填充1234567891011121314151617181920212223func (q *queue) ScheduleSkeleton(from uint64, skeleton []*types.Header) &#123; q.lock.Lock() defer q.lock.Unlock() if q.headerResults != nil &#123; panic("skeleton assembly already in progress") &#125; q.headerTaskPool = make(map[uint64]*types.Header) q.headerTaskQueue = prque.New(nil) q.headerPeerMiss = make(map[string]map[uint64]struct&#123;&#125;) // Reset availability to correct invalid chains q.headerResults = make([]*types.Header, len(skeleton)*MaxHeaderFetch) q.headerProced = 0 q.headerOffset = from q.headerContCh = make(chan bool, 1) for i, header := range skeleton &#123; index := from + uint64(i*MaxHeaderFetch) q.headerTaskPool[index] = header q.headerTaskQueue.Push(index, -int64(index)) &#125;&#125; 首先避免重复框架组装，通过检测headerResults是否为空来判断。之后遍历skeleton，skeleton是一组断续的header，他从from+191位置开始，每隔192个区块请求一个，总共请求128个。遍历的时候用headerTaskPool记录框架对于位置的head，并将index按照其负数作为优先级存入headerTaskQueue队列。headerTaskPool和headerTaskQueue的作用和前面Schedule方法中那两对变量作用类似。 ReserveXxx这是一组方法，在downloader的Synchronise流程最后定义了一组fetch方法，最后都调用了fetchParts方法，其中reserve参数就是这里对应的ReserveXxx方法，这组方法的主要用途是从TaskQueue队列中领取任务构造请求便于后续执行。 一共有三个方法：ReserveReceipts、ReserveBodies和ReserveHeaders，但是ReserveReceipts和ReserveBodies都调用了reserveHeaders方法12345678910111213141516171819func (q *queue) ReserveBodies(p *peerConnection, count int) (*fetchRequest, bool, error) &#123; isNoop := func(header *types.Header) bool &#123; return header.TxHash == types.EmptyRootHash &amp;&amp; header.UncleHash == types.EmptyUncleHash &#125; q.lock.Lock() defer q.lock.Unlock() return q.reserveHeaders(p, count, q.blockTaskPool, q.blockTaskQueue, q.blockPendPool, q.blockDonePool, isNoop)&#125;func (q *queue) ReserveReceipts(p *peerConnection, count int) (*fetchRequest, bool, error) &#123; isNoop := func(header *types.Header) bool &#123; return header.ReceiptHash == types.EmptyRootHash &#125; q.lock.Lock() defer q.lock.Unlock() return q.reserveHeaders(p, count, q.receiptTaskPool, q.receiptTaskQueue, q.receiptPendPool, q.receiptDonePool, isNoop)&#125; reserveHeaders这里看一下这个方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970func (q *queue) reserveHeaders(p *peerConnection, count int, taskPool map[common.Hash]*types.Header, taskQueue *prque.Prque, pendPool map[string]*fetchRequest, donePool map[common.Hash]struct&#123;&#125;, isNoop func(*types.Header) bool) (*fetchRequest, bool, error) &#123; if taskQueue.Empty() &#123; return nil, false, nil &#125; if _, ok := pendPool[p.id]; ok &#123; return nil, false, nil &#125; space := q.resultSlots(pendPool, donePool) send := make([]*types.Header, 0, count) skip := make([]*types.Header, 0) progress := false for proc := 0; proc &lt; space &amp;&amp; len(send) &lt; count &amp;&amp; !taskQueue.Empty(); proc++ &#123; header := taskQueue.PopItem().(*types.Header) hash := header.Hash() index := int(header.Number.Int64() - int64(q.resultOffset)) if index &gt;= len(q.resultCache) || index &lt; 0 &#123; common.Report("index allocation went beyond available resultCache space") return nil, false, errInvalidChain &#125; if q.resultCache[index] == nil &#123; components := 1 if q.mode == FastSync &#123; components = 2 &#125; q.resultCache[index] = &amp;fetchResult&#123; Pending: components, Hash: hash, Header: header, &#125; &#125; if isNoop(header) &#123; donePool[hash] = struct&#123;&#125;&#123;&#125; delete(taskPool, hash) space, proc = space-1, proc-1 q.resultCache[index].Pending-- progress = true continue &#125; if p.Lacks(hash) &#123; skip = append(skip, header) &#125; else &#123; send = append(send, header) &#125; &#125; for _, header := range skip &#123; taskQueue.Push(header, -int64(header.Number.Uint64())) &#125; if progress &#123; q.active.Signal() &#125; if len(send) == 0 &#123; return nil, progress, nil &#125; request := &amp;fetchRequest&#123; Peer: p, Headers: send, Time: time.Now(), &#125; pendPool[p.id] = request return request, progress, nil&#125; 首先检查taskQueue是否为空，taskQueue是作为参数传入的，对应ReserveBodies和ReserveReceipts分别是blockTaskQueue和receiptTaskQueue，这两个队列分别在前面Schedule方法中被填充。接着计算了fetch的上限，创建了两个数组send和skip。 然后开始循环，每次从taskQueue获取优先级最高的item，然后根据区块头的高度计算index，index表示在resultCache的位置，resultCache是一个fetchResult数组，存储已经下载完毕的结果。如果resultCache对应位置为空，则构造一个fetchResult对象存入。然后调用了isNoop方法，这是方法的一个参数，用于检测是否为包含交易。如果是的话表示不需要继续操作，将其donePool对应元素置空，然后从taskPool中删除，由于taskPool被改变，则space和proc两个计数器响应的都减一。如果不为空，检测hash是否在lacking中，如在表示没有这个hash相关数据，则放入skip中，否则放入send中。 循环结束后，也就是从taskPool中分类一定数量的head后，遍历skip，将其中改的head按期高度的负数再次添加到对应taskQueue队列中。然后如果progress为true，表示刚才循环中出现没有交易的区块头，则调用active的Signal方法，唤醒wait，他在Result方法中阻塞，稍后介绍。之后检测send数组，如果空则返回，否则构建一个fetchRequest，然后按照peer的id放入pendPool。 ReserveHeaders这个方法和前面的ScheduleSkeleton一样只有在骨架模式下才回调用，该方法实现如下1234567891011121314151617181920212223242526272829303132333435func (q *queue) ReserveHeaders(p *peerConnection, count int) *fetchRequest &#123; q.lock.Lock() defer q.lock.Unlock() if _, ok := q.headerPendPool[p.id]; ok &#123; return nil &#125; send, skip := uint64(0), []uint64&#123;&#125; for send == 0 &amp;&amp; !q.headerTaskQueue.Empty() &#123; from, _ := q.headerTaskQueue.Pop() if q.headerPeerMiss[p.id] != nil &#123; if _, ok := q.headerPeerMiss[p.id][from.(uint64)]; ok &#123; skip = append(skip, from.(uint64)) continue &#125; &#125; send = from.(uint64) &#125; for _, from := range skip &#123; q.headerTaskQueue.Push(from, -int64(from)) &#125; if send == 0 &#123; return nil &#125; request := &amp;fetchRequest&#123; Peer: p, From: send, Time: time.Now(), &#125; q.headerPendPool[p.id] = request return request&#125; 逻辑和reserveHeaders类似，首先检测peer是否已在headerPendPool中。然后遍历headerTaskQueue，每次取优先级最高的，在检测对应hash是否在headerPeerMiss中，headerPeerMiss记录了每个peer明确不可用的区块，是的话放入skip以跳过，这个循环直到取到一个有效的head位置，然后记录from值到send。后续的逻辑就和reserveHeaders差不多，对于skip的再次放入headerTaskQueue，然后构造一个fetchRequest放入headerPendPool中。注意这个fetchRequest和前面的reserveHeaders最后构造的不太一样，这里没有传入Heads字段，而是写入了From字段，表示骨架中第一个有效的head，由于骨架是有规律的记录起始位置即可。 DeliverXxx这也是一组方法，和ReserveXxx类似，都是在调用fetchParts时作为参数传入的，这组方法的作用是在数据下载完毕后被调用。有DeliverBodies、DeliverReceipts和DeliverReceipts三个，前两个都是直接调用了deliver方法12345678910111213141516171819202122232425262728func (q *queue) DeliverBodies(id string, txLists [][]*types.Transaction, uncleLists [][]*types.Header) (int, error) &#123; q.lock.Lock() defer q.lock.Unlock() reconstruct := func(header *types.Header, index int, result *fetchResult) error &#123; if types.DeriveSha(types.Transactions(txLists[index])) != header.TxHash || types.CalcUncleHash(uncleLists[index]) != header.UncleHash &#123; return errInvalidBody &#125; result.Transactions = txLists[index] result.Uncles = uncleLists[index] return nil &#125; return q.deliver(id, q.blockTaskPool, q.blockTaskQueue, q.blockPendPool, q.blockDonePool, bodyReqTimer, len(txLists), reconstruct)&#125;func (q *queue) DeliverReceipts(id string, receiptList [][]*types.Receipt) (int, error) &#123; q.lock.Lock() defer q.lock.Unlock() reconstruct := func(header *types.Header, index int, result *fetchResult) error &#123; if types.DeriveSha(types.Receipts(receiptList[index])) != header.ReceiptHash &#123; return errInvalidReceipt &#125; result.Receipts = receiptList[index] return nil &#125; return q.deliver(id, q.receiptTaskPool, q.receiptTaskQueue, q.receiptPendPool, q.receiptDonePool, receiptReqTimer, len(receiptList), reconstruct)&#125; deliver1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func (q *queue) deliver(id string, taskPool map[common.Hash]*types.Header, taskQueue *prque.Prque, pendPool map[string]*fetchRequest, donePool map[common.Hash]struct&#123;&#125;, reqTimer metrics.Timer, results int, reconstruct func(header *types.Header, index int, result *fetchResult) error) (int, error) &#123; request := pendPool[id] if request == nil &#123; return 0, errNoFetchesPending &#125; reqTimer.UpdateSince(request.Time) delete(pendPool, id) if results == 0 &#123; for _, header := range request.Headers &#123; request.Peer.MarkLacking(header.Hash()) &#125; &#125; var ( accepted int failure error useful bool ) for i, header := range request.Headers &#123; if i &gt;= results &#123; break &#125; index := int(header.Number.Int64() - int64(q.resultOffset)) if index &gt;= len(q.resultCache) || index &lt; 0 || q.resultCache[index] == nil &#123; failure = errInvalidChain break &#125; if err := reconstruct(header, i, q.resultCache[index]); err != nil &#123; failure = err break &#125; hash := header.Hash() donePool[hash] = struct&#123;&#125;&#123;&#125; q.resultCache[index].Pending-- useful = true accepted++ request.Headers[i] = nil delete(taskPool, hash) &#125; for _, header := range request.Headers &#123; if header != nil &#123; taskQueue.Push(header, -int64(header.Number.Uint64())) &#125; &#125; if accepted &gt; 0 &#123; q.active.Signal() &#125; switch &#123; case failure == nil || failure == errInvalidChain: return accepted, failure case useful: return accepted, fmt.Errorf("partial failure: %v", failure) default: return accepted, errStaleDelivery &#125;&#125; 首先检测相应id是否在pendPool，pendPool是参数，对应DeliverBodies和DeliverReceipts分别是blockPendPool和receiptPendPool，他们分别在对应的ReserveXxx中被填充。如果没有则返回错误，有的话先从pendPool将其删除，表示已经结束。之后检查result的值，他表示DeliverXxx传入的List的长度，这个list表示检索到的数据集合，如果为0表示相应的head在该peer取不到，则调用MarkLacking将其添加到lacking中。 接下来进入一个循环，变量最开始从pendPool取出的request的Headers，然后计算在resultCache的index，之后利用reconstruct构建，reconstruct是传入的参数，主要作用是补全fetchResult，如在DeliverReceipts中是补全Receipts字段，在DeliverBodies补全Transactions和Uncles字段。之后在donePool标记对应hash的任务已经完成，并且useful写为true，accepted自增一，清空request对应位置的数据，并且删除taskPool对应hash内容。 循环结束后，由于刚才循环最后遍历results个，可能有剩余，将剩余的head放入对应taskQueue中。之后如果accept大于一，表示有任务真正完成了，同样调用active的Signal唤醒阻塞，和前面reserveHeaders类似。最后返回错误报告和accepted数量。 DeliverHeaders1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374func (q *queue) DeliverHeaders(id string, headers []*types.Header, headerProcCh chan []*types.Header) (int, error) &#123; q.lock.Lock() defer q.lock.Unlock() request := q.headerPendPool[id] if request == nil &#123; return 0, errNoFetchesPending &#125; headerReqTimer.UpdateSince(request.Time) delete(q.headerPendPool, id) target := q.headerTaskPool[request.From].Hash() accepted := len(headers) == MaxHeaderFetch if accepted &#123; if headers[0].Number.Uint64() != request.From &#123; log.Trace("First header broke chain ordering", "peer", id, "number", headers[0].Number, "hash", headers[0].Hash(), request.From) accepted = false &#125; else if headers[len(headers)-1].Hash() != target &#123; log.Trace("Last header broke skeleton structure ", "peer", id, "number", headers[len(headers)-1].Number, "hash", headers[len(headers)-1].Hash(), "expected", target) accepted = false &#125; &#125; if accepted &#123; for i, header := range headers[1:] &#123; hash := header.Hash() if want := request.From + 1 + uint64(i); header.Number.Uint64() != want &#123; log.Warn("Header broke chain ordering", "peer", id, "number", header.Number, "hash", hash, "expected", want) accepted = false break &#125; if headers[i].Hash() != header.ParentHash &#123; log.Warn("Header broke chain ancestry", "peer", id, "number", header.Number, "hash", hash) accepted = false break &#125; &#125; &#125; if !accepted &#123; log.Trace("Skeleton filling not accepted", "peer", id, "from", request.From) miss := q.headerPeerMiss[id] if miss == nil &#123; q.headerPeerMiss[id] = make(map[uint64]struct&#123;&#125;) miss = q.headerPeerMiss[id] &#125; miss[request.From] = struct&#123;&#125;&#123;&#125; q.headerTaskQueue.Push(request.From, -int64(request.From)) return 0, errors.New("delivery not accepted") &#125; copy(q.headerResults[request.From-q.headerOffset:], headers) delete(q.headerTaskPool, request.From) ready := 0 for q.headerProced+ready &lt; len(q.headerResults) &amp;&amp; q.headerResults[q.headerProced+ready] != nil &#123; ready += MaxHeaderFetch &#125; if ready &gt; 0 &#123; process := make([]*types.Header, ready) copy(process, q.headerResults[q.headerProced:q.headerProced+ready]) select &#123; case headerProcCh &lt;- process: log.Trace("Pre-scheduled new headers", "peer", id, "count", len(process), "from", process[0].Number) q.headerProced += len(process) default: &#125; &#125; if len(q.headerTaskPool) == 0 &#123; q.headerContCh &lt;- false &#125; return len(headers), nil&#125; 大致逻辑和deliver类似，参数headers是收到的数据。先判断收到的消息是否符合我们要请求的。先从headerPendPool取出对应request，然后判断headers的长度是否为192，是的话验证headers中第一个是否是请求的起始位置，再验证最后一个是否符合要求，二者任何一个不合要求就将accepted置为false。接下来就是验证这一组head是否有关联，一个是序号上的一个是父hash是否对应。对于accepted为false时，在headerPeerMiss标记对应peer的相应head无效，并将相应再次放入headerTaskQueue中并返回错误。对于结果正确的情况，现将headers复制到headerResults，然后从headerTaskPool删除。接着计算已经准备好的head数ready，然后将其发送到headerProcCh触发downloader中processHeaders的相关逻辑。接着调整headerProced的值，它表示已经处理的head数量。 ExpireXxx也是一组方法，用于在downloader的fetchParts使用，1234567891011121314151617181920func (q *queue) ExpireHeaders(timeout time.Duration) map[string]int &#123; q.lock.Lock() defer q.lock.Unlock() return q.expire(timeout, q.headerPendPool, q.headerTaskQueue, headerTimeoutMeter)&#125;func (q *queue) ExpireBodies(timeout time.Duration) map[string]int &#123; q.lock.Lock() defer q.lock.Unlock() return q.expire(timeout, q.blockPendPool, q.blockTaskQueue, bodyTimeoutMeter)&#125;func (q *queue) ExpireReceipts(timeout time.Duration) map[string]int &#123; q.lock.Lock() defer q.lock.Unlock() return q.expire(timeout, q.receiptPendPool, q.receiptTaskQueue, receiptTimeoutMeter)&#125; 都是调用了expire方法12345678910111213141516171819func (q *queue) expire(timeout time.Duration, pendPool map[string]*fetchRequest, taskQueue *prque.Prque, timeoutMeter metrics.Meter) map[string]int &#123; expiries := make(map[string]int) for id, request := range pendPool &#123; if time.Since(request.Time) &gt; timeout &#123; timeoutMeter.Mark(1)l if request.From &gt; 0 &#123; taskQueue.Push(request.From, -int64(request.From)) &#125; for _, header := range request.Headers &#123; taskQueue.Push(header, -int64(header.Number.Uint64())) &#125; expiries[id] = len(request.Headers) delete(pendPool, id) &#125; &#125; return expiries&#125; 主要是遍历pendPool，分别对应headerPendPool、blockPendPool和receiptPendPool，这些pool都保存着等待处理的request。遍历每个request看是否超时，对于超时的请求将其请求的head再次放入taskQueue等待后续处理，并按id将其请求的heads数存入expiries，然后将其从pendPool移除，最后返回expiries。 CancelXxx也是一组方法，用于在downloader的fetchParts使用，1234567891011func (q *queue) CancelHeaders(request *fetchRequest) &#123; q.cancel(request, q.headerTaskQueue, q.headerPendPool)&#125;func (q *queue) CancelBodies(request *fetchRequest) &#123; q.cancel(request, q.blockTaskQueue, q.blockPendPool)&#125;func (q *queue) CancelReceipts(request *fetchRequest) &#123; q.cancel(request, q.receiptTaskQueue, q.receiptPendPool)&#125; 都调用了cancel方法123456789101112func (q *queue) cancel(request *fetchRequest, taskQueue *prque.Prque, pendPool map[string]*fetchRequest) &#123; q.lock.Lock() defer q.lock.Unlock() if request.From &gt; 0 &#123; taskQueue.Push(request.From, -int64(request.From)) &#125; for _, header := range request.Headers &#123; taskQueue.Push(header, -int64(header.Number.Uint64())) &#125; delete(pendPool, request.Peer.id)&#125; 主要主要是取消某个request，但是请求的head还要重新放入taskQueue等待下次处理，最后将其从pendPool移除。 RetrieveHeaders这个方法出现在fillHeaderSkeleton最后，他返回结果重置状态为下一次ScheduleSkeleton做准备123456789func (q *queue) RetrieveHeaders() ([]*types.Header, int) &#123; q.lock.Lock() defer q.lock.Unlock() headers, proced := q.headerResults, q.headerProced q.headerResults, q.headerProced = nil, 0 return headers, proced&#125; statesync.go主要是用来同步状态信息。第一次被创建是在downloader的processFastSyncContent方法中，调用了syncState方法12345678910111213141516171819202122func (d *Downloader) syncState(root common.Hash) *stateSync &#123; s := newStateSync(d, root) select &#123; case d.stateSyncStart &lt;- s: case &lt;-d.quitCh: s.err = errCancelStateFetch close(s.done) &#125; return s&#125;func newStateSync(d *Downloader, root common.Hash) *stateSync &#123; return &amp;stateSync&#123; d: d, sched: state.NewStateSync(root, d.stateDB), keccak: sha3.NewLegacyKeccak256(), tasks: make(map[common.Hash]*stateTask), deliver: make(chan *stateReq), cancel: make(chan struct&#123;&#125;), done: make(chan struct&#123;&#125;), &#125;&#125; 创建过程中有一个sched成员，是一个trie.Sync对象，构造过程如下123456789101112131415161718192021222324252627// go-ethereum\core\state\sync.gofunc NewStateSync(root common.Hash, database trie.DatabaseReader) *trie.Sync &#123; var syncer *trie.Sync callback := func(leaf []byte, parent common.Hash) error &#123; var obj Account if err := rlp.Decode(bytes.NewReader(leaf), &amp;obj); err != nil &#123; return err &#125; syncer.AddSubTrie(obj.Root, 64, parent, nil) syncer.AddRawEntry(common.BytesToHash(obj.CodeHash), 64, parent) return nil &#125; syncer = trie.NewSync(root, database, callback) return syncer&#125;// go-ethereum\trie\sync.gofunc NewSync(root common.Hash, database DatabaseReader, callback LeafCallback) *Sync &#123; ts := &amp;Sync&#123; database: database, membatch: newSyncMemBatch(), requests: make(map[common.Hash]*request), queue: prque.New(nil), &#125; ts.AddSubTrie(root, 0, common.Hash&#123;&#125;, callback) return ts&#125; 最后调用trie的NewSync方法构造了一个Sync，Sync是用于同步状态树的。最后的AddSubTrie如下123456789101112131415161718192021222324252627func (s *Sync) AddSubTrie(root common.Hash, depth int, parent common.Hash, callback LeafCallback) &#123; if root == emptyRoot &#123; return &#125; if _, ok := s.membatch.batch[root]; ok &#123; return &#125; key := root.Bytes() blob, _ := s.database.Get(key) if local, err := decodeNode(key, blob, 0); local != nil &amp;&amp; err == nil &#123; return &#125; req := &amp;request&#123; hash: root, depth: depth, callback: callback, &#125; if parent != (common.Hash&#123;&#125;) &#123; ancestor := s.requests[parent] if ancestor == nil &#123; panic(fmt.Sprintf("sub-trie ancestor not found: %x", parent)) &#125; ancestor.deps++ req.parents = append(req.parents, ancestor) &#125; s.schedule(req)&#125; 在开始状态下构建了request，然后调用schedule12345678func (s *Sync) schedule(req *request) &#123; if old, ok := s.requests[req.hash]; ok &#123; old.parents = append(old.parents, req.parents...) return &#125; s.queue.Push(req.hash, int64(req.depth)) s.requests[req.hash] = req&#125; 也是通过将请求放入队列中进行调度工作。 回到syncState，sched创建后就向stateSyncStart发送了消息，内容就是StateSync对象。 stateFetcher在downloader的New方法最后启动了两个goroutine方法，第二个就是stateFetcher方法。1234567891011121314func (d *Downloader) stateFetcher() &#123; for &#123; select &#123; case s := &lt;-d.stateSyncStart: for next := s; next != nil; &#123; next = d.runStateSync(next) &#125; case &lt;-d.stateCh: // Ignore state responses while no sync is running. case &lt;-d.quitCh: return &#125; &#125;&#125; 一个go-select结构，前面syncState中触发了这里的逻辑，调用了runStateSync方法 runStateSync12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091func (d *Downloader) runStateSync(s *stateSync) *stateSync &#123; var ( active = make(map[string]*stateReq) // Currently in-flight requests finished []*stateReq // Completed or failed requests timeout = make(chan *stateReq) // Timed out active requests ) defer func() &#123; for _, req := range active &#123; req.timer.Stop() req.peer.SetNodeDataIdle(len(req.items)) &#125; &#125;() go s.run() defer s.Cancel() peerDrop := make(chan *peerConnection, 1024) peerSub := s.d.peers.SubscribePeerDrops(peerDrop) defer peerSub.Unsubscribe() for &#123; var ( deliverReq *stateReq deliverReqCh chan *stateReq ) if len(finished) &gt; 0 &#123; deliverReq = finished[0] deliverReqCh = s.deliver &#125; select &#123; case next := &lt;-d.stateSyncStart: return next case &lt;-s.done: return nil case deliverReqCh &lt;- deliverReq: copy(finished, finished[1:]) finished[len(finished)-1] = nil finished = finished[:len(finished)-1] case pack := &lt;-d.stateCh: req := active[pack.PeerId()] if req == nil &#123; log.Debug("Unrequested node data", "peer", pack.PeerId(), "len", pack.Items()) continue &#125; req.timer.Stop() req.response = pack.(*statePack).states finished = append(finished, req) delete(active, pack.PeerId()) case p := &lt;-peerDrop: req := active[p.id] if req == nil &#123; continue &#125; req.timer.Stop() req.dropped = true finished = append(finished, req) delete(active, p.id) case req := &lt;-timeout: if active[req.peer.id] != req &#123; continue &#125; finished = append(finished, req) delete(active, req.peer.id) case req := &lt;-d.trackStateReq: if old := active[req.peer.id]; old != nil &#123; log.Warn("Busy peer assigned new state fetch", "peer", old.peer.id) // Make sure the previous one doesn't get siletly lost old.timer.Stop() old.dropped = true finished = append(finished, old) &#125; req.timer = time.AfterFunc(req.timeout, func() &#123; select &#123; case timeout &lt;- req: case &lt;-s.done: &#125; &#125;) active[req.peer.id] = req &#125; &#125;&#125; 这里直接调用了run方法，是在一个单独的goroutine中，随后有一个for-select结构等待逻辑触发。run内容如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546func (s *stateSync) run() &#123; s.err = s.loop() close(s.done)&#125;func (s *stateSync) loop() (err error) &#123; newPeer := make(chan *peerConnection, 1024) peerSub := s.d.peers.SubscribeNewPeers(newPeer) defer peerSub.Unsubscribe() defer func() &#123; cerr := s.commit(true) if err == nil &#123; err = cerr &#125; &#125;() for s.sched.Pending() &gt; 0 &#123; if err = s.commit(false); err != nil &#123; return err &#125; s.assignTasks() select &#123; case &lt;-newPeer: case &lt;-s.cancel: return errCancelStateFetch case &lt;-s.d.cancelCh: return errCancelStateFetch case req := &lt;-s.deliver: log.Trace("Received node data response", "peer", req.peer.id, "count", len(req.response), "dropped", req.dropped, "timeout", !req.dropped &amp;&amp; req.timedOut()) if len(req.items) &lt;= 2 &amp;&amp; !req.dropped &amp;&amp; req.timedOut() &#123; log.Warn("Stalling state sync, dropping peer", "peer", req.peer.id) s.d.dropPeer(req.peer.id) &#125; delivered, err := s.process(req) if err != nil &#123; log.Warn("Node data write error", "err", err) return err &#125; req.peer.SetNodeDataIdle(delivered) &#125; &#125; return nil&#125; 先调用了sched的Pending方法，这个方法返回requests的长度，requests在schedule时被填充方法，如果大于0表示有等待调度的任务。之后进入循环，调用commit，最开始没有可以提交的，直接返回nil。接着调用assignTasks123456789101112131415161718192021222324252627282930313233343536373839404142func (s *stateSync) assignTasks() &#123; peers, _ := s.d.peers.NodeDataIdlePeers() for _, p := range peers &#123; cap := p.NodeDataCapacity(s.d.requestRTT()) req := &amp;stateReq&#123;peer: p, timeout: s.d.requestTTL()&#125; s.fillTasks(cap, req) if len(req.items) &gt; 0 &#123; req.peer.log.Trace("Requesting new batch of data", "type", "state", "count", len(req.items)) select &#123; case s.d.trackStateReq &lt;- req: req.peer.FetchNodeData(req.items) case &lt;-s.cancel: case &lt;-s.d.cancelCh: &#125; &#125; &#125;&#125;func (s *stateSync) fillTasks(n int, req *stateReq) &#123; if len(s.tasks) &lt; n &#123; new := s.sched.Missing(n - len(s.tasks)) for _, hash := range new &#123; s.tasks[hash] = &amp;stateTask&#123;make(map[string]struct&#123;&#125;)&#125; &#125; &#125; req.items = make([]common.Hash, 0, n) req.tasks = make(map[common.Hash]*stateTask, n) for hash, t := range s.tasks &#123; if len(req.items) == n &#123; break &#125; if _, ok := t.attempts[req.peer.id]; ok &#123; continue &#125; t.attempts[req.peer.id] = struct&#123;&#125;&#123;&#125; req.items = append(req.items, hash) req.tasks[hash] = t delete(s.tasks, hash) &#125;&#125; NodeDataIdlePeers获取对应状态下空闲的peer，之后遍历所有idle的peer，然后构造请求，fillTasks中先调用了sched的Missing方法，这个方法将sched中schedule方法存入队列的请求取出。取出后将hash存入tasks，随后填充请求的items与tasks。一个请求构造完之后，在assignTasks的select结构中赋值给trackStateReq触发runStateSync里的逻辑。同时又调用了peer的FetchNodeData方法，FetchNodeData就是调用peer的RequestNodeData方法，发送GetNodeDataMsg方法。 发送GetNodeDataMsg消息后，对方会回复NodeDataMsg消息，这是调用downloader的DeliverNodeData方法。这个方法只是将接收到的数据发送到destCh，也就是d.stateCh，同样触发runStateSyn里逻辑。 由于刚才的run和loop都是再独立goroutine中运行的，所以runStateSync正常进入select结构阻塞。 首先触发trackStateReq逻辑，这个是追踪请求的，首先看该peer是否请求过，没有的话设置一个定时器，并将该请求按id存入active中，同时也制定了超时的逻辑。 其次触发的是d.stateCh，也是先检测是否是之前请求的，是的话停止定时器，然后填充请求的响应字段，然后向finished追加内容，一次循环结束，下一次循环开始时，取finished第一个内容，在select中触发deliverReqCh逻辑，由于deliverReqCh等于s.deliver，所以也触发loop中的逻辑，这里先调用process方法处理响应的内容。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748func (s *stateSync) process(req *stateReq) (int, error) &#123; duplicate, unexpected, successful := 0, 0, 0 defer func(start time.Time) &#123; if duplicate &gt; 0 || unexpected &gt; 0 &#123; s.updateStats(0, duplicate, unexpected, time.Since(start)) &#125; &#125;(time.Now()) for _, blob := range req.response &#123; _, hash, err := s.processNodeData(blob) switch err &#123; case nil: s.numUncommitted++ s.bytesUncommitted += len(blob) successful++ case trie.ErrNotRequested: unexpected++ case trie.ErrAlreadyProcessed: duplicate++ default: return successful, fmt.Errorf("invalid state node %s: %v", hash.TerminalString(), err) &#125; if _, ok := req.tasks[hash]; ok &#123; delete(req.tasks, hash) &#125; &#125; npeers := s.d.peers.Len() for hash, task := range req.tasks &#123; if len(req.response) &gt; 0 || req.timedOut() &#123; delete(task.attempts, req.peer.id) &#125; if len(task.attempts) &gt;= npeers &#123; return successful, fmt.Errorf("state node %s failed with all peers (%d tries, %d peers)", hash.TerminalString(), len(task.attempts), npeers) &#125; s.tasks[hash] = task &#125; return successful, nil&#125;func (s *stateSync) processNodeData(blob []byte) (bool, common.Hash, error) &#123; res := trie.SyncResult&#123;Data: blob&#125; s.keccak.Reset() s.keccak.Write(blob) s.keccak.Sum(res.Hash[:0]) committed, _, err := s.sched.Process([]trie.SyncResult&#123;res&#125;) return committed, res.Hash, err&#125; 由于响应可能是多组数据，所以遍历每一组数据，调用processNodeData进行处理，processNodeData主要是构建SyncResult以便sched处理，sched的process方法主要就是将数据解析为树中节点，然后在递归的去请求节点的孩子，直到一棵树建立，请求的方法还是构建请求放入requests等待调度，这里不再详细说明。总之经过processNodeData一次响应的数据被处理，如果没有错误，numUncommitted和bytesUncommitted对应增加，然后将成功的请求从tasks中移除，未成功的放回队列等待下次请求。回到loop中对于逻辑，处理完之后，没有错的话修改对应peer状态信息。 题图来自unsplash：https://unsplash.com/photos/3Xj6BntfsIU]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中eth-downloader源码学习（一）]]></title>
    <url>%2F2019%2F05%2F16%2Fgo-ethereum%E4%B8%ADeth-downloader%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A01%2F</url>
    <content type="text"><![CDATA[本文是downloader的源码分析的第一部分，分析downloader.go也就是主流程 newdownloader主要是进行网络的同步，有两种同步模式，FullSync和FastSync，后者只能在第一次运行时才有效，这里可见ProtocolManager源码。关于两种同步模式，FullSync会通过下载区块头和区块体构建区块链，包括区块的验证，交易的执行，账户的状态改变等，就类似于一个一个插入区块。而FastSync在开始时会直接下载区块头、区块体和收据，并不执行交易，然后在最后若干个区块才会像FullSync一样进行区块同步。 downloader在ProtocolManager创建时被创建，用的是New方法：12345678910111213141516171819202122232425262728293031323334func New(mode SyncMode, stateDb ethdb.Database, mux *event.TypeMux, chain BlockChain, lightchain LightChain, dropPeer peerDropFn) *Downloader &#123; if lightchain == nil &#123; lightchain = chain &#125; dl := &amp;Downloader&#123; mode: mode, stateDB: stateDb, mux: mux, queue: newQueue(), peers: newPeerSet(), rttEstimate: uint64(rttMaxEstimate), rttConfidence: uint64(1000000), blockchain: chain, lightchain: lightchain, dropPeer: dropPeer, headerCh: make(chan dataPack, 1), bodyCh: make(chan dataPack, 1), receiptCh: make(chan dataPack, 1), bodyWakeCh: make(chan bool, 1), receiptWakeCh: make(chan bool, 1), headerProcCh: make(chan []*types.Header, 1), quitCh: make(chan struct&#123;&#125;), stateCh: make(chan dataPack), stateSyncStart: make(chan *stateSync), syncStatsState: stateSyncStats&#123; processed: rawdb.ReadFastTrieProgress(stateDb), &#125;, trackStateReq: make(chan *stateReq), &#125; go dl.qosTuner() go dl.stateFetcher() return dl&#125; 首先根据传入的参数创建了一个Downloader对象，然后启动了两个goroutine分别执行qosTuner和stateFetcher方法。 Synchronise通过前面的ProtocolManager的学习，我们了解到总共有两个地方调用了Synchronise，一个是收到一个NewBlockMsg消息时，表示对方有新的区块，如果对方的总难度大于我们，则进行同步调用pm的synchronise方法。另外在启动pm时，在syncer方法中无论是forceSync定时器到时间或者newPeerCh得到赋值（在连接到一个peer时触发）都会调用synchronise。在pm的synchronise中会调用Synchronise方法 Synchronise方法实现如下：1234567891011121314151617181920func (d *Downloader) Synchronise(id string, head common.Hash, td *big.Int, mode SyncMode) error &#123; err := d.synchronise(id, head, td, mode) switch err &#123; case nil: case errBusy: case errTimeout, errBadPeer, errStallingPeer, errEmptyHeaderSet, errPeersUnavailable, errTooOld, errInvalidAncestor, errInvalidChain: log.Warn("Synchronisation failed, dropping peer", "peer", id, "err", err) if d.dropPeer == nil &#123; log.Warn("Downloader wants to drop peer, but peerdrop-function is not set", "peer", id) &#125; else &#123; d.dropPeer(id) &#125; default: log.Warn("Synchronisation failed, retrying", "err", err) &#125; return err&#125; 直接调用synchronise方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455func (d *Downloader) synchronise(id string, hash common.Hash, td *big.Int, mode SyncMode) error &#123; if d.synchroniseMock != nil &#123; return d.synchroniseMock(id, hash) &#125; if !atomic.CompareAndSwapInt32(&amp;d.synchronising, 0, 1) &#123; return errBusy &#125; defer atomic.StoreInt32(&amp;d.synchronising, 0) if atomic.CompareAndSwapInt32(&amp;d.notified, 0, 1) &#123; log.Info("Block synchronisation started") &#125; d.queue.Reset() d.peers.Reset() for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123; select &#123; case &lt;-ch: default: &#125; &#125; for _, ch := range []chan dataPack&#123;d.headerCh, d.bodyCh, d.receiptCh&#125; &#123; for empty := false; !empty; &#123; select &#123; case &lt;-ch: default: empty = true &#125; &#125; &#125; for empty := false; !empty; &#123; select &#123; case &lt;-d.headerProcCh: default: empty = true &#125; &#125; d.cancelLock.Lock() d.cancelCh = make(chan struct&#123;&#125;) d.cancelPeer = id d.cancelLock.Unlock() defer d.Cancel() channel open d.mode = mode p := d.peers.Peer(id) if p == nil &#123; return errUnknownPeer &#125; return d.syncWithPeer(p, hash, td)&#125; 这一个方法是在做同步前的准备工作，先确定只有一个实例运行，然后重置queue和peers,表示一次同步准备开始，清空几个channel。之后从peers取出对应id的peer。peer保存着已连接的peer的peerConnection对象，由pm在新连接到来时通过downloader的RegisterPeer方法添加。然后执行syncWithPeer:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071func (d *Downloader) syncWithPeer(p *peerConnection, hash common.Hash, td *big.Int) (err error) &#123; d.mux.Post(StartEvent&#123;&#125;) defer func() &#123; if err != nil &#123; d.mux.Post(FailedEvent&#123;err&#125;) &#125; else &#123; latest := d.lightchain.CurrentHeader() d.mux.Post(DoneEvent&#123;latest&#125;) &#125; &#125;() if p.version &lt; 62 &#123; return errTooOld &#125; log.Debug("Synchronising with the network", "peer", p.id, "eth", p.version, "head", hash, "td", td, "mode", d.mode) defer func(start time.Time) &#123; log.Debug("Synchronisation terminated", "elapsed", time.Since(start)) &#125;(time.Now()) latest, err := d.fetchHeight(p) if err != nil &#123; return err &#125; height := latest.Number.Uint64() origin, err := d.findAncestor(p, latest) if err != nil &#123; return err &#125; d.syncStatsLock.Lock() if d.syncStatsChainHeight &lt;= origin || d.syncStatsChainOrigin &gt; origin &#123; d.syncStatsChainOrigin = origin &#125; d.syncStatsChainHeight = height d.syncStatsLock.Unlock() pivot := uint64(0) if d.mode == FastSync &#123; if height &lt;= uint64(fsMinFullBlocks) &#123; origin = 0 &#125; else &#123; pivot = height - uint64(fsMinFullBlocks) if pivot &lt;= origin &#123; origin = pivot - 1 &#125; &#125; &#125; d.committed = 1 if d.mode == FastSync &amp;&amp; pivot != 0 &#123; d.committed = 0 &#125; d.queue.Prepare(origin+1, d.mode) if d.syncInitHook != nil &#123; d.syncInitHook(origin, height) &#125; fetchers := []func() error&#123; func() error &#123; return d.fetchHeaders(p, origin+1, pivot) &#125;, // Headers are always retrieved func() error &#123; return d.fetchBodies(origin + 1) &#125;, // Bodies are retrieved during normal and fast sync func() error &#123; return d.fetchReceipts(origin + 1) &#125;, // Receipts are retrieved during fast sync func() error &#123; return d.processHeaders(origin+1, pivot, td) &#125;, &#125; if d.mode == FastSync &#123; fetchers = append(fetchers, func() error &#123; return d.processFastSyncContent(latest) &#125;) &#125; else if d.mode == FullSync &#123; fetchers = append(fetchers, d.processFullSyncContent) &#125; return d.spawnSync(fetchers)&#125; 这个表示从某个peer开始同步，先调用fetchHeight获取区块头：123456789101112131415161718192021222324252627282930313233343536func (d *Downloader) fetchHeight(p *peerConnection) (*types.Header, error) &#123; p.log.Debug("Retrieving remote chain height") head, _ := p.peer.Head() go p.peer.RequestHeadersByHash(head, 1, 0, false) ttl := d.requestTTL() timeout := time.After(ttl) for &#123; select &#123; case &lt;-d.cancelCh: return nil, errCancelBlockFetch case packet := &lt;-d.headerCh: if packet.PeerId() != p.id &#123; log.Debug("Received headers from incorrect peer", "peer", packet.PeerId()) break &#125; headers := packet.(*headerPack).headers if len(headers) != 1 &#123; p.log.Debug("Multiple headers for single request", "headers", len(headers)) return nil, errBadPeer &#125; head := headers[0] p.log.Debug("Remote head header identified", "number", head.Number, "hash", head.Hash()) return head, nil case &lt;-timeout: p.log.Debug("Waiting for head header timed out", "elapsed", ttl) return nil, errTimeout case &lt;-d.bodyCh: case &lt;-d.receiptCh: &#125; &#125;&#125; 这里主要就是启动一个goroutine利用RequestHeadersByHash方法去请求区块头，这里的peer是pm的newPeer方法创建的，RequestHeadersByHash就是发送一个GetBlockHeadersMsg消息。由于是在单独线程执行的RequestHeadersByHash，在外面设置了一个定时器，超时的话报错。 另外在回顾pm，在对方收到GetBlockHeadersMsg消息后，会回复BlockHeadersMsg消息，在fetcher过滤完后调用DeliverHeaders方法：12345678910111213141516171819202122232425func (d *Downloader) DeliverHeaders(id string, headers []*types.Header) (err error) &#123; return d.deliver(id, d.headerCh, &amp;headerPack&#123;id, headers&#125;, headerInMeter, headerDropMeter)&#125;func (d *Downloader) deliver(id string, destCh chan dataPack, packet dataPack, inMeter, dropMeter metrics.Meter) (err error) &#123; inMeter.Mark(int64(packet.Items())) defer func() &#123; if err != nil &#123; dropMeter.Mark(int64(packet.Items())) &#125; &#125;() d.cancelLock.RLock() cancel := d.cancelCh d.cancelLock.RUnlock() if cancel == nil &#123; return errNoSyncActive &#125; select &#123; case destCh &lt;- packet: return nil case &lt;-cancel: return errNoSyncActive &#125;&#125; 这里向destCh也就是headerCh赋值，也就触发fetchHeight中的对应逻辑，从而返回获得的区块头，这个区块头就是该peer的最新的区块。回到syncWithPeer中，又用findAncestor方法去寻找大家的共同祖先以便开始同步。 再往下设置了pivot，这是针对快速同步而言的，在最后64个块，即使是快速同步模式也要使用fullmode模式，这里如果对方高度小于64，则从0开始同步而pivot也为0，否则如果刚才计算的公共祖先在最后64个以内，则从倒数第64个开始同步而且pivot也设为倒数第64个区块高度。另外还设置committed的值，为1时表示快速模式结束。然后调用了queue的prepare方法准备进行同步，prepare主要是配置了偏移量和同步模式以便于调度时寻找正确区块。 接着设置一组fetcher方法分别用于fetch区块头、区块体和收据以及处理区块头，另外根据模式的不同添加不通的方法，最后调用spawnSync123456789101112131415161718192021func (d *Downloader) spawnSync(fetchers []func() error) error &#123; errc := make(chan error, len(fetchers)) d.cancelWg.Add(len(fetchers)) for _, fn := range fetchers &#123; fn := fn go func() &#123; defer d.cancelWg.Done(); errc &lt;- fn() &#125;() &#125; for i := 0; i &lt; len(fetchers); i++ &#123; if i == len(fetchers)-1 &#123; d.queue.Close() &#125; if err = &lt;-errc; err != nil &#123; break &#125; &#125; d.queue.Close() d.Cancel() return err&#125; 这里为fetchers中每个方法都启动一个goroutine去执行，等待结束或出错。我们看一下fetchers中的方法 fetchHeaders123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138func (d *Downloader) fetchHeaders(p *peerConnection, from uint64, pivot uint64) error &#123; p.log.Debug("Directing header downloads", "origin", from) defer p.log.Debug("Header download terminated") skeleton := true // Skeleton assembly phase or finishing up request := time.Now() // time of the last skeleton fetch request timeout := time.NewTimer(0) // timer to dump a non-responsive active peer &lt;-timeout.C // timeout channel should be initially empty defer timeout.Stop() var ttl time.Duration getHeaders := func(from uint64) &#123; request = time.Now() ttl = d.requestTTL() timeout.Reset(ttl) if skeleton &#123; p.log.Trace("Fetching skeleton headers", "count", MaxHeaderFetch, "from", from) go p.peer.RequestHeadersByNumber(from+uint64(MaxHeaderFetch)-1, MaxSkeletonSize, MaxHeaderFetch-1, false) &#125; else &#123; p.log.Trace("Fetching full headers", "count", MaxHeaderFetch, "from", from) go p.peer.RequestHeadersByNumber(from, MaxHeaderFetch, 0, false) &#125; &#125; getHeaders(from) for &#123; select &#123; case &lt;-d.cancelCh: return errCancelHeaderFetch case packet := &lt;-d.headerCh: if packet.PeerId() != p.id &#123; log.Debug("Received skeleton from incorrect peer", "peer", packet.PeerId()) break &#125; headerReqTimer.UpdateSince(request) timeout.Stop() if packet.Items() == 0 &amp;&amp; skeleton &#123; skeleton = false getHeaders(from) continue &#125; if packet.Items() == 0 &#123; if atomic.LoadInt32(&amp;d.committed) == 0 &amp;&amp; pivot &lt;= from &#123; p.log.Debug("No headers, waiting for pivot commit") select &#123; case &lt;-time.After(fsHeaderContCheck): getHeaders(from) continue case &lt;-d.cancelCh: return errCancelHeaderFetch &#125; &#125; p.log.Debug("No more headers available") select &#123; case d.headerProcCh &lt;- nil: return nil case &lt;-d.cancelCh: return errCancelHeaderFetch &#125; &#125; headers := packet.(*headerPack).headers if skeleton &#123; filled, proced, err := d.fillHeaderSkeleton(from, headers) if err != nil &#123; p.log.Debug("Skeleton chain invalid", "err", err) return errInvalidChain &#125; headers = filled[proced:] from += uint64(proced) &#125; else &#123; if n := len(headers); n &gt; 0 &#123; head := uint64(0) if d.mode == LightSync &#123; head = d.lightchain.CurrentHeader().Number.Uint64() &#125; else &#123; head = d.blockchain.CurrentFastBlock().NumberU64() if full := d.blockchain.CurrentBlock().NumberU64(); head &lt; full &#123; head = full &#125; &#125; if head+uint64(reorgProtThreshold) &lt; headers[n-1].Number.Uint64() &#123; delay := reorgProtHeaderDelay if delay &gt; n &#123; delay = n &#125; headers = headers[:n-delay] &#125; &#125; &#125; if len(headers) &gt; 0 &#123; p.log.Trace("Scheduling new headers", "count", len(headers), "from", from) select &#123; case d.headerProcCh &lt;- headers: case &lt;-d.cancelCh: return errCancelHeaderFetch &#125; from += uint64(len(headers)) getHeaders(from) &#125; else &#123; p.log.Trace("All headers delayed, waiting") select &#123; case &lt;-time.After(fsHeaderContCheck): getHeaders(from) continue case &lt;-d.cancelCh: return errCancelHeaderFetch &#125; &#125; case &lt;-timeout.C: if d.dropPeer == nil &#123; p.log.Warn("Downloader wants to drop peer, but peerdrop-function is not set", "peer", p.id) break &#125; p.log.Debug("Header request timed out", "elapsed", ttl) headerTimeoutMeter.Mark(1) d.dropPeer(p.id) for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123; select &#123; case ch &lt;- false: case &lt;-d.cancelCh: &#125; &#125; select &#123; case d.headerProcCh &lt;- nil: case &lt;-d.cancelCh: &#125; return errBadPeer &#125; &#125;&#125; 这个方法比较长，基本上分了两部分首先定义了一个getHeaders方法，用于从对应的peer获取一定数量的head，指定起始位置之后，根据是否是骨架模式来决定下载哪些head。如果是骨架模式，则从from+191开始获取128个head，每两个head之间间隔191个区块，这样构成一个断续的框架。如果不是骨架模式，则从from开始连续请求192个区块。请求方法都是peer的RequestHeadersByNumber方法，发送了GetBlockHeadersMsg消息，这个我们前面分析过，会触发接下来的for-select结构的headerCh逻辑。 在对应case中，首先验证了是否来自对应的peer，判断返回的head数，如果为0且是骨架模式，则禁用骨架模式，再次调用getHeaders请求head。如果再一次获取的head数量还是0，且仍处于快速模式并且没有进入最后64个区块，则等待3秒后继续刚才的连续请求知道接收到取消信号；如果获取的head数量还是0但不处于快速模式，表示已经同步完毕，给headerProcCh赋值并退出，headerProcCh影响processHeaders里的逻辑。 对于收到的区块头数量不为0的话，根据不同模式进行不同处理。 如果是骨架模式，则调用fillHeaderSkeleton去填充那个框架，这个方法里先调用ScheduleSkeleton进行调用，然后调用了fetchParts方法，这个稍后再讲。 如果不是骨架模式，表示我们从from开始连续请求了192个head，这里根据具体情况延迟最后几个区块头。总之这个if-else结构确定了下一步fetch的head集合。然后将该集合内的head赋值给headerProcCh触发processHeaders中对应逻辑，并更新from的值再次调用getHeaders去请求下一批head，直到没有head可取，等待3秒再次尝试。 fetchBodies1234567891011121314151617181920func (d *Downloader) fetchBodies(from uint64) error &#123; log.Debug("Downloading block bodies", "origin", from) var ( deliver = func(packet dataPack) (int, error) &#123; pack := packet.(*bodyPack) return d.queue.DeliverBodies(pack.peerID, pack.transactions, pack.uncles) &#125; expire = func() map[string]int &#123; return d.queue.ExpireBodies(d.requestTTL()) &#125; fetch = func(p *peerConnection, req *fetchRequest) error &#123; return p.FetchBodies(req) &#125; capacity = func(p *peerConnection) int &#123; return p.BlockCapacity(d.requestRTT()) &#125; setIdle = func(p *peerConnection, accepted int) &#123; p.SetBodiesIdle(accepted) &#125; ) err := d.fetchParts(errCancelBodyFetch, d.bodyCh, deliver, d.bodyWakeCh, expire, d.queue.PendingBlocks, d.queue.InFlightBlocks, d.queue.ShouldThrottleBlocks, d.queue.ReserveBodies, d.bodyFetchHook, fetch, d.queue.CancelBodies, capacity, d.peers.BodyIdlePeers, setIdle, "bodies") log.Debug("Block body download terminated", "err", err) return err&#125; 相比fetchHeaders，fetchBodies就简单很多，就是直接调用fetchParts，关于fetchParts稍后再分析 fetchReceipts1234567891011121314151617181920func (d *Downloader) fetchReceipts(from uint64) error &#123; log.Debug("Downloading transaction receipts", "origin", from) var ( deliver = func(packet dataPack) (int, error) &#123; pack := packet.(*receiptPack) return d.queue.DeliverReceipts(pack.peerID, pack.receipts) &#125; expire = func() map[string]int &#123; return d.queue.ExpireReceipts(d.requestTTL()) &#125; fetch = func(p *peerConnection, req *fetchRequest) error &#123; return p.FetchReceipts(req) &#125; capacity = func(p *peerConnection) int &#123; return p.ReceiptCapacity(d.requestRTT()) &#125; setIdle = func(p *peerConnection, accepted int) &#123; p.SetReceiptsIdle(accepted) &#125; ) err := d.fetchParts(errCancelReceiptFetch, d.receiptCh, deliver, d.receiptWakeCh, expire, d.queue.PendingReceipts, d.queue.InFlightReceipts, d.queue.ShouldThrottleReceipts, d.queue.ReserveReceipts, d.receiptFetchHook, fetch, d.queue.CancelReceipts, capacity, d.peers.ReceiptIdlePeers, setIdle, "receipts") log.Debug("Transaction receipt download terminated", "err", err) return err&#125; 和fetchBodies一样，都是直接调用fetchParts processHeaders123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124func (d *Downloader) processHeaders(origin uint64, pivot uint64, td *big.Int) error &#123; rollback := []*types.Header&#123;&#125; defer func() &#123; if len(rollback) &gt; 0 &#123; hashes := make([]common.Hash, len(rollback)) for i, header := range rollback &#123; hashes[i] = header.Hash() &#125; lastHeader, lastFastBlock, lastBlock := d.lightchain.CurrentHeader().Number, common.Big0, common.Big0 if d.mode != LightSync &#123; lastFastBlock = d.blockchain.CurrentFastBlock().Number() lastBlock = d.blockchain.CurrentBlock().Number() &#125; d.lightchain.Rollback(hashes) curFastBlock, curBlock := common.Big0, common.Big0 if d.mode != LightSync &#123; curFastBlock = d.blockchain.CurrentFastBlock().Number() curBlock = d.blockchain.CurrentBlock().Number() &#125; log.Warn("Rolled back headers", "count", len(hashes), "header", fmt.Sprintf("%d-&gt;%d", lastHeader, d.lightchain.CurrentHeader().Number), "fast", fmt.Sprintf("%d-&gt;%d", lastFastBlock, curFastBlock), "block", fmt.Sprintf("%d-&gt;%d", lastBlock, curBlock)) &#125; &#125;() gotHeaders := false for &#123; select &#123; case &lt;-d.cancelCh: return errCancelHeaderProcessing case headers := &lt;-d.headerProcCh: if len(headers) == 0 &#123; for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123; select &#123; case ch &lt;- false: case &lt;-d.cancelCh: &#125; &#125; if d.mode != LightSync &#123; head := d.blockchain.CurrentBlock() if !gotHeaders &amp;&amp; td.Cmp(d.blockchain.GetTd(head.Hash(), head.NumberU64())) &gt; 0 &#123; return errStallingPeer &#125; &#125; if d.mode == FastSync || d.mode == LightSync &#123; head := d.lightchain.CurrentHeader() if td.Cmp(d.lightchain.GetTd(head.Hash(), head.Number.Uint64())) &gt; 0 &#123; return errStallingPeer &#125; &#125; rollback = nil return nil &#125; gotHeaders = true for len(headers) &gt; 0 &#123; select &#123; case &lt;-d.cancelCh: return errCancelHeaderProcessing default: &#125; limit := maxHeadersProcess if limit &gt; len(headers) &#123; limit = len(headers) &#125; chunk := headers[:limit] if d.mode == FastSync || d.mode == LightSync &#123; unknown := make([]*types.Header, 0, len(headers)) for _, header := range chunk &#123; if !d.lightchain.HasHeader(header.Hash(), header.Number.Uint64()) &#123; unknown = append(unknown, header) &#125; &#125; frequency := fsHeaderCheckFrequency if chunk[len(chunk)-1].Number.Uint64()+uint64(fsHeaderForceVerify) &gt; pivot &#123; frequency = 1 &#125; if n, err := d.lightchain.InsertHeaderChain(chunk, frequency); err != nil &#123; if n &gt; 0 &#123; rollback = append(rollback, chunk[:n]...) &#125; log.Debug("Invalid header encountered", "number", chunk[n].Number, "hash", chunk[n].Hash(), "err", err) return errInvalidChain &#125; rollback = append(rollback, unknown...) if len(rollback) &gt; fsHeaderSafetyNet &#123; rollback = append(rollback[:0], rollback[len(rollback)-fsHeaderSafetyNet:]...) &#125; &#125; if d.mode == FullSync || d.mode == FastSync &#123; for d.queue.PendingBlocks() &gt;= maxQueuedHeaders || d.queue.PendingReceipts() &gt;= maxQueuedHeaders &#123; select &#123; case &lt;-d.cancelCh: return errCancelHeaderProcessing case &lt;-time.After(time.Second): &#125; &#125; inserts := d.queue.Schedule(chunk, origin) if len(inserts) != len(chunk) &#123; log.Debug("Stale headers") return errBadPeer &#125; &#125; headers = headers[limit:] origin += uint64(limit) &#125; d.syncStatsLock.Lock() if d.syncStatsChainHeight &lt; origin &#123; d.syncStatsChainHeight = origin - 1 &#125; d.syncStatsLock.Unlock() for _, ch := range []chan bool&#123;d.bodyWakeCh, d.receiptWakeCh&#125; &#123; select &#123; case ch &lt;- true: default: &#125; &#125; &#125; &#125;&#125; 这是固定的一组fetchers中的最后一个启动的方法，用于处理收到了head。 首先定义了一个defer执行的方法用于在出错时回滚。接着还是一个无限循环加select的结构，还记得前面fetchHeaders方法最后将一组head赋值给headerProcCh了么，就在这里触发了响应逻辑。 首先处理的传来的head数量为0的情况，为0的情况是在fetchHeaders中fetch区块头结束后给headerProcCh传了nil导致的，此时给bodyWakeCh和receiptWakeCh都传了false。接着判断了如果对方此时总难度还比我们大，但是我们却取不到什么东西则返回一个错误 对于传来的head数量不为0时，先判断数量是否大于2048，否则进行截断，先处理前2048个。接着对于同步模式是FastSync或者LightSync的情况，先遍历了传来的head在本地是否已有，没有的存入unknown中。接着定义了frequency，原始值为100，但是如果是最后64个则为1，这个值表示在插入时每隔多少个区块验证一次，最后64个区块需要全部验证，其余的每100个验证一次。然后调用InsertHeaderChain进行插入，这是core/blockchain.go中的方法，返回的n表示实在第几个区块出错的，最后如果有错则将chunk[:n]添加到rollback便于回滚，目的是一旦出错则回滚所有内容。如果没错也将刚才unknown的内容添加到rollback，如果回滚的总量大于2048，只取最后2048个区块。 再往下如果是FullSync或FastSync模式，先判断queue的PendingBlocks或PendingReceipts数量是否大于规定，是的话先等待1秒，反复循环直到其数量满足要求。然后调用了Schedule申请调度，接下来修改headers和origin循环处理剩余的head。 最后给通道d.bodyWakeCh, d.receiptWakeCh发送消息，触发对应逻辑。 fetchParts123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146// The instrumentation parameters:// - errCancel: fetch操作被取消时返回的错误类型// - deliveryCh: 检索下载数据包的通道// - deliver: 将数据包传递到特定队列的回调函数// - wakeCh: 当心的任务到来时唤醒fetch// - expire: 因为超时而终止的回调// - pending: 还需要下载的任务数量// - inFlight: 正在处理的请求数量// - throttle: 用于检测某个队列是否已满// - reserve: 用来将新的下载任务保留给特定的peer// - fetchHook: 用于通知正在启动新的任务// - fetch: 发送网络请求// - cancel: 取消正在请求的下载// - capacity: 获取网络带宽// - idle: 检测peer是否空闲// - setIdle: 设置peer为空闲// - kind: 正在下载的类型func (d *Downloader) fetchParts(errCancel error, deliveryCh chan dataPack, deliver func(dataPack) (int, error), wakeCh chan bool, expire func() map[string]int, pending func() int, inFlight func() bool, throttle func() bool, reserve func(*peerConnection, int) (*fetchRequest, bool, error), fetchHook func([]*types.Header), fetch func(*peerConnection, *fetchRequest) error, cancel func(*fetchRequest), capacity func(*peerConnection) int, idle func() ([]*peerConnection, int), setIdle func(*peerConnection, int), kind string) error &#123; ticker := time.NewTicker(100 * time.Millisecond) defer ticker.Stop() update := make(chan struct&#123;&#125;, 1) finished := false for &#123; select &#123; case &lt;-d.cancelCh: return errCancel case packet := &lt;-deliveryCh: if peer := d.peers.Peer(packet.PeerId()); peer != nil &#123; accepted, err := deliver(packet) if err == errInvalidChain &#123; return err &#125; if err != errStaleDelivery &#123; setIdle(peer, accepted) &#125; switch &#123; case err == nil &amp;&amp; packet.Items() == 0: peer.log.Trace("Requested data not delivered", "type", kind) case err == nil: peer.log.Trace("Delivered new batch of data", "type", kind, "count", packet.Stats()) default: peer.log.Trace("Failed to deliver retrieved data", "type", kind, "err", err) &#125; &#125; select &#123; case update &lt;- struct&#123;&#125;&#123;&#125;: default: &#125; case cont := &lt;-wakeCh: if !cont &#123; finished = true &#125; select &#123; case update &lt;- struct&#123;&#125;&#123;&#125;: default: &#125; case &lt;-ticker.C: select &#123; case update &lt;- struct&#123;&#125;&#123;&#125;: default: &#125; case &lt;-update: if d.peers.Len() == 0 &#123; return errNoPeers &#125; for pid, fails := range expire() &#123; if peer := d.peers.Peer(pid); peer != nil &#123; if fails &gt; 2 &#123; peer.log.Trace("Data delivery timed out", "type", kind) setIdle(peer, 0) &#125; else &#123; peer.log.Debug("Stalling delivery, dropping", "type", kind) if d.dropPeer == nil &#123; peer.log.Warn("Downloader wants to drop peer, but peerdrop-function is not set", "peer", pid) &#125; else &#123; d.dropPeer(pid) &#125; &#125; &#125; &#125; if pending() == 0 &#123; if !inFlight() &amp;&amp; finished &#123; log.Debug("Data fetching completed", "type", kind) return nil &#125; break &#125; progressed, throttled, running := false, false, inFlight() idles, total := idle() for _, peer := range idles &#123; if throttle() &#123; throttled = true break &#125; if pending() == 0 &#123; break &#125; request, progress, err := reserve(peer, capacity(peer)) if err != nil &#123; return err &#125; if progress &#123; progressed = true &#125; if request == nil &#123; continue &#125; if request.From &gt; 0 &#123; peer.log.Trace("Requesting new batch of data", "type", kind, "from", request.From) &#125; else &#123; peer.log.Trace("Requesting new batch of data", "type", kind, "count", len(request.Headers), "from", request.Headers[0].Number) &#125; if fetchHook != nil &#123; fetchHook(request.Headers) &#125; if err := fetch(peer, request); err != nil &#123; panic(fmt.Sprintf("%v: %s fetch assignment failed", peer, kind)) &#125; running = true &#125; if !progressed &amp;&amp; !throttled &amp;&amp; !running &amp;&amp; len(idles) == total &amp;&amp; pending() &gt; 0 &#123; return errPeersUnavailable &#125; &#125; &#125;&#125; 这个方法在前面多次出现，这里详细分析一下。首先这个方法的参数非常多，大致功能在方法前的注释部分已经写了，可以简单参考一下。 首先设置了一个ticker，每100毫秒触发一次，触发时向update写入内容，触发相应逻辑：首先判断peer数量是否为0，然后调用expire方法获取那些因为超时而终止的请求，expire根据传入的参数有不同的方法，但都属于queue的ExpireXxx其中之一，最后返回的是一个map，保存着每个peer超时的请求的head数量。回到fetchParts中，遍历这个map，如果对应peer失效的head数大于2，者将其设为idle状态。否则调用pm的removePeer方法将该peer移除。 处理完超时的请求后，调用了pending方法，这个方法主要就是返回queue中headerTaskQueue、blockTaskQueue和receiptTaskQueue这几个队列其中某个的大小，这些队列存储着调度任务。如果对应队列为空的话，调用了inFlight方法，对应的是queue中headerPendPool、blockPendPool和receiptPendPool这几个请求等待池中对应的那个池是否为空，如果不为空但是finished为true表示完成则退出，否则表示暂时没有任务，进行下次循环等待逻辑触发。 接下来设置了几个标志位，然后通过idle方法获取了对应状态空闲的peer。之后遍历这些空闲的peer。下面调用了throttle方法，分别对应queue中的ShouldThrottleBlocks和ShouldThrottleReceipts，在fillHeaderSkeleton中调用fetchParts该方法时直接返回false。ShouldThrottleBlocks和ShouldThrottleReceipts分别返回对应下载任务是否需要限流。如果需要则停止本次操作，等待下一次。否则如果没有等待的任务则也停止本次操作。 再往下调用了reserve，对应的是queue的ReserveHeaders、ReserveBodies和ReserveReceipts方法。传入的参数是相应的peer的HeaderCapacity、BlockCapacity或ReceiptCapacity返回的结果。关于ReserveXxx后面会详细介绍，这里简单说一下作用。对于ReserveHeaders，是构造一个请求，请求中包含了起始位置，让后将请求放入headerPendPool并返回这个请求，headerPendPool存储了等待下载的请求。对于ReserveBodies和ReserveReceipts则是将对应的taskQueue的head进行分类，并构造请求结果放入resultCache中，之后将要跳过的head重新放入taskQueue，最后构建一个请求包含剩余的head，并将该请求放入对应的pendPool，最后返回该请求以及处理状态progress。其中的taskQueue是在调用Schedule时放入的，这里取出准备进行请求。 回到fetchParts中，经过reserve方法后，返回了构造的请求。进行了简单的判断后，调用了fetch方法去处理请求。分别对应peer的FetchHeaders、FetchBodies和FetchReceipts。这几个方法就是根据请求的内容实际调用peer的Request去发送请求。 这样一个idle状态的peer处理完毕，后面会遍历所有idle状态的peer执行相同逻辑。 除了update对应的逻辑，还有deliveryCh对应的逻辑。回顾pm的handleMsg逻辑，在收到BlockHeadersMsg、BlockBodiesMsg和ReceiptsMsg消息后，这几个消息对应前面FetchHeaders、FetchBodies和FetchReceipts发送的请求消息的回应，也就是在收到响应后，会调用downloader的相应DeliverXxx方法，之后调用deliver方法，这个方法的主要作用是向headerCh、bodyCh和receiptCh某一个发送收到的包，headerCh、bodyCh和receiptCh这三个channel分别在调用fetchParts时被传入deliveryCh参数，所以收到响应后触发了deliveryCh对应的逻辑。 在这里面，首先调用了deliver方法，这个分别对应queue的DeliverHeaders、DeliverBodies和DeliverReceipts方法。这几个方法后面会详细介绍，这里简单说一下作用。对于DeliverHeaders方法主要是检查收到的heads是否正确，不正确的话将其重新放回headerTaskQueue等待后续处理。正确的话将准备好的head传入headerProcCh触发processHeaders中逻辑并返回收到的head数量。对于DeliverBodies和DeliverReceipts，主要是对收到的数据进行检查，成功的补全fetchResult，不成功放入taskQueue重新请求。最后返回成功接收的数量，然后将对应peer设为空闲，最后打印log。 processFastSyncContent123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778func (d *Downloader) processFastSyncContent(latest *types.Header) error &#123; stateSync := d.syncState(latest.Root) defer stateSync.Cancel() go func() &#123; if err := stateSync.Wait(); err != nil &amp;&amp; err != errCancelStateFetch &#123; d.queue.Close() // wake up Results &#125; &#125;() pivot := uint64(0) if height := latest.Number.Uint64(); height &gt; uint64(fsMinFullBlocks) &#123; pivot = height - uint64(fsMinFullBlocks) &#125; var ( oldPivot *fetchResult // Locked in pivot block, might change eventually oldTail []*fetchResult // Downloaded content after the pivot ) for &#123; results := d.queue.Results(oldPivot == nil) // Block if we're not monitoring pivot staleness if len(results) == 0 &#123; if oldPivot == nil &#123; return stateSync.Cancel() &#125; select &#123; case &lt;-d.cancelCh: return stateSync.Cancel() default: &#125; &#125; if d.chainInsertHook != nil &#123; d.chainInsertHook(results) &#125; if oldPivot != nil &#123; results = append(append([]*fetchResult&#123;oldPivot&#125;, oldTail...), results...) &#125; if atomic.LoadInt32(&amp;d.committed) == 0 &#123; latest = results[len(results)-1].Header if height := latest.Number.Uint64(); height &gt; pivot+2*uint64(fsMinFullBlocks) &#123; log.Warn("Pivot became stale, moving", "old", pivot, "new", height-uint64(fsMinFullBlocks)) pivot = height - uint64(fsMinFullBlocks) &#125; &#125; P, beforeP, afterP := splitAroundPivot(pivot, results) if err := d.commitFastSyncData(beforeP, stateSync); err != nil &#123; return err &#125; if P != nil &#123; if oldPivot != P &#123; stateSync.Cancel() stateSync = d.syncState(P.Header.Root) defer stateSync.Cancel() go func() &#123; if err := stateSync.Wait(); err != nil &amp;&amp; err != errCancelStateFetch &#123; d.queue.Close() // wake up Results &#125; &#125;() oldPivot = P &#125; select &#123; case &lt;-stateSync.done: if stateSync.err != nil &#123; return stateSync.err &#125; if err := d.commitPivotBlock(P); err != nil &#123; return err &#125; oldPivot = nil case &lt;-time.After(time.Second): oldTail = afterP continue &#125; &#125; if err := d.importBlockResults(afterP); err != nil &#123; return err &#125; &#125;&#125; 这是fast模式特有的方法，也是整个快速同步过程中的最后一步。首先调用syncState，这个方法后面会分析，syncState启动后开始同步状态树。与此同时processFastSyncContent中计算了pivot，这个值和前面syncWithPeer中的pivot类似。随后启动了一个死循环，循环中先调用Results方法，Results主要取出已经处理完成的块。然后将这些块根据pivot的值分为3部分（使用splitAroundPivot）：pivot之前的、pivot之后的和pivot位置上的。然后将之前的直接插入区块链（使用commitFastSyncData方法），对于之后的虽然也要插入区块链，但是不直接插入收据数据。 processFullSyncContent1234567891011121314func (d *Downloader) processFullSyncContent() error &#123; for &#123; results := d.queue.Results(true) if len(results) == 0 &#123; return nil &#125; if d.chainInsertHook != nil &#123; d.chainInsertHook(results) &#125; if err := d.importBlockResults(results); err != nil &#123; return err &#125; &#125;&#125; 这个是full模式下的最后一步，首先还是调用Results获取已经处理完毕的块，然后调用importBlockResults方法插入区块链，和processFastSyncContent中处理pivot点之后的区块一样，不直接插入下载的收据，详细插入过程在BlockChain源码部分分析。 processFullSyncContent与processFastSyncContent也就集中体现了两种同步方式的区别 DeliverXxx是一组方法，一共有四个DeliverHeaders、DeliverBodies、DeliverReceipts和DeliverNodeData，前三个在queue中有同名方法，但作用不同。这几个方法主要用在pm中，用于在收到对应响应时执行对应逻辑123456789101112131415func (d *Downloader) DeliverHeaders(id string, headers []*types.Header) (err error) &#123; return d.deliver(id, d.headerCh, &amp;headerPack&#123;id, headers&#125;, headerInMeter, headerDropMeter)&#125;func (d *Downloader) DeliverBodies(id string, transactions [][]*types.Transaction, uncles [][]*types.Header) (err error) &#123; return d.deliver(id, d.bodyCh, &amp;bodyPack&#123;id, transactions, uncles&#125;, bodyInMeter, bodyDropMeter)&#125;func (d *Downloader) DeliverReceipts(id string, receipts [][]*types.Receipt) (err error) &#123; return d.deliver(id, d.receiptCh, &amp;receiptPack&#123;id, receipts&#125;, receiptInMeter, receiptDropMeter)&#125;func (d *Downloader) DeliverNodeData(id string, data [][]byte) (err error) &#123; return d.deliver(id, d.stateCh, &amp;statePack&#123;id, data&#125;, stateInMeter, stateDropMeter)&#125; 都只是调用了deliver方法，区别在于传入的数据和触发异步逻辑的channel123456789101112131415161718192021func (d *Downloader) deliver(id string, destCh chan dataPack, packet dataPack, inMeter, dropMeter metrics.Meter) (err error) &#123; inMeter.Mark(int64(packet.Items())) defer func() &#123; if err != nil &#123; dropMeter.Mark(int64(packet.Items())) &#125; &#125;() d.cancelLock.RLock() cancel := d.cancelCh d.cancelLock.RUnlock() if cancel == nil &#123; return errNoSyncActive &#125; select &#123; case destCh &lt;- packet: return nil case &lt;-cancel: return errNoSyncActive &#125;&#125; 没有什么实际动作，关键是将收到的数据传给destCh触发后续逻辑，对于前三个方法都是触发fetchParts中deliveryCh的逻辑，第四个方法触发了statesync中runStateSyn方法的逻辑。 题图来自unsplash：https://unsplash.com/photos/PHdLDymaV90]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过RPC与太坊节点交互]]></title>
    <url>%2F2019%2F05%2F13%2F%E9%80%9A%E8%BF%87RPC%E4%B8%8E%E5%A4%AA%E5%9D%8A%E8%8A%82%E7%82%B9%E4%BA%A4%E4%BA%92%2F</url>
    <content type="text"><![CDATA[背景geth提供了一整套的rpc接口，分为标准接口和扩展接口，平时我们打开geth客户端默认开放的就是标准接口，关于标准接口中所有接口的详细内容见这里，除了标准接口之外geth又添加了一系列扩展接口，如用于节点管理的admin系列接口，管理挖矿miner系列接口等，详细说明见这里，要想使用这一类rpc接口，需要在启动geth客户端时使用指定所开放的接口。 以太坊实现rpc的方法有多种，外部可以使用的有http，ipc和ws。下面分别介绍一下 HTTP-RPC要使用这种rpc需要在启动时使用–rpc开启，默认开放在8545端口上，可以使用–rpcport修改，另外还可以用–rpcaddr指定监听地址，默认为localhost，修改外外网ip就可以在外网访问本地节点；用–rpcapi指定所开放的api。（后面的ipc和ws模式都有相关参数设置） curl命令由于是jsonrpc类型的接口，所以我们需要向目标地址端口发送json格式数据来，首先可以根据官方文档说明的使用curl命令体验一下，命令如下：1curl -X POST --data '&#123;"jsonrpc":"2.0","method":"rpc_modules","params":[],"id":67&#125;' 127.0.0.1:8545 -X POST指定使用post方式发送数据，–data指定发送的Jason数据，其中需要指定的几个字段我们稍后介绍，最后跟上地址和端口。最后返回下面数据，这里我们请求的是服务端开发的api接口：123456789101112&#123; "id": 67, "jsonrpc": "2.0", "result": &#123; "eth": "1.0", "evm": "1.0", "net": "1.0", "personal": "1.0", "rpc": "1.0", "web3": "1.0" &#125;&#125; 还有一点需要注意的是，如果使用ganache测试上面的命令基本可以通过，如果用geth测试，需要加上-H “Content-Type: application/json” 代码调用除了使用命令行的方法，我们还可以使用代码调用：12345678910111213141516171819202122package mainimport ( "fmt" "io/ioutil" "log" "net/http" "strings")func main() &#123; resp,err:=http.Post("http://127.0.0.1:8545","application/x-www-form-urlencoded",strings.NewReader(`&#123;"jsonrpc":"2.0","method":"rpc_modules","params":[],"id":67&#125;`)) if err!=nil&#123; log.Fatal(err) &#125; defer resp.Body.Close() body,err:=ioutil.ReadAll(resp.Body) if err!=nil&#123; log.Fatal(err) &#125; fmt.Println(string(body))&#125; 和前面使用的curl命令效果一样，发送一个post请求，注意contentType要为”application/x-www-form-urlencoded”，但是在geth测试中要改为application/json，为了谨慎起见建议无论用什么测试都将contentType设为application/json。 既然是发送的json数据，我们实际使用时候并不想每次都直接写入json字符串，我们还可以使用json对象形式，关于json对象的数据结构，我们通过翻阅源码（详见这里）可知go-ethereum的jsonrpc数据结构如下1234567891011121314type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125;type jsonError struct &#123; Code int `json:"code"` Message string `json:"message"` Data interface&#123;&#125; `json:"data,omitempty"`&#125; 无论收发都用的是jsonrpcMessage，这里也可以发现我们请求的时候需要指定一下内容：Version：版本号，字段是jsonrpc；ID：本次请求的ID，字段是id；Method：本次请求的方法，字段是method；Params：本次请求的方法参数列表，字段是params。剩余的Error和Result是响应中包含的。既然知道了json对象，我们就可以构建一个对象然后像上面一样发送请求，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "bytes" "encoding/json" "fmt" "io/ioutil" "log" "net/http")type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125;type jsonError struct &#123; Code int `json:"code"` Message string `json:"message"` Data interface&#123;&#125; `json:"data,omitempty"`&#125;func main() &#123; msg:=jsonrpcMessage&#123;Version:"2.0",Method:"rpc_modules",Params:json.RawMessage&#123;&#125;,ID:json.RawMessage("5")&#125; data,err:=json.Marshal(msg) if err!=nil&#123; log.Fatal("Marshal:",err) &#125; resp,err:=http.Post("http://127.0.0.1:8545","application/json",bytes.NewReader(data)) if err!=nil&#123; log.Fatal("Post:",err) &#125; defer resp.Body.Close() body,err:=ioutil.ReadAll(resp.Body) if err!=nil&#123; log.Fatal("ReadAll:",err) &#125; var result jsonrpcMessage err=json.Unmarshal(body,&amp;result) if err!=nil&#123; log.Fatal("Unmarshal:",err) &#125; fmt.Println(string(result.Result))&#125; 上面举得都是不带参数的例子，对于带参数的主要问题是在源码中jsonrpcMessage的Params字段是一个json.RawMessage类型，当然我们可以给他改为[]string，不过不修改也可以使用，json.RawMessage主要作用就是在序列化或反序列化时保持数据原样，而json.RawMessage本身实际上就是一个字节数组，详细信息可见json源码。所以我们在给结构体中json.RawMessage类型字段赋值时要先对数据进行一次序列化，即变为字节数组后再赋值，如下调用了web3_sha3方法12params,_:=json.Marshal([]string&#123;"0x68656c6c6f20776f726c64"&#125;)msg:=jsonrpcMessage&#123;Version:"2.0",Method:"web3_sha3",Params:params,ID:json.RawMessage("5")&#125; IPC-RPC不同于http-rpc，ipc形式的rpc在geth户客户端是默认开启的，默认文件路径是datadir/geth.ipc，在linux中使用的是unix socket形式 nc命令根据官方文档提示，我们可以用nc命令实现调用，还是发送一段json数据，如下1echo '&#123;"jsonrpc":"2.0","method":"rpc_modules","params":[],"id":1&#125;' | nc -U mychain/chain1/geth.ipc 代码调用go语言版本的代码调用如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package mainimport ( "bytes" "encoding/json" "fmt" "log" "net")type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125;type jsonError struct &#123; Code int `json:"code"` Message string `json:"message"` Data interface&#123;&#125; `json:"data,omitempty"`&#125;func main() &#123; msg:=jsonrpcMessage&#123;Version:"2.0",Method:"rpc_modules",Params:json.RawMessage&#123;&#125;,ID:json.RawMessage("5")&#125; data,err:=json.Marshal(msg) if err!=nil &#123; log.Fatalln("Marshal: ",err) &#125; conn,err:=net.Dial("unix","/home/chenw/chenyy/mychain/chain1/geth.ipc") defer conn.Close() if err!=nil &#123; log.Fatalln("dial: ",err) &#125; _,err=conn.Write(data) if err!=nil &#123; log.Fatalln("write: ",err) &#125; temp := make([]byte,1024) var buf bytes.Buffer var result jsonrpcMessage count:=0 for&#123; n,err:=conn.Read(temp) if err!=nil &#123; log.Fatalln("read: ",err) &#125; count+=n buf.Write(temp) if json.Valid(buf.Bytes()[:count]) &#123; break &#125; &#125; json.Unmarshal(buf.Bytes()[:count],&amp;result) fmt.Println(string(result.Result))&#125; websocket-RPC最后再演示一下websocket的rpc调用，首先要注意的是go的标准包并不支持websocket，go-ethereum使用的是golang官方维护的一个net包–”golang.org/x/net/websocket”，其中有websocket实现，但是该包并不完善，官方推荐使用Gorilla WebSocket，所以首先要安装该包1go get github.com/gorilla/websocket 其次要测试ws，要在启动以太坊节点时加上–ws参数，完整客户端测试代码如下1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( "encoding/json" "fmt" "github.com/gorilla/websocket" "log" "net/url")type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125;type jsonError struct &#123; Code int `json:"code"` Message string `json:"message"` Data interface&#123;&#125; `json:"data,omitempty"`&#125;func main() &#123; msg:=jsonrpcMessage&#123;Version:"2.0",Method:"rpc_modules",Params:json.RawMessage&#123;&#125;,ID:json.RawMessage("5")&#125; u:=url.URL&#123;Scheme:"ws",Host:"127.0.0.1:8546"&#125; c,_,err:=websocket.DefaultDialer.Dial(u.String(),nil); if err!=nil&#123; log.Fatal("Dial:",err) &#125; defer c.Close() err=c.WriteJSON(msg) if err!=nil&#123; log.Fatal("WriteJSON:",err) &#125; var result jsonrpcMessage err=c.ReadJSON(&amp;result) if err!=nil&#123; log.Fatal("ReadJSON:",err) &#125; fmt.Println(string(result.Result))&#125; 跨语言原生调用既然是jsonrpc格式请求，那么跨语言的交互也是必须的，下面用java语言演示一下httprpc调用，首先定义json数据对象12345678910111213class JsonMsg&#123; String jsonrpc; int id; String method; JsonArray params; JsonErr error; JsonElement result;&#125;class JsonErr&#123; int code; String message; String data;&#125; 其中params我定义为一个JsonArray类型，result定义为JsonElement类型，处理json数据时使用Gson库：1234567891011121314151617181920212223242526272829303132333435public class GethRPC &#123; public static void main(String[] args) &#123; Gson gson = new Gson(); JsonMsg msg = new JsonMsg(); msg.jsonrpc = "2.0"; msg.method = "web3_clientVersion"; msg.id = 5; String request = gson.toJson(msg); System.out.println(request); try&#123; URL url = new URL("http://127.0.0.1:8545"); URLConnection conn = url.openConnection(); conn.setRequestProperty("Content-Type", "application/json"); conn.setRequestProperty("charset", "utf-8"); conn.setRequestProperty("Content-length",request.length()+""); conn.setDoInput(true); conn.setDoOutput(true); conn.setUseCaches(false); BufferedOutputStream outputStream = new BufferedOutputStream(conn.getOutputStream()); outputStream.write(request.getBytes(),0,request.getBytes().length); outputStream.close(); BufferedInputStream inputStream = new BufferedInputStream(conn.getInputStream()); ByteArrayOutputStream result = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int length; while ((length = inputStream.read(buffer)) != -1) &#123; result.write(buffer, 0, length); &#125; System.out.println(result.toString("UTF-8")); System.out.println(gson.fromJson(result.toString("UTF-8"),JsonMsg.class).result); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; 对于有参数的rpc调用如下：12345678910111213141516171819202122232425262728293031323334353637383940public class GethRPC &#123; public static void main(String[] args) &#123; Gson gson = new Gson(); JsonMsg msg = new JsonMsg(); msg.jsonrpc = "2.0"; msg.method = "web3_sha3"; JsonArray params = new JsonArray(); params.add("0x68656c6c6f20776f726c64"); msg.params = params; msg.id = 5; String request = gson.toJson(msg); System.out.println(request); try&#123; URL url = new URL("http://127.0.0.1:8545"); URLConnection conn = url.openConnection(); conn.setRequestProperty("Content-Type", "application/json"); conn.setRequestProperty("charset", "utf-8"); conn.setRequestProperty("Content-length",request.length()+""); conn.setDoInput(true); conn.setDoOutput(true); conn.setUseCaches(false); BufferedOutputStream outputStream = new BufferedOutputStream(conn.getOutputStream()); outputStream.write(request.getBytes(),0,request.getBytes().length); outputStream.close(); BufferedInputStream inputStream = new BufferedInputStream(conn.getInputStream()); ByteArrayOutputStream result = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int length; while ((length = inputStream.read(buffer)) != -1) &#123; result.write(buffer, 0, length); &#125; System.out.println(result.toString("UTF-8")); System.out.println(gson.fromJson(result.toString("UTF-8"),JsonMsg.class).result); inputStream.close(); result.close(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; web3.js像前面那样直接通过以太坊的rpc接口进行交互也行的通，但是还是比较麻烦，于是以太坊官方推出了一个库–web3.js，他是用js实现的API，用于和以太坊节点通信，底层还是rpc调用，只是帮我们封装了一系列方法，我们直接调用即可。 使用起来很简单，首先在工程目录下安装web3（当然前提是安装了node.js）：1npm install web3 然后开启以太坊节点，如ganache-cli，下面提供一个示例获取节点上的所有账户和某些账户的余额：1234var Web3 = require("web3");var web3 = new Web3(new Web3.providers.HttpProvider("http://localhost:8545"));web3.eth.getAccounts().then(console.log);web3.eth.getBalance("0x383edc3e6721b037263a92bf7218cc71fe617cd9").then(console.log); 使用起来很简单，首先获取web3模块，然后创建web3对象，创建时使用HttpProvider也就是http-rpc的方式连接以太坊节点，当然也可以使用websocket的方法连接，这时首先要开启节点的websocket功能（使用–ws），然后创建web3对象时用一下方式：1var web3 = new Web3(new Web3.providers.WebsocketProvider('ws://localhost:8546')); 另外关于web3.js的api问题，由于不同版本的api变化较大，详细信息参考官方文档。 当然web3.js是是为js语言服务的，相应的还有python版、java版的类似库供我们使用。 题图来自unsplash：https://unsplash.com/photos/8pgK9350lv4]]></content>
      <categories>
        <category>以太坊</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中eth-Fetcher源码学习]]></title>
    <url>%2F2019%2F05%2F10%2Fgo-ethereum%E4%B8%ADeth-Fetcher%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[数据结构fetcher负责收集来自各个对等点的块通知并进行处理。前面在介绍ProtocolManager时就出现过，我们先看数据结构1234567891011type announce struct &#123; hash common.Hash // Hash of the block being announced number uint64 // Number of the block being announced (0 = unknown | old protocol) header *types.Header // Header of the block partially reassembled (new protocol) time time.Time // Timestamp of the announcement origin string // Identifier of the peer originating the notification fetchHeader headerRequesterFn // Fetcher function to retrieve the header of an announced block fetchBodies bodyRequesterFn // Fetcher function to retrieve the body of an announced block&#125; announce是一个通知，表示网络中有新块出现。1234type inject struct &#123; origin string block *types.Block&#125; inject表示要插入一个区块。1234567891011121314151617181920212223242526272829303132333435363738type Fetcher struct &#123; // Various event channels notify chan *announce inject chan *inject headerFilter chan chan *headerFilterTask bodyFilter chan chan *bodyFilterTask done chan common.Hash quit chan struct&#123;&#125; // Announce states announces map[string]int // Per peer announce counts to prevent memory exhaustion announced map[common.Hash][]*announce // Announced blocks, scheduled for fetching fetching map[common.Hash]*announce // Announced blocks, currently fetching fetched map[common.Hash][]*announce // Blocks with headers fetched, scheduled for body retrieval completing map[common.Hash]*announce // Blocks with headers, currently body-completing // Block cache queue *prque.Prque // Queue containing the import operations (block number sorted) queues map[string]int // Per peer block counts to prevent memory exhaustion queued map[common.Hash]*inject // Set of already queued blocks (to dedupe imports) // Callbacks getBlock blockRetrievalFn // Retrieves a block from the local chain verifyHeader headerVerifierFn // Checks if a block's headers have a valid proof of work broadcastBlock blockBroadcasterFn // Broadcasts a block to connected peers chainHeight chainHeightFn // Retrieves the current chain's height insertChain chainInsertFn // Injects a batch of blocks into the chain dropPeer peerDropFn // Drops a peer for misbehaving // Testing hooks announceChangeHook func(common.Hash, bool) // Method to call upon adding or deleting a hash from the announce list queueChangeHook func(common.Hash, bool) // Method to call upon adding or deleting a block from the import queue fetchingHook func([]common.Hash) // Method to call upon starting a block (eth/61) or header (eth/62) fetch completingHook func([]common.Hash) // Method to call upon starting a block body fetch (eth/62) importedHook func(*types.Block) // Method to call upon successful block import (both eth/61 and eth/62)&#125; New在创建ProtocolManager时使用了NewProtocolManager方法，在最后使用fetcher的new方法创建了一个fetcher：1234567891011121314151617181920212223242526manager.fetcher = fetcher.New(blockchain.GetBlockByHash, validator, manager.BroadcastBlock, heighter, inserter, manager.removePeer)func New(getBlock blockRetrievalFn, verifyHeader headerVerifierFn, broadcastBlock blockBroadcasterFn, chainHeight chainHeightFn, insertChain chainInsertFn, dropPeer peerDropFn) *Fetcher &#123; return &amp;Fetcher&#123; notify: make(chan *announce), inject: make(chan *inject), headerFilter: make(chan chan *headerFilterTask), bodyFilter: make(chan chan *bodyFilterTask), done: make(chan common.Hash), quit: make(chan struct&#123;&#125;), announces: make(map[string]int), announced: make(map[common.Hash][]*announce), fetching: make(map[common.Hash]*announce), fetched: make(map[common.Hash][]*announce), completing: make(map[common.Hash]*announce), queue: prque.New(nil), queues: make(map[string]int), queued: make(map[common.Hash]*inject), getBlock: getBlock, verifyHeader: verifyHeader, broadcastBlock: broadcastBlock, chainHeight: chainHeight, insertChain: insertChain, dropPeer: dropPeer, &#125;&#125; new方法并没有什么实际逻辑，只是创建了一个对象，只不过传入了几个方法：getBlock表示根据hash值获取对应区块，verifyHeader用来验证区块头，broadcastBlock表示给peer广播区块，chainHeight用来获取区块链高度，insertChain用来插入区块，dropPeer用来删除一个peer。 上面几个方法中getBlock、chainHeight和insertChain都是BlockChain的方法，verifyHeader是共识引擎的方法，broadcastBlock和dropPeer都是ProtocolManager的方法。 Start &amp; loop在ProtocolManager调用Start方法启动后，会调用syncer方法，此时启动fetcher，使用的是Start方法：123func (f *Fetcher) Start() &#123; go f.loop()&#125; 可见只是启动了一个goroutine去执行loop12345678910111213141516171819202122232425262728293031323334353637383940func (f *Fetcher) loop() &#123; fetchTimer := time.NewTimer(0) completeTimer := time.NewTimer(0) for &#123; for hash, announce := range f.fetching &#123; if time.Since(announce.time) &gt; fetchTimeout &#123; f.forgetHash(hash) &#125; &#125; height := f.chainHeight() for !f.queue.Empty() &#123; op := f.queue.PopItem().(*inject) hash := op.block.Hash() if f.queueChangeHook != nil &#123; f.queueChangeHook(hash, false) &#125; number := op.block.NumberU64() if number &gt; height+1 &#123; f.queue.Push(op, -int64(number)) if f.queueChangeHook != nil &#123; f.queueChangeHook(hash, true) &#125; break &#125; if number+maxUncleDist &lt; height || f.getBlock(hash) != nil &#123; f.forgetBlock(hash) continue &#125; f.insert(op.origin, op.block) &#125; select &#123; .... &#125; &#125;&#125; 既然是loop就还是一样的套路，里面有一个死循环，再嵌套一个select结构用来触发相应事件。在loop首先定义了两个定时器，不过此时定时时间都是0，也就是立即会触发。 然后进入for循环，先遍历所有正在fetcher的announce，对于那些fetcher超过5秒的进行抛弃。然后获取了区块链高度，接着遍历了queue队列，这是一个优先级队列，优先级是其区块编号的负数，这样编号越小的区块优先级越高。每次从队列顶端取一个，这个是inject对象，如果他的编号大于当前区块高度加一，就先放回队列然后退出循环，否则如果区块过于旧，即比当前区块高度减7还小就抛弃，最后如果合适就插入。 遍历完queue后进入select结构。其中一些case我们后面会陆续介绍。在loop中会通过四个map记录announce状态：announced表示等待fetch，fetching表示正在fetch；fetched表示fetch完头部等待fetch区块体；completing表示完全结束。 FilterHeaders在pm中如果收到code为BlockHeadersMsg的消息时，这个消息是在请求方发送GetBlockHeadersMsg消息后收到响应的消息，表示接收到了区块头，这时会调用fetcher的FilterHeaders方法去处理123456789101112131415161718192021222324func (f *Fetcher) FilterHeaders(peer string, headers []*types.Header, time time.Time) []*types.Header &#123; log.Trace("Filtering headers", "peer", peer, "headers", len(headers)) filter := make(chan *headerFilterTask) select &#123; case f.headerFilter &lt;- filter: case &lt;-f.quit: return nil &#125; select &#123; case filter &lt;- &amp;headerFilterTask&#123;peer: peer, headers: headers, time: time&#125;: case &lt;-f.quit: return nil &#125; select &#123; case task := &lt;-filter: return task.headers case &lt;-f.quit: return nil &#125;&#125; 首先给headerFilter赋值，触发loop中对应逻辑1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465case filter := &lt;-f.headerFilter: var task *headerFilterTask select &#123; case task = &lt;-filter: case &lt;-f.quit: return &#125; headerFilterInMeter.Mark(int64(len(task.headers))) unknown, incomplete, complete := []*types.Header&#123;&#125;, []*announce&#123;&#125;, []*types.Block&#123;&#125; for _, header := range task.headers &#123; hash := header.Hash() if announce := f.fetching[hash]; announce != nil &amp;&amp; announce.origin == task.peer &amp;&amp; f.fetched[hash] == nil &amp;&amp; f.completing[hash] == nil &amp;&amp; f.queued[hash] == nil &#123; if header.Number.Uint64() != announce.number &#123; log.Trace("Invalid block number fetched", "peer", announce.origin, "hash", header.Hash(), "announced", announce.number, "provided", header.Number) f.dropPeer(announce.origin) f.forgetHash(hash) continue &#125; if f.getBlock(hash) == nil &#123; announce.header = header announce.time = task.time if header.TxHash == types.DeriveSha(types.Transactions&#123;&#125;) &amp;&amp; header.UncleHash == types.CalcUncleHash([]*types.Header&#123;&#125;) &#123; log.Trace("Block empty, skipping body retrieval", "peer", announce.origin, "number", header.Number, "hash", header.Hash()) block := types.NewBlockWithHeader(header) block.ReceivedAt = task.time complete = append(complete, block) f.completing[hash] = announce continue &#125; incomplete = append(incomplete, announce) &#125; else &#123; log.Trace("Block already imported, discarding header", "peer", announce.origin, "number", header.Number, "hash", header.Hash()) f.forgetHash(hash) &#125; &#125; else &#123; unknown = append(unknown, header) &#125; &#125; headerFilterOutMeter.Mark(int64(len(unknown))) select &#123; case filter &lt;- &amp;headerFilterTask&#123;headers: unknown, time: task.time&#125;: case &lt;-f.quit: return &#125; for _, announce := range incomplete &#123; hash := announce.header.Hash() if _, ok := f.completing[hash]; ok &#123; continue &#125; f.fetched[hash] = append(f.fetched[hash], announce) if len(f.fetched) == 1 &#123; f.rescheduleComplete(completeTimer) &#125; &#125; for _, block := range complete &#123; if announce := f.completing[block.Hash()]; announce != nil &#123; f.enqueue(announce.origin, block) &#125; &#125; 在对应case中，首先就是一个select结构，这里代码优点特殊，首先headerFilter这个channel里面存储的也是一个channel，回到FilterHeaders的第二个select中，给filter赋值headerFilterTask对象，其中包装了peerID，区块头和当前时间，再回到loop的case中，这里select阻塞得到释放，task得到赋值，是一个headerFilterTask对象。 接着定义了三个数组：unknown, incomplete, complete，然后遍历刚才传过来的一些区块头。先进行了许多判断，主要是确定这个头正在在fetch，接着如果返回的高度和我们请求的区块高度不一样，则删除这个peer并删除这个hash，然后判断下一个head。接着如果一样的话，尝试从本地取区块，如果取不到，在接下来的一个判断中判断这个块是否为空，也就是没有交易且没有叔块，这时创建一个空的区块放入complete中，并将对应的announce放入completing表示fetch完成，若能从本地取到对应区块，则表示已经fetch过了，则抛弃这个hash。再往下，如果不满足最开始的判断，则将对于头放入unknown中。 在遍历完所有head后，再构造一个headerFilterTask将unknown放入其中，然后将这个headerFilterTask赋值给filter，这时触发FilterHeaders的第三个select，在那里面将task的heads返回，也就是刚才放入unknown中的，随后交给Downloader处理。 在loop的对应case中还有操作，首先遍历所有incomplete，这个里面的表示那些在fetch的，而且没有fetch完的，而且对应区块也不是空的announce，首先看其是否在completing中，也就是fetch完的，这时进行忽略，否则将announce放入fetched中对于hash的数组中。接着如果fetched只有一个等待fetch区块体的任务，则调用rescheduleComplete重置completeTimer定时器。 接着遍历complete数组，如果对应区块的announce在completing中也就是以及fetch完成的，则调用enqueue方法插入区块，这个方法稍后介绍。 FilterBodies和上一个类似，这个方法是在请求一个区块体收到响应后进行了调用：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677func (f *Fetcher) FilterBodies(peer string, transactions [][]*types.Transaction, uncles [][]*types.Header, time time.Time) ([][]*types.Transaction, [][]*types.Header) &#123; log.Trace("Filtering bodies", "peer", peer, "txs", len(transactions), "uncles", len(uncles)) filter := make(chan *bodyFilterTask) select &#123; case f.bodyFilter &lt;- filter: case &lt;-f.quit: return nil, nil &#125; select &#123; case filter &lt;- &amp;bodyFilterTask&#123;peer: peer, transactions: transactions, uncles: uncles, time: time&#125;: case &lt;-f.quit: return nil, nil &#125; select &#123; case task := &lt;-filter: return task.transactions, task.uncles case &lt;-f.quit: return nil, nil &#125;&#125; case filter := &lt;-f.bodyFilter: var task *bodyFilterTask select &#123; case task = &lt;-filter: case &lt;-f.quit: return &#125; bodyFilterInMeter.Mark(int64(len(task.transactions))) blocks := []*types.Block&#123;&#125; for i := 0; i &lt; len(task.transactions) &amp;&amp; i &lt; len(task.uncles); i++ &#123; matched := false for hash, announce := range f.completing &#123; if f.queued[hash] == nil &#123; txnHash := types.DeriveSha(types.Transactions(task.transactions[i])) uncleHash := types.CalcUncleHash(task.uncles[i]) if txnHash == announce.header.TxHash &amp;&amp; uncleHash == announce.header.UncleHash &amp;&amp; announce.origin == task.peer &#123; matched = true if f.getBlock(hash) == nil &#123; block := types.NewBlockWithHeader(announce.header).WithBody(task.transactions[i], task.uncles[i]) block.ReceivedAt = task.time blocks = append(blocks, block) &#125; else &#123; f.forgetHash(hash) &#125; &#125; &#125; &#125; if matched &#123; task.transactions = append(task.transactions[:i], task.transactions[i+1:]...) task.uncles = append(task.uncles[:i], task.uncles[i+1:]...) i-- continue &#125; &#125; bodyFilterOutMeter.Mark(int64(len(task.transactions))) select &#123; case filter &lt;- task: case &lt;-f.quit: return &#125; for _, block := range blocks &#123; if announce := f.completing[block.Hash()]; announce != nil &#123; f.enqueue(announce.origin, block) &#125; &#125; &#125; 逻辑和上面的类似，这次是过滤body，主要是滤掉那些已经fetch完成的，剩余的返回交给Downloader处理，这里不再详述。 NotifyNotify方法是在pm收到NewBlockHashesMsg消息时得到调用，NewBlockHashesMsg是自己向其他peer发送新区快消息时用的code。接收方收到这个code表示有新的区块，在检测自己是否有相应区块后，将每个未知区块fetcher处理1234567891011121314151617func (f *Fetcher) Notify(peer string, hash common.Hash, number uint64, time time.Time, headerFetcher headerRequesterFn, bodyFetcher bodyRequesterFn) error &#123; block := &amp;announce&#123; hash: hash, number: number, time: time, origin: peer, fetchHeader: headerFetcher, fetchBodies: bodyFetcher, &#125; select &#123; case f.notify &lt;- block: return nil case &lt;-f.quit: return errTerminated &#125;&#125; 这里主要是构建了一个announce对象，表示有新区块的通知，然后传递给notify触发loop的逻辑：1234567891011121314151617181920212223242526272829303132case notification := &lt;-f.notify: propAnnounceInMeter.Mark(1) count := f.announces[notification.origin] + 1 if count &gt; hashLimit &#123; log.Debug("Peer exceeded outstanding announces", "peer", notification.origin, "limit", hashLimit) propAnnounceDOSMeter.Mark(1) break &#125; if notification.number &gt; 0 &#123; if dist := int64(notification.number) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist &#123; log.Debug("Peer discarded announcement", "peer", notification.origin, "number", notification.number, "hash", notification.hash, "distance", dist) propAnnounceDropMeter.Mark(1) break &#125; &#125; if _, ok := f.fetching[notification.hash]; ok &#123; break &#125; if _, ok := f.completing[notification.hash]; ok &#123; break &#125; f.announces[notification.origin] = count f.announced[notification.hash] = append(f.announced[notification.hash], notification) if f.announceChangeHook != nil &amp;&amp; len(f.announced[notification.hash]) == 1 &#123; f.announceChangeHook(notification.hash, true) &#125; if len(f.announced) == 1 &#123; f.rescheduleFetch(fetchTimer) &#125; 首先将来源的announce数量加1，然后判断是否超出最大数量，在检查区块高度是否太低或太高，也就是区块太旧或太新。然后检查该announce是否正在fetch或者已经完成。若都不是，则将其添加到announced中等待fetch，另外若添加完announced长度为1则立即重置fetchTimer进行fetch。 EnqueueEnqueue方法是在pm收到NewBlockMsg消息后执行，NewBlockMsg也是自己向其他佩尔发送新的区块信息时的code，Enqueue实现如下：123456789101112func (f *Fetcher) Enqueue(peer string, block *types.Block) error &#123; op := &amp;inject&#123; origin: peer, block: block, &#125; select &#123; case f.inject &lt;- op: return nil case &lt;-f.quit: return errTerminated &#125;&#125; 构建了一个inject对象，然后赋值给inject触发loop的逻辑：123case op := &lt;-f.inject: propBroadcastInMeter.Mark(1) f.enqueue(op.origin, op.block) enqueue逻辑如下：1234567891011121314151617181920212223242526272829303132func (f *Fetcher) enqueue(peer string, block *types.Block) &#123; hash := block.Hash() count := f.queues[peer] + 1 if count &gt; blockLimit &#123; log.Debug("Discarded propagated block, exceeded allowance", "peer", peer, "number", block.Number(), "hash", hash, "limit", blockLimit) propBroadcastDOSMeter.Mark(1) f.forgetHash(hash) return &#125; if dist := int64(block.NumberU64()) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist &#123; log.Debug("Discarded propagated block, too far away", "peer", peer, "number", block.Number(), "hash", hash, "distance", dist) propBroadcastDropMeter.Mark(1) f.forgetHash(hash) return &#125; if _, ok := f.queued[hash]; !ok &#123; op := &amp;inject&#123; origin: peer, block: block, &#125; f.queues[peer] = count f.queued[hash] = op f.queue.Push(op, -int64(block.NumberU64())) if f.queueChangeHook != nil &#123; f.queueChangeHook(op.block.Hash(), true) &#125; log.Debug("Queued propagated block", "peer", peer, "number", block.Number(), "hash", hash, "queued", f.queue.Size()) &#125;&#125; 和Notify逻辑类似，也是给来源加一，再判断是否超出最大值，然后判断区块是否太旧或太新。对于符合条件的，判断是否添加到queued中，若没有，则重新创建一个inject对象添加到queued和queue中。 fetchTimer前面的种种方法基本上都是对到来的announce进行分类，而在开头的两个定时器则真正担负了驱动作用，先看fetchTimer，由于开始设置的时间为0，所以立即触发：1234567891011121314151617181920212223242526272829case &lt;-fetchTimer.C: request := make(map[string][]common.Hash) for hash, announces := range f.announced &#123; if time.Since(announces[0].time) &gt; arriveTimeout-gatherSlack &#123; announce := announces[rand.Intn(len(announces))] f.forgetHash(hash) if f.getBlock(hash) == nil &#123; request[announce.origin] = append(request[announce.origin], hash) f.fetching[hash] = announce &#125; &#125; &#125; for peer, hashes := range request &#123; log.Trace("Fetching scheduled headers", "peer", peer, "list", hashes) fetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes go func() &#123; if f.fetchingHook != nil &#123; f.fetchingHook(hashes) &#125; for _, hash := range hashes &#123; headerFetchMeter.Mark(1) fetchHeader(hash) // Suboptimal, but protocol doesn't allow batch header retrievals &#125; &#125;() &#125; f.rescheduleFetch(fetchTimer) 首先遍历announced，announced存储了对于同一个区块来自不同peer的announce，它的第一个announce则是最早的哪一个，如果400毫秒，则随机取一个announce，然后删除该hash，如果这个hash还未fetch到，则将其添加到fetching中，并在request中记录，request记录了同一个来源的多个hash。随后遍历所有request，获得每个来源的fetchHeader方法，这个方法在调用Notify方法构建一个announce时被传入，是peer的一个方法，只要是发送一个GetBlockHeadersMsg消息去获取区块头，之后在每次循环后启动一个goroutine去变量该来源的所有hash然后请求。最后重置fetchTimer。 发送GetBlockHeadersMsg后，如果顺利会收到BlockHeadersMsg消息，这时也就触发FilterHeaders，这是回到前面分析的逻辑，将所有head分三类，unknown的交给download处理，incomplete的存放到fetched中等待fetch区块体，complete的且fetch完成的交给enqueue处理。 completeTimer1234567891011121314151617181920212223case &lt;-completeTimer.C: request := make(map[string][]common.Hash) for hash, announces := range f.fetched &#123; announce := announces[rand.Intn(len(announces))] f.forgetHash(hash) if f.getBlock(hash) == nil &#123; request[announce.origin] = append(request[announce.origin], hash) f.completing[hash] = announce &#125; &#125; for peer, hashes := range request &#123; log.Trace("Fetching scheduled bodies", "peer", peer, "list", hashes) if f.completingHook != nil &#123; f.completingHook(hashes) &#125; bodyFetchMeter.Mark(int64(len(hashes))) go f.completing[hashes[0]].fetchBodies(hashes) &#125; f.rescheduleComplete(completeTimer) completeTimer的逻辑和fetchTimer类似，只不过前一个是fetch区块头，这个是fetch区块体。首先是从fetched中取一组announce，他们都对应一个区块。然后从中随机取一个announce，若果本地没有该区块则添加到reuqest，这个同意也是存储一个来源的多个announce，然后变量request，调用announce的fetchBodies方法去请求一个来源的多个区块，fetchBodies也是在创建announce时传入的，他会发送GetBlockBodiesMsg消息，同样如果顺利的话会收到BlockBodiesMsg消息，触发FilterBodies方法，又回到前面的逻辑。 insert之前许多方法中我们都调用了enqueue方法，这里将一个个inject对象放入queue队列里，然后在loop的每个循环开始，处理queue队列里的东西，对于符合规定的，调用insert方法：12345678910111213141516171819202122232425262728293031323334353637func (f *Fetcher) insert(peer string, block *types.Block) &#123; hash := block.Hash() log.Debug("Importing propagated block", "peer", peer, "number", block.Number(), "hash", hash) go func() &#123; defer func() &#123; f.done &lt;- hash &#125;() parent := f.getBlock(block.ParentHash()) if parent == nil &#123; log.Debug("Unknown parent of propagated block", "peer", peer, "number", block.Number(), "hash", hash, "parent", block.ParentHash()) return &#125; switch err := f.verifyHeader(block.Header()); err &#123; case nil: propBroadcastOutTimer.UpdateSince(block.ReceivedAt) go f.broadcastBlock(block, true) case consensus.ErrFutureBlock: default: log.Debug("Propagated block verification failed", "peer", peer, "number", block.Number(), "hash", hash, "err", err) f.dropPeer(peer) return &#125; if _, err := f.insertChain(types.Blocks&#123;block&#125;); err != nil &#123; log.Debug("Propagated block import failed", "peer", peer, "number", block.Number(), "hash", hash, "err", err) return &#125; propAnnounceOutTimer.UpdateSince(block.ReceivedAt) go f.broadcastBlock(block, false) if f.importedHook != nil &#123; f.importedHook(block) &#125; &#125;()&#125; 直接启动了一个goroutine，先获取要插入区块的父块，如果不存在停止插入，然后验证区块头，出错的话而且不是consensus.ErrFutureBlock错误的话，抛弃来源的peer，没有错的话启动一个goroutine调用broadcastBlock方法。之后调用insertchain方法插入一个区块，如果插入成功再次调用broadcastBlock方法，这里第二个参数为true，关于broadcastBlock在ProtocolManager分析中有介绍。另外insertChain方法是blockchain的方法，后面会涉及到。 rescheduleFetch前面也多次涉及到了这个方法，在定时器触发时最后会用到，在notify添加完一个announce后如果announced长度为一，表示之前announced都已处理过，这是要重新启动定时器。12345678910111213func (f *Fetcher) rescheduleFetch(fetch *time.Timer) &#123; if len(f.announced) == 0 &#123; return &#125; // Otherwise find the earliest expiring announcement earliest := time.Now() for _, announces := range f.announced &#123; if earliest.After(announces[0].time) &#123; earliest = announces[0].time &#125; &#125; fetch.Reset(arriveTimeout - time.Since(earliest))&#125; 首先announced长度为0，表示没有要fetch的任务，则返回，前面说过，在notify中向announced新添加时会触发此方法重设定时器。之后遍历所有announced，每个hash对应的那组取第一个也就时间最早的那个announce尝试更新earliest，最后earliest为所有announce最早的那一个，然后重设fetchTimer定时器。 类似的还有一个rescheduleComplete，大致逻辑一样，不在赘述 forgetHash这个也多次出现，出钥匙删除一个hash对应的announce1234567891011121314151617181920212223242526272829303132333435363738func (f *Fetcher) forgetHash(hash common.Hash) &#123; for _, announce := range f.announced[hash] &#123; f.announces[announce.origin]-- if f.announces[announce.origin] == 0 &#123; delete(f.announces, announce.origin) &#125; &#125; delete(f.announced, hash) if f.announceChangeHook != nil &#123; f.announceChangeHook(hash, false) &#125; if announce := f.fetching[hash]; announce != nil &#123; f.announces[announce.origin]-- if f.announces[announce.origin] == 0 &#123; delete(f.announces, announce.origin) &#125; delete(f.fetching, hash) &#125; for _, announce := range f.fetched[hash] &#123; f.announces[announce.origin]-- if f.announces[announce.origin] == 0 &#123; delete(f.announces, announce.origin) &#125; &#125; delete(f.fetched, hash) if announce := f.completing[hash]; announce != nil &#123; f.announces[announce.origin]-- if f.announces[announce.origin] == 0 &#123; delete(f.announces, announce.origin) &#125; delete(f.completing, hash) &#125;&#125; 首先遍历announced对应hash的所有announce，然后将对应来源的计数器减1，如果减到0则删除该来源的计数器。然后从announced删除hash对应的值。结合如果fetching、fetched及completing有对应的键值对，也相应的删除。 stop123func (f *Fetcher) Stop() &#123; close(f.quit)&#125; 这个就是关闭方法，关闭quit这个通道，触发多个地方的逻辑，第一个就是loop中，这里面退出了无限循环，其次还有其他涉及select阻塞的地方，如notify、FilterHeaders等，都是直接退出。 题图来自unsplash：https://unsplash.com/photos/m6tAqZvy4RM]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中eth-ProtocolManager源码学习]]></title>
    <url>%2F2019%2F04%2F29%2Fgo-ethereum%E4%B8%ADeth-ProtocolManager%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[NewProtocolManager在eth的创建过程中初始化了一个protocolManager成员，从名称上看是协议管理者，实际上它是用来管理Ethereum的子协议的，也是上层消息的处理分发的类。由于和上一篇P2P有很大的联系，所以单独拿出来分析一下。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// go-ethereum\eth\handler.gofunc NewProtocolManager(config *params.ChainConfig, mode downloader.SyncMode, networkID uint64, mux *event.TypeMux, txpool txPool, engine consensus.Engine, blockchain *core.BlockChain, chaindb ethdb.Database, whitelist map[uint64]common.Hash) (*ProtocolManager, error) &#123; manager := &amp;ProtocolManager&#123; networkID: networkID, eventMux: mux, txpool: txpool, blockchain: blockchain, chainconfig: config, peers: newPeerSet(), whitelist: whitelist, newPeerCh: make(chan *peer), noMorePeers: make(chan struct&#123;&#125;), txsyncCh: make(chan *txsync), quitSync: make(chan struct&#123;&#125;), &#125; if mode == downloader.FastSync &amp;&amp; blockchain.CurrentBlock().NumberU64() &gt; 0 &#123; log.Warn("Blockchain not empty, fast sync disabled") mode = downloader.FullSync &#125; if mode == downloader.FastSync &#123; manager.fastSync = uint32(1) &#125; manager.SubProtocols = make([]p2p.Protocol, 0, len(ProtocolVersions)) for i, version := range ProtocolVersions &#123; if mode == downloader.FastSync &amp;&amp; version &lt; eth63 &#123; continue &#125; version := version manager.SubProtocols = append(manager.SubProtocols, p2p.Protocol&#123; Name: ProtocolName, Version: version, Length: ProtocolLengths[i], Run: func(p *p2p.Peer, rw p2p.MsgReadWriter) error &#123; peer := manager.newPeer(int(version), p, rw) select &#123; case manager.newPeerCh &lt;- peer: manager.wg.Add(1) defer manager.wg.Done() return manager.handle(peer) case &lt;-manager.quitSync: return p2p.DiscQuitting &#125; &#125;, NodeInfo: func() interface&#123;&#125; &#123; return manager.NodeInfo() &#125;, PeerInfo: func(id enode.ID) interface&#123;&#125; &#123; if p := manager.peers.Peer(fmt.Sprintf("%x", id[:8])); p != nil &#123; return p.Info() &#125; return nil &#125;, &#125;) &#125; if len(manager.SubProtocols) == 0 &#123; return nil, errIncompatibleConfig &#125; manager.downloader = downloader.New(mode, chaindb, manager.eventMux, blockchain, nil, manager.removePeer) validator := func(header *types.Header) error &#123; return engine.VerifyHeader(blockchain, header, true) &#125; heighter := func() uint64 &#123; return blockchain.CurrentBlock().NumberU64() &#125; inserter := func(blocks types.Blocks) (int, error) &#123; if atomic.LoadUint32(&amp;manager.fastSync) == 1 &#123; log.Warn("Discarded bad propagated block", "number", blocks[0].Number(), "hash", blocks[0].Hash()) return 0, nil &#125; atomic.StoreUint32(&amp;manager.acceptTxs, 1) // Mark initial sync done on any fetcher import return manager.blockchain.InsertChain(blocks) &#125; manager.fetcher = fetcher.New(blockchain.GetBlockByHash, validator, manager.BroadcastBlock, heighter, inserter, manager.removePeer) return manager, nil&#125; 在初始化对象后，先判断了节点同步方法，如果是FastSync而当前节点又不是0，就改为FullSync，这也就是FastSync模式只在第一次有效的原因。然后配置了manager的同步方式。接下来我们可以看到他所管理的子协议实际上就是p2p协议，这里在pm初始化的同时就创建了一个p2p的Protocol数组SubProtocols。然后遍历ProtocolVersions，这个代表协议版本号。在我当前的版本中支持{eth63, eth62}，关于eth63、eth62及以太坊网络协议的更多说明见这里。 对于每个版本都向SubProtocols中添加一个Protocol对象，其名字就是eth，ProtocolLengths长度对于eth63而言是17，对于eth62是8；接下来定义一个Run方法，前文在分析p2p-peer时，对于每个peer都会启动所有协议，启动时会在一个独立的goroutine中运行run方法。在run方法中先用newPeer创建了一个peer（p2p-peer的封装）：12345678910111213141516171819func (pm *ProtocolManager) newPeer(pv int, p *p2p.Peer, rw p2p.MsgReadWriter) *peer &#123; return newPeer(pv, p, newMeteredMsgWriter(rw))&#125;// go-ethereum\eth\peer.gofunc newPeer(version int, p *p2p.Peer, rw p2p.MsgReadWriter) *peer &#123; return &amp;peer&#123; Peer: p, rw: rw, version: version, id: fmt.Sprintf("%x", p.ID().Bytes()[:8]), knownTxs: mapset.NewSet(), knownBlocks: mapset.NewSet(), queuedTxs: make(chan []*types.Transaction, maxQueuedTxs), queuedProps: make(chan *propEvent, maxQueuedProps), queuedAnns: make(chan *types.Block, maxQueuedAnns), term: make(chan struct&#123;&#125;), &#125;&#125; handle接着给manager的newPeerCh赋值，执行handle方法,用来处理连接12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func (pm *ProtocolManager) handle(p *peer) error &#123; if pm.peers.Len() &gt;= pm.maxPeers &amp;&amp; !p.Peer.Info().Network.Trusted &#123; return p2p.DiscTooManyPeers &#125; p.Log().Debug("Ethereum peer connected", "name", p.Name()) var ( genesis = pm.blockchain.Genesis() head = pm.blockchain.CurrentHeader() hash = head.Hash() number = head.Number.Uint64() td = pm.blockchain.GetTd(hash, number) ) if err := p.Handshake(pm.networkID, td, hash, genesis.Hash()); err != nil &#123; p.Log().Debug("Ethereum handshake failed", "err", err) return err &#125; if rw, ok := p.rw.(*meteredMsgReadWriter); ok &#123; rw.Init(p.version) &#125; if err := pm.peers.Register(p); err != nil &#123; p.Log().Error("Ethereum peer registration failed", "err", err) return err &#125; defer pm.removePeer(p.id) if err := pm.downloader.RegisterPeer(p.id, p.version, p); err != nil &#123; return err &#125; pm.syncTransactions(p) if daoBlock := pm.chainconfig.DAOForkBlock; daoBlock != nil &#123; if err := p.RequestHeadersByNumber(daoBlock.Uint64(), 1, 0, false); err != nil &#123; return err &#125; p.forkDrop = time.AfterFunc(daoChallengeTimeout, func() &#123; p.Log().Debug("Timed out DAO fork-check, dropping") pm.removePeer(p.id) &#125;) defer func() &#123; if p.forkDrop != nil &#123; p.forkDrop.Stop() p.forkDrop = nil &#125; &#125;() &#125; for number := range pm.whitelist &#123; if err := p.RequestHeadersByNumber(number, 1, 0, false); err != nil &#123; return err &#125; &#125; for &#123; if err := pm.handleMsg(p); err != nil &#123; p.Log().Debug("Ethereum message handling failed", "err", err) return err &#125; &#125;&#125; Handshake首先检测是否超过最大peer数量或者不是信任节点，检测通过的话进行Ethereum握手。1234567891011121314151617181920212223242526272829303132// go-ethereum\eth\peer.gofunc (p *peer) Handshake(network uint64, td *big.Int, head common.Hash, genesis common.Hash) error &#123; errc := make(chan error, 2) var status statusData go func() &#123; errc &lt;- p2p.Send(p.rw, StatusMsg, &amp;statusData&#123; ProtocolVersion: uint32(p.version), NetworkId: network, TD: td, CurrentBlock: head, GenesisBlock: genesis, &#125;) &#125;() go func() &#123; errc &lt;- p.readStatus(network, &amp;status, genesis) &#125;() timeout := time.NewTimer(handshakeTimeout) defer timeout.Stop() for i := 0; i &lt; 2; i++ &#123; select &#123; case err := &lt;-errc: if err != nil &#123; return err &#125; case &lt;-timeout.C: return p2p.DiscReadTimeout &#125; &#125; p.td, p.head = status.TD, status.CurrentBlock return nil&#125; 首先启动一个goroutine利用Send发送一条初始消息，这里的Send是p2p包中message.go的方法，但是send方法中又调用了参数中的MsgWriter，这里的MsgWriter是在p2p包内peer.go在启动协议时传入的，实际上是protoRW的WriteMsg，但最终实际执行者是rlpx。这里还有一点需要注意的是，在发送时将原来的code加了一个offset，因为eth的协议code是从0开始，如果不加offset，会在读取时被当做基本协议过滤掉（详见p2p的peer源码分析），这个offset最后会在读取时减去恢复出原始的code。 发送的msg的code是StatusMsg，即0。发送的消息有协议版本，网络ID，总难度当前区块和创世区块。之后又启动一个goroutine去读取消息：1234567891011121314151617181920212223242526func (p *peer) readStatus(network uint64, status *statusData, genesis common.Hash) (err error) &#123; msg, err := p.rw.ReadMsg() if err != nil &#123; return err &#125; if msg.Code != StatusMsg &#123; return errResp(ErrNoStatusMsg, "first msg has code %x (!= %x)", msg.Code, StatusMsg) &#125; if msg.Size &gt; ProtocolMaxMsgSize &#123; return errResp(ErrMsgTooLarge, "%v &gt; %v", msg.Size, ProtocolMaxMsgSize) &#125; // Decode the handshake and make sure everything matches if err := msg.Decode(&amp;status); err != nil &#123; return errResp(ErrDecode, "msg %v: %v", msg, err) &#125; if status.GenesisBlock != genesis &#123; return errResp(ErrGenesisBlockMismatch, "%x (!= %x)", status.GenesisBlock[:8], genesis[:8]) &#125; if status.NetworkId != network &#123; return errResp(ErrNetworkIdMismatch, "%d (!= %d)", status.NetworkId, network) &#125; if int(status.ProtocolVersion) != p.version &#123; return errResp(ErrProtocolVersionMismatch, "%d (!= %d)", status.ProtocolVersion, p.version) &#125; return nil&#125; 首先调用ReadMsg，这个ReadMsg是p2p包内peer.go中protoRW的方法，回顾peer源码分析，对于一个peer当收到一条消息时，如果消息不是基本消息，会给protoRW的in字段赋值，而在ReadMsg会阻塞的从in字段读取msg并返回。回到readStatus中，首先判断code是否是StatusMsg，在判断size大小是否合格。之后调用msg的Decode方法解码，就是rlp解码，最后将数据写入statusData，之后对双方的创世区块、网络ID一届协议版本进行对比，判断是否匹配，不匹配的话返回具体错误。 回到Handshake中，在启动收发数据的goroutine的同时，启动了一个定时器，时间是5s，来判断是否握手超时，在判断超时时也判断了收发是否报错。握手成功后记录对方的总难度和当前区块。有一点需要注意的是，Handshake的这两个收发goroutine是没有先后关系的，因为我们p2p的peer是在主动发送或收到一个请求后经过握手建立的，建立成功后双方各自实例化一个peer对象，然后启动协议，并执行协议的Run方法，这些步骤在双方是独立进行的。 Register &amp; broadcast再回到handle中，经过刚才的握手后，如果双方的区块链信息也匹配，则将这个peer注册到ProtocolManager的peers中，这个注册会在结束时被移除。注册方法如下：123456789101112131415func (ps *peerSet) Register(p *peer) error &#123; ps.lock.Lock() defer ps.lock.Unlock() if ps.closed &#123; return errClosed &#125; if _, ok := ps.peers[p.id]; ok &#123; return errAlreadyRegistered &#125; ps.peers[p.id] = p go p.broadcast() return nil&#125; 主要实现就是将peer添加到pm的peers字段中用来集中管理，并启动了一个goroutine去调用broadcast：1234567891011121314151617181920212223242526func (p *peer) broadcast() &#123; for &#123; select &#123; case txs := &lt;-p.queuedTxs: if err := p.SendTransactions(txs); err != nil &#123; return &#125; p.Log().Trace("Broadcast transactions", "count", len(txs)) case prop := &lt;-p.queuedProps: if err := p.SendNewBlock(prop.block, prop.td); err != nil &#123; return &#125; p.Log().Trace("Propagated block", "number", prop.block.Number(), "hash", prop.block.Hash(), "td", prop.td) case block := &lt;-p.queuedAnns: if err := p.SendNewBlockHashes([]common.Hash&#123;block.Hash()&#125;, []uint64&#123;block.NumberU64()&#125;); err != nil &#123; return &#125; p.Log().Trace("Announced block", "number", block.Number(), "hash", block.Hash()) case &lt;-p.term: return &#125; &#125;&#125; 这也是一个无限循环，用于事件处理，具体逻辑稍后介绍。 之后开始同步交易，将自己交易池中等待的交易发送给对方。然后又验证了DAO硬分叉，另外如果有白名单则也去请求，和前面验证DAO一样，都是通过编号去请求头。 handleMsg最后来到主循环，调用handleMsg去处理消息：12345678910111213141516171819func (pm *ProtocolManager) handleMsg(p *peer) error &#123; // Read the next message from the remote peer, and ensure it's fully consumed msg, err := p.rw.ReadMsg() if err != nil &#123; return err &#125; if msg.Size &gt; ProtocolMaxMsgSize &#123; return errResp(ErrMsgTooLarge, "%v &gt; %v", msg.Size, ProtocolMaxMsgSize) &#125; defer msg.Discard() // Handle the message depending on its contents switch &#123; case msg.Code == StatusMsg: return errResp(ErrExtraStatusMsg, "uncontrolled status message") ... &#125; return nil&#125; GetBlockHeadersMsg这一部分代码非常多，由于是p2p通信的上层部分，所以要考虑的情况十分多。我们简单看几个，以刚才验证DAO分叉和请求白名单所用的RequestHeadersByNumber方法为例（其余的会在介绍后续流程时涉及到），首先发送如下请求：1234func (p *peer) RequestHeadersByNumber(origin uint64, amount int, skip int, reverse bool) error &#123; p.Log().Debug("Fetching batch of headers", "count", amount, "fromnum", origin, "skip", skip, "reverse", reverse) return p2p.Send(p.rw, GetBlockHeadersMsg, &amp;getBlockHeadersData&#123;Origin: hashOrNumber&#123;Number: origin&#125;, Amount: uint64(amount), Skip: uint64(skip), Reverse: reverse&#125;)&#125; 同样是发送一个msg，其code是GetBlockHeadersMsg，在handleMsg中对于逻辑如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778case msg.Code == GetBlockHeadersMsg: var query getBlockHeadersData if err := msg.Decode(&amp;query); err != nil &#123; return errResp(ErrDecode, "%v: %v", msg, err) &#125; hashMode := query.Origin.Hash != (common.Hash&#123;&#125;) first := true maxNonCanonical := uint64(100) var ( bytes common.StorageSize headers []*types.Header unknown bool ) for !unknown &amp;&amp; len(headers) &lt; int(query.Amount) &amp;&amp; bytes &lt; softResponseLimit &amp;&amp; len(headers) &lt; downloader.MaxHeaderFetch &#123; var origin *types.Header if hashMode &#123; if first &#123; first = false origin = pm.blockchain.GetHeaderByHash(query.Origin.Hash) if origin != nil &#123; query.Origin.Number = origin.Number.Uint64() &#125; &#125; else &#123; origin = pm.blockchain.GetHeader(query.Origin.Hash, query.Origin.Number) &#125; &#125; else &#123; origin = pm.blockchain.GetHeaderByNumber(query.Origin.Number) &#125; if origin == nil &#123; break &#125; headers = append(headers, origin) bytes += estHeaderRlpSize switch &#123; case hashMode &amp;&amp; query.Reverse: ancestor := query.Skip + 1 if ancestor == 0 &#123; unknown = true &#125; else &#123; query.Origin.Hash, query.Origin.Number = pm.blockchain.GetAncestor(query.Origin.Hash, query.Origin.Number, ancestor, &amp;maxNonCanonical) unknown = (query.Origin.Hash == common.Hash&#123;&#125;) &#125; case hashMode &amp;&amp; !query.Reverse: var ( current = origin.Number.Uint64() next = current + query.Skip + 1 ) if next &lt;= current &#123; infos, _ := json.MarshalIndent(p.Peer.Info(), "", " ") p.Log().Warn("GetBlockHeaders skip overflow attack", "current", current, "skip", query.Skip, "next", next, "attacker", infos) unknown = true &#125; else &#123; if header := pm.blockchain.GetHeaderByNumber(next); header != nil &#123; nextHash := header.Hash() expOldHash, _ := pm.blockchain.GetAncestor(nextHash, next, query.Skip+1, &amp;maxNonCanonical) if expOldHash == query.Origin.Hash &#123; query.Origin.Hash, query.Origin.Number = nextHash, next &#125; else &#123; unknown = true &#125; &#125; else &#123; unknown = true &#125; &#125; case query.Reverse: if query.Origin.Number &gt;= query.Skip+1 &#123; query.Origin.Number -= query.Skip + 1 &#125; else &#123; unknown = true &#125; case !query.Reverse: query.Origin.Number += query.Skip + 1 &#125; &#125; return p.SendBlockHeaders(headers) 第一步就是解码，得到请求消息getBlockHeadersData，其中包含要查询的某一个区块的编号或hash，查询数量，跳过的数量，是否反向查询等。然后判断查询用的是编号还是hash，之后再一个循环内，根据请求获取头数据，然后放到heads中，最后通过SendBlockHeaders发送数据：123func (p *peer) SendBlockHeaders(headers []*types.Header) error &#123; return p2p.Send(p.rw, BlockHeadersMsg, headers)&#125; BlockHeadersMsg可见code是BlockHeadersMsg，回到请求方，对应的逻辑如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152case msg.Code == BlockHeadersMsg: var headers []*types.Header if err := msg.Decode(&amp;headers); err != nil &#123; return errResp(ErrDecode, "msg %v: %v", msg, err) &#125; if len(headers) == 0 &amp;&amp; p.forkDrop != nil &#123; // Possibly an empty reply to the fork header checks, sanity check TDs verifyDAO := true if daoHeader := pm.blockchain.GetHeaderByNumber(pm.chainconfig.DAOForkBlock.Uint64()); daoHeader != nil &#123; if _, td := p.Head(); td.Cmp(pm.blockchain.GetTd(daoHeader.Hash(), daoHeader.Number.Uint64())) &gt;= 0 &#123; verifyDAO = false &#125; &#125; if verifyDAO &#123; p.Log().Debug("Seems to be on the same side of the DAO fork") p.forkDrop.Stop() p.forkDrop = nil return nil &#125; &#125; filter := len(headers) == 1 if filter &#123; if p.forkDrop != nil &amp;&amp; pm.chainconfig.DAOForkBlock.Cmp(headers[0].Number) == 0 &#123; p.forkDrop.Stop() p.forkDrop = nil if err := misc.VerifyDAOHeaderExtraData(pm.chainconfig, headers[0]); err != nil &#123; p.Log().Debug("Verified to be on the other side of the DAO fork, dropping") return err &#125; p.Log().Debug("Verified to be on the same side of the DAO fork") return nil &#125; if want, ok := pm.whitelist[headers[0].Number.Uint64()]; ok &#123; if hash := headers[0].Hash(); want != hash &#123; p.Log().Info("Whitelist mismatch, dropping peer", "number", headers[0].Number.Uint64(), "hash", hash, "want", want) return errors.New("whitelist block mismatch") &#125; p.Log().Debug("Whitelist block verified", "number", headers[0].Number.Uint64(), "hash", want) &#125; headers = pm.fetcher.FilterHeaders(p.id, headers, time.Now()) &#125; if len(headers) &gt; 0 || !filter &#123; err := pm.downloader.DeliverHeaders(p.id, headers) if err != nil &#123; log.Debug("Failed to deliver headers", "err", err) &#125; &#125; 到这里也是首先解析返回的数据，首先对于DAO分叉验证，如果收到的heads内容为空，则验证通过，最后如果验证通过则取消刚才请求时的定时器，否则那个定时器到期后会中断连接。接着当heads长度为1是，还是先验证DAO分叉，如果不必验证则是刚才请求的白名单区块，进行验证，主要是进行hash匹配。最后如果heads长度大于1则执行downloader的DeliverHeaders方法。 到这里handle基本分析完了，回到NewProtocolManager中，刚才主要看了定义协议时的Run方法，除了定义Run还定义了NodeInfo和PeerInfo，这两个方法也是共p2p调用的。在添加完要管理的协议后，检查总共协议的数量，如果为0则退出。否则调用downloader.New创建一个Downloader。接着配置了validator方法用来验证头部；heighter方法用来获取区块链高度；inserter 方法用于插入区块，但是如果开启fastSync，则不会使用，最后生成一个fetcher，这是用来汇集各个peer的区块通知。 Start这样一个ProtocolManager就创建并初始化完毕，随后随着Ethereum的启动，也会调用ProtocolManager的start方法12345678910111213func (pm *ProtocolManager) Start(maxPeers int) &#123; pm.maxPeers = maxPeers pm.txsCh = make(chan core.NewTxsEvent, txChanSize) pm.txsSub = pm.txpool.SubscribeNewTxsEvent(pm.txsCh) go pm.txBroadcastLoop() pm.minedBlockSub = pm.eventMux.Subscribe(core.NewMinedBlockEvent&#123;&#125;) go pm.minedBroadcastLoop() go pm.syncer() go pm.txsyncLoop()&#125; txBroadcastLoop主要是启动了几个goroutine，分别进行交易的广播，挖矿广播，网络同步和交易同步等。对于交易广播：12345678910111213141516171819202122232425262728293031323334353637383940func (pm *ProtocolManager) txBroadcastLoop() &#123; for &#123; select &#123; case event := &lt;-pm.txsCh: pm.BroadcastTxs(event.Txs) case &lt;-pm.txsSub.Err(): return &#125; &#125;&#125;func (pm *ProtocolManager) BroadcastTxs(txs types.Transactions) &#123; var txset = make(map[*peer]types.Transactions) for _, tx := range txs &#123; peers := pm.peers.PeersWithoutTx(tx.Hash()) for _, peer := range peers &#123; txset[peer] = append(txset[peer], tx) &#125; log.Trace("Broadcast transaction", "hash", tx.Hash(), "recipients", len(peers)) &#125; for peer, txs := range txset &#123; peer.AsyncSendTransactions(txs) &#125;&#125;func (ps *peerSet) PeersWithoutTx(hash common.Hash) []*peer &#123; ps.lock.RLock() defer ps.lock.RUnlock() list := make([]*peer, 0, len(ps.peers)) for _, p := range ps.peers &#123; if !p.knownTxs.Contains(hash) &#123; list = append(list, p) &#125; &#125; return list&#125; 当收到合法的交易时，变调用BroadcastTxs方法，在BroadcastTxs中，先查询每个peer是否有这个交易（通过判断knownTxs字段，knownTxs的内容实在pm中收到TxMsg消息时添加的，所以存储着对于peer所有的tx信息），找出没有的peer放入txset中，然后调用AsyncSendTransactions发送12345678910func (p *peer) AsyncSendTransactions(txs []*types.Transaction) &#123; select &#123; case p.queuedTxs &lt;- txs: for _, tx := range txs &#123; p.knownTxs.Add(tx.Hash()) &#125; default: p.Log().Debug("Dropping transaction propagation", "count", len(txs)) &#125;&#125; 这是一个异步发送方法，首先标记这个peer已有这些tx信息，由于是传值给queuedTxs，所以触发broadcast方法中对于的逻辑，123456789101112case txs := &lt;-p.queuedTxs: if err := p.SendTransactions(txs); err != nil &#123; return &#125; p.Log().Trace("Broadcast transactions", "count", len(txs))func (p *peer) SendTransactions(txs types.Transactions) error &#123; for _, tx := range txs &#123; p.knownTxs.Add(tx.Hash()) &#125; return p2p.Send(p.rw, TxMsg, txs)&#125; 最后利用SendTransactions中的Send方法发送，发送的包是TxMsg，顺便看一下接受到该包时的逻辑，还是在handleMsg中：12345678910111213141516case msg.Code == TxMsg: if atomic.LoadUint32(&amp;pm.acceptTxs) == 0 &#123; break &#125; var txs []*types.Transaction if err := msg.Decode(&amp;txs); err != nil &#123; return errResp(ErrDecode, "msg %v: %v", msg, err) &#125; for i, tx := range txs &#123; if tx == nil &#123; return errResp(ErrDecode, "transaction %d is nil", i) &#125; p.MarkTransaction(tx.Hash()) &#125; pm.txpool.AddRemotes(txs) 由于是pm主要是事件分发，所以主要就是先进行解码，然后标记对应的peer有相关tx，最后交给txpool处理。 minedBroadcastLoopstart中调用的另外一个方法是minedBroadcastLoop12345678func (pm *ProtocolManager) minedBroadcastLoop() &#123; for obj := range pm.minedBlockSub.Chan() &#123; if ev, ok := obj.Data.(core.NewMinedBlockEvent); ok &#123; pm.BroadcastBlock(ev.Block, true) // First propagate block to peers pm.BroadcastBlock(ev.Block, false) // Only then announce to the rest &#125; &#125;&#125; 这里当收到订阅事件时，调用BroadcastBlock用来广播区块：12345678910111213141516171819202122232425262728293031323334func (pm *ProtocolManager) BroadcastBlock(block *types.Block, propagate bool) &#123; hash := block.Hash() peers := pm.peers.PeersWithoutBlock(hash) if propagate &#123; var td *big.Int if parent := pm.blockchain.GetBlock(block.ParentHash(), block.NumberU64()-1); parent != nil &#123; td = new(big.Int).Add(block.Difficulty(), pm.blockchain.GetTd(block.ParentHash(), block.NumberU64()-1)) &#125; else &#123; log.Error("Propagating dangling block", "number", block.Number(), "hash", hash) return &#125; transferLen := int(math.Sqrt(float64(len(peers)))) if transferLen &lt; minBroadcastPeers &#123; transferLen = minBroadcastPeers &#125; if transferLen &gt; len(peers) &#123; transferLen = len(peers) &#125; transfer := peers[:transferLen] for _, peer := range transfer &#123; peer.AsyncSendNewBlock(block, td) &#125; log.Trace("Propagated block", "hash", hash, "recipients", len(transfer), "duration", common.PrettyDuration(time.Since(block.ReceivedAt))) return &#125; if pm.blockchain.HasBlock(hash, block.NumberU64()) &#123; for _, peer := range peers &#123; peer.AsyncSendNewBlockHash(block) &#125; log.Trace("Announced block", "hash", hash, "recipients", len(peers), "duration", common.PrettyDuration(time.Since(block.ReceivedAt))) &#125;&#125; 这个方法根据其第二个参数的不同，有两种不同的执行逻辑。首先寻找没有改区块的peer，然后当propagate为true时，先计算含该区块的总难度，然后对部分peer发送区块信息及总难度，如果是false则，在自己拥有该区块的前提下给peers发送区块的hash，二者分别调用了AsyncSendNewBlock和peer.AsyncSendNewBlockHash(block)1234567891011121314151617func (p *peer) AsyncSendNewBlock(block *types.Block, td *big.Int) &#123; select &#123; case p.queuedProps &lt;- &amp;propEvent&#123;block: block, td: td&#125;: p.knownBlocks.Add(block.Hash()) default: p.Log().Debug("Dropping block propagation", "number", block.NumberU64(), "hash", block.Hash()) &#125;&#125;func (p *peer) AsyncSendNewBlockHash(block *types.Block) &#123; select &#123; case p.queuedAnns &lt;- block: p.knownBlocks.Add(block.Hash()) default: p.Log().Debug("Dropping block announcement", "number", block.NumberU64(), "hash", block.Hash()) &#125;&#125; AsyncSendNewBlock方法中给queuedProps赋值，然后标记该peer拥有该区块。赋值后触发broadcast中的逻辑：12345678910case prop := &lt;-p.queuedProps: if err := p.SendNewBlock(prop.block, prop.td); err != nil &#123; return &#125; p.Log().Trace("Propagated block", "number", prop.block.Number(), "hash", prop.block.Hash(), "td", prop.td)func (p *peer) SendNewBlock(block *types.Block, td *big.Int) error &#123; p.knownBlocks.Add(block.Hash()) return p2p.Send(p.rw, NewBlockMsg, []interface&#123;&#125;&#123;block, td&#125;)&#125; 最后调用SendNewBlock利用p2p发送区块信息和总难度，所发的msg是NewBlockMsg。 对于AsyncSendNewBlockHash方法，先给queuedAnns赋值，然后标记该peer知道该区块，之后触发broadcast中的逻辑：1234567891011121314151617case block := &lt;-p.queuedAnns: if err := p.SendNewBlockHashes([]common.Hash&#123;block.Hash()&#125;, []uint64&#123;block.NumberU64()&#125;); err != nil &#123; return &#125; p.Log().Trace("Announced block", "number", block.Number(), "hash", block.Hash())func (p *peer) SendNewBlockHashes(hashes []common.Hash, numbers []uint64) error &#123; for _, hash := range hashes &#123; p.knownBlocks.Add(hash) &#125; request := make(newBlockHashesData, len(hashes)) for i := 0; i &lt; len(hashes); i++ &#123; request[i].Hash = hashes[i] request[i].Number = numbers[i] &#125; return p2p.Send(p.rw, NewBlockHashesMsg, request)&#125; 这里调用SendNewBlockHashes发送区块hash和编号，发送的msg是NewBlockHashesMsg。 顺便也看一下接受的逻辑，对于NewBlockMsg，还HandleMsg中123456789101112131415161718192021222324case msg.Code == NewBlockMsg: var request newBlockData if err := msg.Decode(&amp;request); err != nil &#123; return errResp(ErrDecode, "%v: %v", msg, err) &#125; request.Block.ReceivedAt = msg.ReceivedAt request.Block.ReceivedFrom = p p.MarkBlock(request.Block.Hash()) pm.fetcher.Enqueue(p.id, request.Block) var ( trueHead = request.Block.ParentHash() trueTD = new(big.Int).Sub(request.TD, request.Block.Difficulty()) ) if _, td := p.Head(); trueTD.Cmp(td) &gt; 0 &#123; p.SetHead(trueHead, trueTD) currentBlock := pm.blockchain.CurrentBlock() if trueTD.Cmp(pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())) &gt; 0 &#123; go pm.synchronise(p) &#125; &#125; 首先进行解码，然后取出收到的时间和发送对象，之后标记对应的peer拥有该区块，然后交给fetcher处理。接着计算出对方的总难度减去区块的难度是否大于0，然后更新对应peer的区块链头和总难度，接着计算双方总难度之差，如果对方大于自己，则去同步。 对于另外一个消息NewBlockHashesMsg，逻辑如下：1234567891011121314151617case msg.Code == NewBlockHashesMsg: var announces newBlockHashesData if err := msg.Decode(&amp;announces); err != nil &#123; return errResp(ErrDecode, "%v: %v", msg, err) &#125; for _, block := range announces &#123; p.MarkBlock(block.Hash) &#125; unknown := make(newBlockHashesData, 0, len(announces)) for _, block := range announces &#123; if !pm.blockchain.HasBlock(block.Hash, block.Number) &#123; unknown = append(unknown, block) &#125; &#125; for _, block := range unknown &#123; pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies) &#125; 这里也是先解码，然后标记对应的peer有响应的区块，然后统计自由不知道的区块最后交给fetcher处理。 syncerstart还启动了syncer方法：123456789101112131415161718192021222324func (pm *ProtocolManager) syncer() &#123; pm.fetcher.Start() defer pm.fetcher.Stop() defer pm.downloader.Terminate() forceSync := time.NewTicker(forceSyncCycle) defer forceSync.Stop() for &#123; select &#123; case &lt;-pm.newPeerCh: if pm.peers.Len() &lt; minDesiredPeerCount &#123; break &#125; go pm.synchronise(pm.peers.BestPeer()) case &lt;-forceSync.C: go pm.synchronise(pm.peers.BestPeer()) case &lt;-pm.noMorePeers: return &#125; &#125;&#125; 这里首先启动了fetcher，关于fetcher稍后介绍，然后启动了一个定时器每5秒执行一次逻辑。下面是一个阻塞型的事件触发逻辑，其中关于定时器的就是调用synchronise去同步。 txsyncLoopstart中最后还有一个txsyncLoop：123456789101112131415161718192021222324func (pm *ProtocolManager) txsyncLoop() &#123; .... for &#123; select &#123; case s := &lt;-pm.txsyncCh: pending[s.p.ID()] = s if !sending &#123; send(s) &#125; case err := &lt;-done: sending = false if err != nil &#123; pack.p.Log().Debug("Transaction send failed", "err", err) delete(pending, pack.p.ID()) &#125; if s := pick(); s != nil &#123; send(s) &#125; case &lt;-pm.quitSync: return &#125; &#125;&#125; 这里主要是先定义了两个方法，然后启动了一个循环取处理事件，第一个事件在syncTransactions中发出，它在ProtocolManager的handle中调用，handle在会在每个peer建立后得到调用，所以也就是对新来的连接会执行syncTransactions方法：1234567891011121314func (pm *ProtocolManager) syncTransactions(p *peer) &#123; var txs types.Transactions pending, _ := pm.txpool.Pending() for _, batch := range pending &#123; txs = append(txs, batch...) &#125; if len(txs) == 0 &#123; return &#125; select &#123; case pm.txsyncCh &lt;- &amp;txsync&#123;p, txs&#125;: case &lt;-pm.quitSync: &#125;&#125; 在syncTransactions中，首先获取所有等待中的交易，然后打包传给txsyncCh触发txsyncLoop中的逻辑。主要是调用send方法，就是开始定义的：12345678910111213141516send := func(s *txsync) &#123; size := common.StorageSize(0) pack.p = s.p pack.txs = pack.txs[:0] for i := 0; i &lt; len(s.txs) &amp;&amp; size &lt; txsyncPackSize; i++ &#123; pack.txs = append(pack.txs, s.txs[i]) size += s.txs[i].Size() &#125; s.txs = s.txs[:copy(s.txs, s.txs[len(pack.txs):])] if len(s.txs) == 0 &#123; delete(pending, s.p.ID()) &#125; s.p.Log().Trace("Sending batch of transactions", "count", len(pack.txs), "bytes", size) sending = true go func() &#123; done &lt;- pack.p.SendTransactions(pack.txs) &#125;()&#125; 这里一次只发送一部分交易信息，要求发送的消息总大小不超过txsyncPackSize。之后如果全都发送的话，把该peer从pending中移除，表示没有消息要发送，然后更新剩余信息。之后启动一个goroutine发送信息，使用的是SendTransactions方法，前文介绍过，并将发送结果传给done，触发txsyncLoop中select另外一个逻辑，这里如果发送无错则先调用pick方法：123456789101112pick := func() *txsync &#123; if len(pending) == 0 &#123; return nil &#125; n := rand.Intn(len(pending)) + 1 for _, s := range pending &#123; if n--; n == 0 &#123; return s &#125; &#125; return nil&#125; 这是从pending中随机选一个等待发送的peer（表示为一个txsync对象，里面含有一个peer和对应的tx），然后调用send方法。直到所有等待的都发送完了（先前一次没有发完的txsync也会在后续被随机选到再次发送），send–pick逻辑结束。 题图来自unsplash：https://unsplash.com/photos/fR9U2S31Exs]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中p2p源码学习]]></title>
    <url>%2F2019%2F04%2F23%2Fgo-ethereum%E4%B8%ADp2p%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前一篇笔记学习了以太坊p2p网络的发现和维护机制，这篇笔记就来了解一下p2p服务 server.go这是P2P服务的主逻辑代码所在处 Start服务的启动代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354func (srv *Server) Start() (err error) &#123; srv.lock.Lock() defer srv.lock.Unlock() if srv.running &#123; //判断是否启动，避免重复启动 return errors.New("server already running") &#125; srv.running = true srv.log = srv.Config.Logger if srv.log == nil &#123; srv.log = log.New() &#125; if srv.NoDial &amp;&amp; srv.ListenAddr == "" &#123; //判断节点是否主动连接其他节点或者监听提起节点 srv.log.Warn("P2P server will be useless, neither dialing nor listening") &#125; // static fields if srv.PrivateKey == nil &#123; return errors.New("Server.PrivateKey must be set to a non-nil key") &#125; if srv.newTransport == nil &#123; srv.newTransport = newRLPX &#125; if srv.Dialer == nil &#123; srv.Dialer = TCPDialer&#123;&amp;net.Dialer&#123;Timeout: defaultDialTimeout&#125;&#125; &#125; srv.quit = make(chan struct&#123;&#125;) srv.addpeer = make(chan *conn) srv.delpeer = make(chan peerDrop) srv.posthandshake = make(chan *conn) srv.addstatic = make(chan *enode.Node) srv.removestatic = make(chan *enode.Node) srv.addtrusted = make(chan *enode.Node) srv.removetrusted = make(chan *enode.Node) srv.peerOp = make(chan peerOpFunc) srv.peerOpDone = make(chan struct&#123;&#125;) if err := srv.setupLocalNode(); err != nil &#123; return err &#125; if srv.ListenAddr != "" &#123; if err := srv.setupListening(); err != nil &#123; return err &#125; &#125; if err := srv.setupDiscovery(); err != nil &#123; return err &#125; dynPeers := srv.maxDialedConns() dialer := newDialState(srv.localnode.ID(), srv.StaticNodes, srv.BootstrapNodes, srv.ntab, dynPeers, srv.NetRestrict) srv.loopWG.Add(1) go srv.run(dialer) return nil&#125; 首先判断是否启动，避免多起启动实例，然后将服务已运行的标志位置true。然后初始化log实例，检查是否要主动连接其他节点，检查私钥是否为空。之后配置rlpx与dial类，稍后再介绍这两个东西。再往下初始化了一系列的channel留作同步用。接着调用了setupLocalNode实现如下 setupLocalNode12345678910111213141516171819202122232425262728293031323334353637func (srv *Server) setupLocalNode() error &#123; pubkey := crypto.FromECDSAPub(&amp;srv.PrivateKey.PublicKey) srv.ourHandshake = &amp;protoHandshake&#123;Version: baseProtocolVersion, Name: srv.Name, ID: pubkey[1:]&#125; for _, p := range srv.Protocols &#123; srv.ourHandshake.Caps = append(srv.ourHandshake.Caps, p.cap()) &#125; sort.Sort(capsByNameAndVersion(srv.ourHandshake.Caps)) db, err := enode.OpenDB(srv.Config.NodeDatabase) if err != nil &#123; return err &#125; srv.nodedb = db srv.localnode = enode.NewLocalNode(db, srv.PrivateKey) srv.localnode.SetFallbackIP(net.IP&#123;127, 0, 0, 1&#125;) srv.localnode.Set(capsByNameAndVersion(srv.ourHandshake.Caps)) for _, p := range srv.Protocols &#123; for _, e := range p.Attributes &#123; srv.localnode.Set(e) &#125; &#125; switch srv.NAT.(type) &#123; case nil: case nat.ExtIP: ip, _ := srv.NAT.ExternalIP() srv.localnode.SetStaticIP(ip) default: srv.loopWG.Add(1) go func() &#123; defer srv.loopWG.Done() if ip, err := srv.NAT.ExternalIP(); err == nil &#123; srv.localnode.SetStaticIP(ip) &#125; &#125;() &#125; return nil&#125; 首先FromECDSAPub是将公钥以字节数组的形式表示（根据椭圆加密算法，我们知道公钥实际上是一对点坐标，这里我们将这对点用字节数组表示出来），之后构造了握手协议的实例，主要记录了版本号（5）；服务名以及ID（就是公钥）。之后遍历了服务的所有协议，将每个协议的cap添加到握手协议的caps中（cap实际上记录了该协议的版本号及名字）。下面先创建了数据库，并配置给服务。接着调用NewLocalNode创建本地节点，实际上就是实例化了一个LocalNode对象，存储了公钥私钥数据库对象等信息。接下来设置了fallbackIP，Set方法实际上是将对象存储在localnode的entries中，capsByNameAndVersion实现了Entry接口。然后遍历服务中所有协议的所有Attributes（实际上也是一个个Entry数组）存储起来。 setupListening配置完localnode后接着调用了setupListening12345678910111213141516171819202122func (srv *Server) setupListening() error &#123; listener, err := net.Listen("tcp", srv.ListenAddr) if err != nil &#123; return err &#125; laddr := listener.Addr().(*net.TCPAddr) srv.ListenAddr = laddr.String() srv.listener = listener srv.localnode.Set(enr.TCP(laddr.Port)) srv.loopWG.Add(1) go srv.listenLoop() if !laddr.IP.IsLoopback() &amp;&amp; srv.NAT != nil &#123; srv.loopWG.Add(1) go func() &#123; nat.Map(srv.NAT, srv.quit, "tcp", laddr.Port, laddr.Port, "ethereum p2p") srv.loopWG.Done() &#125;() &#125; return nil&#125; 这里主要是监听某个tcp端口地址，启动了listenLoop1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253func (srv *Server) listenLoop() &#123; defer srv.loopWG.Done() srv.log.Debug("TCP listener up", "addr", srv.listener.Addr()) tokens := defaultMaxPendingPeers if srv.MaxPendingPeers &gt; 0 &#123; tokens = srv.MaxPendingPeers &#125; slots := make(chan struct&#123;&#125;, tokens) for i := 0; i &lt; tokens; i++ &#123; slots &lt;- struct&#123;&#125;&#123;&#125; &#125; for &#123; &lt;-slots var ( fd net.Conn err error ) for &#123; fd, err = srv.listener.Accept() if netutil.IsTemporaryError(err) &#123; srv.log.Debug("Temporary read error", "err", err) continue &#125; else if err != nil &#123; srv.log.Debug("Read error", "err", err) return &#125; break &#125; if srv.NetRestrict != nil &#123; if tcp, ok := fd.RemoteAddr().(*net.TCPAddr); ok &amp;&amp; !srv.NetRestrict.Contains(tcp.IP) &#123; srv.log.Debug("Rejected conn (not whitelisted in NetRestrict)", "addr", fd.RemoteAddr()) fd.Close() slots &lt;- struct&#123;&#125;&#123;&#125; continue &#125; &#125; var ip net.IP if tcp, ok := fd.RemoteAddr().(*net.TCPAddr); ok &#123; ip = tcp.IP &#125; fd = newMeteredConn(fd, true, ip) srv.log.Trace("Accepted connection", "addr", fd.RemoteAddr()) go func() &#123; srv.SetupConn(fd, inboundConn, nil) slots &lt;- struct&#123;&#125;&#123;&#125; &#125;() &#125;&#125; 首先规定了最大的等待连接数量tokens，然后创建了一个容量与之一样大的channel，在于一个无限循环中中，利用channel机制，启动了tokens个无限循环。每个循环会接收一个连接请求，实际上虽然是无限循环，在获得一个请求后循环便结束了（之所以要用无限循环是要跳过其中的临时性错误）。然后检查白名单，不在名单内的IP都拒绝服务。对于可以服务的连接，单独启动一个goroutine去处理，然后主循环继续，如果连接数未达到最大，则继续等待连接到来。处理连接的方法是SetupConn：123456789func (srv *Server) SetupConn(fd net.Conn, flags connFlag, dialDest *enode.Node) error &#123; c := &amp;conn&#123;fd: fd, transport: srv.newTransport(fd), flags: flags, cont: make(chan error)&#125; err := srv.setupConn(c, flags, dialDest) if err != nil &#123; c.close(err) srv.log.Trace("Setting up connection failed", "addr", fd.RemoteAddr(), "err", err) &#125; return err&#125; SetupConn是执行一个握手协议，并尝试把连接创建成一个peer对象。可以看到只是先创建了conn对象，然后调用了setupConn：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func (srv *Server) setupConn(c *conn, flags connFlag, dialDest *enode.Node) error &#123; srv.lock.Lock() running := srv.running srv.lock.Unlock() if !running &#123; return errServerStopped &#125; var dialPubkey *ecdsa.PublicKey if dialDest != nil &#123; dialPubkey = new(ecdsa.PublicKey) if err := dialDest.Load((*enode.Secp256k1)(dialPubkey)); err != nil &#123; return errors.New("dial destination doesn't have a secp256k1 public key") &#125; &#125; remotePubkey, err := c.doEncHandshake(srv.PrivateKey, dialPubkey) if err != nil &#123; srv.log.Trace("Failed RLPx handshake", "addr", c.fd.RemoteAddr(), "conn", c.flags, "err", err) return err &#125; if dialDest != nil &#123; // For dialed connections, check that the remote public key matches. if dialPubkey.X.Cmp(remotePubkey.X) != 0 || dialPubkey.Y.Cmp(remotePubkey.Y) != 0 &#123; return DiscUnexpectedIdentity &#125; c.node = dialDest &#125; else &#123; c.node = nodeFromConn(remotePubkey, c.fd) &#125; if conn, ok := c.fd.(*meteredConn); ok &#123; conn.handshakeDone(c.node.ID()) &#125; clog := srv.log.New("id", c.node.ID(), "addr", c.fd.RemoteAddr(), "conn", c.flags) err = srv.checkpoint(c, srv.posthandshake) if err != nil &#123; clog.Trace("Rejected peer before protocol handshake", "err", err) return err &#125; phs, err := c.doProtoHandshake(srv.ourHandshake) if err != nil &#123; clog.Trace("Failed proto handshake", "err", err) return err &#125; if id := c.node.ID(); !bytes.Equal(crypto.Keccak256(phs.ID), id[:]) &#123; clog.Trace("Wrong devp2p handshake identity", "phsid", hex.EncodeToString(phs.ID)) return DiscUnexpectedIdentity &#125; c.caps, c.name = phs.Caps, phs.Name err = srv.checkpoint(c, srv.addpeer) if err != nil &#123; clog.Trace("Rejected peer", "err", err) return err &#125; clog.Trace("connection set up", "inbound", dialDest == nil) return nil&#125; 首先确保服务正在运行，然后判断远端节点是否为nil（为nil其实是被动连接，不为nil其实是在dial中主动连接），来计算其公钥。当收到一个连接时，这里为nil不执行。然后调用doEncHandshake开始加密握手，这里实际上是调用的rlpx中的方法，稍后再讲。这里最后得到远端的公钥。对于收到一个连接，远端node开始为空，这里调用nodeFromConn创建一个，主要是记录公钥、ip地址及端口号。接着执行checkpoint方法：12345678910111213func (srv *Server) checkpoint(c *conn, stage chan&lt;- *conn) error &#123; select &#123; case stage &lt;- c: case &lt;-srv.quit: return errServerStopped &#125; select &#123; case err := &lt;-c.cont: return err case &lt;-srv.quit: return errServerStopped &#125;&#125; 实际上就是给posthandshake赋值，然后触发后续逻辑，我们稍后再讲。紧接着又执行了协议握手，调用了doProtoHandshake方法，也是rlpx中方法，传入的参数是ourHandshake，也就是在配置localnode是初始化的，记录了版本号、服务名和自己公钥以及服务中所有协议的摘要。这个方法返回远端的协议信息，之后在conn对象中记录下来远端的服务名和服务中所有协议摘要。同样也通过checkpoint传递给addpeer用来触发后续逻辑。完成后就和远端建立的连接。 setupDiscovery刚才我们在分析配置网络监听的代码时顺便看了收到连接时的逻辑。再回到Start中，下面又调用了setupDiscovery;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (srv *Server) setupDiscovery() error &#123; if srv.NoDiscovery &amp;&amp; !srv.DiscoveryV5 &#123; return nil &#125; addr, err := net.ResolveUDPAddr("udp", srv.ListenAddr) if err != nil &#123; return err &#125; conn, err := net.ListenUDP("udp", addr) if err != nil &#123; return err &#125; realaddr := conn.LocalAddr().(*net.UDPAddr) srv.log.Debug("UDP listener up", "addr", realaddr) if srv.NAT != nil &#123; if !realaddr.IP.IsLoopback() &#123; go nat.Map(srv.NAT, srv.quit, "udp", realaddr.Port, realaddr.Port, "ethereum discovery") &#125; &#125; srv.localnode.SetFallbackUDP(realaddr.Port) var unhandled chan discover.ReadPacket var sconn *sharedUDPConn if !srv.NoDiscovery &#123; if srv.DiscoveryV5 &#123; unhandled = make(chan discover.ReadPacket, 100) sconn = &amp;sharedUDPConn&#123;conn, unhandled&#125; &#125; cfg := discover.Config&#123; PrivateKey: srv.PrivateKey, NetRestrict: srv.NetRestrict, Bootnodes: srv.BootstrapNodes, Unhandled: unhandled, &#125; ntab, err := discover.ListenUDP(conn, srv.localnode, cfg) if err != nil &#123; return err &#125; srv.ntab = ntab &#125; if srv.DiscoveryV5 &#123; var ntab *discv5.Network var err error if sconn != nil &#123; ntab, err = discv5.ListenUDP(srv.PrivateKey, sconn, "", srv.NetRestrict) &#125; else &#123; ntab, err = discv5.ListenUDP(srv.PrivateKey, conn, "", srv.NetRestrict) &#125; if err != nil &#123; return err &#125; if err := ntab.SetFallbackNodes(srv.BootstrapNodesV5); err != nil &#123; return err &#125; srv.DiscV5 = ntab &#125; return nil&#125; 这里主要就是监听udp连接，配置私钥、白名单、bootstrap节点等，然后调用discover的ListenUDP开始节点发现，后续逻辑详见这里。 run稍微总结一下，start的逻辑主要是配置：配置localnode，处理tcp连接用于节点通信，处理udp连接用于节点发现。配置完毕后，调用newDialState创建了一个dialstate对象，然后运行run方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455func (srv *Server) run(dialstate dialer) &#123; srv.log.Info("Started P2P networking", "self", srv.localnode.Node()) defer srv.loopWG.Done() defer srv.nodedb.Close() var ( peers = make(map[enode.ID]*Peer) inboundCount = 0 trusted = make(map[enode.ID]bool, len(srv.TrustedNodes)) taskdone = make(chan task, maxActiveDialTasks) runningTasks []task queuedTasks []task // tasks that can't run yet ) for _, n := range srv.TrustedNodes &#123; trusted[n.ID()] = true &#125; delTask := func(t task) &#123; for i := range runningTasks &#123; if runningTasks[i] == t &#123; runningTasks = append(runningTasks[:i], runningTasks[i+1:]...) break &#125; &#125; &#125; startTasks := func(ts []task) (rest []task) &#123; i := 0 for ; len(runningTasks) &lt; maxActiveDialTasks &amp;&amp; i &lt; len(ts); i++ &#123; t := ts[i] srv.log.Trace("New dial task", "task", t) go func() &#123; t.Do(srv); taskdone &lt;- t &#125;() runningTasks = append(runningTasks, t) &#125; return ts[i:] &#125; scheduleTasks := func() &#123; queuedTasks = append(queuedTasks[:0], startTasks(queuedTasks)...) if len(runningTasks) &lt; maxActiveDialTasks &#123; nt := dialstate.newTasks(len(runningTasks)+len(queuedTasks), peers, time.Now()) queuedTasks = append(queuedTasks, startTasks(nt)...) &#125; &#125;running: for &#123; scheduleTasks() select&#123; ... &#125; &#125;&#125; run方法主要是处理一些连接的逻辑，首先定义了两个队列runningTasks与queuedTasks，保存正在运行和等待运行的任务。然后定义了三个处理任务的方法。delTask就是删除任务。startTasks就是将任务添加到runningTasks并执行do方法，对于暂时无法运行的任务则返回。scheduleTasks是用来启动任务，他会先尝试启动等待中的任务，然后用newTasks新建一个任务，添加到queuedTasks中。 在接下来的一个无限循环开始，首先启动scheduleTasks，触发一些连接的建立和任务的启动，之后进入select开始阻塞，等待特定的逻辑被触发。 run:running回顾刚才的代码流程，在执行完加密握手后，调用了checkpoint，将一个conn对象传给了srv.posthandshake，出发了run中如下逻辑：123456789case c := &lt;-srv.posthandshake: if trusted[c.node.ID()] &#123; c.flags |= trustedConn &#125; select &#123; case c.cont &lt;- srv.encHandshakeChecks(peers, inboundCount, c): case &lt;-srv.quit: break running &#125; 首先检测是否是可信节点，是的话修改flags的值。然后执行encHandshakeChecks方法：1234567891011121314func (srv *Server) encHandshakeChecks(peers map[enode.ID]*Peer, inboundCount int, c *conn) error &#123; switch &#123; case !c.is(trustedConn|staticDialedConn) &amp;&amp; len(peers) &gt;= srv.MaxPeers: return DiscTooManyPeers case !c.is(trustedConn) &amp;&amp; c.is(inboundConn) &amp;&amp; inboundCount &gt;= srv.maxInboundConns(): return DiscTooManyPeers case peers[c.node.ID()] != nil: return DiscAlreadyConnected case c.node.ID() == srv.localnode.ID(): return DiscSelf default: return nil &#125;&#125; 前两个case主要是通过检查conn的flags判断是节点的性质以及连接数，后两个检查是否是自己或者已连接。检查结果赋值给c.cont，这时回到checkpoint中，如果刚才检查无误setupConn流程继续，否则则抛出异常拒绝服务。 再往下，在setupConn中执行完协议握手后，同样调用了checkpoint方法，这次是给srv.addpeer赋值来触发逻辑：1234567891011121314151617181920case c := &lt;-srv.addpeer: err := srv.protoHandshakeChecks(peers, inboundCount, c) if err == nil &#123; p := newPeer(c, srv.Protocols) if srv.EnableMsgEvents &#123; p.events = &amp;srv.peerFeed &#125; name := truncateName(c.name) srv.log.Debug("Adding p2p peer", "name", name, "addr", c.fd.RemoteAddr(), "peers", len(peers)+1) go srv.runPeer(p) peers[c.node.ID()] = p if p.Inbound() &#123; inboundCount++ &#125; &#125; select &#123; case c.cont &lt;- err: case &lt;-srv.quit: break running &#125; 同样先检查节点，这次调用的是protoHandshakeChecks：123456func (srv *Server) protoHandshakeChecks(peers map[enode.ID]*Peer, inboundCount int, c *conn) error &#123; if len(srv.Protocols) &gt; 0 &amp;&amp; countMatchingProtocols(srv.Protocols, c.caps) == 0 &#123; return DiscUselessPeer &#125; return srv.encHandshakeChecks(peers, inboundCount, c)&#125; 由于握手后，我们知道了对方能提供的协议详情，这里进行了匹配检查，如果双方没有能匹配到的协议，则返回DiscUselessPeer，之后和刚才加密握手一样调用encHandshakeChecks进行节点检查。最后如果都没有问题，调用newPeer创建一个新的Peer。这里表示握手通过，连接正式建立。之后进行了后续操作，如将刚才生成的peer记录下来，另外如果是一个接入的连接，则inboundCount自增。同时调用了runPeer方法1234567891011121314151617181920func (srv *Server) runPeer(p *Peer) &#123; if srv.newPeerHook != nil &#123; srv.newPeerHook(p) &#125; srv.peerFeed.Send(&amp;PeerEvent&#123; Type: PeerEventTypeAdd, Peer: p.ID(), &#125;) remoteRequested, err := p.run() srv.peerFeed.Send(&amp;PeerEvent&#123; Type: PeerEventTypeDrop, Peer: p.ID(), Error: err.Error(), &#125;) srv.delpeer &lt;- peerDrop&#123;p, err, remoteRequested&#125;&#125; 这里主要是先广播了peer的建立，然后调用peer的run方法，这里稍后再讲，知道peer连接断开，然后给delpeer赋值触发相应逻辑。由于runPeer是运行在一个单独goroutine中，所以不会阻塞server的run运行，我们回到run中，srv.addpeer对应的逻辑最后有个阻塞，会给c.cont赋值，这时回到setupConn，如果赋值为空表示没有错误，连接正常，则继续setupConn的逻辑。这样一次握手完成。再看peer断开时，srv.delpeer被赋值，触发如下逻辑：12345678case pd := &lt;-srv.delpeer: d := common.PrettyDuration(mclock.Now() - pd.created) pd.log.Debug("Removing p2p peer", "duration", d, "peers", len(peers)-1, "req", pd.requested, "err", pd.err) delete(peers, pd.ID()) if pd.Inbound() &#123; inboundCount-- &#125;&#125; 主要的逻辑就是从peers删除对应的peer，然后如果是接入型peer，inboundCount再自减1。 到这里server的主逻辑分析完毕，除了这些，服务还提供了一些方法供外部使用，首先看AddPeer：123456func (srv *Server) AddPeer(node *enode.Node) &#123; select &#123; case srv.addstatic &lt;- node: case &lt;-srv.quit: &#125;&#125; 也是利用channel模式触发run中的逻辑123case n := &lt;-srv.addstatic: srv.log.Trace("Adding static node", "node", n) dialstate.addStatic(n) 很简单就是将要添加的节点dialstate的static这个map中，key就是节点的ID，值就是一个dialTask。 除此之外还有RemovePeer、AddTrustedPeer、RemoveTrustedPeer等方法，都是利用向一个channel中赋值，来触发run中的逻辑这里不再详细叙述。 rlpx.go这是一个较独立的模块，所以拿出来分析了，详见此文：go-ethereum中p2p-rlpx源码学习 dial.godial在p2p中也负责链接的建立，在p2pserver中第一次出现是在start方法内构造了一个TCPDialer对象赋值给Dialer：123456789101112 if srv.Dialer == nil &#123; srv.Dialer = TCPDialer&#123;&amp;net.Dialer&#123;Timeout: defaultDialTimeout&#125;&#125; &#125; type TCPDialer struct &#123; *net.Dialer&#125; func (t TCPDialer) Dial(dest *enode.Node) (net.Conn, error) &#123; addr := &amp;net.TCPAddr&#123;IP: dest.IP(), Port: dest.TCP()&#125; return t.Dialer.Dial("tcp", addr.String())&#125; TCPDialer实际上对Dialer进行了封装，然后提供了Dial用于和指定Node建立tcp链接。除此之外还有一个重要的结构体dialstate，它在p2pserver中的start方法最后进行了实例化，并作为参数传递给了run方法，初始化方法如下：123456789101112131415161718func newDialState(self enode.ID, static []*enode.Node, bootnodes []*enode.Node, ntab discoverTable, maxdyn int, netrestrict *netutil.Netlist) *dialstate &#123; s := &amp;dialstate&#123; maxDynDials: maxdyn, ntab: ntab, self: self, netrestrict: netrestrict, static: make(map[enode.ID]*dialTask), dialing: make(map[enode.ID]connFlag), bootnodes: make([]*enode.Node, len(bootnodes)), randomNodes: make([]*enode.Node, maxdyn/2), hist: new(dialHistory), &#125; copy(s.bootnodes, bootnodes) for _, n := range static &#123; s.addStatic(n) &#125; return s&#125; maxDynDials就是server的maxDialedConns，计算如下：12345678910func (srv *Server) maxDialedConns() int &#123; if srv.NoDiscovery || srv.NoDial &#123; return 0 &#125; r := srv.DialRatio if r == 0 &#123; r = defaultDialRatio &#125; return srv.MaxPeers / r&#125; 他在节点从不进行发现或进行连接时等于0，否则根据MaxPeers和DialRatio计算。ntab就是discover的table，代表节点发现协议。其他的赋值了信赖节点和boot节点。实例化之后，在run方法中调用了它的下面几个方法： newTasks这是在定义scheduleTasks时调用的1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func (s *dialstate) newTasks(nRunning int, peers map[enode.ID]*Peer, now time.Time) []task &#123; if s.start.IsZero() &#123; s.start = now &#125; var newtasks []task addDial := func(flag connFlag, n *enode.Node) bool &#123; if err := s.checkDial(n, peers); err != nil &#123; log.Trace("Skipping dial candidate", "id", n.ID(), "addr", &amp;net.TCPAddr&#123;IP: n.IP(), Port: n.TCP()&#125;, "err", err) return false &#125; s.dialing[n.ID()] = flag newtasks = append(newtasks, &amp;dialTask&#123;flags: flag, dest: n&#125;) return true &#125; needDynDials := s.maxDynDials for _, p := range peers &#123; if p.rw.is(dynDialedConn) &#123; needDynDials-- &#125; &#125; for _, flag := range s.dialing &#123; if flag&amp;dynDialedConn != 0 &#123; needDynDials-- &#125; &#125; s.hist.expire(now) for id, t := range s.static &#123; err := s.checkDial(t.dest, peers) switch err &#123; case errNotWhitelisted, errSelf: log.Warn("Removing static dial candidate", "id", t.dest.ID, "addr", &amp;net.TCPAddr&#123;IP: t.dest.IP(), Port: t.dest.TCP()&#125;, "err", err) delete(s.static, t.dest.ID()) case nil: s.dialing[id] = t.flags newtasks = append(newtasks, t) &#125; &#125; if len(peers) == 0 &amp;&amp; len(s.bootnodes) &gt; 0 &amp;&amp; needDynDials &gt; 0 &amp;&amp; now.Sub(s.start) &gt; fallbackInterval &#123; bootnode := s.bootnodes[0] s.bootnodes = append(s.bootnodes[:0], s.bootnodes[1:]...) s.bootnodes = append(s.bootnodes, bootnode) if addDial(dynDialedConn, bootnode) &#123; needDynDials-- &#125; &#125; randomCandidates := needDynDials / 2 if randomCandidates &gt; 0 &#123; n := s.ntab.ReadRandomNodes(s.randomNodes) for i := 0; i &lt; randomCandidates &amp;&amp; i &lt; n; i++ &#123; if addDial(dynDialedConn, s.randomNodes[i]) &#123; needDynDials-- &#125; &#125; &#125; i := 0 for ; i &lt; len(s.lookupBuf) &amp;&amp; needDynDials &gt; 0; i++ &#123; if addDial(dynDialedConn, s.lookupBuf[i]) &#123; needDynDials-- &#125; &#125; s.lookupBuf = s.lookupBuf[:copy(s.lookupBuf, s.lookupBuf[i:])] if len(s.lookupBuf) &lt; needDynDials &amp;&amp; !s.lookupRunning &#123; s.lookupRunning = true newtasks = append(newtasks, &amp;discoverTask&#123;&#125;) &#125; if nRunning == 0 &amp;&amp; len(newtasks) == 0 &amp;&amp; s.hist.Len() &gt; 0 &#123; t := &amp;waitExpireTask&#123;s.hist.min().exp.Sub(now)&#125; newtasks = append(newtasks, t) &#125; return newtasks&#125; 他所返回的是一组task对象，task有一个Do方法。开头第一个检查时间的是为了初始化开始时间。然后定义了addDial方法，主要将节点包装成dialTask添加到newtasks中。不过首先对节点进行了检查，主要是检查是否已连接或者正在连接或者非信任节点等。之后计算了需要建立动态连接的数量。 然后遍历所有静态节点，检查每个节点，没有问题的将其暂存到newtasks中。接下来如果已连接数为0，并且已经过了fallbackInterval时间，则寻找一个bootnode进行连接。接下来在randomNodes中添加需要建立动态连接的数量的一半的节点。后面如果还未达到需要建立动态连接的数量要求，则从lookupBuf中挑选。如果数量还不够创建discoverTask添加进去，用于节点发现。最后当什么都不做创建waitExpireTask返回。 这个方法就是添加一系列要执行的任务。 Do之后回到p2pserver的run方法中，在startTasks方法内，会启动这一系列任务，通过Do方法，不同的任务有同的Do方法： dialTask1234567891011121314151617func (t *dialTask) Do(srv *Server) &#123; if t.dest.Incomplete() &#123; if !t.resolve(srv) &#123; return &#125; &#125; err := t.dial(srv, t.dest) if err != nil &#123; log.Trace("Dial error", "task", t, "err", err) // Try resolving the ID of static nodes if dialing failed. if _, ok := err.(*dialError); ok &amp;&amp; t.flags&amp;staticDialedConn != 0 &#123; if t.resolve(srv) &#123; t.dial(srv, t.dest) &#125; &#125; &#125;&#125; Incomplete方法是检查节点是否有IP地址，如果没有则调用resolve方法：123456789101112131415161718192021222324252627func (t *dialTask) resolve(srv *Server) bool &#123; if srv.ntab == nil &#123; log.Debug("Can't resolve node", "id", t.dest.ID, "err", "discovery is disabled") return false &#125; if t.resolveDelay == 0 &#123; t.resolveDelay = initialResolveDelay &#125; if time.Since(t.lastResolved) &lt; t.resolveDelay &#123; return false &#125; resolved := srv.ntab.Resolve(t.dest) t.lastResolved = time.Now() if resolved == nil &#123; t.resolveDelay *= 2 if t.resolveDelay &gt; maxResolveDelay &#123; t.resolveDelay = maxResolveDelay &#125; log.Debug("Resolving node failed", "id", t.dest.ID, "newdelay", t.resolveDelay) return false &#125; t.resolveDelay = initialResolveDelay t.dest = resolved log.Debug("Resolved node", "id", t.dest.ID, "addr", &amp;net.TCPAddr&#123;IP: t.dest.IP(), Port: t.dest.TCP()&#125;) return true&#125; 这个方法是进程查询的，规定最小查询间隔是60秒。调用的是table中的Resolve，具体代码就不贴了，实际上就是先查找k桶，找到目标节点返回或摘到离他较近的节点调用lookup进行查找，所以就是节点查找的过程。如果查不到节点，则将最小查询间隔翻倍。如果查到的话，则更新节点。回到Do中，如果IP地址被补全，则调用dial进行连接，12345678func (t *dialTask) dial(srv *Server, dest *enode.Node) error &#123; fd, err := srv.Dialer.Dial(dest) if err != nil &#123; return &amp;dialError&#123;err&#125; &#125; mfd := newMeteredConn(fd, false, dest.IP()) return srv.SetupConn(mfd, t.flags, dest)&#125; Dialer实际上就是前文的TCPDialer，建立tcp连接后，调用了SetupConn，之后的逻辑前文以及分析过了。 discoverTask12345678func (t *discoverTask) Do(srv *Server) &#123; next := srv.lastLookup.Add(lookupInterval) if now := time.Now(); now.Before(next) &#123; time.Sleep(next.Sub(now)) &#125; srv.lastLookup = time.Now() t.results = srv.ntab.LookupRandom()&#125; 首先也是判断是否在最小间隔内，若是则等待，否则执行disocer的LookupRandom方法进行随机查找 waitExpireTask123func (t waitExpireTask) Do(*Server) &#123; time.Sleep(t.Duration)&#125; 就是一个定时方法 addStatic removeStatic这两个方法是提供给p2pserver的run方法中使用的，就是添加或移除节点。 dial总结结合p2pserver分析，可知首先封装了一个TCP连接对象给server。然后初始化dialstate进行连接的建立。首先在run的大循环中第一次调用scheduleTasks，此时queuedTasks和queuedTasks都为空，此时添加的任务就是那些静态节点或桶中节点包装的dialTask，以及还有可能的discoverTask和最后的waitExpireTask。然后启动这些任务。对于dialTask，主动和相关节点建立联系；对于discoverTask，执行节点发现逻辑；对于waitExpireTask进行定时方法。 peer.gonewPeer前面介绍了链路建立的准备工作，到这里peer代表一个已经建立好的连接。在p2p服务中，最早出现peer的地方是在节点主动发出或收到一个连接请求，并进行协议握手后，双方检查协议匹配性，检查通过后利用newPeer方法建立了一个peer对象，表示一条稳定的连接：12345678910111213func newPeer(conn *conn, protocols []Protocol) *Peer &#123; protomap := matchProtocols(protocols, conn.caps, conn) p := &amp;Peer&#123; rw: conn, running: protomap, created: mclock.Now(), disc: make(chan DiscReason), protoErr: make(chan error, len(protomap)+1), // protocols + pingLoop closed: make(chan struct&#123;&#125;), log: log.New("id", conn.node.ID(), "conn", conn.flags), &#125; return p&#125; matchProtocols表示双方都能提供的协议，参数中protocols表示自己能提供的协议，conn.caps表示对方能提供的协议，来看具体实现：1234567891011121314151617181920212223func matchProtocols(protocols []Protocol, caps []Cap, rw MsgReadWriter) map[string]*protoRW &#123; sort.Sort(capsByNameAndVersion(caps)) offset := baseProtocolLength result := make(map[string]*protoRW)outer: for _, cap := range caps &#123; for _, proto := range protocols &#123; if proto.Name == cap.Name &amp;&amp; proto.Version == cap.Version &#123; // If an old protocol version matched, revert it if old := result[cap.Name]; old != nil &#123; offset -= old.Length &#125; // Assign the new match result[cap.Name] = &amp;protoRW&#123;Protocol: proto, offset: offset, in: make(chan Msg), w: rw&#125; offset += proto.Length continue outer &#125; &#125; &#125; return result&#125; 基本就是遍历自己和对方的协议集合，将所有名字和版本号一样的协议封装成protoRW对象并按名字存入result中，最后返回二者都能提供的协议集合。 run回到newPeer中，构建了一个Peer对象并返回。紧接着启动了一个goroutine去调用runPeer，在runPeer中执行了peer的run方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445func (p *Peer) run() (remoteRequested bool, err error) &#123; var ( writeStart = make(chan struct&#123;&#125;, 1) writeErr = make(chan error, 1) readErr = make(chan error, 1) reason DiscReason // sent to the peer ) p.wg.Add(2) go p.readLoop(readErr) go p.pingLoop() writeStart &lt;- struct&#123;&#125;&#123;&#125; p.startProtocols(writeStart, writeErr)loop: for &#123; select &#123; case err = &lt;-writeErr: if err != nil &#123; reason = DiscNetworkError break loop &#125; writeStart &lt;- struct&#123;&#125;&#123;&#125; case err = &lt;-readErr: if r, ok := err.(DiscReason); ok &#123; remoteRequested = true reason = r &#125; else &#123; reason = DiscNetworkError &#125; break loop case err = &lt;-p.protoErr: reason = discReasonForError(err) break loop case err = &lt;-p.disc: reason = discReasonForError(err) break loop &#125; &#125; close(p.closed) p.rw.close(reason) p.wg.Wait() return remoteRequested, err&#125; readLoop在run方法中，首先在一个独立goroutine中启动了readLoop方法：123456789101112131415func (p *Peer) readLoop(errc chan&lt;- error) &#123; defer p.wg.Done() for &#123; msg, err := p.rw.ReadMsg() if err != nil &#123; errc &lt;- err return &#125; msg.ReceivedAt = time.Now() if err = p.handle(msg); err != nil &#123; errc &lt;- err return &#125; &#125;&#125; 这就是一个阻塞型的从流中读取信息的方法。rw是conn类型，conn是在开启一个tcp连接后，在SetupConn中将net.Conn包装后的对象。它的ReadMsg实际上就是rlpx的ReadMsg方法，前文已经分析过，返回的是一个Msg对象。之后在readLoop中给mag打上接受的时间戳，然后调用handle处理这个msg12345678910111213141516171819202122232425func (p *Peer) handle(msg Msg) error &#123; switch &#123; case msg.Code == pingMsg: msg.Discard() go SendItems(p.rw, pongMsg) case msg.Code == discMsg: var reason [1]DiscReason rlp.Decode(msg.Payload, &amp;reason) return reason[0] case msg.Code &lt; baseProtocolLength: return msg.Discard() default: proto, err := p.getProto(msg.Code) if err != nil &#123; return fmt.Errorf("msg code out of range: %v", msg.Code) &#125; select &#123; case proto.in &lt;- msg: return nil case &lt;-p.closed: return io.EOF &#125; &#125; return nil&#125; 这里主要是根据msg.Code决定执行的逻辑。主要是判断是否是ping消息或的断开连接的消息。都不是的话判断code是否满足规范，满足的话根据code取具体的协议getProto：12345678func (p *Peer) getProto(code uint64) (*protoRW, error) &#123; for _, proto := range p.running &#123; if code &gt;= proto.offset &amp;&amp; code &lt; proto.offset+proto.Length &#123; return proto, nil &#125; &#125; return nil, newPeerError(errInvalidMsgCode, "%d", code)&#125; 这里根据code查找具体协议，匹配的方式是根据协议的offset和length，看是否在[offset,offset+length)区间内，然后返回具体协议。找到后将msg赋值给proto.in触发相应逻辑。到这里handle执行完毕，readLoop的一个循环结束，开始下一个循环等待数据到来，这样一次完整的数据读取完成。还有一点需要注意的是handle多次出现了Discard方法：123456func (msg Msg) Discard() error &#123; _, err := io.Copy(ioutil.Discard, msg.Payload) return err&#125;var Discard io.Writer = devNull(0) 由于msg的payload携带的是一个Reader对象，当消息抛弃是也要把read的内容读完，所以这里使用Discard这个虚拟的写对象，这个不执行什么实际操作，但是不会报错，可以安全的丢弃数据。 pingLoop再回到run方法中，和readLoop同时启动的还有pingLoop1234567891011121314151617func (p *Peer) pingLoop() &#123; ping := time.NewTimer(pingInterval) defer p.wg.Done() defer ping.Stop() for &#123; select &#123; case &lt;-ping.C: if err := SendItems(p.rw, pingMsg); err != nil &#123; p.protoErr &lt;- err return &#125; ping.Reset(pingInterval) case &lt;-p.closed: return &#125; &#125;&#125; 这相当于是一个心跳包，即使双方没有数据传输，也要每隔一段时间内发送一个ping包看对方是否在线，这里时间间隔是15秒。15秒后执行SendItems方法1234567891011func SendItems(w MsgWriter, msgcode uint64, elems ...interface&#123;&#125;) error &#123; return Send(w, msgcode, elems)&#125;func Send(w MsgWriter, msgcode uint64, data interface&#123;&#125;) error &#123; size, r, err := rlp.EncodeToReader(data) if err != nil &#123; return err &#125; return w.WriteMsg(Msg&#123;Code: msgcode, Size: uint32(size), Payload: r&#125;)&#125; 这里的ping包是一个空包，只有一个pingMsg，最后还用rlpx的WriteMsg发送一个封装好的msg对象。发送后对方接受的逻辑就在上文分析的handle方法，123case msg.Code == pingMsg: msg.Discard() go SendItems(p.rw, pongMsg) 可见显示抛弃消息，然后为了避免阻塞发送了pong包，和发送ping包一样。当我们接受到pong包时，由于pongMsg小于baseProtocolLength，所以直接被抛弃。 startProtocols再回到run中，由于readLoop和pingLoop都是异步进行了，我们看主线程的逻辑，首先调用了startProtocols12345678910111213141516171819202122232425func (p *Peer) startProtocols(writeStart &lt;-chan struct&#123;&#125;, writeErr chan&lt;- error) &#123; p.wg.Add(len(p.running)) for _, proto := range p.running &#123; proto := proto proto.closed = p.closed proto.wstart = writeStart proto.werr = writeErr var rw MsgReadWriter = proto if p.events != nil &#123; rw = newMsgEventer(rw, p.events, p.ID(), proto.Name) &#125; p.log.Trace(fmt.Sprintf("Starting protocol %s/%d", proto.Name, proto.Version)) go func() &#123; err := proto.Run(p, rw) if err == nil &#123; p.log.Trace(fmt.Sprintf("Protocol %s/%d returned", proto.Name, proto.Version)) err = errProtocolReturned &#125; else if err != io.EOF &#123; p.log.Trace(fmt.Sprintf("Protocol %s/%d failed", proto.Name, proto.Version), "err", err) &#125; p.protoErr &lt;- err p.wg.Done() &#125;() &#125;&#125; running就是在newPeer中挑选的匹配上的协议，这里遍历这些协议进行启动操作。由于这里遍历的是Protocol的封装类protoRW，所以先对其几个channel赋值，然后启动一个匿名方法，执行协议的Run方法。 run:loop在启动完所有协议后，开启了一个loop，也是一个无限循环，这个主要是处理各种错误的，如读写错误等，对于所有读写错误处理都是直接结束循环，后续触发peer的结束。 题图来自unsplash：https://unsplash.com/photos/gooBgyq17i0]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中p2p-rlpx源码学习]]></title>
    <url>%2F2019%2F04%2F21%2Fgo-ethereum%E4%B8%ADp2p-rlpx%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[rlpx是一种传输协议，它是基于tcp的，用于节点之间的信息，rlpx并不是什么的缩写，而是基于rlp序列化命名的。代码主要集中在p2p包的rlpx.go中，以太坊主要借助这个协议进行节点间数据传输，所传输的数据也是加密的 ECIES加密ECIES全称Elliptic Curve Integrated Encryption Scheme，即椭圆曲线集成加密方案，是一种混合加密方法。 假设Alice要发发送一条加密消息给Bob，Alice知晓Bob的公钥KB（后文中||符号表示简单的拼接,如a||b=ab）。为了加密消息m，Alice进行如下流程： 首先生成一个随机数r，然后生成公钥R=r*G。 计算出共享秘密S = Px。其中（Px，Py）= r*KB。 得到S后，计算kE || kM = KDF(S,32)（KDF是密钥生成函数，见文档5.8节）。 随机生成一个初始化向量iv。 最后发送给Bob的消息为：R || iv || c || d，其中c为以kE为密钥，以iv为初始化向量对m进行AES的CTR模式加密（CTR模式,AES加密）；d为以kM为密钥，使用SHA-256作为摘要函数，对iv||c计算HMAC（HMAC） Bob在收到消息后，进行如下步骤： 计算共享秘密S，S=Px，其中（Px，Py） = kB*R（注意kB是Bob私钥，KB是Bob公钥，利用的椭圆曲线加密原理，简单证明如下：kB*R = kB*r*G=r*KB =（Px，Py）） 根据共享秘密S计算出密钥：kE || kM = KDF(S,32) 先验证d，即对iv || c使用kM作为密钥计算HMAC 再利用kE作为密钥，以iv为初始化向量，使用AES算法的CTR模式进行解密得到明文m 上述步骤的大致思想就是利用非对称加密算法安全的交换密钥，在使用对称加密算法加密消息，弥补非对称算法的性能缺陷。 握手协议 发起者尝试连接接受者，并发送auth消息 接受者验证auth消息 接受者构造应答auth-ack消息 接受者计算共享秘密，发送第一个加密消息：hello 发起者收到auth-ack消息并计算共享秘密 发起者发送它的第一个加密消息：hello 双方验证各自收到的对方第一个加密消息 若有效，则加密握手完成 auth消息如下：123456auth = auth-size || enc-auth-bodyauth-size：enc-auth-body的长度enc-auth-body = ecies.encrypt(recipient-pubk, auth-body || auth-padding, auth-size) #auth-size不会被写入密文但是会写入HMACauth-padding ：任意填充数据auth-body = [sig, initiator-pubk, initiator-nonce, auth-vsn, ...]auth-vsn = 4 auth-ack消息如下：123456ack = ack-size || enc-ack-bodyack-size = enc-ack-body的长度enc-ack-body = ecies.encrypt(initiator-pubk, ack-body || ack-padding, ack-size)ack-padding ：任意填充数据ack-body = [recipient-ephemeral-pubk, recipient-nonce, ack-vsn, ...]ack-vsn = 4 几个秘密生成算法： 静态共享秘密：static-shared-secret = ecdh.agree(privkey, remote-pubk)。ecdh是一种基于ecc的密钥协商算法 临时密钥: ephemeral-key = ecdh.agree(ephemeral-privkey, remote-ephemeral-pubk) 共享秘密：shared-secret = keccak256(ephemeral-key || keccak256(nonce || initiator-nonce)) aes密钥：aes-secret = keccak256(ephemeral-key || shared-secret) mac密钥：mac-secret = keccak256(ephemeral-key || aes-secret) 帧握手成功之后所有消息都是以帧的形式传播。帧的目的是在一个连接上复用多个功能。其次，由于框架型的消息为消息身份验证提供了合理的分界点，因此加密和身份验证流变得非常简单。帧通过在握手过程中生成的密钥进行加密和身份验证。 帧格式如下：123456789frame = header-ciphertext || header-mac || frame-ciphertext || frame-macheader-ciphertext = aes(aes-secret, header)header = frame-size || header-data || header-paddingheader-data = [capability-id, context-id]capability-id = integer, always zerocontext-id = integer, always zeroheader-padding = zero-fill header to 16-byte boundaryframe-ciphertext = aes(aes-secret, frame-data || frame-padding)frame-padding = zero-fill frame-data to 16-byte boundary MAC就是所谓的消息认证码，rlpx中使用keccak256作为hash函数，并且使用了两个不同的mac用作不同方向的通信，分别是egress-mac和ingress-mac。这两个mac会在通信中不断更新，其构造如下 发送方初始状态：12egress-mac = keccak256.init((mac-secret ^ recipient-nonce) || auth)ingress-mac = keccak256.init((mac-secret ^ initiator-nonce) || ack) 接收方初始状态：12egress-mac = keccak256.init((mac-secret ^ initiator-nonce) || ack)ingress-mac = keccak256.init((mac-secret ^ recipient-nonce) || auth) 当帧发送时，要根据发送的数据更新egress-mac：123header-mac-seed = aes(mac-secret, keccak256.digest(egress-mac)[:16] ^ header-ciphertext)egress-mac = keccak256.update(egress-mac, header-mac-seed)header-mac = keccak256.digest(egress-mac)[:16] 帧mac的计算如下：1234egress-mac = keccak256.update(egress-mac, frame-ciphertext)frame-mac-seed = aes(mac-secret, keccak256.digest(egress-mac)[:16]) ^ keccak256.digest(egress-mac)[:16]egress-mac = keccak256.update(egress-mac, frame-mac-seed)frame-mac = keccak256.digest(egress-mac)[:16] 接收方收到后，以同样方式更新ingress-mac，通过对比来判断通信完整性。 源码首先回顾一下rlpx的服务中的创建：123456789101112131415newTransport func(net.Conn) transportsrv.newTransport = newRLPXfunc newRLPX(fd net.Conn) transport &#123; fd.SetDeadline(time.Now().Add(handshakeTimeout)) return &amp;rlpx&#123;fd: fd&#125;&#125;type rlpx struct &#123; fd net.Conn rmu, wmu sync.Mutex rw *rlpxFrameRW&#125; rlpx之所以能被赋值给newTransport是因为他实现了transport接口：123456789101112131415161718192021type transport interface &#123; doEncHandshake(prv *ecdsa.PrivateKey, dialDest *ecdsa.PublicKey) (*ecdsa.PublicKey, error) doProtoHandshake(our *protoHandshake) (*protoHandshake, error) MsgReadWriter close(err error)&#125;type MsgReadWriter interface &#123; MsgReader MsgWriter&#125;type MsgReader interface &#123; ReadMsg() (Msg, error)&#125;type MsgWriter interface &#123; WriteMsg(Msg) error&#125; doEncHandshake在服务的启动中配置tcp连接时，每接到一个tcp连接，在setupConn中调用了doEncHandshake执行加密握手：123456789101112131415161718func (t *rlpx) doEncHandshake(prv *ecdsa.PrivateKey, dial *ecdsa.PublicKey) (*ecdsa.PublicKey, error) &#123; var ( sec secrets err error ) if dial == nil &#123; sec, err = receiverEncHandshake(t.fd, prv) &#125; else &#123; sec, err = initiatorEncHandshake(t.fd, prv, dial) &#125; if err != nil &#123; return nil, err &#125; t.wmu.Lock() t.rw = newRLPXFrameRW(t.fd, sec) t.wmu.Unlock() return sec.Remote.ExportECDSA(), nil&#125; 当收到一个连接时，dial为null，调用receiverEncHandshake，当发起一个连接时调用initiatorEncHandshake。先看发起一个连接：123456789101112131415161718192021222324func initiatorEncHandshake(conn io.ReadWriter, prv *ecdsa.PrivateKey, remote *ecdsa.PublicKey) (s secrets, err error) &#123; h := &amp;encHandshake&#123;initiator: true, remote: ecies.ImportECDSAPublic(remote)&#125; authMsg, err := h.makeAuthMsg(prv) if err != nil &#123; return s, err &#125; authPacket, err := sealEIP8(authMsg, h) if err != nil &#123; return s, err &#125; if _, err = conn.Write(authPacket); err != nil &#123; return s, err &#125; authRespMsg := new(authRespV4) authRespPacket, err := readHandshakeMsg(authRespMsg, encAuthRespLen, prv, conn) if err != nil &#123; return s, err &#125; if err := h.handleAuthResp(authRespMsg); err != nil &#123; return s, err &#125; return h.secrets(authPacket, authRespPacket)&#125; 首先初始化encHandshake，并用其构造一个auth消息：12345678910111213141516171819202122232425262728293031func (h *encHandshake) makeAuthMsg(prv *ecdsa.PrivateKey) (*authMsgV4, error) &#123; h.initNonce = make([]byte, shaLen) _, err := rand.Read(h.initNonce) if err != nil &#123; return nil, err &#125; h.randomPrivKey, err = ecies.GenerateKey(rand.Reader, crypto.S256(), nil) if err != nil &#123; return nil, err &#125; token, err := h.staticSharedSecret(prv) if err != nil &#123; return nil, err &#125; signed := xor(token, h.initNonce) signature, err := crypto.Sign(signed, h.randomPrivKey.ExportECDSA()) if err != nil &#123; return nil, err &#125; msg := new(authMsgV4) copy(msg.Signature[:], signature) copy(msg.InitiatorPubkey[:], crypto.FromECDSAPub(&amp;prv.PublicKey)[1:]) copy(msg.Nonce[:], h.initNonce) msg.Version = 4 return msg, nil&#125; 首先随机一个随机数，长度32字节。然后构造一对秘钥用于ECDH，然后计算静态共享秘钥（使用自己私钥和对方公钥，按照ECDH算法）。接着将共享秘钥和自己的随机数异或，并将结果用ecc算法签名。字后构造出auth消息，包含签名值，自己的公钥，自己的随机数，以及版本号。 生成auth消息后，按EIP8协议进行封装1234567891011121314func sealEIP8(msg interface&#123;&#125;, h *encHandshake) ([]byte, error) &#123; buf := new(bytes.Buffer) if err := rlp.Encode(buf, msg); err != nil &#123; return nil, err &#125; pad := padSpace[:mrand.Intn(len(padSpace)-100)+100] buf.Write(pad) prefix := make([]byte, 2) binary.BigEndian.PutUint16(prefix, uint16(buf.Len()+eciesOverhead)) enc, err := ecies.Encrypt(rand.Reader, h.remote, buf.Bytes(), nil, prefix) return append(prefix, enc...), err&#125; 可见先进行rlp编码，然后进行填充随机长度的内容（最少100字节），然后计算长度前缀，前缀表示长度，包含填充后内容长度以及加上公钥初始化向量及MAC消息后的总长度。最后对内容进行加密（加密流程见前文ECIES加密），最后在头部补上前缀得到最后封装数据。 继续回到initiatorEncHandshake一切消息准备完毕后，通过连接发送握手包，下面我们分析收到一个握手请求时的逻辑。 同样还是doEncHandshake，收到一个连接请求时，也就是加密握手包，此时dial为空，执行receiverEncHandshake：1234567891011121314151617181920212223242526272829func receiverEncHandshake(conn io.ReadWriter, prv *ecdsa.PrivateKey) (s secrets, err error) &#123; authMsg := new(authMsgV4) authPacket, err := readHandshakeMsg(authMsg, encAuthMsgLen, prv, conn) if err != nil &#123; return s, err &#125; h := new(encHandshake) if err := h.handleAuthMsg(authMsg, prv); err != nil &#123; return s, err &#125; authRespMsg, err := h.makeAuthResp() if err != nil &#123; return s, err &#125; var authRespPacket []byte if authMsg.gotPlain &#123; authRespPacket, err = authRespMsg.sealPlain(h) &#125; else &#123; authRespPacket, err = sealEIP8(authRespMsg, h) &#125; if err != nil &#123; return s, err &#125; if _, err = conn.Write(authRespPacket); err != nil &#123; return s, err &#125; return h.secrets(authPacket, authRespPacket)&#125; 这个方法表示接受到一个加密握手，首先调用readHandshakeMsg读取信息：这里会尝试用两种标准进行解码，一种是我们前面讲的对握手包进行了加密，这里直接尝试解密，否则进行其他尝试，具体就不细讲了，最后返回所读到的信息，同时解码authMsg。 然后创建了一个encHandshake对象，执行handleAuthMsg方法：123456789101112131415161718192021222324252627func (h *encHandshake) handleAuthMsg(msg *authMsgV4, prv *ecdsa.PrivateKey) error &#123; rpub, err := importPublicKey(msg.InitiatorPubkey[:]) if err != nil &#123; return err &#125; h.initNonce = msg.Nonce[:] h.remote = rpub if h.randomPrivKey == nil &#123; h.randomPrivKey, err = ecies.GenerateKey(rand.Reader, crypto.S256(), nil) if err != nil &#123; return err &#125; &#125; token, err := h.staticSharedSecret(prv) if err != nil &#123; return err &#125; signedMsg := xor(token, h.initNonce) remoteRandomPub, err := secp256k1.RecoverPubkey(signedMsg, msg.Signature[:]) if err != nil &#123; return err &#125; h.remoteRandomPub, _ = importPublicKey(remoteRandomPub) return nil&#125; 这个方法是用来处理发起方发送的auth消息。获取读取了发起方的公钥、随机数，同时自己也生成了随机的密钥对用于ECDH，之后利用自己密钥和远端公钥生成静态共享秘密，并利用该结果与对方的随机数异或，然后验证签名并得到远端随机公钥 处理完远端的消息收，开始构造响应：123456789101112func (h *encHandshake) makeAuthResp() (msg *authRespV4, err error) &#123; h.respNonce = make([]byte, shaLen) if _, err = rand.Read(h.respNonce); err != nil &#123; return nil, err &#125; msg = new(authRespV4) copy(msg.Nonce[:], h.respNonce) copy(msg.RandomPubkey[:], exportPubkey(&amp;h.randomPrivKey.PublicKey)) msg.Version = 4 return msg, nil&#125; 响应主要包含自己的随机数，自己的随机公钥和版本号。然后对消息进行封装，根据最新版本调用的是sealEIP8方法，前文已进行过分析。封装后发送给发起人。此时对于接收方握手已经完成，可以构造秘密：12345678910111213141516171819202122232425262728func (h *encHandshake) secrets(auth, authResp []byte) (secrets, error) &#123; ecdheSecret, err := h.randomPrivKey.GenerateShared(h.remoteRandomPub, sskLen, sskLen) if err != nil &#123; return secrets&#123;&#125;, err &#125; sharedSecret := crypto.Keccak256(ecdheSecret, crypto.Keccak256(h.respNonce, h.initNonce)) aesSecret := crypto.Keccak256(ecdheSecret, sharedSecret) s := secrets&#123; Remote: h.remote, AES: aesSecret, MAC: crypto.Keccak256(ecdheSecret, aesSecret), &#125; mac1 := sha3.NewLegacyKeccak256() mac1.Write(xor(s.MAC, h.respNonce)) mac1.Write(auth) mac2 := sha3.NewLegacyKeccak256() mac2.Write(xor(s.MAC, h.initNonce)) mac2.Write(authResp) if h.initiator &#123; s.EgressMAC, s.IngressMAC = mac1, mac2 &#125; else &#123; s.EgressMAC, s.IngressMAC = mac2, mac1 &#125; return s, nil&#125; 首先利用自己的随机私钥和远端的随机公钥生成共享秘密。然后利用该秘密和双方的随机数生成最终共享秘密。利用共享秘密和最终共享秘密生成aes秘密，再利用aes秘密个共享秘密生成mac秘密，最后远端公钥和aes、mac秘密构成一个主秘密。最后如前文介绍额方法配置EgressMAC和IngressMAC 在接收方发送完响应后，再回到发起人的角度，在initiatorEncHandshake方法中readHandshakeMsg方法读到一个响应，这个逻辑不在重复，之后处理这个响应：12345func (h *encHandshake) handleAuthResp(msg *authRespV4) (err error) &#123; h.respNonce = msg.Nonce[:] h.remoteRandomPub, err = importPublicKey(msg.RandomPubkey[:]) return err&#125; 很简单就是获取对方的随机数和随机公钥，到这里加密握手，实际上是密钥交换的所有信息都交换完毕，双方知晓对方的随机数和随机公钥，可以独立的构建主秘密，所以在initiatorEncHandshake最后发起人也调用secrets构建了主秘密。 最后回到doEncHandshake，在生成主秘密后，构建了rlpx帧的读写器，主要是构造了用于aes和hamc的加密器（都是ctr模式，初始化向量全为0），最后构造了rlpxFrameRW对象。最后将远端公钥返回。 前面握手协议已经完成，中间涉及了许多秘密和密钥，我们这里来梳理一下： 静态共享秘密：利用的是自己的私钥和对方的公钥生成，二者按照ECDH算法计算后结果一致，由于用的是自己固定的密钥对，无论在何时这个秘密都是固定的，所以称为静态共享秘密，它的作用是与随机数进行异或后进行签名，进行身份认证，因为只有是公钥对应的私钥的持有人才能计算出和发起方一致的秘密。 随机密钥：在握手时双方都会生成一对随机密钥，用于后续通信的加密。 共享秘密：和静态共享秘密类似，只不过是用双方随机生成的密钥对按照ECDH算法生成，这样保证了即使密钥泄漏，也只影响本次通信。 最终共享秘密：为了保证密钥的随机性，现将二者随机数拼接后进行摘要，然后将结果与共享秘密拼接后再进行摘要得到最终秘密。 在发起人对消息加密时，按照的就是前文ecies的流程，通过对方公钥与自己一个随机数生成秘密S，再利用KDF函数生成AES和HMAC要用的密钥。当然为了保护自己的随机数，发起方随机生成了一对密钥，并将公钥发送，用于对方计算S 总结一下加密握手，实际上就是密钥交换，为了构建通信时的密钥，需要知道对方的随机公钥和随机数。最开始发起人只知道接受者的公钥，所以根据ECIES算法传递了自己的随机公钥和随机数，接收方收到之后自己也生成了随机公钥的随机数，测试接收方以及能构建主秘密，发起人收到响应后，根据接收方的随机公钥的随机数同样也能构建一样的主秘密。 doProtoHandshake在p2p服务的start逻辑中，紧随加密握手之后进行了协议握手123456789101112131415func (t *rlpx) doProtoHandshake(our *protoHandshake) (their *protoHandshake, err error) &#123; werr := make(chan error, 1) go func() &#123; werr &lt;- Send(t.rw, handshakeMsg, our) &#125;() if their, err = readProtocolHandshake(t.rw, our); err != nil &#123; &lt;-werr // make sure the write terminates too return nil, err &#125; if err := &lt;-werr; err != nil &#123; return nil, fmt.Errorf("write error: %v", err) &#125; t.rw.snappy = their.Version &gt;= snappyProtocolVersion return their, nil&#125; 传入的对象是protoHandshake，在sserver的etupLocalNode方法中构建了该对象，存储了自己的协议版本，服务名，ID和自己所有协议信息。在doProtoHandshake中首先调用了Send方法进行发送1234567func Send(w MsgWriter, msgcode uint64, data interface&#123;&#125;) error &#123; size, r, err := rlp.EncodeToReader(data) if err != nil &#123; return err &#125; return w.WriteMsg(Msg&#123;Code: msgcode, Size: uint32(size), Payload: r&#125;)&#125; 首先用rlp进行编码，然后将消息码（握手消息代码为0），消息长度和消息内容封装，并用MsgWriter的WriteMsg进行发送。MsgWriter是一个接口，在doProtoHandshake实际的执行者是rlpxFrameRW，即在加密握手最后构造的对象，它的WriteMsg实现如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546func (rw *rlpxFrameRW) WriteMsg(msg Msg) error &#123; ptype, _ := rlp.EncodeToBytes(msg.Code) if rw.snappy &#123; if msg.Size &gt; maxUint24 &#123; return errPlainMessageTooLarge &#125; payload, _ := ioutil.ReadAll(msg.Payload) payload = snappy.Encode(nil, payload) msg.Payload = bytes.NewReader(payload) msg.Size = uint32(len(payload)) &#125; headbuf := make([]byte, 32) fsize := uint32(len(ptype)) + msg.Size if fsize &gt; maxUint24 &#123; return errors.New("message size overflows uint24") &#125; putInt24(fsize, headbuf) // TODO: check overflow copy(headbuf[3:], zeroHeader) rw.enc.XORKeyStream(headbuf[:16], headbuf[:16]) // first half is now encrypted copy(headbuf[16:], updateMAC(rw.egressMAC, rw.macCipher, headbuf[:16])) if _, err := rw.conn.Write(headbuf); err != nil &#123; return err &#125; tee := cipher.StreamWriter&#123;S: rw.enc, W: io.MultiWriter(rw.conn, rw.egressMAC)&#125; if _, err := tee.Write(ptype); err != nil &#123; return err &#125; if _, err := io.Copy(tee, msg.Payload); err != nil &#123; return err &#125; if padding := fsize % 16; padding &gt; 0 &#123; if _, err := tee.Write(zero16[:16-padding]); err != nil &#123; return err &#125; &#125; fmacseed := rw.egressMAC.Sum(nil) mac := updateMAC(rw.egressMAC, rw.macCipher, fmacseed) _, err := rw.conn.Write(mac) return err&#125; 第一步是对msg的code字段进行rlp编码，之后如果压缩可用的话对消息进行压缩，然后更新message的内容和大小。 接下来是头部的构造。首先计算帧大小，包括刚才编码的code字段长度和msg的大小，不过最大长度不能大于^uint32(0) &gt;&gt; 8 (即2^24 - 1)。接下来用3个字节存储长度(大端模式)，之后填充{0xC2, 0x80, 0x80}这3个字节。之后对前16个字节进行加密（注意XORKeyStream就是aes的ctr模式加密算法） 再往下是写入头的消息认证码，调用updateMAC方法123456789func updateMAC(mac hash.Hash, block cipher.Block, seed []byte) []byte &#123; aesbuf := make([]byte, aes.BlockSize) block.Encrypt(aesbuf, mac.Sum(nil)) for i := range aesbuf &#123; aesbuf[i] ^= seed[i] &#125; mac.Write(aesbuf) return mac.Sum(nil)[:16]&#125; updateMAC就和前文mac那一节中介绍的一样。会多次用到，这里需要三个参数，第一个是要更新的hash，第二个是加密方法，第三个是种子。首先对hash中当前数据计算hash值然后进行加密，接下来把加密值与种子逐字节的异或，并将结果写入hash，更新完毕，同时计算并返回更新后的hash值。这这段代码中，要更新的是egressMAC，种子是刚才加密过的头数据。 回到WriteMsg中，将返回的hash值从headbuf的第16字节开始写入。到这里头部构造完成，是根据前文帧的定义包含了头部数据密文及头部数据hash。然后通过conn的write发送出去。conn就是最初构造rlpx传入的网络连接。 接下来开始处理帧主体内容，先是构造了StreamWriter，所有传入的数据都会被加密处理，它的writer是一个MultiWriter，包含了conn和egressMAC两个写对象，表示同一份数据会被两个对象同时写。接下来首先写入ptype也就是经rlp编码过msg.Code，之后写入msg的Payload就是帧内容。最后写入填充内容，保证数据是16的整数倍，填充的内容全为0。之后又进行了一次mac更新，依旧是更新egressMAC。种子是刚才持续写入数据后计算出的hash值。最后利用刚才网络通道将mac值发送出去。 上面几步就完成了前文帧定义中的几部分数据的构造与发送。再回到doProtoHandshake中，由于发送时异步进行的，在发送同时进行了readProtocolHandshake操作12345678910111213141516171819202122232425func readProtocolHandshake(rw MsgReader, our *protoHandshake) (*protoHandshake, error) &#123; msg, err := rw.ReadMsg() if err != nil &#123; return nil, err &#125; if msg.Size &gt; baseProtocolMaxMsgSize &#123; return nil, fmt.Errorf("message too big") &#125; if msg.Code == discMsg &#123; var reason [1]DiscReason rlp.Decode(msg.Payload, &amp;reason) return nil, reason[0] &#125; if msg.Code != handshakeMsg &#123; return nil, fmt.Errorf("expected handshake, got %x", msg.Code) &#125; var hs protoHandshake if err := msg.Decode(&amp;hs); err != nil &#123; return nil, err &#125; if len(hs.ID) != 64 || !bitutil.TestBytes(hs.ID) &#123; return nil, DiscInvalidIdentity &#125; return &amp;hs, nil&#125; 这是读取对方的握手包。首先调用ReadMsg读取信息，依旧用的是rlpxFrameRW的ReadMsg方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func (rw *rlpxFrameRW) ReadMsg() (msg Msg, err error) &#123; headbuf := make([]byte, 32) if _, err := io.ReadFull(rw.conn, headbuf); err != nil &#123; return msg, err &#125; shouldMAC := updateMAC(rw.ingressMAC, rw.macCipher, headbuf[:16]) if !hmac.Equal(shouldMAC, headbuf[16:]) &#123; return msg, errors.New("bad header MAC") &#125; rw.dec.XORKeyStream(headbuf[:16], headbuf[:16]) // first half is now decrypted fsize := readInt24(headbuf) var rsize = fsize if padding := fsize % 16; padding &gt; 0 &#123; rsize += 16 - padding &#125; framebuf := make([]byte, rsize) if _, err := io.ReadFull(rw.conn, framebuf); err != nil &#123; return msg, err &#125; rw.ingressMAC.Write(framebuf) fmacseed := rw.ingressMAC.Sum(nil) if _, err := io.ReadFull(rw.conn, headbuf[:16]); err != nil &#123; return msg, err &#125; shouldMAC = updateMAC(rw.ingressMAC, rw.macCipher, fmacseed) if !hmac.Equal(shouldMAC, headbuf[:16]) &#123; return msg, errors.New("bad frame MAC") &#125; rw.dec.XORKeyStream(framebuf, framebuf) content := bytes.NewReader(framebuf[:fsize]) if err := rlp.Decode(content, &amp;msg.Code); err != nil &#123; return msg, err &#125; msg.Size = uint32(content.Len()) msg.Payload = content if rw.snappy &#123; payload, err := ioutil.ReadAll(msg.Payload) if err != nil &#123; return msg, err &#125; size, err := snappy.DecodedLen(payload) if err != nil &#123; return msg, err &#125; if size &gt; int(maxUint24) &#123; return msg, errPlainMessageTooLarge &#125; payload, err = snappy.Decode(nil, payload) if err != nil &#123; return msg, err &#125; msg.Size, msg.Payload = uint32(size), bytes.NewReader(payload) &#125; return msg, nil&#125; 第一步先从流中读取32字节，就是头部数据，根据刚才发送数据的分析，包括16字节的加密信息和16字节的mac。读取后根据以前16字节信息为种子更新ingressMAC验证数据时候有误，无误的话对前16字节解密，同时读取前3字节信息，还原出长度信息。由于填充的存在还要计算出发送方填充了多少数据，计算出实际长度。下面就从流中读取帧主体信息。同样也将信息写入ingressMAC，并计算出hash值后作为种子更新一次ingressMAC，与数据流的最后16字节也就是帧mac进行对比看数据是否被篡改。确认无误后解密数据。在去除填充数据后，先解码出code信息，然后填充msg其他字段，另外如果压缩可用的话，还要进行解压操作。最后返回message对象。 读取出正确的msg后，回到readProtocolHandshake中，下面就是根据不同的code执行不同的逻辑。这里进区分了为discMsg，不为handshakeMsg以及其他（就是code是handshakeMsg）的情况。我们先看是handshakeMsg的情况，就是刚才我们分析的发送代码发送的code。第一步当然是解码消息，获得protoHandshake对象，进行简单的检查后返回。这一步是获得了对象p2p所有协议的信息。 在回到doProtoHandshake中，读取到信息后，如果没有错误，则等待Send的完成，如果发送也没有错误，则配置一下snappy，条件就是对方的版本大于5，如果成立以后的信息都会进行压缩。最后返回对方的握手信息，逻辑又回到p2p的server中。这样协议握手也完成了。 在rlpx中也提供了ReadMsg和WriteMsg方法，不过具体实现也是直接调用rlpxFrameRW的读写，前面已经分析过了这里不再重复。 题图来自unsplash：https://unsplash.com/photos/ZIlG-_lwXbg]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中p2p-discover源码学习]]></title>
    <url>%2F2019%2F04%2F15%2Fgo-ethereum%E4%B8%ADp2p-discover%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[区块链系统就是一个基于P2P网络的系统，这里先来学习一下以太坊的P2P网络实现。P2P网络运作的第一个要求就是节点之间能互相发现，这里以太坊用到了一个名为Kademlia的协议算法，这里来梳理一下ethereum P2P的discover实现 Kademlia协议这个协议是2002年美国纽约大学Petar Maymounkov和David Mazières发表的一篇论文中所介绍的，该论文的核心部分翻译见这里,下面我们就来详细介绍一下这个协议 概述Kademlia规定了网络的结构，也规定了通过节点查询进行信息交换的方式。Kademlia网络节点之间使用UDP进行通讯。参与通讯的所有节点形成一张虚拟网（或者叫做覆盖网）。这些节点通过一组数字（或称为节点ID）来进行身份标识。节点ID不仅可以用来做身份标识，还可以用来进行值定位（标识这哪些节点存储哪些资源）。 当进行节点搜索时，Kademlia算法需要知道与这些值相关的键，然后分步在网络中开始搜索，每一步都会找到一些节点，这些节点的ID与键更为接近，如果有节点直接返回搜索的值或者再也无法找到与键更为接近的节点ID的时候搜索便会停止。这种搜索值的方法是非常高效的：与其他的分布式散列表的实现类似，在一个包含n个节点的系统的值的搜索中，Kademlia仅访问O(log(n))个节点。 节点Kademlia定义每个节点都以一个随机的ID，文中定义有160位，不必确保两个节点ID有什么联系，唯一需要做的足够随机。 距离度量Kademlia定义两个节点的距离为两个节点ID异或的结果。如节点A为010101，节点B为110001，二者异或的100100，转换为十进制就是36，则二者之间的距离就是36。关于选择异或作为距离的度量，作者表示有一些几个特点： 一个节点到自己的距离为0，即d(x,x) = 0 从A到B与从B到A的距离相等，即d(x,y) = d(y,x) 满足三角不等式：d(x,z) = d(x,y) XOR d(y,z),而a+b&gt;a XOR b 有了这三点，就足以证明异或算法也可以作为距离度量的标准，更重要的是异或计算非常高效。实际上用异或计算距离，更重要的是给出了一个节点分类的标准，类似于显示生活根据距离分类一样，便于通过一个ID搜索一个节点，也就是节点发现 K桶文章提出了一个K桶的概念，实际上就是一个列表，如果ID有160位，那么一个节点就有160个所谓K桶，第i个桶保存着距离自己[2^i,2^i+1)范围内的节点，当寻找一个节点时，就从相应范围内的列表去搜索，k是一个列表的最大长度，如20。可知i越大，区间范围越大，里面的节点数可能越多。离自己越近的k桶内所记录的节点数虽然越少，但命中率越高。所以进行节点搜索是去寻找目标节点距离附近的节点，在进一步迭代，就能很快找到所需节点。 K桶使用一种类似于最近最久未使用的淘汰算法，当新节点被探知时，如果所在k桶未满，则直接在队尾插入，如果已满，则ping队头节点，如果节点不在线，则移除，把新节点插到队尾，如果队头节点在线，则从队头移到队尾，新节点被抛弃 RPC消息Kademlia是利用一系列RPC消息来维护网络的 PING主要作用是探测一个节点是否仍在线 STORE通知一个节点存储一个键值对 FIND_NODE节点定位。计算距离，寻找对应区间的k桶，选择一些节点发送消息，返回这些节点所知的距离目标节点更近的节点，然后对这些节点再次发送消息，多次迭代，最后定位到节点。 FIND_VALUE定位资源。类似于FIND_NODE，返回的是节点的信息，如IP地址，udp端口即节点ID。 加入网络要加入一个P2P首先必须要与一个网络内的节点建立通信，之后新节点进行自我定位，通过这种方法其他节点可以更新自己的k桶，新节点也可以获得网络信息。 其他还有一些详细的协议规范请参考论文。 源码分析go-ethereum的p2p实现源码主要集中在p2p目录下，该目录下的discover主要实现了节点方法算法，本文主要来梳理这一部分源码 table.go在源码中table就是Kademlia的主要实现地方，先看常量和结构体123456789101112131415161718192021222324252627282930313233343536373839404142const ( alpha = 3 // Kademlia concurrency factor bucketSize = 16 // Kademlia bucket size maxReplacements = 10 // Size of per-bucket replacement list // We keep buckets for the upper 1/15 of distances because // it's very unlikely we'll ever encounter a node that's closer. hashBits = len(common.Hash&#123;&#125;) * 8 nBuckets = hashBits / 15 // Number of buckets bucketMinDistance = hashBits - nBuckets // Log distance of closest bucket // IP address limits. bucketIPLimit, bucketSubnet = 2, 24 // at most 2 addresses from the same /24 tableIPLimit, tableSubnet = 10, 24 maxFindnodeFailures = 5 // Nodes exceeding this limit are dropped refreshInterval = 30 * time.Minute revalidateInterval = 10 * time.Second copyNodesInterval = 30 * time.Second seedMinTableTime = 5 * time.Minute seedCount = 30 seedMaxAge = 5 * 24 * time.Hour)type Table struct &#123; mutex sync.Mutex // protects buckets, bucket content, nursery, rand buckets [nBuckets]*bucket // index of known nodes by distance nursery []*node // bootstrap nodes rand *mrand.Rand // source of randomness, periodically reseeded ips netutil.DistinctNetSet db *enode.DB // database of known nodes net transport refreshReq chan chan struct&#123;&#125; initDone chan struct&#123;&#125; closeOnce sync.Once closeReq chan struct&#123;&#125; closed chan struct&#123;&#125; nodeAddedHook func(*node) // for testing&#125; 首先常量中定义了一些Kademlia协议中的一些值，如k桶容量也就是k等于16，每次查找的节点为3，k桶置换表大小为10。有一点和协议不同的是，这里定义k桶的数量为hash长度的15分之一，没有像协议中定义有hash有多长就有多少个k桶。另外还有超时重试次数，刷新间隔等定义。 table中维护了一组k桶实例，一组bootstrap节点，还有数据库等辅助参数。我们看k桶的定义12345type bucket struct &#123; entries []*node replacements []*node ips netutil.DistinctNetSet&#125; 和协议中定义的类似，一组节点和一组置换节点。下面看初始化代码1234567891011121314151617181920212223242526272829303132333435func newTable(t transport, db *enode.DB, bootnodes []*enode.Node) (*Table, error) &#123; tab := &amp;Table&#123; net: t, db: db, refreshReq: make(chan chan struct&#123;&#125;), initDone: make(chan struct&#123;&#125;), closeReq: make(chan struct&#123;&#125;), closed: make(chan struct&#123;&#125;), rand: mrand.New(mrand.NewSource(0)), ips: netutil.DistinctNetSet&#123;Subnet: tableSubnet, Limit: tableIPLimit&#125;, &#125; if err := tab.setFallbackNodes(bootnodes); err != nil &#123; return nil, err &#125; for i := range tab.buckets &#123; tab.buckets[i] = &amp;bucket&#123; ips: netutil.DistinctNetSet&#123;Subnet: bucketSubnet, Limit: bucketIPLimit&#125;, &#125; &#125; tab.seedRand() tab.loadSeedNodes() go tab.loop() return tab, nil&#125;func (tab *Table) setFallbackNodes(nodes []*enode.Node) error &#123; for _, n := range nodes &#123; if err := n.ValidateComplete(); err != nil &#123; return fmt.Errorf("bad bootstrap node %q: %v", n, err) &#125; &#125; tab.nursery = wrapNodes(nodes) return nil&#125; 首先初始化一个table实例，然后调用setFallbackNodes初始化连接节点。在setFallbackNodes中先检查所有节点是否有效，接下来的wrapNodes方法主要是将enode.Node类型对象包装为discover包内的node对象。 在setFallbackNodes方法中table的bootstrap被设置完成之后，接下来的一个遍历是用来初始化所有k桶。 再往下，tab.seedRand()方法先用crypto/rand中的Read随机生成一个长度为8的byte数组，并用该数组生成一个64位int类型数去作为rand的种子。接下来loadSeedNodes实现如下12345678910func (tab *Table) loadSeedNodes() &#123; seeds := wrapNodes(tab.db.QuerySeeds(seedCount, seedMaxAge)) seeds = append(seeds, tab.nursery...) for i := range seeds &#123; seed := seeds[i] age := log.Lazy&#123;Fn: func() interface&#123;&#125; &#123; return time.Since(tab.db.LastPongReceived(seed.ID(), seed.IP())) &#125;&#125; log.Trace("Found seed node in database", "id", seed.ID(), "addr", seed.addr(), "age", age) tab.addSeenNode(seed) &#125;&#125; 还是先用wrapNodes进行了一次包装，这次包装的对象来自于数据库，tab.db保存的是已知的节点，我们要查找的种子节点数量为30，种子节点最长寿命为5天（根据前面常量定义），QuerySeeds的逻辑也很简单，就是从数据库中随机查找，但是要过滤掉那些太老的节点，而且最后返回的节点数不超过30。接下来将数据库中返回的节点和前面的种子节点进行合并，开始遍历，遍历的目的是利用addSeenNode将节点添加到合适的桶中，既然要添加的合适的桶中，就要计算距离，我们来看看距离的计算1234567891011121314// go-ethereum\p2p\enode\node.gofunc LogDist(a, b ID) int &#123; lz := 0 //记录前导0数量 for i := range a &#123; x := a[i] ^ b[i] if x == 0 &#123; //结果为8表示全为零，就是8个前导零 lz += 8 &#125; else &#123; lz += bits.LeadingZeros(x) break &#125; &#125; return len(a)*8 - lz&#125; 其实严格来说，这里已经不叫距离计算，由于前面k桶数量并不是根据原始Kademlia协议中写的那样定义而是ID的比特数除以15，所以对应的距离计算也要改变，通过阅读代码，我们发现距离定义变为比特数减去两个ID对应字节异或后前导零的数量之和的差。根据距离选桶的实现如下1234567func (tab *Table) bucket(id enode.ID) *bucket &#123; d := enode.LogDist(tab.self().ID(), id) if d &lt;= bucketMinDistance &#123; return tab.buckets[0] &#125; return tab.buckets[d-bucketMinDistance-1]&#125; 其中最短距离bucketMinDistance = hashBits - nBuckets。为的是确保能找到一个合适的桶，避免差值过大。在回到addSeenNode，找的合适的桶时，先判断是否满了或已包含，来决定否添加，或是否添加到缓存表中。加载完种子节点之后，启动了一个goroutine运行loop，实现如下。12345678910111213141516171819func (tab *Table) loop() &#123; var ( revalidate = time.NewTimer(tab.nextRevalidateTime()) refresh = time.NewTicker(refreshInterval) copyNodes = time.NewTicker(copyNodesInterval) refreshDone = make(chan struct&#123;&#125;) // where doRefresh reports completion revalidateDone chan struct&#123;&#125; // where doRevalidate reports completion waiting = []chan struct&#123;&#125;&#123;tab.initDone&#125; // holds waiting callers while doRefresh runs ) defer refresh.Stop() defer revalidate.Stop() defer copyNodes.Stop() // Start initial refresh. go tab.doRefresh(refreshDone)loop: .....&#125; 首先初始化了几个定时器和几个channel。之后启动了一个goroutine执行初始化刷新。12345678910111213141516func (tab *Table) doRefresh(done chan struct&#123;&#125;) &#123; defer close(done) tab.loadSeedNodes() var key ecdsa.PublicKey if err := tab.self().Load((*enode.Secp256k1)(&amp;key)); err == nil &#123; tab.lookup(encodePubkey(&amp;key), false) &#125; for i := 0; i &lt; 3; i++ &#123; var target encPubkey crand.Read(target[:]) tab.lookup(target, false) &#125;&#125; 刷新操作中先加载了种子节点。之后执行了自我查找，就是查找自己，用的就是lookup，我们来看一下实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849func (tab *Table) lookup(targetKey encPubkey, refreshIfEmpty bool) []*node &#123; var ( target = enode.ID(crypto.Keccak256Hash(targetKey[:])) asked = make(map[enode.ID]bool) seen = make(map[enode.ID]bool) reply = make(chan []*node, alpha) pendingQueries = 0 result *nodesByDistance ) asked[tab.self().ID()] = true for &#123; tab.mutex.Lock() result = tab.closest(target, bucketSize) tab.mutex.Unlock() if len(result.entries) &gt; 0 || !refreshIfEmpty &#123; break &#125; &lt;-tab.refresh() refreshIfEmpty = false &#125; for &#123; for i := 0; i &lt; len(result.entries) &amp;&amp; pendingQueries &lt; alpha; i++ &#123; n := result.entries[i] if !asked[n.ID()] &#123; asked[n.ID()] = true pendingQueries++ go tab.findnode(n, targetKey, reply) &#125; &#125; if pendingQueries == 0 &#123; break &#125; select &#123; case nodes := &lt;-reply: for _, n := range nodes &#123; if n != nil &amp;&amp; !seen[n.ID()] &#123; seen[n.ID()] = true result.push(n, bucketSize) &#125; &#125; case &lt;-tab.closeReq: return nil &#125; pendingQueries-- &#125; return result.entries&#125; 首先定义了一系列变量，然后从k桶中取得离目标最近的几个节点，实现如下12345678910111213141516func (tab *Table) closest(target enode.ID, nresults int) *nodesByDistance &#123; close := &amp;nodesByDistance&#123;target: target&#125; for _, b := range &amp;tab.buckets &#123; for _, n := range b.entries &#123; if n.livenessChecks &gt; 0 &#123; close.push(n, nresults) &#125; &#125; &#125; return close&#125;type nodesByDistance struct &#123; entries []*node target enode.ID&#125; nodesByDistance类型存储着目标ID和一组距离目标较近的节点。实际上closest逻辑很简单，就是遍历所有桶内的节点，看是比已有的更近，判断是否添加的逻辑在push中：12345678910111213func (h *nodesByDistance) push(n *node, maxElems int) &#123; ix := sort.Search(len(h.entries), func(i int) bool &#123; return enode.DistCmp(h.target, h.entries[i].ID(), n.ID()) &gt; 0 &#125;) if len(h.entries) &lt; maxElems &#123; h.entries = append(h.entries, n) &#125; if ix == len(h.entries) &#123; &#125; else &#123; copy(h.entries[ix+1:], h.entries[ix:]) h.entries[ix] = n &#125;&#125; DistCmp是给a，b判断二者谁离目标更近， sort.Search则是得出给定的ID在entries的位置，如果最后ix排到末尾而且entries已满，说明这个点不比已有的点目标更近。继续回到lookup，找到一组离目标较近的节点后，在第二个循环体内，开始遍历这一组节点，对每个节点都执行findnode操作，但是最多每次并发执行alpha个，也就是3个。由于entries是有序的，所以前面的都是例目标最近的。下面看findnode操作：1234567891011121314151617181920212223func (tab *Table) findnode(n *node, targetKey encPubkey, reply chan&lt;- []*node) &#123; fails := tab.db.FindFails(n.ID(), n.IP()) r, err := tab.net.findnode(n.ID(), n.addr(), targetKey) if err == errClosed &#123; reply &lt;- nil return &#125; else if err != nil || len(r) == 0 &#123; fails++ tab.db.UpdateFindFails(n.ID(), n.IP(), fails) log.Trace("Findnode failed", "id", n.ID(), "failcount", fails, "err", err) if fails &gt;= maxFindnodeFailures &#123; log.Trace("Too many findnode failures, dropping", "id", n.ID(), "failcount", fails) tab.delete(n) &#125; &#125; else if fails &gt; 0 &#123; tab.db.UpdateFindFails(n.ID(), n.IP(), fails-1) &#125; for _, n := range r &#123; tab.addSeenNode(n) &#125; reply &lt;- r&#125; 实际上findnode的逻辑并不在这里，这里先不管后面再说，先知道findnode会返回一组离目标更近的node，否则返回一个错误。对于某个node当错误次数大于5次时就把它删除。而对于之前出错但这次成功的话，就将其累积出错次数减一。最后遍历返回的一组node，调用addSeenNode，这个方法在之前加载种子节点时出现，就是将节点添加到合适桶中。方法最后向reply中写入r。这样就回到lookup中，有一个select，当reply可以取值时，执行下面逻辑1234567case nodes := &lt;-reply: for _, n := range nodes &#123; if n != nil &amp;&amp; !seen[n.ID()] &#123; seen[n.ID()] = true result.push(n, bucketSize) &#125; &#125; 这里继续将新得到的node添加到有序的entries中，继续启动新一轮循环按照前面的逻辑继续查找。至于什么时候停止呢？在遍历entries时，对于每个node会判断是否访问过，对于访问过就不在进行findnode，当所有entries都被访问就意味着已经找不到离目标更近的节点了，这是for循环结束，pendingQueries为0，根据代码执行break退出外层循环，返回entries。这样lookup就执行完毕。代码返回到doRefresh中，在执行完初始的自我查找之后，开始了一个小循环，进行随机查找，只查找3个，每次产生一个随机的ID调用lookup进行查找，目的都是尽可能的完善桶。doRefresh结束后后回到loop中，由于doRefresh是一个单独的goroutine，loop主要循环在loop标签的代码中：1234567891011121314151617181920212223242526272829303132loop: for &#123; select &#123; case &lt;-refresh.C: tab.seedRand() if refreshDone == nil &#123; refreshDone = make(chan struct&#123;&#125;) go tab.doRefresh(refreshDone) &#125; case req := &lt;-tab.refreshReq: waiting = append(waiting, req) if refreshDone == nil &#123; refreshDone = make(chan struct&#123;&#125;) go tab.doRefresh(refreshDone) &#125; case &lt;-refreshDone: for _, ch := range waiting &#123; close(ch) &#125; waiting, refreshDone = nil, nil case &lt;-revalidate.C: revalidateDone = make(chan struct&#123;&#125;) go tab.doRevalidate(revalidateDone) case &lt;-revalidateDone: revalidate.Reset(tab.nextRevalidateTime()) revalidateDone = nil case &lt;-copyNodes.C: go tab.copyLiveNodes() case &lt;-tab.closeReq: break loop &#125; &#125; 可见还是一个同步代码。外层是一个无限循环，内存是一个select阻塞，根据不同的操作触发不同代码。首先是一个refresh定时器，每30分钟触发一次，调用doRefresh执行刷新。除了定时刷新还有主动刷新，使用的是refreshReq这个channel。另外还有一个revalidate定时器，它的时间不固定，随机从0到10秒内选一个时间，到时间后触发doRevalidate，逻辑如下：12345678910111213141516171819202122232425func (tab *Table) doRevalidate(done chan&lt;- struct&#123;&#125;) &#123; defer func() &#123; done &lt;- struct&#123;&#125;&#123;&#125; &#125;() last, bi := tab.nodeToRevalidate() if last == nil &#123; return &#125; err := tab.net.ping(last.ID(), last.addr()) tab.mutex.Lock() defer tab.mutex.Unlock() b := tab.buckets[bi] if err == nil &#123; last.livenessChecks++ log.Debug("Revalidated node", "b", bi, "id", last.ID(), "checks", last.livenessChecks) tab.bumpInBucket(b, last) return &#125; if r := tab.replace(b, last); r != nil &#123; log.Debug("Replaced dead node", "b", bi, "id", last.ID(), "ip", last.IP(), "checks", last.livenessChecks, "r", r.ID(), "rip", r.IP()) &#125; else &#123; log.Debug("Removed dead node", "b", bi, "id", last.ID(), "ip", last.IP(), "checks", last.livenessChecks) &#125;&#125; 这段代码主要逻辑是随机找一个非空的桶，取得其最后一个节点，然后去ping这个节点，看是否在线，如果在线将其移到桶的前部，否则从缓存节点找一个去替代这个节点。当操作结束后，重新设置revalidate时间，准备下一次随机验证。最后还有一个定时器copyNodesInterval，每30分钟触发一次，执行copyLiveNodes逻辑12345678910111213func (tab *Table) copyLiveNodes() &#123; tab.mutex.Lock() defer tab.mutex.Unlock() now := time.Now() for _, b := range &amp;tab.buckets &#123; for _, n := range b.entries &#123; if n.livenessChecks &gt; 0 &amp;&amp; now.Sub(n.addedAt) &gt;= seedMinTableTime &#123; tab.db.UpdateNode(unwrapNode(n)) &#125; &#125; &#125;&#125; 主要逻辑是，遍历所有节点，对存活检查过的，且添加时间大于5分钟的节点存入数据库，存储的内容是经过rlp编码的数据。再回到loop中，只剩下一个关闭请求的channel，用于退出loop。退出loop的逻辑也很简单，如下12345678910if refreshDone != nil &#123; &lt;-refreshDone&#125;for _, ch := range waiting &#123; close(ch)&#125;if revalidateDone != nil &#123; &lt;-revalidateDone&#125;close(tab.closed) 先等待刷新结束，然后关闭那些等待中的操作，再等待验证结束，最后关闭closed用于正常退出close方法。closeReq是在close方法中发出的：123456789func (tab *Table) Close() &#123; tab.closeOnce.Do(func() &#123; if tab.net != nil &#123; tab.net.close() &#125; close(tab.closeReq) &lt;-tab.closed &#125;)&#125; 到这里p2p节点的发现以及维护逻辑源码梳理完毕。总体还是很清晰的，基本都是按照Kademlia协议要求的进行的，主要流程是先加载种子节点，这些种子节点来源于用户指定或者之前数据库的值，然后利用自我查找进一步的填充k桶，最后通过各种定时器维护k桶。 udp.go前面table.go实现了Kademlia协议，udp则是进行网络通信的，先看常量的定义123456const ( pingPacket = iota + 1 // zero is 'reserved' pongPacket findnodePacket neighborsPacket) 定义了4种数据包，pingPacket就是询问节点是否在线，pongPacket是对ping的回应。findnodePacket是请求节点，neighborsPacket是对findnode的响应。详细的结构体如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253type ( ping struct &#123; senderKey *ecdsa.PublicKey // filled in by preverify Version uint From, To rpcEndpoint Expiration uint64 // Ignore additional fields (for forward compatibility). Rest []rlp.RawValue `rlp:"tail"` &#125; // pong is the reply to ping. pong struct &#123; // This field should mirror the UDP envelope address // of the ping packet, which provides a way to discover the // the external address (after NAT). To rpcEndpoint ReplyTok []byte // This contains the hash of the ping packet. Expiration uint64 // Absolute timestamp at which the packet becomes invalid. // Ignore additional fields (for forward compatibility). Rest []rlp.RawValue `rlp:"tail"` &#125; // findnode is a query for nodes close to the given target. findnode struct &#123; Target encPubkey Expiration uint64 // Ignore additional fields (for forward compatibility). Rest []rlp.RawValue `rlp:"tail"` &#125; // reply to findnode neighbors struct &#123; Nodes []rpcNode Expiration uint64 // Ignore additional fields (for forward compatibility). Rest []rlp.RawValue `rlp:"tail"` &#125; rpcNode struct &#123; IP net.IP // len 4 for IPv4 or 16 for IPv6 UDP uint16 // for discovery protocol TCP uint16 // for RLPx protocol ID encPubkey &#125; rpcEndpoint struct &#123; IP net.IP // len 4 for IPv4 or 16 for IPv6 UDP uint16 // for discovery protocol TCP uint16 // for RLPx protocol &#125;) 还有两个接口，分别定义数据包和upd连接。123456789101112131415type packet interface &#123; // preverify checks whether the packet is valid and should be handled at all. preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error // handle handles the packet. handle(t *udp, from *net.UDPAddr, fromID enode.ID, mac []byte) // name returns the name of the packet for logging purposes. name() string&#125;type conn interface &#123; ReadFromUDP(b []byte) (n int, addr *net.UDPAddr, err error) WriteToUDP(b []byte, addr *net.UDPAddr) (n int, err error) Close() error LocalAddr() net.Addr&#125; udp的结构如下12345678910111213type udp struct &#123; conn conn netrestrict *netutil.Netlist priv *ecdsa.PrivateKey localNode *enode.LocalNode db *enode.DB tab *Table wg sync.WaitGroup addReplyMatcher chan *replyMatcher gotreply chan reply closing chan struct&#123;&#125;&#125; 接下来看udp的创建123456789101112131415161718192021222324252627282930func ListenUDP(c conn, ln *enode.LocalNode, cfg Config) (*Table, error) &#123; tab, _, err := newUDP(c, ln, cfg) if err != nil &#123; return nil, err &#125; return tab, nil&#125;func newUDP(c conn, ln *enode.LocalNode, cfg Config) (*Table, *udp, error) &#123; udp := &amp;udp&#123; conn: c, priv: cfg.PrivateKey, netrestrict: cfg.NetRestrict, localNode: ln, db: ln.Database(), closing: make(chan struct&#123;&#125;), gotreply: make(chan reply), addReplyMatcher: make(chan *replyMatcher), &#125; tab, err := newTable(udp, ln.Database(), cfg.Bootnodes) if err != nil &#123; return nil, nil, err &#125; udp.tab = tab udp.wg.Add(2) go udp.loop() go udp.readLoop(cfg.Unhandled) return udp.tab, udp, nil&#125; 外部调用的是ListenUDP，传入一个连接，然后调用newUDP创建，由于UDP是为table服务的，所以也创建了table。接下来启动了两个goroutine，后面再讲，我们下面主要看看那几个PRC是如何实现的 ping在table中的doRevalidate也就是检查节点活性的时候调用udp的ping方法12345678910111213141516171819202122232425262728func (t *udp) ping(toid enode.ID, toaddr *net.UDPAddr) error &#123; return &lt;-t.sendPing(toid, toaddr, nil)&#125;func (t *udp) sendPing(toid enode.ID, toaddr *net.UDPAddr, callback func()) &lt;-chan error &#123; req := &amp;ping&#123; Version: 4, From: t.ourEndpoint(), To: makeEndpoint(toaddr, 0), Expiration: uint64(time.Now().Add(expiration).Unix()), &#125; packet, hash, err := encodePacket(t.priv, pingPacket, req) if err != nil &#123; errc := make(chan error, 1) errc &lt;- err return errc &#125; errc := t.pending(toid, toaddr.IP, pongPacket, func(p interface&#123;&#125;) (matched bool, requestDone bool) &#123; matched = bytes.Equal(p.(*pong).ReplyTok, hash) if matched &amp;&amp; callback != nil &#123; callback() &#125; return matched, matched &#125;) t.localNode.UDPContact(toaddr) t.write(toaddr, toid, req.name(), packet) return errc&#125; 主要执行的地方在sendPing，首先构造一个ping对象，这里面指明了发送方和接收方，超时时间为20s。接收方和发送方都是以rpcEndpoint表示的，内含IP地址，udp和tcp端口。紧接着调用encodePacket打包数据。12345678910111213141516171819func encodePacket(priv *ecdsa.PrivateKey, ptype byte, req interface&#123;&#125;) (packet, hash []byte, err error) &#123; b := new(bytes.Buffer) b.Write(headSpace) b.WriteByte(ptype) if err := rlp.Encode(b, req); err != nil &#123; log.Error("Can't encode discv4 packet", "err", err) return nil, nil, err &#125; packet = b.Bytes() sig, err := crypto.Sign(crypto.Keccak256(packet[headSize:]), priv) if err != nil &#123; log.Error("Can't sign discv4 packet", "err", err) return nil, nil, err &#125; copy(packet[macSize:], sig) hash = crypto.Keccak256(packet[macSize:]) copy(packet, hash) return packet, hash, nil&#125; 数据包中首先有一个长度为97的空字节数组，然后写入包的类型即pingPacket，最后再将刚才的ping对象编码为rlp格式写入。然后对数据进行签名，签名前先对除开头空字节部分以外的数据进行摘要。然后将签名结果写入开头预留的地方，然后在对签名数据和数据进行摘要，填充到开头，这样就完成了对数据打包，这也是常见的消息认证的步骤。回到sendPing中，有了要发送的数据，接下来调用pending12345678910111213func (t *udp) pending(id enode.ID, ip net.IP, ptype byte, callback replyMatchFunc) &lt;-chan error &#123; ch := make(chan error, 1) p := &amp;replyMatcher&#123;from: id, ip: ip, ptype: ptype, callback: callback, errc: ch&#125; select &#123; case t.addReplyMatcher &lt;- p: // loop will handle it case &lt;-t.closing: ch &lt;- errClosed &#125; return ch&#125;type replyMatchFunc func(interface&#123;&#125;) (matched bool, requestDone bool) pending主要是添加一个响应的匹配者用于匹配响应，匹配主要是通过对hash进行对比，这里的hash是前面数据包中的签名数据和数据摘要后的结果。最后发送数据。其实到这里还没有结束，sendPing返回一个channel对象err，而在ping中一直阻塞，知道可以从err中取值。err是由pending返回的，在pending中被replyMatcher持有并赋值给addReplyMatcher，这是触发loop方法（在newUDP中启动的一个goroutine）中的select结构中的一个条件123case p := &lt;-t.addReplyMatcher: p.deadline = time.Now().Add(respTimeout) plist.PushBack(p) 这里将pending中构造的replyMatcher存到plist中。 findnode在table中的lookup中使用了findnode功能，为的是进行节点查找，而实际执行的地方在udp的findnode中123456789101112131415161718192021222324252627func (t *udp) findnode(toid enode.ID, toaddr *net.UDPAddr, target encPubkey) ([]*node, error) &#123; if time.Since(t.db.LastPingReceived(toid, toaddr.IP)) &gt; bondExpiration &#123; t.ping(toid, toaddr) time.Sleep(respTimeout) &#125; nodes := make([]*node, 0, bucketSize) nreceived := 0 errc := t.pending(toid, toaddr.IP, neighborsPacket, func(r interface&#123;&#125;) (matched bool, requestDone bool) &#123; reply := r.(*neighbors) for _, rn := range reply.Nodes &#123; nreceived++ n, err := t.nodeFromRPC(toaddr, rn) if err != nil &#123; log.Trace("Invalid neighbor node received", "ip", rn.IP, "addr", toaddr, "err", err) continue &#125; nodes = append(nodes, n) &#125; return true, nreceived &gt;= bucketSize &#125;) t.send(toaddr, toid, findnodePacket, &amp;findnode&#123; Target: target, Expiration: uint64(time.Now().Add(expiration).Unix()), &#125;) return nodes, &lt;-errc&#125; 首先对于那些超过24小时没有ping过的节点先ping一次看是否存活。之后也是利用pending添加了一个响应的匹配。最后调用send发送数据，和ping一样，也是先进行打包，在发送数据。 响应对于响应，这里要看在新建udp时启动的第二个goroutine–readLoop。在readLoop中先分析了udp包的长度和发送者，然后处理这个包12345678910111213141516func (t *udp) handlePacket(from *net.UDPAddr, buf []byte) error &#123; packet, fromKey, hash, err := decodePacket(buf) if err != nil &#123; log.Debug("Bad discv4 packet", "addr", from, "err", err) return err &#125; fromID := fromKey.id() if err == nil &#123; err = packet.preverify(t, from, fromID, fromKey) &#125; log.Trace("&lt;&lt; "+packet.name(), "id", fromID, "addr", from, "err", err) if err == nil &#123; packet.handle(t, from, fromID, hash) &#125; return err&#125; 第一步先解包12345678910111213141516171819202122232425262728293031func decodePacket(buf []byte) (packet, encPubkey, []byte, error) &#123; if len(buf) &lt; headSize+1 &#123; return nil, encPubkey&#123;&#125;, nil, errPacketTooSmall &#125; hash, sig, sigdata := buf[:macSize], buf[macSize:headSize], buf[headSize:] shouldhash := crypto.Keccak256(buf[macSize:]) if !bytes.Equal(hash, shouldhash) &#123; return nil, encPubkey&#123;&#125;, nil, errBadHash &#125; fromKey, err := recoverNodeKey(crypto.Keccak256(buf[headSize:]), sig) if err != nil &#123; return nil, fromKey, hash, err &#125; var req packet switch ptype := sigdata[0]; ptype &#123; case pingPacket: req = new(ping) case pongPacket: req = new(pong) case findnodePacket: req = new(findnode) case neighborsPacket: req = new(neighbors) default: return nil, fromKey, hash, fmt.Errorf("unknown type: %d", ptype) &#125; s := rlp.NewStream(bytes.NewReader(sigdata[1:]), 0) err = s.Decode(req) return req, fromKey, hash, err&#125; 解包就是打包的逆过程。我们先回顾一下打包的内容：Hash(签名加数据)，签名(对数据摘要后签名)，数据(类型，请求体)。再看解包过程，先判断长度是否争取，然后分理出hash，签名和数据。然后验证hash是否正确。再根据签名以及被签名的内容计算出公钥。之后根据类型（数据部分的第一个字节）构造出请求对象。然后解码原始数据。通过解包我们得到了请求数据，发送节点公钥，以及hash值。之后回到handlePacket中，先计算发送者ID（就是对公钥的摘要），接着根据不同的请求执行不同的逻辑。 ping的接受与响应以ping为例，执行ping的preverify和handle方法1234567891011func (req *ping) preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error &#123; if expired(req.Expiration) &#123; return errExpired &#125; key, err := decodePubkey(fromKey) if err != nil &#123; return errors.New("invalid public key") &#125; req.senderKey = key return nil&#125; preverify主要是判断是否超时然后解码出公钥。主要处理逻辑在handle中12345678910111213141516171819func (req *ping) handle(t *udp, from *net.UDPAddr, fromID enode.ID, mac []byte) &#123; t.send(from, fromID, pongPacket, &amp;pong&#123; To: makeEndpoint(from, req.From.TCP), ReplyTok: mac, Expiration: uint64(time.Now().Add(expiration).Unix()), &#125;) n := wrapNode(enode.NewV4(req.senderKey, from.IP, int(req.From.TCP), from.Port)) if time.Since(t.db.LastPongReceived(n.ID(), from.IP)) &gt; bondExpiration &#123; t.sendPing(fromID, from, func() &#123; t.tab.addVerifiedNode(n) &#125;) &#125; else &#123; t.tab.addVerifiedNode(n) &#125; t.db.UpdateLastPingReceived(n.ID(), from.IP, time.Now()) t.localNode.UDPEndpointStatement(from, &amp;net.UDPAddr&#123;IP: req.To.IP, Port: int(req.To.UDP)&#125;)&#125; 直接是调用send发送数据，由于是相应ping，所以这里类型为pongPacket，相应体也是一个pong对象，同用叶经理了打包和发送的过程。发送完之后还有一些事情要处理。首先判断这个节点上一次pong相应是否超过24小时，若是超过则进行ping，否则更新节点，随后也要更新数据库。 pong的接收到这一步我们梳理了节点A发送ping到节点B，B返回一个pong相应到节点A，我们再看节点A收到pong相应的动作。直接看pong的preverify和handle。1234567891011121314151617181920func (req *pong) preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error &#123; if expired(req.Expiration) &#123; return errExpired &#125; if !t.handleReply(fromID, from.IP, pongPacket, req) &#123; return errUnsolicitedReply &#125; return nil&#125;func (t *udp) handleReply(from enode.ID, fromIP net.IP, ptype byte, req packet) bool &#123; matched := make(chan bool, 1) select &#123; case t.gotreply &lt;- reply&#123;from, fromIP, ptype, req, matched&#125;: // loop will handle it return &lt;-matched case &lt;-t.closing: return false &#125;&#125; preverify第一步也是验证是否超时，接着调用handleReply分发相应。首先是t.gotreply获得赋值，触发loop中的select逻辑，123456789101112131415case r := &lt;-t.gotreply: var matched bool // whether any replyMatcher considered the reply acceptable. for el := plist.Front(); el != nil; el = el.Next() &#123; p := el.Value.(*replyMatcher) if p.from == r.from &amp;&amp; p.ptype == r.ptype &amp;&amp; p.ip.Equal(r.ip) &#123; ok, requestDone := p.callback(r.data) matched = matched || ok if requestDone &#123; p.errc &lt;- nil plist.Remove(el) &#125; contTimeouts = 0 &#125; &#125; r.matched &lt;- matched 这里首先遍历plist，plist存储着我们发送请求时的响应匹配者，也就是回调。我们通过发送者，请求类型和ip三个条件判断是否匹配。如果匹配上的话执行callback方法，对于ping的callback并没有实质的内容，只是通过比较两个hash值是否相等来判断是否匹配。两个hash值分别是发送ping请求时对签名和数据的摘要以及pong响应的ReplyTok，而ReplyTok来自于对请求包解包后得到hash，实际上也就是请求所携带的hash，只不过在响应是写到了pong的ReplyTok字段中。只有二者相等，才能证明是从正确节点得到了响应。接下来如果请求结束，则给p.errc赋值为nil并移除这个回调，对于p.err这个channel，他在发送请求后一直阻塞，知道这里阻塞得到解除，ping流程结束。回到loop的select中，接着给matched赋值，这时handleReply的阻塞得到解决，preverify方法调用结束，接着调用handle方法，这里主要就是更新节点信息。刚才是成功响应时的流程，对于超时的情况，在loop的select有一个timeout触发的case，他会检测plist中各个回调是否超时，对于超时的给p.errc赋值超时错误，然后移除该回调。同时统计超时次数，对于超时次数过多的话检查时间是否准确。这个我们稍后再讲。 findnode的接收与响应我们再梳理一下findnode的接收与响应。前面的逻辑都是一样的，直接从handlePacket中开始，实际上是看preverify和handle。123456789func (req *findnode) preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error &#123; if expired(req.Expiration) &#123; return errExpired &#125; if time.Since(t.db.LastPongReceived(fromID, from.IP)) &gt; bondExpiration &#123; return errUnknownNode &#125; return nil&#125; 首先判断是否超时，再看这个节点是否过长时间没有响应。主要看handle12345678910111213141516171819202122func (req *findnode) handle(t *udp, from *net.UDPAddr, fromID enode.ID, mac []byte) &#123; target := enode.ID(crypto.Keccak256Hash(req.Target[:])) t.tab.mutex.Lock() closest := t.tab.closest(target, bucketSize).entries t.tab.mutex.Unlock() p := neighbors&#123;Expiration: uint64(time.Now().Add(expiration).Unix())&#125; var sent bool for _, n := range closest &#123; if netutil.CheckRelayIP(from.IP, n.IP()) == nil &#123; p.Nodes = append(p.Nodes, nodeToRPC(n)) &#125; if len(p.Nodes) == maxNeighbors &#123; t.send(from, fromID, neighborsPacket, &amp;p) p.Nodes = p.Nodes[:0] sent = true &#125; &#125; if len(p.Nodes) &gt; 0 || !sent &#123; t.send(from, fromID, neighborsPacket, &amp;p) &#125;&#125; 首先得到目标的ID，然后调用table的closest得出距目标较近的一组节点，然后构造响应体，主要有超时时间和要返回的节点，最后通过send方法发送响应。到这里我们梳理了节点A发送findnode请求到B，B找到一组节点发回A，再看A接到neighborsPacket响应时的动作，主要还是看preverify和handle。123456789func (req *neighbors) preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error &#123; if expired(req.Expiration) &#123; return errExpired &#125; if !t.handleReply(fromID, from.IP, neighborsPacket, req) &#123; return errUnsolicitedReply &#125; return nil&#125; 先检查超时，在调用handleReply，还是回到loop中执行之前findnode时预留的回调。回调如下：12345678910111213func(r interface&#123;&#125;) (matched bool, requestDone bool) &#123; reply := r.(*neighbors) for _, rn := range reply.Nodes &#123; nreceived++ n, err := t.nodeFromRPC(toaddr, rn) if err != nil &#123; log.Trace("Invalid neighbor node received", "ip", rn.IP, "addr", toaddr, "err", err) continue &#125; nodes = append(nodes, n) &#125; return true, nreceived &gt;= bucketSize &#125; 在这里将接受到的节点存储到nodes中，在findnode最后errc阻塞得到接触，findnode顺利返回nodes供table使用。 ndoe.go这是discover包内的节点类，它包装了enode，同时又附加了节点添加时间和活性检查时间两个成员12345type node struct &#123; enode.Node addedAt time.Time livenessChecks uint &#125; 这个类提供了一组对公钥操作的方法：encodePubkey是将公钥记为64字节类型，decodePubkey则是从字节数组还原公钥，recoverNodeKey从签名数据和原始数据中还原出公钥。还规定了节点的ID就是对公钥的字节数组形式摘要的结果。最后提供了一组包装与解包装enode的方法. ntp.go这是一个时间校准的工具类，在udp中如果多次超时的话就要考虑是否是本地时间出错。调用了checkClockDrift方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758func checkClockDrift() &#123; drift, err := sntpDrift(ntpChecks) if err != nil &#123; return &#125; if drift &lt; -driftThreshold || drift &gt; driftThreshold &#123; log.Warn(fmt.Sprintf("System clock seems off by %v, which can prevent network connectivity", drift)) log.Warn("Please enable network time synchronisation in system settings.") &#125; else &#123; log.Debug("NTP sanity check done", "drift", drift) &#125;&#125;func sntpDrift(measurements int) (time.Duration, error) &#123; addr, err := net.ResolveUDPAddr("udp", ntpPool+":123") if err != nil &#123; return 0, err &#125; request := make([]byte, 48) request[0] = 3&lt;&lt;3 | 3 drifts := []time.Duration&#123;&#125; for i := 0; i &lt; measurements+2; i++ &#123; conn, err := net.DialUDP("udp", nil, addr) if err != nil &#123; return 0, err &#125; defer conn.Close() sent := time.Now() if _, err = conn.Write(request); err != nil &#123; return 0, err &#125; conn.SetDeadline(time.Now().Add(5 * time.Second)) reply := make([]byte, 48) if _, err = conn.Read(reply); err != nil &#123; return 0, err &#125; elapsed := time.Since(sent) sec := uint64(reply[43]) | uint64(reply[42])&lt;&lt;8 | uint64(reply[41])&lt;&lt;16 | uint64(reply[40])&lt;&lt;24 frac := uint64(reply[47]) | uint64(reply[46])&lt;&lt;8 | uint64(reply[45])&lt;&lt;16 | uint64(reply[44])&lt;&lt;24 nanosec := sec*1e9 + (frac*1e9)&gt;&gt;32 t := time.Date(1900, 1, 1, 0, 0, 0, 0, time.UTC).Add(time.Duration(nanosec)).Local() drifts = append(drifts, sent.Sub(t)+elapsed/2) &#125; sort.Sort(durationSlice(drifts)) drift := time.Duration(0) for i := 1; i &lt; len(drifts)-1; i++ &#123; drift += drifts[i] &#125; return drift / time.Duration(measurements), nil&#125; 首先可以看出来是以udp方法通信的，目标地址是pool.ntp.org:123。首先构造了请求体，就是一个长度为48的字节数组，第一个字节是00011011（从左到右第3-5位表示协议版本号，也就是3，第6-8位表示操作模式，客户端为3）。接下来启动一个循环，一共5次。每次都通过udp与目标地址通信。读取到的响应长度也是48字节。分两部分，最后4字节表示秒的小数部分，再向前数4个字节表示秒。之后我们计算出服务给我们的时间的纳秒表示，之后计算出我们与服务器的时间差。详细的SNTP协议见官方文档 题图来自unsplash：https://unsplash.com/photos/-CZERTBlepA]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSL协议学习]]></title>
    <url>%2F2019%2F04%2F15%2FSSL%2F</url>
    <content type="text"><![CDATA[简介SSL全称Secure Sockets Layer，即安全套接层。简而言之，它是一项标准技术，可确保互联网连接安全，保护两个系统之间发送的任何敏感数据，防止网络犯罪分子读取和修改任何传输信息，包括个人资料。两个系统可能是指服务器和客户端或两个服务器之间。 SSL与TSLSSL最初由Netscape公司在1994年推出，此后，成为最为著名的Web安全机制，所有主要web浏览器都支持SSL。1996年发布的3.0版本是使用最广的版本（官方文档），但是2014年10月，Google发布在SSL 3.0中发现设计缺陷，建议禁用此一协议。Google在自己公司相关产品中陆续禁止回溯兼容，强制使用TLS协议。Mozilla也在11月25日发布的Firefox 34中彻底禁用了SSL 3.0。 TLS全称Transport Layer Security，即传输层安全性协议。是更为安全的升级版 SSL。TSL1.0（官方文档）是IETF将SSL标准化的结果，从技术上讲，TLS 1.0与SSL 3.0的差异非常微小。TLS随后又发布了1.1、1.2与1.3版本。其中1.3版本2018年才发布，支持的浏览器较少。所有TLS版本在2011年3月发布的RFC 6176中删除了对SSL的兼容，这样TLS会话将永远无法协商使用的SSL 2.0以避免安全问题。本文主要讲述SSL3.0内容 工作原理SSL可以看做TCP/IP协议中的一层，位于应用层和传输层之间，属于一种附加层，没有改层也可以正常通信，但是缺少安全性。 SSL有3个子协议：握手协议、记录协议和警报协议 握手协议这是客户端与服务端进行SSL通信时的第一个子协议，该协议会在客户端与服务端传输一系列信息，信息有如下三个字段： Type：类型字段，一共有10种类型，占1字节 Length：表示消息长度，占3字节 Content：消息参数，长度不固定 对于握手协议，一般分4个阶段 建立安全能力握手的第一阶段包含两个消息：“client hello”和“server hello”。 首先客户端向服务器发送“client hello”消息，包含以下字段： Version：客户端支持的最高SSL协议版本 Random：随机数，包含两个字段：32位日期时间和28位随机数 Session ID：会话号，若为非0值，表示连接已建立，但是客户端要更新参数；为0表示要建立新连接 Cipher suite：客户端支持的加密算法清单 Compression method：客户端支持的压缩算法 可见“client hello”是将客户端的一些情况发送给服务端，以便连接的建立 服务端收到客户端消息后，返回“server hello”消息，字段和“client hello”相同，但用途不同： Version：表示客户端和服务端共同支持的最高SSL版本的最低版本，如一方支持3.0一方支持3.1，则选择3.0版本 Random：同样包含32位日期时间和28位随机数 Session ID：若客户端发送的位非0值，则使用客户端发送的值，否则服务端生成一个新的ID Cipher suite：服务器选择的加密算法 Compression method：服务器选择的压缩算法 到此客户端与服务端在一些基本问题上达成共识，在这些共识的基础上进行后续步骤 服务器认证与秘钥交换握手的第二阶段，该阶段只有服务器发送消息，客户端只接受消息。一般有以下几步： 服务端将自己的数字证书和到根CA的证书链发送给客户端，供客户端进行认证 在第一步没有发送证书时，这一步才会发送服务器的公钥到客户端（数字证书中包含公钥，所以有数字证书就不用这一步） 服务器请求客户端证书，这一步是可选的，不要求全部链接都进行客户端认证 该阶段结束，发送“ServerHelloDone”信息，不包含任何参数，等待客户端响应。 客户端认证与秘钥交换握手的第三阶段，该阶段只有客户端发送消息，服务器只接受消息。一般有以下几步： 这一步是可选的，只有在服务端请求客户端证书时，客户端才发送自己的证书。对于服务器要求但客户端没有证书的情况，客户端发送“No certificate”消息，后续由服务端决定通信是否继续 秘钥交换，客户端生成48字节的预备秘密，用服务器公钥加密发送给服务器 证书验证，也只在服务器请求客户端证书时才执行。这一步客户端要证明自己是证书的所有者，一般将前面握手第一阶段中发送的随机数进行摘要并用自己私钥加密发送给服务端 完成阶段这一阶段由客户端启动。一共有四个消息，首先客户端发送改变加密规范消息和完成消息，服务端也随后也发送这两个消息。 这阶段需要一个主秘密，它是由前一步中的预备秘密和第一阶段中客户端与服务端的随机数进行拼接后进行摘要后生产的。主秘密产生后再和第一阶段中客户端与服务端的随机数进行拼接然后再次进行摘要得到会话的对称秘钥。 根据之前的握手信息，如果客户端和服务端都能对Finish信息进行正常加解密且消息正确的被验证，则说明握手通道已经建立成功，接下来，双方可以使用上面产生的Session Secret对数据进行加密传输了。 记录协议完成握手后，进入SSL记录协议，一般提供两个服务：保密性和完整性 SSL记录协议以要传输的信息位输入，首先进行分块，对每块可选的进行压缩，然后增加MAC信息，之后进行加密，在添加头信息，之后交由TCP协议的下一层处理，具体步骤如下： 分块：每块16KB 压缩：可选，但必须是无损压缩 加MAC：对前一步的输出计算MAC（消息认证码），类似于HMAC，秘钥使用的即使握手阶段协商的秘钥。 加密：用握手阶段协商的秘钥对上一步输出进行加密 添加头部：包含以下几个字段：内容类型（8位）：指上一层处理记录所用的协议；主版本（8位）：如SSL3.1，主版本位3；次版本（8位）：如SSL3.1，次版本是1；压缩长度（16位）：指原始信息或压缩过的信息的长度 可见记录协议就是实际通信所用的协议 警报协议通信双方任何一方发现错误时，向对方发送警报信息。若错误是致命的则立即关闭连接，终止传输，同时删除回话号、秘密和秘钥。如果错误不严重，则处理错误并继续通信。 每个警报消息有两字节，第一个字节指出错误类型，1代表一般错误，2代表致命错误；第二个字节指出详细错误 致命错误如下： 警报 描述 无关消息(unexpected_message) 收到不适当消息 坏记录(bad_record_mac) 收到的消息没有正确的MAC 解压失败(decompression_failure) 解压缩功能收到错误输入 握手失败(handshake_failure) 发送方无法从收到的选项中得到可接受的参数 非法参数(illegal_parameter) 握手消息中字段越界或其他字段不一致 非致命错误： 警报 描述 无证书(no_certificate) 没有适当证书 坏证书(bad_certificate) 证书验证失败 不支持的证书(unsupported_certificate) 不支持的证书类型 证书吊销(certificate_revoked) 证书已被吊销 证书过期(certificate_expired) 证书已过期 证书未知(certificate_unknown) 处理证书时出现未知错误 关闭通知(close_notify) 表示发送方在本次连接中不再发送任何信息，双方都要发送这个消息后才关闭连接 关闭与恢复连接对于关闭连接双方都要发送close_notify消息，这样才能优雅的借书连接。若有一方没有发送该信息，则连接无法恢复 从整个流程看，握手协议比较复杂与费时，所以复用或恢复连接是一个较好的选择，算法可以协商复用，若一方不同意则不能复用，另外，对于任何连接，在24小时后不得复用 题图来自unsplash：https://unsplash.com/photos/UZ3V6AV5y4o]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字证书]]></title>
    <url>%2F2019%2F04%2F15%2F%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[背景数字证书又称公开密钥证书、公钥证书等。是用于公开密钥基础建设的电子文件，用来证明公开密钥拥有者的身份。此文件包含了公钥信息、拥有者身份信息（主体）、以及数字证书认证机构（发行者）对这份文件的数字签名，以保证这个文件的整体内容正确无误。拥有者凭着此文件，可向计算机系统或其他用户表明身份。如果你信任签发的机构，就可以信任证书上的密钥，凭公钥加密与拥有者进行可靠的通信。 数字证书技术细节X.509 是密码学里公钥证书的格式标准。X.509 证书己应用在包括TLS/SSL在内的众多 Intenet协议里.同时它也用在很多非在线应用场景里。X.509最早与X.500一起发布于1988年7月3日。后来又做了两次修订，最新标准是X.509v3。 证书结构一般有以下几部分组成： 版本号 序列号 签名算法 颁发者 有效期（在有效期前后都是无效的） 主体名（即证书所指的用户或组织） 主体公钥信息（公钥算法，主题公钥） 颁发者唯一身份信息（可选） 主体唯一身份信息（可选） 扩展信息（可选） 证书签名算法 数字签名 证书的生成与使用证书生成 申请者生成一对足够强的秘钥，并对私钥进行保密 申请者将公钥连同其他信息组成证书请求发送给注册机构 注册机构验证申请者是公钥的持有人，验证方法有很多，如要求申请人用私钥对请求进行数字签名，注册机构用公钥验证。 验证成功后，注册机构将申请人的公钥、主体信息及有效期等一些信息组成证书基本数据 注册机构用自己的私钥对证书进行签名 将签名好的证书颁发给申请人 证书使用 证书所有者将自己的证书对外公开 第三方用注册机构的公钥验证证书签名，确保证书是可信的机构颁发的 验证成功后可以利用公钥对消息进行加密然后与证书所有者进行通信 证书的验证证书层次证书机构(CA)在实际中是分层的，假设A和B分属不同的子CA，如A属于CA20，B属于CA242，二者互相不知道对方CA的公钥。所以要获得这两个CA的证书，他们的证书由其上一级CA签名，一直到根CA。对于根CA的证书一般都固定到软件中，有了根CA的公钥就可以层层验证下面子CA的证书，这样就可以确保子CA的可信。 交叉证书若A与B位于不同国家，可能各个国家有自己的根CA，而国家自己没有再高一级的CA。这是就无法确保获得的对应根CA的有效性。这是可以进行交叉证书。如A属于中国，B属于美国。这是中国的根CA获得一个由美国根CA颁发的证书，同样美国的根CA也获得一个由中国跟CA颁发的证书。这样，A本来就拥有中国根CA的证书，用其公钥验证美国的根CA是否值得信任，然后获得美国根CA的证书与公钥，与处在美国的B进行可信通信。 证书的吊销脱机证书吊销状态检查需要一个证书吊销表（CRL），这个表不包括过期的证书，只包含因故吊销的证书。这个表按照固定时间更新，用户定期下载这个表。之所以成为脱机，是因为在更新间隔内，用户只用检查本地的表即可。当用户收到一个证书后进行如下检查 有效期检查 有效性检查，即CA的签名是否正确 查询CRL检查是否被吊销 联机证书状态协议主要是CA提供一个服务器，可以实时查询证书状态，验证证书是否吊销 题图来自unsplash：https://unsplash.com/photos/9NUeLk0uqME]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HMAC算法]]></title>
    <url>%2F2019%2F04%2F05%2FHMAC%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景首先说一下什么是MAC，MAC全称Message authentication code，即消息认证码。是经过特定算法后产生的一小段信息，检查某段消息的完整性，以及作身份验证。 在网络传输中，由于一般的传输通道是透明的，所以对消息进行认证是十分必要的，认证消息是否被修改，无论是恶意攻击或意外改变。一般的操作是对消息产生认证码，然后连同消息和认证码一起发送，接收方用同样的方法计算认证码，看两个认证码是否一致。 HMAC全称Hash-based message authentication code，即散列消息认证码(官方文档)是一个比较完善的消息认证码机制。是一种通过特别计算方式之后产生的消息认证码（MAC），使用密码散列函数，同时结合一个加密密钥。它可以用来保证数据的完整性，同时可以用来作某个消息的身份验证。 详细流程调整秘钥长度秘钥是收发双发都知晓的一个对称加密的秘钥。算法第一步要调整秘钥长度，使其和消息块长度匹配。分一下三种情况 k&lt;b：秘钥长度小于消息块长，这是需要在秘钥左边填充一定的0，使其等于消息块长 k=b：不做任何处理 k&gt;b：对秘钥进行信息摘要，使其等于消息块长，摘要算法和HMAC中用到的散列算法一样 生成S1将K与ipad进行异或运算生成S1，ipad = (00110110) 重复 b/8次，也就是说ipad长度和消息块长相等 填充将消息M拼接到S1后面 消息摘要对上一步拼接后的信息进行摘要得到H 生成S2将K与opad进行异或运算生成S2，opad = (01011010) 重复 b/8次，也就是说opad长度和消息块长相等 填充将前面摘要得到的H拼接到S2后面 消息摘要对上一步拼接后的信息进行摘要得到HMAC。 整体流程还是很简单的，整体流程如下： 算法分析HMAC主要解决的发送方的认证和消息完整性认证。首先中间涉及的秘钥只有收发双发知道，所以攻击者即使篡改消息也无法生成相应的HMAC，同样且只有持有正确秘钥的发送方才能正确生成HMAC。其次，由于摘要算法，只要消息不完整，验证也不会通过。最后，由于摘要算法是单向函数，所以无法从消息和HMAC推测秘钥。 但是HMAC也存在下面几个问题： 秘钥交换问题是一个普遍存在的问题，对于中间人攻击，HMAC也无能为力 HMAC不适用与多个接收方情况，由于是对称加密，接收方并不能认证消息来自某个发送方，任何一个接收方都可以伪造消息 若是不同收发方使用不同的秘钥，则秘钥管理也比较困难 接收方也可能伪造消息，对于一个HMAC并不能判断具体是哪一方发出的。 题图来自unsplash：https://unsplash.com/photos/Anosw0HcGRk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SHA-2算法]]></title>
    <url>%2F2019%2F04%2F03%2FSHA-2%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景前面介绍了SHA-1的详细内容。因为SHA-1已经被认为是不安全的，所以又开发了SHA-2。SHA-2可分为6种不同标准：SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。其后数字表示摘要长度。 SHA-256和SHA-512是很新的散列函数，前者以定义一个word为32位，后者则定义一个word为64位。它们分别使用了不同的偏移量，或用不同的常量，然而，实际上二者结构是相同的，只在循环运行的次数上有所差异。SHA-224以及SHA-384则是前述二种散列函数的截短版，利用不同的初始值做计算。我们这里介绍SHA-512的内容，其余标准见标准文档 详细流程SHA-512的最大数据长度为2^128 - 1。它的摘要长度为512位，分块长度为1024位。SHA-512是按照SHA-1的模型而来的，而SHA-1又是仿照MD5而来的，所以他们之间有很多相似之处，对于相似地方我们只简要说明一下 填充填充为1024的倍数少128位，通用填充总是要进行的，即使已满足条件 添加长度将原始信息长度写成128位形式填充到最后 分块按1024一组进行分块 初始化链接变量一共有8个初始化变量，实际上多少个初始化变量是由最后摘要长度决定的。如MD5为128位，就是4个，SHA-1位160位，就是5个。而SHA-512是512位，就是8个，但每个是64位：12345678A = 6a09e667f3bcc908B = bb67ae8584caa73bC = 3c6ef372fe94f82bD = a54ff53a5f1d36f1E = 510e527fade682d1F = 9b05688c2b3e6c1fG = 1f83d9abfb41bd6bH = 5be0cd19137e2179 轮次操作 将初始化变量复制到abcdefgh中 将当前子块每64位一组，分16组 一共有80轮，每轮以当前块，abcdefgh和常量K[t]，常量总共有80个，这些常数的取值是前80个质数的立方根的小数部分的前64位。每轮操作如下：12345678910temp1 = h + ch(e,f,g) + sum1(e)+wt+kttemp2 = sum0(a) + maj(a,b,c)a = temp1 + temp2b = ac = bd = ce = d + temp1f = eg = fh = g 上面运算中t为轮次号，加法均是加完之后取2^64模，几个函数如下定义：1234ch(e,f,g) = (e and f) xor (not e and g)maj(a,b,c) = (a and b) xor (a and c) xor (b and c)sum1(e) = e&gt;&gt;14 xor e&gt;&gt;18 xor e&gt;&gt;41sum0(a) = a&gt;&gt;28 xor a&gt;&gt;34 xor a&gt;&gt;39 对于每轮中的w，前16轮就是分好的16组子块，后面的w如下计算1234wt = a1(w(t-2)) + w(t-7) + a0(w(t-15)) + w(t-16)a1(x) = x&gt;&gt;1 xor x&gt;&gt;8 xor x&gt;3a0(x) = x&gt;&gt;17 xor x&gt;&gt;19 xor x&gt;10 上面&gt;&gt;表示循环右移，&gt;表示右移，空出的补零 80轮之后计算出的abcdefgh分别加上原来的ABCDEFGH作为处理下一个块的输入 和MD5与SHA-1一样，处理完所有块之后，最后的ABCDEFGH拼接到一起就是摘要信息。 题图来自unsplash：https://unsplash.com/photos/OIYrmG5FNFg]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SHA-1算法]]></title>
    <url>%2F2019%2F04%2F02%2FSHA-1%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景SHA全称Secure Hash Algorithm，即安全散列算法。它是一个算法簇，包含多种算法。是FIPS所认证的安全散列算法。能计算出一个数字消息所对应到的，长度固定的字符串（又称消息摘要）的算法。且若输入的消息不同，它们对应到不同字符串的机率很高。 SHA-1于1995年发布，应用相当广泛，被认为是MD5的替代者，但是随着技术的进步SHA-1已经被认为是不安全的，特别是2017年荷兰密码学研究小组CWI和Google正式宣布攻破了SHA-1 SHA-2在2001年发布，包括SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。虽然至今尚未出现对SHA-2有效的攻击，它的算法跟SHA-1基本上仍然相似，所以理论上也有漏洞 SHA-3在2015年正式发布，SHA-3并不是要取代SHA-2，因为SHA-2当前并没有出现明显的弱点。由于对MD5出现成功的破解，以及对SHA-0和SHA-1出现理论上破解的方法，NIST感觉需要一个与之前算法不同的，可替换的加密散列算法，也就是现在的SHA-3。 SHA家族几种算法比较如下： 这里我们先来梳理SHA-1的详细过程 详细流程SHA-1和MD5设计非常类似，标准文档链接，基本步骤如下 填充和MD5一样，填充总是增加的，也就是512的倍数少64 添加长度将原始长度的64位表示添加到末尾 分块每512位一块 初始化链接变量总共有5个，其中ABCD和MD5一样，D的值位C3D2E1F0。五个值如下12345A=67452301B=efcdab89C=98badcfeD=10325476E=c3d2e1f0 处理块 将A~E赋值到a~e 将每块分为16个子块，每个子块32位 SHA共4轮，每轮20步，输入为子块，abcde，常量。整体算法和MD5类似。与MD5不同，这里的常量仅有四个值，每轮用一个，分别是：5a827999,6ed9eba1,8f1bbcdc，ca62c1d6。 每一步的逻辑如下图所示 具体来说，一次操作的数学表达式如下：1abcde=(e + P + a&lt;&lt;5 + W[] + K[]),a,b&lt;&lt;30,c,d P依然还是一个非线性操作，&lt;&lt;表示循环左移，W[]表示计算某一子块，K[]表示该轮的常量 w是将16个子块扩展为80个，前16个就是原16个子块，后面的按照下面公式计算1w[t] = (w[t-16] xor w[t-14] xor w[t-8] xor w[t-3])&lt;&lt;1 P的具体运算如下轮次 | P—|—1 | (b AND c) OR ((NOT b) AND d)2 | b xor c xor d3 | (b AND c) or (b AND d) OR (c AND d)4 | b xor c xor d 就这样对每一块执行80次后，输出的abcde就是160位的散列值。相比于MD5无规则的运算，SHA-1基本可以用公式表示整个算法 题图来自unsplash：https://unsplash.com/photos/I2UR7wEftf4]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MD5算法与实现]]></title>
    <url>%2F2019%2F04%2F02%2FMD5%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景MD5全称Message-Digest Algorithm，就是信息摘要算法。是一种被广泛使用的密码散列函数，可以产生出一个128位的散列值，它是由美国密码学家Ron Rivest开发的，于1992年公开。最开始算法是MD，很快出现MD2，不过算法很脆弱，又改为研究MD3，不过最终研发失败。接下来又出现MD4，但仍不理想，最后研发出MD5，成为一个全世界广泛使用的算法。 如今，MD5被证实存在一系列弱点，可以被加以破解，同时也无法防止碰撞，所以已经不适合安全认证。但是，MD5算法因其普遍、稳定、快速的特点，仍广泛应用于普通数据的错误检查领域。 作为一个经典算法，这里就详细梳理一下整个流程。MD5标准文档见这里 详细步骤填充第一步是在初始消息中填充信息，使其达到一个要求的长度，即比512位的倍数少64位。如原始消息是1000位，512*3=1536,1536-64=1472，所以要填充472位。填充的内容是1个1和多个0 填充总是要进行的，即使消息长度已经比512的倍数少64位，仍要填充512位 添加长度计算源消息的长度，表示成64位填充到末尾。如果消息的长度大于2^64，则使用低64位填充，即len mod 2^64 添加完之后，整体长度为512的倍数 分块将输入以512位一组分块 初始化链接变量初始化4个32位数字，16进制表示如下1234A = 0x67452301B = 0xEFCDAB89C = 0x98BADCFED = 0x10325476 处理块前面都是初始化操作，这里开始才是算法开始 复制将4个初始化变量复制到4个变量abcd中，这四个变量组成一个128位寄存器，用于表示中间结果和最终结果 分解将每块512位分解为16个子块，每个子块32位 轮次迭代主循环有4轮，每轮有16次操作。每次操作对abcd的其中三个做一次非线性运算P，然后将所得结果加上第四个变量、一个子块和一个常数。再将所得结果向左循环移位,最后加上abcd的其中给一个，最后用该结果取代abcd其中之一。如下图所示 表示成数学表达式如下1a = b + ((a + P(b,c,d) + M[i] + t[k])&lt;&lt;&lt;s) P的每一轮操作如下： 轮次 P 1 (b AND c) OR ((NOT b) AND b) 2 (b AND d) OR (c AND (NOT d) 3 b XOR c XOR d 4 C XOR (b OR (NOTd) 轮次操作中常量t[i] = 4294967296*abs(sin(i))的整数部分。下面我们给出每一步详细操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081首先定义P的4种运算：F( X ,Y ,Z ) = ( X &amp; Y ) | ( (~X) &amp; Z )G( X ,Y ,Z ) = ( X &amp; Z ) | ( Y &amp; (~Z) )H( X ,Y ,Z ) =X ^ Y ^ ZI( X ,Y ,Z ) =Y ^ ( X | (~Z) )再定义4个函数：FF(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + F(b,c,d) + Mj + ti) &lt;&lt; s)GG(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + G(b,c,d) + Mj + ti) &lt;&lt; s)HH(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + H(b,c,d) + Mj + ti) &lt;&lt; s)II(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + I(b,c,d) + Mj + ti) &lt;&lt; s)这4轮64步分别如下：第一轮：FF(a ,b ,c ,d ,M0 ,7 ,0xd76aa478 )FF(d ,a ,b ,c ,M1 ,12 ,0xe8c7b756 )FF(c ,d ,a ,b ,M2 ,17 ,0x242070db )FF(b ,c ,d ,a ,M3 ,22 ,0xc1bdceee )FF(a ,b ,c ,d ,M4 ,7 ,0xf57c0faf )FF(d ,a ,b ,c ,M5 ,12 ,0x4787c62a )FF(c ,d ,a ,b ,M6 ,17 ,0xa8304613 )FF(b ,c ,d ,a ,M7 ,22 ,0xfd469501)FF(a ,b ,c ,d ,M8 ,7 ,0x698098d8 )FF(d ,a ,b ,c ,M9 ,12 ,0x8b44f7af )FF(c ,d ,a ,b ,M10 ,17 ,0xffff5bb1 )FF(b ,c ,d ,a ,M11 ,22 ,0x895cd7be )FF(a ,b ,c ,d ,M12 ,7 ,0x6b901122 )FF(d ,a ,b ,c ,M13 ,12 ,0xfd987193 )FF(c ,d ,a ,b ,M14 ,17 ,0xa679438e )FF(b ,c ,d ,a ,M15 ,22 ,0x49b40821 )第二轮GG(a ,b ,c ,d ,M1 ,5 ,0xf61e2562 )GG(d ,a ,b ,c ,M6 ,9 ,0xc040b340 )GG(c ,d ,a ,b ,M11 ,14 ,0x265e5a51 )GG(b ,c ,d ,a ,M0 ,20 ,0xe9b6c7aa )GG(a ,b ,c ,d ,M5 ,5 ,0xd62f105d )GG(d ,a ,b ,c ,M10 ,9 ,0x02441453 )GG(c ,d ,a ,b ,M15 ,14 ,0xd8a1e681 )GG(b ,c ,d ,a ,M4 ,20 ,0xe7d3fbc8 )GG(a ,b ,c ,d ,M9 ,5 ,0x21e1cde6 )GG(d ,a ,b ,c ,M14 ,9 ,0xc33707d6 )GG(c ,d ,a ,b ,M3 ,14 ,0xf4d50d87 )GG(b ,c ,d ,a ,M8 ,20 ,0x455a14ed )GG(a ,b ,c ,d ,M13 ,5 ,0xa9e3e905 )GG(d ,a ,b ,c ,M2 ,9 ,0xfcefa3f8 )GG(c ,d ,a ,b ,M7 ,14 ,0x676f02d9 )GG(b ,c ,d ,a ,M12 ,20 ,0x8d2a4c8a )第三轮HH(a ,b ,c ,d ,M5 ,4 ,0xfffa3942 )HH(d ,a ,b ,c ,M8 ,11 ,0x8771f681 )HH(c ,d ,a ,b ,M11 ,16 ,0x6d9d6122 )HH(b ,c ,d ,a ,M14 ,23 ,0xfde5380c )HH(a ,b ,c ,d ,M1 ,4 ,0xa4beea44 )HH(d ,a ,b ,c ,M4 ,11 ,0x4bdecfa9 )HH(c ,d ,a ,b ,M7 ,16 ,0xf6bb4b60 )HH(b ,c ,d ,a ,M10 ,23 ,0xbebfbc70 )HH(a ,b ,c ,d ,M13 ,4 ,0x289b7ec6 )HH(d ,a ,b ,c ,M0 ,11 ,0xeaa127fa )HH(c ,d ,a ,b ,M3 ,16 ,0xd4ef3085 )HH(b ,c ,d ,a ,M6 ,23 ,0x04881d05 )HH(a ,b ,c ,d ,M9 ,4 ,0xd9d4d039 )HH(d ,a ,b ,c ,M12 ,11 ,0xe6db99e5 )HH(c ,d ,a ,b ,M15 ,16 ,0x1fa27cf8 )HH(b ,c ,d ,a ,M2 ,23 ,0xc4ac5665 )第四轮II(a ,b ,c ,d ,M0 ,6 ,0xf4292244 )II(d ,a ,b ,c ,M7 ,10 ,0x432aff97 )II(c ,d ,a ,b ,M14 ,15 ,0xab9423a7 )II(b ,c ,d ,a ,M5 ,21 ,0xfc93a039 )II(a ,b ,c ,d ,M12 ,6 ,0x655b59c3 )II(d ,a ,b ,c ,M3 ,10 ,0x8f0ccc92 )II(c ,d ,a ,b ,M10 ,15 ,0xffeff47d )II(b ,c ,d ,a ,M1 ,21 ,0x85845dd1 )II(a ,b ,c ,d ,M8 ,6 ,0x6fa87e4f )II(d ,a ,b ,c ,M15 ,10 ,0xfe2ce6e0 )II(c ,d ,a ,b ,M6 ,15 ,0xa3014314 )II(b ,c ,d ,a ,M13 ,21 ,0x4e0811a1 )II(a ,b ,c ,d ,M4 ,6 ,0xf7537e82 )II(d ,a ,b ,c ,M11 ,10 ,0xbd3af235 )II(c ,d ,a ,b ,M2 ,15 ,0x2ad7d2bb )II(b ,c ,d ,a ,M9 ,21 ,0xeb86d391 ) 上面是网上大多是文章给出的方法，就是生硬的给出64轮具体操作，但其实每一步都是可以推算的，下面来说一下简单的方法：123456789101112131415161718192021222324252627282930313233343536373839404142首先对于常数，可以通过公式计算，t[i] = 4294967296*abs(sin(i))的整数部分，其中4294967296就是1&lt;&lt;32，即2^32对于这个长度建议是直接写成常量，不然每次都计算也比较耗时：private static final int T[] = &#123; 0xd76aa478, 0xe8c7b756, 0x242070db, 0xc1bdceee, 0xf57c0faf, 0x4787c62a, 0xa8304613, 0xfd469501, 0x698098d8, 0x8b44f7af, 0xffff5bb1, 0x895cd7be, 0x6b901122, 0xfd987193, 0xa679438e, 0x49b40821, 0xf61e2562, 0xc040b340, 0x265e5a51, 0xe9b6c7aa, 0xd62f105d, 0x02441453, 0xd8a1e681, 0xe7d3fbc8, 0x21e1cde6, 0xc33707d6, 0xf4d50d87, 0x455a14ed, 0xa9e3e905, 0xfcefa3f8, 0x676f02d9, 0x8d2a4c8a, 0xfffa3942, 0x8771f681, 0x6d9d6122, 0xfde5380c, 0xa4beea44, 0x4bdecfa9, 0xf6bb4b60, 0xbebfbc70, 0x289b7ec6, 0xeaa127fa, 0xd4ef3085, 0x04881d05, 0xd9d4d039, 0xe6db99e5, 0x1fa27cf8, 0xc4ac5665, 0xf4292244, 0x432aff97, 0xab9423a7, 0xfc93a039, 0x655b59c3, 0x8f0ccc92, 0xffeff47d, 0x85845dd1, 0x6fa87e4f, 0xfe2ce6e0, 0xa3014314, 0x4e0811a1, 0xf7537e82, 0xbd3af235, 0x2ad7d2bb, 0xeb86d391 &#125;; 对于每次取哪一小组明文，是根据轮次定的，定义j是小轮次，0 &lt;= j &lt; 64：第一大轮就是按顺序取1~16小组 i = j第二大轮的计算规则为 i = (1+5*j)%16 即 (j*5+1)&amp;0x0f第三大轮的计算规则为 i = (5+3*j)%16 即 (j*3+5)&amp;0x0F第四大轮的计算规则为 i = (7*j)%16 即 (j*7)&amp;0x0F对于移位，也是根据轮次定的,定义j是小轮次，0 &lt;= j &lt; 64：第一大轮 从[7, 12, 17, 22]取，j%4第一大轮 从[5, 9, 14, 20]取，j%4第一大轮 从[4, 11, 16, 23]取，j%4第一大轮 从[6, 10, 15, 21]取，j%4若写到一个数组中：public static final int S[] = new int[]&#123; 7, 12, 17, 22, 5, 9, 14, 20, 4, 11, 16, 23, 6, 10, 15, 21 &#125;;可以通过如下公式取值：S[(pType &lt;&lt; 2) | (j &amp; 3)]) //pType指第几大轮，j指第几小轮对于每次运算abcd数输入顺序：可以明显观察到，每一小轮之后，下一轮的输入相当于把abcd做循环右移一位，而P运算的输入固定位bcd，所以做如下交换a = d;d = c;c = b;b = temp; 经过这64步之后，A=a，B=b，C=c，D=d，然后将ABCD作为处理下一明文块的输入 应用MD5已经广泛使用在为文件传输提供一定的可靠性方面。例如，服务器预先提供一个MD5校验和，用户下载完文件以后，用MD5算法计算下载文件的MD5校验和，然后通过检查这两个校验和是否一致，就能判断下载的文件是否出错。 实现下面来给出java版本的具体实现，关键步骤有注释，详细代码见这里12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public String md5(String msg)&#123; byte[] msgBytes = msg.getBytes(); int msgBytesLen = msgBytes.length;//原始信息长度，单位bit int numBlock = ((msgBytesLen + 8)&gt;&gt;&gt;6) + 1; //总块数=(原始长度+8bit)/64bit + 1 int totalLen = numBlock &lt;&lt; 6; //补全后的长度 = 块数 * 64bit byte[] padBytes = new byte[totalLen - msgBytesLen]; //需要补的bit数 padBytes[0] = (byte) 0x80; //补一个1和若干个0 long msgLen = (long)msgBytesLen &lt;&lt; 3; //计算出多少bit，长度*8 for(int i = 0;i&lt;8;i++)&#123; padBytes[padBytes.length - 8 + i] = (byte) msgLen;//从低位开始写入长度 msgLen &gt;&gt;&gt;= 8; &#125; int a = A,b =B,c = C,d = D; //赋值常量 int[] buffer = new int[16]; //每块512位，16个int类型 for (int i = 0;i&lt;numBlock;i++)&#123; int index = i &lt;&lt; 6; for (int j = 0;j&lt;64;j++,index++) //index是msg的游标，j是buffer的游标，一个int类型存4个byte类型 //从低位开始存 buffer[j &gt;&gt;&gt; 2] = ((int) ((index &lt; msgBytesLen) ? msgBytes[index] : padBytes[index - msgBytesLen]) &lt;&lt; 24) | (buffer[j &gt;&gt;&gt; 2] &gt;&gt;&gt; 8); int tempa = a; //记录abcd的临时变量 int tempb = b; int tempc = c; int tempd = d; for (int j = 0;j&lt;64;j++) &#123; //64小轮 int pType = j &gt;&gt;&gt; 4; //判断是第几大轮 int f = 0; //P运算的值 int bufferIndex = j; //buffer的游标 switch (pType)&#123; //定义不同大轮的具体P运算 case 0: f = (b &amp;c) | (~b &amp; d); break; case 1: f = (b &amp; d) | (c &amp; ~d); bufferIndex = (bufferIndex*5+1)&amp;0x0f; //明文子组和轮数的关系 break; case 2: f = b ^ c ^ d; bufferIndex = (bufferIndex * 3 + 5) &amp; 0x0F; break; case 3: f = c ^ (b | ~d); bufferIndex = (bufferIndex * 7) &amp; 0x0F; break; &#125; //运算 int temp = b + Integer.rotateLeft(a + f + buffer[bufferIndex] + T[j], S[(pType &lt;&lt; 2) | (j &amp; 3)]); //交换abcd a = d; d = c; c = b; b = temp; &#125; //分组处理完之后abcd各自累加 a += tempa; b += tempb; c += tempc; d += tempd; &#125; //abcd写到16个byte中 byte[] out = new byte[16]; int count = 0; for (int i = 0;i&lt;4;i++)&#123; int n = (i == 0) ? a : ((i == 1) ? b : ((i == 2) ? c : d)); for (int j = 0;j&lt;4;j++)&#123; out[count++] = (byte)n; n&gt;&gt;&gt;=8; &#125; &#125; //转为十六进制表示 StringBuffer sb = new StringBuffer(); for (byte bout : out)&#123; sb.append(HEX[(bout&gt;&gt;&gt;4)&amp;0xf]); sb.append(HEX[bout&amp;0xf]); &#125; return sb.toString();&#125; 简单测试后结果正确无误 题图来自unsplash：https://unsplash.com/photos/HsEz1XZ1TO8]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kademlia：一个基于异或度量的P2P信息系统]]></title>
    <url>%2F2019%2F04%2F01%2FKademlia%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E%E5%BC%82%E6%88%96%E5%BA%A6%E9%87%8F%E7%9A%84P2P%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[论文原文：https://link.springer.com/chapter/10.1007%2F3-540-45748-8_5 原文除了摘要，总共有5部分，分别是：介绍、系统描述、证明、实现要点、总结。这里只翻译摘要和核心的系统描述以及实现要点部分 摘要我们描述了一个在易发生故障的环境中具有可证明的一致性和高性能的P2P系统。我们的系统使用一种新的基于异或度量拓扑来进行路由查询和结点定位，这种拓扑简化了算法并易于证明。该拓扑在信息交换时仅传递或增强有用的信息，系统利用这些信息进行并行或异步的信息查询，同时也能容忍节点故障，并且不会给用户带来超时延迟 系统描述我们的系统基本上采取了和其他DHT系统一样的方法。节点的 ID 是 160 位不透明的值，我们的算法也是逐步“逼近”所期望的 ID ，并以对数级的速度收敛到要查询的目标。 Kademlia把一个节点看这一颗二叉树的叶子，每个节点的位置由其ID的最短唯一前缀决定。图一展示了一个唯一前缀为0011节点在树中的位置。对于任意给定的一个节点，我们都把树划分为一系列不包含该节点的逐步降低的子树。最高层的子树有二叉树中不包含该节点的那一半组成，接下来的子树由剩余的不包含该节点的一半组成，以此类推。在示例中的0011节点，子树被圈出来，分别由前缀为0,01,000以及0010的节点构成 Kademlia协议确保每个节点都至少知晓这些子树中的一个节点。有了这个保证，任何一个节点都可以通过ID定位其他节点。1110的示例，其中节点 0011通过逐步查询它所知道的最佳节点来取得和越来越低层次子树的联系；最后查询收敛到目标节点。 接下来，我们会补充一些细节，并更具体的描述查询算法。首先，我们会给出 ID 接近这个概念的准确定义，这样就可以谈及“在距离 key 最近的k个节点上存储或者查询 键值对”这样的行为。然后，我们会介绍一个查询协议，该协议即使在任何节点都不和某个key具有相同的前缀或者和某个给定节点关联的子树中有一些为空的情况下，都可以正常工作。 异或度量每个Kademlia节点都有160位的ID，节点id构造像Chord一样，但是为了简化，我们假设机器在加入系统时选择一个随机的160位标识符。节点传输的每个消息都包含其ID，并且允许接收方在必要时记录发送方的存在。 key同样也是160位的标识符。为了发布和查找键值对，Kademlia依赖于两个标识符之间的距离。给定两个160位标识符x和y,Kademlia将它们之间的距离定义为它们的为异或（d(x,y)），并转化为整数。 我们首先注意到虽然异或不是欧几里得度量，但仍是有效的。很明显，d(x,x) = 0。如果x ≠ y则d(x,y)&gt;0。以及d(x,y)=d(y,x)。除此之外，异或还满足三角不等式，因为d(x,z) = d(x,y) xor d(y,z),而a+b &gt;= a xor b 和chord的顺时针圆周度量一样，异或也是单向的。给定任意一个点x和距离d&gt;0，都会存在一个点y，使得d(x,y) = d。单向性确保所有对相同键的查找都沿着相同的路径收敛，而不管初始节点是什么。因此，沿着查找路径缓存键值对可以缓解热点。就像Pastry一样，但不像Chord，异或拓扑是对称的，即(d(x,y) = d(y,x)) 节点状态Kademlia节点存储彼此之间的路由联系信息。对于每个i（0 &lt;= i &lt; 160），节点都会存储一个含有&lt;IP地址列表;UDP端口;节点ID&gt;列表，每个列表项表示距离自己2^i和2^i+1之间的节点。我们称这些列表为k桶。每个k桶都按照时间顺序进行排序，最后一次看到的节点位于头部，最近一次看到的节点位于尾部。对于较小的i值，为k桶通常是空的(因为没有合适的节点)。对于较大的i值，列表长度可以增长到k，其中k是一个系统范围的全局变量。选择k时，任何给定的k个节点都不太可能在一小时内发生故障(例如k = 20)。 当Kademlia节点接收到来自另一个节点的任何消息(请求或响应)时，它将更新发送方节点ID所在的k桶。如果发送节点已经存在于收件人的k桶中，则收件人将其移动到列表的末尾。如果节点还没有在适当的的k桶中，并且桶的条目数小于k，那么接收方只需在列表的末尾插入新的发送方。但是，如果应村的k桶已满，则接收方将PING k桶的最近最少出现的节点，以决定该做什么。如果最近最少出现的节点没有响应，则将其从k桶中删除，并在末尾插入新的发送者。否则，如果最近最少出现的节点有响应，则将其移动到列表的末尾，并丢弃新发送方的联系人。 k桶有效地实现了一个最近很少键的清除策略，除非活动节点从未从列表中删除。这种对旧的联系的处理是基于对Saroiu等人收集的Gnutella微量数据分析而得出的。图1显示了Gnutella节点继续在线一个小时的百分比，这是当前正常运行的时间函数。节点运行的时间越长，它继续运行一个小时的可能性就越大。通过保留旧的联系人，k桶最大化了它们所存的节点保持在线的可能性。 k桶的第二个好处是，可以抵抗特定的DoS攻击。无法通过向系统中注入新节点来刷新节点的路由状态。Kademlia节点只会在旧节点离开系统时将新节点插入到k桶中。 Kademlia协议Kademlia协议由四个rpc组成：PING, STORE, FIND NODE 和 FIND VALUE。PING探测一个节点，看看它是否在线。STORE指示节点存储键值对，以便以后检索。 FIND NODE以160位的ID作为参数。接收者返回&lt;IP地址;UDP端口;节点ID&gt;三元组表示它知道的最接近目标ID的k个节点。这些三元组可以来自单个k桶，也可以来自多个k桶（如果最近的k桶没有满的话）。在任何情况下，RPC接收方都必须返回k个条目(除非所有k个桶的组合中有少于k个节点，在这种情况下，它返回它所知道的每个节点)。 FIND VALUE的行为类似于FIND NODE，也返回&lt;IP地址;UDP端口;节点ID&gt;三元组，只有一个例外。如果RPC接收方收到了STORE的RPC，它只返回存储值。 在所有RPC中，接收者必须回显一个160位的随机RPC ID，这为地址伪造提供了一定的抵抗力。还可以在RPC应答上附加ping，以便RPC接收方获得对发送方网络地址,从而获得额外保证。 Kademlia参与者必须执行的最重要的过程是定位距离某个给定节点ID最近的k个节点。我们将此过程称为节点查找。Kademlia使用递归算法进行节点查找。查找发起者首先从最近的非空k桶中选择α个节点（如果已知节点数少于α，则选择全部节点）。。发起者发送并行或异步的rpc FIND NODE给α个节点。α是一个全系统的并发性参数，比如3 在递归步骤中，初始节点将FIND NODE重新发送到它从之前的rpc结果中了解到的节点（这个递归可以从先前的RPC返回后开始）。收到响应后，发起者向离目标更近的其中α个未被请求的节点发送FIND NODE。无法快速响应的节点将从考虑中删除，直到它们再次响应。如果一轮查找节点未能返回比已知的更近的节点，则初始节点将FIND NODE重新发送给它尚未查询的k个最近的节点。当初始节点查询并从它所知的k个最近的节点中获得响应时，查找将终止。当α= 1查找算法类似于Chord的信息消耗和延迟检测失败的节点。然而，Kademlia可以通过路由获得更低的延迟，因为它可以灵活地选择k个节点中的任意一个来转发请求。 大多数操作都是根据上面的查找过程实现的。要存储键值对，参与者需要找到距离键最近的k个节点，并向它们发送STORE rpc。此外，每个节点每小时重新发布它拥有的键值对，这确保键值对的持久性概率维持较高水平。通常，我们还需要键值对的原始发布者每24小时重新发布一次。否则，所有的键值对将在最初发布24小时后过期，从而限制系统中的陈旧信息。 最后，为了使键值对的发布-搜索在声明周期中保持一致，我们要求每当一个节点w观察到一个新的节点u时，这个新节点u更接近w的一些键值对时，w将这些对复制到u，而不从自己的数据库中删除。 要查找一个键值对，初始节点首先进行查找，查找id最接近的k个节点。不过，使用的rpc是FIND VALUE。此外，当任何节点返回值时，程序立即停止。出于缓存的目的，一旦查找成功，请求节点将键值对存储在它观察到的最接近目标但没有返回值的节点上。 由于拓扑的单向性，未来对相同键的搜索可能会在查询最近的节点之前命中缓存的条目。在某个键非常流行的时候，系统可能会在许多节点上缓存它。。为了避免“过度缓存”，我们将任何节点数据库中的键值对的过期时间设置为与当前节点和ID最接近的节点之间的节点数量成指数反比。虽然简单的LRU清除将导致类似的生存期分布，但是没有选择缓存大小的天生方法，因为节点不知道系统将存储多少值。 桶中内容经常会保持最新，这是由于通过节点传输的请求流量造成的。为了避免在没有通信量的情况下出现病态情况，每个节点需要在某个桶所在范围内一个小时没有执行节点查找时进行刷新。刷新意味着在桶的范围内随机选择一个ID，并对该ID执行节点搜索。 要加入网络，节点u必须与已经参与其中的节点w有联系。然后，u对自己的节点ID执行节点查找。最后，u刷新所有k桶。在刷新期间，u都填充自己的k桶，并根据需要将自己插入其他节点的k桶中。 路由表根据协议，Kademlia的基本路由表结构相当简单，不过在处理高度不平衡的树时需要稍作改进。路由表是一个二叉树，它的叶子是k桶。每个k桶包含一些节点，它们的id具有一些公共前缀。前缀是k桶在二叉树中的位置。因此每个k桶覆盖ID空间的某个范围，所有k桶一起覆盖整个160位ID空间，没有重叠。 路由树中的节点根据需要动态分配。图4说明了这个过程。最开始，一个节点u的路由树只有一个节点，一个k桶覆盖整个ID空间。当u获得一个新的连接时，他就会将其插入适当的k桶。如果该桶未满，只需简单插入。反之，如果k桶的范围包含u自己的ID，那么这个bucket就会被分成两个新桶，旧的内容被划分到这两个桶中，然后重复插入尝试。如果k桶已满，且不包含u的ID，则直接丢弃新的信息。 一个复杂的情况出现在高度不平衡的树中。假设节点u加入系统，并且是ID从000开始的惟一节点。进一步假设系统已经有超过k个前缀为001的节点。每个带001前缀的节点将有一个空的应该将u插入其中的k桶，但是u在对其k桶进行更新是只会通知到其中k个节点。为了避免这个问题，Kademlia节点将所有有效的联系人保存在至少k个节点大小的子树中，即使这需要分割桶，而节点本身的ID并不驻留在桶中。图5显示了这些额外的分割。当 u 更新这些分割过的 buckets 时，所有具有 001 前缀的节点都会得到通知。 高效的key重发布为了确保键值对的持久性，节点必须定期重新发布key。否则，有两种情况会导致对有效 key 的查询失败。首先，在发布时，最初获得键值对的k个节点中的一些会离开网络。其次，新加入节点的 ID 相比键值对的原始发布节点，可能距离该key更近一些。在这两种情况下，拥有键值对的节点必须要对其进行重新发布，这样就再次保证了从距离该 key 最近的 k 个节点上可以获取该 key 。 为了对节点离开造成的问题的弥补， Kademlia 每一小时就对每个键值对进行重新发布。这种实现会导致很多消息往来，存储键值对的k个节点每小时都会进行一次节点查询，饭后进行k-1出STORErpc调用。幸运的是，可以对这种过程进行优化。首先，当一个节点收到一个针对某个键值对的STORE rpc时，他可以认为该rpc也发送给了其他k-1个节点，因此他就不会重新发布键值对。这就保证了只要重新发布间隔不是精确同步的，对于任何一个键值对来说，每小时只会有一个节点对其进行重新发布。 第二个优化是避免在重新发布key之前进行节点查找。如2.4小节所示，为了解决不平衡树，节点在需要时可以分裂k桶以保持其具有关于一个节点个数超过k的边缘子树的全部知识。在重新发布键值对之前，如果节点u更新了该字数中k个节点的所有k桶，那么他将自动获取关于某个key值最近的k个节点信息。对于这些桶的更新代价可以分摊到许多key的重新发布上。 要想知道为何在对规模大于k的子树中的桶进行更新后，就无需再进行节点查询操作，就得考虑两种情况。如果要被重新发布的key位于该子树覆盖的ID区间内，那么由于该子树的规模至少为 k ，并且 u 具有关于该子树的全部知识，因此u一定知道距离该key最近的 k 个节点。另一方面，如果key位于子树范围之外，而u是距离该key最近的k个节点之一，那么按照 u 的k桶规则，所有距离该key比子树更近一些的区间中的元素都少于k。因此， u 将知道这些k桶中的所有节点，再加上关于子树的知识，就可以得到距离该 key 最近的 k 个节点。 当一个新节点加入系统时，对于每个 key-vaule 对来说，如果该节点为其 k 个最近节点之一，那么必须对其进行存储。系统中原有的节点同样可以通过其边缘子树的完整知识，知道哪些键值对需要存储在该新增节点上。每个了解到新节点的节点都会发起 STORE RPC 把相关的 key-value 对传送到新节点之上。为了避免重复的 STORE RPC ，只有那些自身 ID 比其他节点 ID 更接近 key 的节点才会进行 key-value 对的传送。 实现注意事项在本小节中，我们将介绍两个用来改进 Kademlia 实现性能的重要技术。 优化联系记录对于k桶最基本的属性是能够提供LRU检查，并且在不丢失任何有效信息的情况下删除无效信息。如2.2节所述，如果一个k桶已满，他会在收到该桶范围内的任何一个位置节点的消息时发送一条PING。这个PING用来检测最近最少使用的节点是否仍然有效。如果无效，新的节点为替代带旧的节点。不幸的是，这种行为会导致大量的ping消息充斥在网络中 为了减少这些流量，Kademlia会延迟这个探测行为，直到要发送一条有用的消息给他们时。当一个节点收到一个未知节点的消息时，如果所在的k桶已满，节点会把它放在一个置换缓存中，当节点下次查询是，对于无效的节点会被用缓存中的节点替换。缓存中的节点时按照时间排序的，最近的节点有最高的优先级。 有一个和Kademlia使用UDP相关的问题。当网络丢包时，会丢失一些有效节点的信息。通常丢包意味着网络阻塞，所以Kademlia会锁定那些未响应的节点，并在一个以指数增长的退避时间间隔内不向其发送任何消息。因为在Kademlia查询过程中，大部分情况下只需联系到 k 个节点中的一个，所以一般情况下，系统不会向同一节点重传被丢弃的 RPCs 如果连续五条消息都没有响应，则认为是过期的。如果k桶不满，或缓存为空，那么Kademlia只是将过期信息打上标记，而不是立即清除，这就保证了节点出现短暂的网络故障时，不会完全清除其k桶 加速查询另一个优化是用过增加路由表大小来减少查询的步数。从概念上讲，可以考虑每次使用b位ID而不是一位。和前面介绍一样，期望的步数是log2n。如果把路由表扩大到2^blog2^b n个k桶，我们可以减少步数到log2^b n 2.4小节较少了当Kademlia节点的k桶满且其区间包含了节点自己ID是，如何去分裂该k桶。然而，在实现中，也会把不包含节点自己ID的区间分裂成b-1层。比如，如果b=2，不包含节点ID的那一半会分类一次。如果b=3，会分裂两层，最多四个区间，以此类推。大致的分裂规则是，如果一个满的k桶包含了节点自身的ID或其在路由树中的深度d满足d=O(mod b)，就会被分裂，当前实现是b=5 虽然基于 XOR 的路由算法和 Pastry、 Tapestry以及 Plaxton 分布式搜素算法中第一阶段的路由算法很相似，但是当它们一般化到 b&gt;1 时就都变得非常复杂。如果没有基于XOR的拓扑，就需要另外使用一个算法结构来从具有相同前缀但是后 b 位又不同的节点中找出目标节点。这三个算法采用了不同的方法来解决这个问题，各具缺点；除了大小为O(2^b log2^b n)的主路由表外，它们都需要一个大小为O(2^b)的二级路由表。这增加了启动和维护的成本，也使协议变得复杂，并且对于Pastry和Tapestry来说，也使得对其进行正确性和一致性方面的规范分析变得困难或不可能。有一个针对Plaxton的证明，但是该系统难以适应像 P2P 这样的高故障概率环境。 题图来自unsplash: https://unsplash.com/photos/phIFdC6lA4E]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非对称加密算法与数字签名]]></title>
    <url>%2F2019%2F03%2F31%2F%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%2F</url>
    <content type="text"><![CDATA[RSA算法背景RSA是一种非对称加密算法，该算法在1977年由Ron Rivest、Adi Shamir和Leonard Adleman三人提出，算法一起三人姓氏开头字母命名。 对极大整数做因数分解的难度决定了RSA算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA算法愈可靠。假如有人找到一种快速因数分解的算法的话，那么用RSA加密的信息的可靠性就肯定会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的RSA钥匙才可能被强力方式解破。到当前为止，世界上还没有任何可靠的攻击RSA算法的方式。只要其钥匙的长度足够长，用RSA加密的信息实际上是不能被解破的。 算法流程RSA算法本身比较简单，基本流程如下： 选择两个大素数p和q，p不等于q 计算N = p*q 令r=(p-1)(q-1) 寻找一个小于r的的整数e，使e与r互质 寻找一个整数d，使 (d*e) mod r = 1 (N,e)是公钥，(N,d)是私钥 加密时，若明文为P，则密文C = P^e mod N 解密时，P = C^d mod N 举例1234567取 p = 7，Q = 17n = p*q = 119r = 6 * 16 = 96取e = 5取d = 77假设明文为10，密文c = 10^e mod n = 40解密： 40^d mod n = 10 RSA安全性分析回顾整个算法。我们公开的是公钥e和n，保密的是私钥d，私钥是由e和r构成的。由于e是公开的，所以攻击者需要求得r。一个途径就是根据公开的n求得p和q就得到了r。但是p和q是很大的素数，导致n也很大，所以因数分解异常困难，有数学分析证明，如果n能达到100位数，那么正确求得q和p需要数十年的时间。 速度毫无疑问，由于涉及大量大数运算，RSA加密速度很慢。一种有效的方法是加密的一方使用一种可靠的对称加密算法加密明文，然后用RSA加密较短的秘钥，最后连同RSA加密的密文和对称加密算法加密的密文一同传输。 数字签名RSA加密算法分公钥秘钥和私钥密码。用RSA进行数字签名的步骤如下 发送方A对消息M进行摘要得到M1 A用自己的私钥对摘要进行加密，得到数字签名DS A将消息M和数字签名DS一同发送给B B对消息M进行摘要得到M2 B用A的公钥对数字签名解密得到M1 对比M2和M1是否相等来判断消息是否完整或被篡改 使用加解密这里用go语言进行演示（其后所有实例完整代码见这里），先看加解密，基本思想就是公钥加密私钥解密12345678910111213141516171819202122232425func main() &#123; read:=rand.Reader privKey,err:=rsa.GenerateKey(read,1024) if err != nil&#123; log.Fatalln(err.Error()) &#125; pubKey := privKey.PublicKey fmt.Println("N:",privKey.N) fmt.Println("公钥E:",privKey.E) fmt.Println("私钥D",privKey.D) plainText := "helloworld5645你好" ciphertext,err:=rsa.EncryptPKCS1v15(read,&amp;pubKey,[]byte(plainText)) if err != nil&#123; log.Fatalln(err.Error()) &#125; fmt.Println(hexToString(ciphertext)) result,err:=rsa.DecryptPKCS1v15(read,privKey,ciphertext) if err != nil&#123; log.Fatalln(err.Error()) &#125; fmt.Println(string(result))&#125; 上面代码中GenerateKey是随机生成一对秘钥，公钥是和私钥相对应的，通过查看源码可以知道公钥的结构体就是包含一个大整数N和一个整数E，私钥除了记录了公钥信息，还记录了一个大整数D就是私钥。代码中使用的加密方法是EncryptPKCS1v15，PKCS是公钥加密标准(Public-Key Cryptography Standards ),PKCS1就是一系列标准的第一个，常记做PKCS#1，也即是RSA加密标准。v15表示1.5版本，详见文档 除了EncryptPKCS1v15的一套加解密方法外，还有一套OAEP方法，是另外一种填充方式，详见文档,用法如下：12ciphertext,err:=rsa.EncryptOAEP(sha256.New(),read,&amp;pubKey,[]byte(plainText),[]byte("hi"))result,err:=rsa.DecryptOAEP(sha256.New(),read,privKey,ciphertext,[]byte("hi")) 值得一提的是在加密时可以指定一个标签，解密时不但要秘钥正确，标签也要对应，否则无法解密，标签可以为空 数字签名数字签名的签名与验证基本思路就是私钥签名，公钥验证123456789101112131415161718192021222324252627282930313233343536func main() &#123; read:=rand.Reader privKey,err:=rsa.GenerateKey(read,1024) if err != nil&#123; log.Fatalln(err.Error()) &#125; pubKey := privKey.PublicKey text := "helloworld5645你好" signature1,err:=rsa.SignPKCS1v15(read,privKey,crypto.Hash(0),[]byte(text)) if err != nil&#123; log.Fatalln(err.Error()) &#125; fmt.Println("signature1:",hex.EncodeToString(signature1)) hashed := sha256.Sum256([]byte(text)) signature2,err:=rsa.SignPKCS1v15(read,privKey,crypto.SHA256,hashed[:]) if err != nil&#123; log.Fatalln(err.Error()) &#125; fmt.Println("signature2:",hex.EncodeToString(signature2)) err=rsa.VerifyPKCS1v15(&amp;pubKey,crypto.Hash(0),[]byte(text),signature1) if err != nil &#123; fmt.Println("签名验证失败") &#125;else &#123; fmt.Println("签名验证成功") &#125; err=rsa.VerifyPKCS1v15(&amp;pubKey,crypto.SHA256,hashed[:],signature2) if err != nil &#123; fmt.Println("签名验证失败") &#125;else &#123; fmt.Println("签名验证成功") &#125;&#125; 首先还是用GenerateKey生成一对秘钥，然后使用SignPKCS1v15进行签名，由于非对称加密的效率问题，官方强烈建议对原文进行摘要后在进行签名，这是需要在第三个参数中指定所用的hash函数，如果不摘要，则用0表示。验证也是一样道理，使用VerifyPKCS1v15函数，传入要验证的内容即可。注意使用的签名和验证函数以一对PKCS1v15后缀的，和加解密一样这是用PKCS1v15标准的。还有一对使用PSS规范的方法，用法基本一样这里不再举例。 DSA算法先介绍一下DSA的一些基本变量123456p ：长度为L的素数，L是64的倍数q ：(p-1)的N位素数因子g ：h^((p-1)/q) mod p ,h是小于p-1的数，g需要大于1x ：小于q的数y ：g^x mod pH ：摘要算法 在以上变量中(p,q,g,y)是公开的，即公钥，x是私钥，签名过程如下（m是消息） 发送方A随机选择一个小于q的随机数k，作为临时秘钥 r=(g^k mod p) mod q s=((1/k)*(H(m)+xr)) mod q r与s作为数字签名连同信息m发送给接收方B B进行如下计算 w = (1/s) mod q u1 = (H(m) * w) mod q u2 = (rw) mod q v = ((g^u1 * y^u2) mod p) mod q 最后比较v与r是否相等验证数字签名 相比RSA可以用作加密，DSA只能用作签名，而且安全程度类似。 使用12345678910111213141516171819202122232425262728293031func main() &#123; read:=rand.Reader privKey:=new(dsa.PrivateKey) err:=dsa.GenerateParameters(&amp;privKey.Parameters,read,dsa.L1024N160) if err!=nil &#123; log.Fatalln(err.Error()) &#125; err=dsa.GenerateKey(privKey,read) if err!=nil &#123; log.Fatalln(err.Error()) &#125; fmt.Println("私钥：X =",privKey.X) fmt.Println("公钥：Y =",privKey.PublicKey.Y) fmt.Println("公共参数：") fmt.Println("p = ",privKey.PublicKey.P) fmt.Println("q = ",privKey.PublicKey.Q) fmt.Println("g = ",privKey.PublicKey.G) r,s,err:=dsa.Sign(read,privKey,[]byte("helloworld")) if err!=nil &#123; log.Fatalln(err.Error()) &#125; fmt.Println("签名结果：\nr=",r) fmt.Println("s=",s) b:=dsa.Verify(&amp;privKey.PublicKey,[]byte("helloworld"),r,s) if b &#123; fmt.Println("签名验证成功") &#125;else &#123; fmt.Println("签名验证失败") &#125;&#125; 首先是生成秘钥对，和rsa需要指定秘钥长度一样，这里要指定密钥对的参数长度，这里选用dsa.L1024N160，L表示p的长度，N表示q的长度。先用GenerateParameters生成参数，再用GenerateKey生成秘钥，然后用Sign签名得到r,s。最后用Verify验证。同样由于效率问题，签名时除非明文较短，否则不要直接对明文签名。注意Go语言中是按照FIPS 186-3标准实现的，详见文档 ElGamal算法和RSA类似，ElGamal是一种非对称加密算法，先介绍它的加密 秘钥生成 选取一个足够大的素数p 选取Zp的生成元E1 随机选取整数d，d小于p-2，计算E2 = E1^d mod p 私钥为d，公钥为(E1,E2,p) 加密 选取随机数r属于Zp-1 C1 = E1^r mod p C2 = M*E2^r mod p (M位明文) C1,C2就是密文 解密计算 (C2 * (C1^d)^-1) mod p = M 数字签名公钥为(E1,E2,p),私钥为d 发送方选择一个随机数r S1 = E1^r mod p S2 = ((M - dS1) r^-1) mod (p-1) S1,S2就是数字签名，M是原始消息，将三种发送给接收方 接收方进行如下计算 V1 = E1 ^ M mod p V2 = (E2^S1 * S1^S2) mod p 比较v1与v2是否相等来进行验证 ECC算法ECC即EllipseCurve Cryptography，全称椭圆曲线加密。是一种基于椭圆曲线数学的公钥密码。与传统的基于大质数因子分解困难性的加密方法不同，ECC 依赖于解决椭圆曲线离散对数问题的困难性。关于椭圆曲线的知识见这里：ECC椭圆曲线详解 加解密过程 发送方A选择一条曲线E，同时选择曲线上一点G作为基点，基点G的阶数为n A选择一个私钥d，d&lt;n。生成公钥K = dG A将E、K和G传给接收方B B收到信息后，将明文编码到一点M（编码方式可自由协商），并产生随机数r，r&lt;n B进行如下计算 C1 = M+rK C2 = rG C1与C2就是密文 A收到密文后进行如下解密：M = C1 - dC2 数字签名使用ECC进行的数字签名被称为ECDSA。基本过程如下， 依旧选择一条曲线E，同时选择曲线上一点G作为基点，基点G的阶数为n 选择一个私钥d，d&lt;n,计算公钥Q = dG 首先计算信息的摘要e 随机选择一个数k，k&lt;n 计算点(x1,y1) = kG 计算r = x1 mod n，如果r=0，回到第4步 计算s = k^-1(e + rd) mod n，如果s = 0，回到第4步 r和s就是签名值 验证如下： 收到消息m和签名值r，s后进行如下计算 先计算摘要e 计算w = s^-1 mod n 计算u1 = ew mod n 计算u2 = rw mod n 计算点(x1,y1) = u1G+u2Q 判断r是否等于x1 密钥协商之前我们讲过Diffie-Hellman密钥协商算法，基于的是大数分解难题，而基于ECC也有一种密钥协商算法，称为ECDH，思想是和Diffie-Hellman类似的，基本流程如下： A,B双方协商一条椭圆曲线及基点G，这些数据是可以明文传播的 A计算自己的公钥和私钥，即da与Da，其中Da=da*G B计算自己的公钥和私钥，即db与Db，其中Db=db*G 双方交换公钥 A计算密钥Sa=da*Db B计算密钥Sb=db*Da 可以证明Sa=Sb：Sa=da*Db=da*db*G，Sb=db*Da=db*da*G 使用下面例子是ecdsa1234567891011121314151617181920func main() &#123; read:=rand.Reader priv,err:=ecdsa.GenerateKey(elliptic.P256(),read) if err != nil &#123; log.Fatalln(err.Error()) &#125; r,s,err:=ecdsa.Sign(read,priv,[]byte("hello")) if err != nil &#123; log.Fatalln(err.Error()) &#125; fmt.Println("签名结果") fmt.Println("r = ",r) fmt.Println("s = ",s) b := ecdsa.Verify(&amp;priv.PublicKey,[]byte("hello"),r,s) if b &#123; fmt.Println("签名验证成功") &#125;else &#123; fmt.Println("签名验证失败") &#125;&#125; 虽然标准包中没有提供ecc的实现，但是有elliptic包，提供了椭圆曲线的一些基本运算，再参考ecdsa可以自行设计加解密算法。对于ecdh在以太坊的ecies有实现123456789101112131415161718func (prv *PrivateKey) GenerateShared(pub *PublicKey, skLen, macLen int) (sk []byte, err error) &#123; if prv.PublicKey.Curve != pub.Curve &#123; return nil, ErrInvalidCurve &#125; if skLen+macLen &gt; MaxSharedKeyLength(pub) &#123; return nil, ErrSharedKeyTooBig &#125; x, _ := pub.Curve.ScalarMult(pub.X, pub.Y, prv.D.Bytes()) if x == nil &#123; return nil, ErrSharedKeyIsPointAtInfinity &#125; sk = make([]byte, skLen+macLen) skBytes := x.Bytes() copy(sk[len(sk)-len(skBytes):], skBytes) return sk, nil&#125; 秘钥格式一些规范对RSA秘钥的格式也有一些要求，具体格式语法就不介绍了，go语言提供方便的转换接口 密钥编码12345678910111213141516171819202122func main() &#123; read:=rand.Reader privKey,err:=rsa.GenerateKey(read,1024) if err != nil&#123; log.Fatalln(err.Error()) &#125; pubKey := privKey.PublicKey encodePrivKey := x509.MarshalPKCS1PrivateKey(privKey) block1:=pem.Block&#123; Type: "RSA PRIVATE KEY", Bytes: encodePrivKey, &#125; pem.Encode(os.Stdout,&amp;block1) encodePubvKey := x509.MarshalPKCS1PublicKey(&amp;pubKey) block2:=pem.Block&#123; Type: "RSA PUBLIC KEY", Bytes: encodePubvKey, &#125; pem.Encode(os.Stdout,&amp;block2)&#125; 首先利用x509包中的MarshalPKCS1PrivateKey方法对秘钥进行序列化，然后利用pem包进行编码，编码前首先要用Block对秘钥进行包装，主要是指定Type，最后生成数据如下123456789101112131415-----BEGIN RSA PRIVATE KEY-----MIICXQIBAAKBgQDQ6x6qUOn6lct8npBizj9thh9RrPi35wez7EHmRLH9QYhJqtJVp/9B5ITgwXR1VBM4shJ3RvNUj+diT8ox0FUuw4+3EZqW5tSgoQGzV3Go+PX+4p21u874GOqYtFUDmhQjMuh4NtsBfnClGsf9pUmInjxsVKKfdUbYZxLKzGK2DwIDAQABAoGAMeyNtmuBjlUvfEcz/7iDpbuQTmdEREYcLB3AHbO6yOdZFymP+9IaiHeAXWk9WDBQK5M6IHC/Ay0kQPUKP18mi4hXKm4hRql3B3rJoV6qiP3/c5hYakhSSPouPmoC30a1ERWnKlH9YSMDOhYUY1c02onYsY9AxM18N27AOYLSMWECQQD75aGjjYY+lDKbUXsqSLgL4hbPTswKjYJU6ps6hkJKEklMI5rQk/J5yLuji7USJdmGJziZin41vGx/NSQlsUuRAkEA1FJGYeC4idHhYZ5NIKgSefWn9+lgIDzxjIAivcViTFLd9bz4UcSQU+FzEHEkA78C0y3g30NqAGkspVuxfO7XnwJBALO26DSM0xswlk5zuqC3Uv+/ZTCwciiRP0wgOXFuujqogzzcJibrdtJmYWDUWvJAqMnqj5oT0em6rdmv60MtE9ECQDvGqiAWV34dw9lq6wX9q64Adni6kKCi59KJpL5O2vzn+6uat0K2F3g2KeIAKIaReWchLIVPAoH5GmO3rAGjcLsCQQDMDtQxU3DTcrLyKgx+N3n4jqkDOsK/iiotvdHFrQvrdPJPsUtSsFa0ejvIO6Mf0d9h4fi4vNIIIIS1QjpAkOE4-----END RSA PRIVATE KEY----- 秘钥解码给出一段上文表示秘钥可以用下面方法解码123456789101112131415161718192021222324func main() &#123; read:=rand.Reader privKey,err:=rsa.GenerateKey(read,1024) if err != nil&#123; log.Fatalln(err.Error()) &#125; encodePrivKey := x509.MarshalPKCS1PrivateKey(privKey) block1:=pem.Block&#123; Type: "RSA PRIVATE KEY", Bytes: encodePrivKey, &#125; file, err := os.Create("priv.pem") pem.Encode(file,&amp;block1) key,err:=ioutil.ReadFile("priv.pem") block,_:=pem.Decode(key) if block ==nil &#123; log.Fatalln("nil") &#125; privkey2,err:=x509.ParsePKCS1PrivateKey(block.Bytes) fmt.Println(privKey.D.Cmp(privkey2.D)==0) fmt.Println(privKey.N.Cmp(privkey2.N)==0)&#125; 基本就是编码的逆过程，先decode再Parse。 其他除了可以编解码PKCS1规范的秘钥，还提供了MarshalPKCS8PrivateKey、MarshalECPrivateKey与 MarshalPKIXPublicKey等，用于支持不同的密钥或规范 题图来自unsplash：https://unsplash.com/photos/KidY3t8O4PE]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grpc学习]]></title>
    <url>%2F2019%2F03%2F31%2Fgrpc%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[背景gRPC是一个高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf序列化协议开发，且支持众多开发语言。关于ProtoBuf的详细内容可以参考我的这篇文章 根据官方页面显示，目前支持的语言如下： 也就是说在这些语言平台上，完全可以用grpc实现rpc通信，同时又由于protobuf的编码效率高，所以可以实现替代jsonrpc HelloWorld 国际惯例，我们先用go语言写一个grpc版本的hellworld。首先要安装grpc库1go get -u google.golang.org/grpc protobuf定义及编译首先定义protobuf文件如下：1234567891011121314151617181920syntax = &quot;proto3&quot;;option java_multiple_files = true;option java_package = &quot;io.grpc.examples.helloworld&quot;;option java_outer_classname = &quot;HelloWorldProto&quot;;package helloworld;service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;message HelloRequest &#123; string name = 1;&#125;message HelloReply &#123; string msg = 1;&#125; 几点需要注意的，首先protobuf版本为proto3，其中定义了两个message，分别用于请求和响应，又定义了一个service，其中有一个rpc方法，接受请求返回响应 然后执行下面命令生成pb.go文件1protoc ./helloworld/helloworld.proto --go_out=plugins=grpc:./ 我们看一下生成的go代码，首先定义的两个message各自成为一个struct123456789101112type HelloRequest struct &#123; Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"` XXX_NoUnkeyedLiteral struct&#123;&#125; `json:"-"` XXX_unrecognized []byte `json:"-"` XXX_sizecache int32 `json:"-"`&#125;type HelloReply struct &#123; Msg string `protobuf:"bytes,1,opt,name=msg,proto3" json:"msg,omitempty"` XXX_NoUnkeyedLiteral struct&#123;&#125; `json:"-"` XXX_unrecognized []byte `json:"-"` XXX_sizecache int32 `json:"-"`&#125; 这两个struct中含有我们定义message时定义的成员变量。之后我们还定义了一个名为Greeter的服务，它变成了一个interface123type GreeterServer interface &#123; SayHello(context.Context, *HelloRequest) (*HelloReply, error)&#125; 这就是要我们写服务时实现这个接口才能正确定义grpc 服务端服务端代码如下1234567891011121314151617181920type server struct &#123;&#125;func (s *server)SayHello(ctx context.Context, in *helloworld.HelloRequest) (*helloworld.HelloReply, error)&#123; fmt.Println("received:",in.Name) return &amp;helloworld.HelloReply&#123;Msg:"hello " + in.Name&#125;,nil&#125;func main() &#123; lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; s:=grpc.NewServer() helloworld.RegisterGreeterServer(s,&amp;server&#123;&#125;) if err := s.Serve(lis); err != nil &#123; log.Fatalf("failed to serve: %v", err) &#125;&#125; 和写普通rpc代码类型，先定义一个服务类，不过这里要实现我们定义的接口。在main入口里可以发现grpc还是基于tcp传输的，这里的逻辑是定义tcp连接和grpc服务，然后将我们刚才写的服务类注册到grpc中，最后用grpc提供的方法去接管tcp连接即可 客户端客户端代码如下123456789101112131415161718func main() &#123; conn,err:=grpc.Dial("127.0.0.1:1234",grpc.WithInsecure()) if err!=nil &#123; log.Fatal("dial:",err.Error()) &#125; defer conn.Close() c:=helloworld.NewGreeterClient(conn) ctx,cancel:=context.WithTimeout(context.Background(),time.Second) defer cancel() r,err:=c.SayHello(ctx,&amp;helloworld.HelloRequest&#123;Name:"world"&#125;) if err!=nil &#123; log.Fatal("dial:",err.Error()) &#125; fmt.Println("greeting",r.Msg)&#125; 可能是为了降低大家学习成本，grpc的接口设置和go rpc标准包类似。首先利用grpc提供的接口去发起一个连接。接下来，grpc很方便的帮我们包装了一个client类，其中有我们可以调用的rpc方法，省去了之前用字符串表示的麻烦，随后就像函数调用一样去调用远程方法即可，返回一个响应，然后我们从响应中读数据。 有一个小问题需要注意的是，用grpc去发起连接时，目标地址如果是本机地址的话不能像go标准包那样简写为”:1234”，需要像上面代码那样写出全名。 最后先运行服务端代码再运行客户端代码，就成功实现利用grpc通信。该节示例代码见这里 grpc相关概念服务类型 grpc定义了四种服务 单项rpc就是最普通的请求响应模式12rpc SayHello(HelloRequest) returns (HelloResponse)&#123;&#125; 服务端流式rpc客户端向服务端发起一个请求，服务端返回一个数据流响应12rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse)&#123;&#125; 客户端流式rpc客户端向服务端发送数据流请求，客户端仅返回一个响应12rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) &#123;&#125; 双向流式rpc客户端与服务端都以数据流形式通信12rpc BidiHello(stream HelloRequest) returns (stream HelloResponse)&#123;&#125; RPC终止与取消在客户端与服务端，二者对调用的成功与否是独立，可能会出现不同的判断。客户端与服务端可在任何时间取消一个rpc，rpc会立即终止，但只影响之后状态，取消前完成的不会回滚。 超时客户端可以指定超时时间，超过这个时间没有响应测返回DEADLINE_EXCEEDED错误，服务端也可查询还有多久去完成响应。 详细内容实际上上面的helloworld已经可以说明grpc的基本使用，下面只是针对另外几种rpc服务类型进行介绍，这里引用官方的例子，完整代码见这里。 protobuf定义12345678910111213141516171819202122232425262728293031323334353637383940414243service RouteGuide &#123; rpc GetFeature(Point) returns (Feature) &#123;&#125; rpc ListFeatures(Rectangle) returns (stream Feature) &#123;&#125; rpc RecordRoute(stream Point) returns (RouteSummary) &#123;&#125; rpc RouteChat(stream RouteNote) returns (stream RouteNote) &#123;&#125;&#125;message Point &#123; int32 latitude = 1; int32 longitude = 2;&#125;message Rectangle &#123; Point lo = 1; Point hi = 2;&#125;message Feature &#123; string name = 1; Point location = 2;&#125;message RouteNote &#123; Point location = 1; string message = 2;&#125;message RouteSummary &#123; int32 point_count = 1; int32 feature_count = 2; int32 distance = 3; int32 elapsed_time = 4;&#125; 如上所述，我们对四种rpc分别定义了一个方法。编译命令如下1protoc --go_out=plugins=grpc:./ route/route.proto 创建服务端回看刚才生成的代码，有这样一个接口123456type RouteGuideServer interface &#123; GetFeature(context.Context, *Point) (*Feature, error) ListFeatures(*Rectangle, RouteGuide_ListFeaturesServer) error RecordRoute(RouteGuide_RecordRouteServer) error RouteChat(RouteGuide_RouteChatServer) error&#125; 我们的服务端首先要创建一个类实现这个接口 普通rpc12345678func (s *routeGuideServer)GetFeature(ctx context.Context, point *route.Point) (*route.Feature, error)&#123; for _,feature:=range s.savedFeatures&#123; if proto.Equal(feature.Location,point)&#123; return feature,nil &#125; &#125; return &amp;route.Feature&#123;Location:point&#125;,nil&#125; 很简单，参数中的Point和Feature都是我们定义的message，通过输入一个point，然后遍历feature集合，查找符合条件的feature。注意比较两个message可以使用proto包提供的equal方法 服务端流式rpc12345678910func (s *routeGuideServer)ListFeatures(rect *route.Rectangle, stream route.RouteGuide_ListFeaturesServer) error&#123; for _,feature := range s.savedFeatures&#123; if inRange(feature.Location,rect) &#123; if err:=stream.Send(feature);err!=nil&#123; return err &#125; &#125; &#125; return nil&#125; 形象的说，这种rpc就是向服务端发送一个请求，服务端以流的形式返回数据。如代码所示，我们指定一个区域，然后判断所有保存的feature是否在区域内，每判断一个，如果符合条件就以send形式发出。grpc为我们做了很形象的包装，对于输出流，我们只需send即可，不必考虑缓存，同步之类的问题，非常方便。唯一需要注意的是，每send一个数据，就需要判断是否报错，然后随时停止。 客户端流式rpc123456789101112131415161718192021222324252627282930func (s *routeGuideServer)RecordRoute(stream route.RouteGuide_RecordRouteServer) error&#123; var pointCount, featureCount, distance int32 var lastPoint *route.Point startTime := time.Now() for &#123; point,err:=stream.Recv() if err == io.EOF&#123; endTime := time.Now() return stream.SendAndClose(&amp;route.RouteSummary&#123; PointCount:pointCount, FeatureCount:featureCount, Distance:distance, ElapsedTime:int32(endTime.Sub(startTime).Seconds()), &#125;) &#125; if err!=nil&#123; return err &#125; pointCount++ for _,feature := range s.savedFeatures&#123; if proto.Equal(feature.Location,point)&#123; featureCount++ &#125; &#125; if lastPoint != nil&#123; distance += calcDistance(lastPoint,point) &#125; lastPoint = point &#125;&#125; 我们定义的是客户端给服务端发送流式数据，然后服务端返回一个响应。如代码所示，grpc也给我提供了一个形象的封装，对于输入流，我们只需要Recv即可，然后判断输入流是否结束，通过EOF标志位，如果结束返回一个响应。注意这里返回的方法是通过调用SendAndClose方法。通过查看SendAndClose实现，他和上面的send方法一样，都是调用了SendMsg方法。 这段实现的大概意思是，客户端发送一个流，流中包含多个point数据的路径，我们遍历这个流，判断每个point是否在已有的feature集合中，然后计算路径长度，最后返回一个RouteSummary信息。 双向流式rpc123456789101112131415161718192021222324func (s *routeGuideServer)RouteChat(stream route.RouteGuide_RouteChatServer) error&#123; for&#123; in,err:=stream.Recv() if err==io.EOF&#123; return nil &#125; if err!=nil&#123; return err &#125; key := serialize(in.Location) s.mu.Lock() s.routeNotes[key] = append(s.routeNotes[key],in) rn :=make([]*route.RouteNote,len(s.routeNotes[key])) copy(rn,s.routeNotes[key]) s.mu.Unlock() for _,note:=range rn&#123; if err:=stream.Send(note);err!=nil &#123; return err &#125; &#125; &#125;&#125; 既然是双向流，那么就是即能收也能发，如代码所示，每次循环通过Recv从客户端接受一个数据，经过一系列处理后通过send给客户端发送数据。最后知道客户端发送完毕或中间报错为止 最后服务端main方法如下123456789101112131415161718func newServer() *routeGuideServer &#123; s := &amp;routeGuideServer&#123;routeNotes: make(map[string][]*route.RouteNote)&#125; data := exampleData if err := json.Unmarshal(data, &amp;s.savedFeatures); err != nil &#123; log.Fatalf("Failed to load default features: %v", err) &#125; return s&#125;func main() &#123; lis,err:=net.Listen("tcp",":1234") if err!=nil&#123; log.Fatal("listen error:",err.Error()) &#125; server:=grpc.NewServer() route.RegisterRouteGuideServer(server,newServer()) server.Serve(lis)&#125; 和helloworld一样，显示创建grpc服务实例，然后注册服务，最后让grpc接管tcp连接 创建客户端首先创建连接部分还是和helloworld一样123456conn,err:=grpc.Dial("127.0.0.1:1234",grpc.WithInsecure())if err!=nil&#123; log.Fatal("dail error",err.Error())&#125;defer conn.Close()client:=pb.NewRouteGuideClient(conn) 我们接下来还是对四种服务进行调用 普通rpc123456789101112printFeature(client, &amp;pb.Point&#123;Latitude: 409146138, Longitude: -746188906&#125;)func printFeature(client pb.RouteGuideClient, point *pb.Point) &#123; log.Printf("Getting feature for point (%d, %d)", point.Latitude, point.Longitude) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() feature, err := client.GetFeature(ctx, point) if err != nil &#123; log.Fatalf("%v.GetFeatures(_) = _, %v: ", client, err) &#125; log.Println(feature)&#125; 对于普通的rpc我们当做函数调用即可，输入一个point返回一个feature 服务端流式rpc123456789101112131415161718192021222324printFeatures(client, &amp;pb.Rectangle&#123; Lo: &amp;pb.Point&#123;Latitude: 400000000, Longitude: -750000000&#125;, Hi: &amp;pb.Point&#123;Latitude: 420000000, Longitude: -730000000&#125;,&#125;)func printFeatures(client pb.RouteGuideClient, rect *pb.Rectangle) &#123; log.Printf("Looking for features within %v", rect) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.ListFeatures(ctx, rect) if err != nil &#123; log.Fatalf("%v.ListFeatures(_) = _, %v", client, err) &#125; for &#123; feature, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; log.Fatalf("%v.ListFeatures(_) = _, %v", client, err) &#125; log.Println(feature) &#125;&#125; 前面说过，这种类型的rpc是客户端发送一个请求，服务端返回一个数据流。这里我们调用ListFeatures方法，给我们返回一个流，然后我们遍历这个流，通过Recv()一次接受一个数据，并通过EOF标志位判断流是否结束 客户端流式rpc123456789101112131415161718192021222324252627runRecordRoute(client)func runRecordRoute(client pb.RouteGuideClient) &#123; r := rand.New(rand.NewSource(time.Now().UnixNano())) pointCount := int(r.Int31n(100)) + 2 var points []*pb.Point for i := 0; i &lt; pointCount; i++ &#123; points = append(points, randomPoint(r)) &#125; log.Printf("Traversing %d points.", len(points)) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.RecordRoute(ctx) if err != nil &#123; log.Fatalf("%v.RecordRoute(_) = _, %v", client, err) &#125; for _, point := range points &#123; if err := stream.Send(point); err != nil &#123; log.Fatalf("%v.Send(%v) = %v", stream, point, err) &#125; &#125; reply, err := stream.CloseAndRecv() if err != nil &#123; log.Fatalf("%v.CloseAndRecv() got error %v, want %v", stream, err, nil) &#125; log.Printf("Route summary: %v", reply)&#125; 对于这种类型，客户端是发送一系列数据，而服务端返回一个响应，如上面代码所述，我们先随机一些point，然后通过send方法一个一个发送给客户端，发送完后，调用CloseAndRecv关闭流然后等待服务端响应。CloseAndRecv和服务端使用的SendAndClose相对应。 双向流式rpc12345678910111213141516171819202122232425262728293031323334353637383940runRouteChat(client)func runRouteChat(client pb.RouteGuideClient) &#123; notes := []*pb.RouteNote&#123; &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 1&#125;, Message: "First message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 2&#125;, Message: "Second message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 3&#125;, Message: "Third message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 1&#125;, Message: "Fourth message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 2&#125;, Message: "Fifth message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 3&#125;, Message: "Sixth message"&#125;, &#125; ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.RouteChat(ctx) if err != nil &#123; log.Fatalf("%v.RouteChat(_) = _, %v", client, err) &#125; waitc := make(chan struct&#123;&#125;) go func() &#123; for &#123; in, err := stream.Recv() if err == io.EOF &#123; // read done. close(waitc) return &#125; if err != nil &#123; log.Fatalf("Failed to receive a note : %v", err) &#125; log.Printf("Got message %s at point(%d, %d)", in.Message, in.Location.Latitude, in.Location.Longitude) &#125; &#125;() for _, note := range notes &#123; if err := stream.Send(note); err != nil &#123; log.Fatalf("Failed to send a note: %v", err) &#125; &#125; stream.CloseSend() &lt;-waitc&#125; 由于客户端与服务端都是收发流数据，在服务端是收到一个数据处理一个然后返回一个，所以我们在客户端不断的发送数据的同时，也启动一个goroutine去接受数据，在发送完数据后要关闭输出流。 总结 对于普通rpc，客户端就当做方法调用一样去调用某个远端的方法，服务端接受数据后按照返回参数返回值即可 对于服务端流式rpc，客户端通过调用方法发送一个数据，然后利用返回值stream去不断接受数据；而服务端在接受到请求后，不断用send发送数据。 对于客户端流式rpc，客户端通过调用方法获得一个stream后，不断的send发送数据，发送完毕后调用CloseAndRecv关闭输出流并等待响应；而服务端不断使用Recv去接受数据，接受完之后调用SendAndClose关闭输入流发送响应 对于双向流式rpc，客户端通过调用方法获得一个stream后，不断的send发送数据，并在发送的时候启动一个goroutine通过Recv接受数据；而服务端则不断的接受数据、处理数据、返回数据。客户端在发送完毕后注意通过CloseSend关闭输出流]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AES加密]]></title>
    <url>%2F2019%2F03%2F30%2FAES%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景全称Advanced Encryption Standard，即高级加密标准。又称Rijndael加密法。是一个用来替换DES的加密算法，在全世界已经广泛使用，官方文档。 算法简述AES算法支持的秘钥长度和明文块位128~256位（32位为步长），常用的组合是128位明文块和128位密文；128位明文块和256位密文。（严格地说，AES和Rijndael加密法并不完全一样，因为Rijndael加密法可以支持更大范围的区块和密钥长度：AES的区块长度固定为128比特，密钥长度则可以是128，192或256比特；而Rijndael使用的密钥和区块长度均可以是128，192或256比特。） AES密码使用了替换与置换思想，秘钥和明文块的长度决定了需要运行的轮数，最少是10轮，即秘钥和明文块都是128位。算法分为以下两个步骤 一次性初始化操作 轮次操作 本文以128位秘钥和128位明文块为标准介绍 一次性初始化操作扩展秘钥输入的秘钥长度为16字节，需要扩展到11个4*4的矩阵中。也就是说将16字节秘钥扩展为176字节。 秘钥扩展可以表示为下图 扩展出来的第一个矩阵就是输入矩阵，将输入矩阵每4字节记为一个字。以K0=a，k1=b，k2=c，k3=d为例，w0=abcd，依次类推。接着记w0，w1，w2，w3位w数组。用w数组扩展出剩余40个w。剩余40个w分别记为w4，w5，…，w43。其中每个wi都和w(i-1)以及w(i-4)有关，基本规则如下： 若i不是4的倍数，则wi = W(i-1) XOR w(i-4)。若i是4的倍数，wi = T(w(i-1)) XOR w(i-4).函数T流程如下图： T函数分为3部分：旋转，代换，常量异或： 旋转：将一个字中的四个字节循环左移1字节，如abcd变为bcda 代换：使用s盒代换，把每个字节的高四位作为行值，第四位作为列值在S盒寻找输出，S盒如下 常量异或：有10个常量，每轮取一个进行异或，这几个常量如下： 轮数 1 2 3 4 5 6 7 8 9 10 常量值 01 02 04 08 10 20 40 80 1B 36 简单示例12345678910111213141516假设初始秘钥分别为：00 01 02 ... 0F，则w0 = 00 01 02 03w1 = 04 05 06 07w2 = 08 09 0A 0Bw3 = 0C 0D 0E 0F为了计算w4，先计算T(w3):旋转得：0D 0E 0F 0CS盒替换得：D7 AB 76 FE常量异或得：D6 AB 76 FE将T函数输出再与w0异或得w4 = D6 AA 72 FDw5 = w4 XOR w1w6 = w5 XOR w2w7 = w6 XOR w3 明文初始化由于明文块也是128位，即16字节，左移也将这16个字节写位4*4的矩阵，列优先。之后与第一个秘钥对应字节进行异或运算。 轮次运算每一轮依次有以下几步 s盒替换就是将输入的矩阵每个元素进行s盒替换 旋转将矩阵第i行循环左移i个字节，如下列1234567891 5 9 132 6 10 143 7 11 154 8 12 16旋转后1 5 9 136 10 14 211 15 3 716 4 8 12 混合列操作将上一步的结果与常量矩阵相乘，运算规则如下1234567891011121314151617有常量矩阵 2 3 1 1A = 1 2 3 1 1 1 2 3 3 1 1 2有输入矩阵 b1 b5 b9 b13b = b2 b6 b10 b14 b3 b7 b11 b15 b4 b8 b12 b16则A*b结果的第一列如下c1 = (b1*2)XOR(b2*3)XOR(b3*1)XOR(b4*1)c1 = (b1*1)XOR(b2*2)XOR(b3*3)XOR(b4*1)c1 = (b1*1)XOR(b2*1)XOR(b3*2)XOR(b4*3)c1 = (b1*3)XOR(b2*1)XOR(b3*1)XOR(b4*2)实际上数学中的矩阵相乘类似，只不过相加改为了异或 结果还是一个4*4矩阵 秘钥异或将上步输出的矩阵与该轮对应的秘钥进行异或运算 总体流程如下（注意最后一轮没有列混合运算） 解密流程也如上图所示，就是反过来，其中s盒的逆如下 解密的逆列混淆用的是如下常数矩阵去乘以密文矩阵：12340E 0B 0D 0909 0E 0B 0D0D 09 0E 0B0B 0D 09 0E 题图来自unsplash：https://unsplash.com/photos/ARVFsI-32Uk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中rpc源码学习]]></title>
    <url>%2F2019%2F03%2F29%2Fgo-ethereum%E4%B8%ADrpc%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[背景RPC全称Remote Procedure Call，即远程过程调用是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。 运行时一次客户机对服务器的RPC调用，基本过程如下图： go语言中的rpcgo语言的标准包中以及有了对RPC的支持，分别在三个层面上即TCP、HTTP和JSONRPC上提供了支持。除了JSONRPC其余两种都只支持以go语言开发的客户端与服务器。 首先，在Go中一个正确的RPC函数应该满足下面要求 函数必须是可导出的（首字母大写） 必须有两个可导出类型的参数 第一个是接受的参数，第二个是返回参数 函数必须有一个error类型的返回值 例子如下：1func (t *T) MethodName(argType T1, replyType *T2) error HTTP RPC服务端代码123456789101112131415161718type HelloService struct &#123;&#125;func (p *HelloService)Hello(requset string,reply *string)error&#123; *reply = "hello " + requset return nil&#125;func main() &#123; rpc.Register(new(HelloService)) rpc.HandleHTTP() err:=http.ListenAndServe(":1234",nil) if err!=nil &#123; fmt.Println(err.Error()) &#125;&#125; 关键有两点，一个是定义供客户端调用的方法，另一个是注册服务，并使RPC托管http服务，最后正常启动http服务 客户端代码123456789func main() &#123; client,err:=rpc.DialHTTP("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; TPC RPC服务端代码12345678910111213func main() &#123; rpc.Register(new(HelloService)) lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; conn,err:=lis.Accept() if err!=nil &#123; log.Fatal("accept:",err.Error()) &#125; rpc.ServeConn(conn)&#125; 供远程调用的方法和前面的例子一样，不在重复，tcprpc和httprpc的不同点就是在于首先正常启动tcp监听，然后接收到的连接交给rpc即可 客户端代码123456789func main() &#123; client,err:=rpc.Dial("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; 和httprpc的唯一区别就是初始化客户端对象的方法不同 jsonRPC服务端代码12345678910111213func main() &#123; rpc.Register(new(HelloService)) lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; conn,err:=lis.Accept() if err!=nil &#123; log.Fatal("accept:",err.Error()) &#125; jsonrpc.ServeConn(conn)&#125; 相比较tcprpc只是在处理tcp连接时使用rpcjson提供的方法。 客户端代码123456789func main() &#123; client,err:=jsonrpc.Dial("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; 唯一区别也只是在创建client实例时的不同，使用jsonrpc提供的方法 由于tcprpc和httprpc都采用gob编码，所以不能跨语言使用，而jsonrpc采用的json格式编码，可以很方便的跨语言，这里提供一个go语言和java语言交互的例子，其中服务端由go语言编写，如上面所示，java编写的客户端如下：1234567891011121314151617181920212223242526272829303132333435public class ClientRequest &#123; public String method; public String[] params; public int id;&#125;public class ServerResponse &#123; public int id; public String result; public String error;&#125;public static void main(String[] args)&#123; try(Socket client = new Socket("127.0.0.1",1234))&#123; OutputStream out = client.getOutputStream(); Gson gson = new Gson(); ClientRequest request = new ClientRequest(); request.id = 1; request.method = "HelloService.Hello"; request.params = new String[]&#123;"hello"&#125;; out.write(gson.toJson(request).getBytes()); client.shutdownOutput(); InputStream in = client.getInputStream(); int len; byte[] buffer = new byte[1024]; StringBuilder sb = new StringBuilder(); while ((len = in.read(buffer))!=-1) sb.append(new String(buffer,0,len)); ServerResponse response = gson.fromJson(sb.toString(),ServerResponse.class); client.shutdownInput(); System.out.println(response.result); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;&#125; 还是基于TCP通信的，由于是借助json传输的，所以需要有json序列化和反序列化操作，且json格式要符合go语言的规定。go语言中规定请求的格式如下：12345678910111213//客户端请求type clientRequest struct&#123; Method string `json:"method"` Params [1]interface&#123;&#125; `json:"params"` Id uint64 `json:"id"`&#125;//服务端请求type serverRequest struct&#123; Method string `json:"method"` Params *json.RawMessage `json:"params"` Id *json.RawMessage `json:"id"`&#125; 规定响应的格式如下123456789101112//客户端响应type clientResponse struct&#123; Id uint64 `json:"id"` Result *json.RawMessage `json:"result"` Error interface&#123;&#125; `json:"error"`&#125;//服务端响应type serverResponse struct&#123; Id uint64 `json:"id"` Result interface&#123;&#125; `json:"result"` Error interface&#123;&#125; `json:"error"`&#125; 在跨语言交互时，要根据上面的定义，编写对应的json文件 go-ethereum中的rpc主要集中在rpc目录下 server.go服务创建与注册首先从服务端开始看，server的结构体以及创建如下123456789101112131415161718// go-ethereum\rpc\server.gotype Server struct &#123; services serviceRegistry idgen func() ID run int32 codecs mapset.Set&#125;type serviceRegistry struct &#123; mu sync.Mutex services map[string]service&#125;func NewServer() *Server &#123; server := &amp;Server&#123;idgen: randomIDGenerator(), codecs: mapset.NewSet(), run: 1&#125; rpcService := &amp;RPCService&#123;server&#125; //MetadataApi = "rpc" server.RegisterName(MetadataApi, rpcService) return server&#125; 结构体中services的类型是serviceRegistry实际上就是记录了所有注册的服务。run用来控制server的运行。codecs是一个set类型，存储所有编解码器。 在创建server时，randomIDGenerator()是一个id的随机生成器。随后调用RegisterName把自己的实例注册进去（RPCService包装了server类）1234567891011121314151617181920212223242526272829303132333435363738func (s *Server) RegisterName(name string, receiver interface&#123;&#125;) error &#123; return s.services.registerName(name, receiver)&#125;// go-ethereum\rpc\service.gofunc (r *serviceRegistry) registerName(name string, rcvr interface&#123;&#125;) error &#123; rcvrVal := reflect.ValueOf(rcvr) if name == "" &#123; return fmt.Errorf("no service name for type %s", rcvrVal.Type().String()) &#125; callbacks := suitableCallbacks(rcvrVal) if len(callbacks) == 0 &#123; return fmt.Errorf("service %T doesn't have any suitable methods/subscriptions to expose", rcvr) &#125; r.mu.Lock() defer r.mu.Unlock() if r.services == nil &#123; r.services = make(map[string]service) &#125; svc, ok := r.services[name] if !ok &#123; svc = service&#123; name: name, callbacks: make(map[string]*callback), subscriptions: make(map[string]*callback), &#125; r.services[name] = svc &#125; for name, cb := range callbacks &#123; if cb.isSubscribe &#123; svc.subscriptions[name] = cb &#125; else &#123; svc.callbacks[name] = cb &#125; &#125; return nil&#125; suitableCallbacks方法如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// go-ethereum\rpc\service.gofunc suitableCallbacks(receiver reflect.Value) map[string]*callback &#123; typ := receiver.Type() callbacks := make(map[string]*callback) for m := 0; m &lt; typ.NumMethod(); m++ &#123; method := typ.Method(m) if method.PkgPath != "" &#123; continue // method not exported &#125; cb := newCallback(receiver, method.Func) if cb == nil &#123; continue // function invalid &#125; name := formatName(method.Name) callbacks[name] = cb &#125; return callbacks&#125;func newCallback(receiver, fn reflect.Value) *callback &#123; fntype := fn.Type() c := &amp;callback&#123;fn: fn, rcvr: receiver, errPos: -1, isSubscribe: isPubSub(fntype)&#125; c.makeArgTypes() if !allExportedOrBuiltin(c.argTypes) &#123; return nil &#125; outs := make([]reflect.Type, fntype.NumOut()) for i := 0; i &lt; fntype.NumOut(); i++ &#123; outs[i] = fntype.Out(i) &#125; if len(outs) &gt; 2 || !allExportedOrBuiltin(outs) &#123; return nil &#125; switch &#123; case len(outs) == 1 &amp;&amp; isErrorType(outs[0]): c.errPos = 0 case len(outs) == 2: if isErrorType(outs[0]) || !isErrorType(outs[1]) &#123; return nil &#125; c.errPos = 1 &#125; return c&#125;type callback struct &#123; fn reflect.Value rcvr reflect.Value argTypes []reflect.Type hasCtx bool errPos int isSubscribe bool &#125; 在suitableCallbacks内先遍历了server的所有方法，对于可导出的，利用newCallback方法创建一个callback对象。一个callback对象中的几个成员意义如下： fn表示对于的方法 rcvr表示方法所在的类 argtypes存储所有输入参数类型（context除外） hasCtx表示参数中是否有Context类型，. errPos表示error类型的返回值是第几个 isSubscribe表示该方法是否可订阅（满足三个条件：第二个输入参数是Context类型，第一个输出参数是Subscription类型，第二个输出参数是error类型） 最后suitableCallbacks返回一个map存储符合条件的callback。接下来初始化serviceRegistry的services，也是一个map。然后创建一个service，存入services。最后遍历刚才callbacks，将其中的可订阅的方法单独拿出来。 总结一下，所谓的serviceRegistry注册方法就是给一个类，然后遍历所有方法，根据方法的参数与返回值归类，最后以service的形式放到serviceRegistry的services中. 服务启动及rpc请求处理分析节点会根据需求启动多种rpc服务，这里我们先以iprpc为例分析，ipcrpc在启动node时使用startIPC启动1234567891011121314// go-ethereum\rpc\ipc.gofunc (s *Server) ServeListener(l net.Listener) error &#123; for &#123; conn, err := l.Accept() if netutil.IsTemporaryError(err) &#123; log.Warn("RPC accept error", "err", err) continue &#125; else if err != nil &#123; return err &#125; log.Trace("Accepted RPC connection", "conn", conn.RemoteAddr()) go s.ServeCodec(NewJSONCodec(conn), OptionMethodInvocation|OptionSubscriptions) &#125;&#125; 整个是一个无限循环，每次循环接受一个连接，然后启动一个goroutine去调用ServeCodec处理，第一个参数是ServerCodec类型：12345678910111213141516171819func NewJSONCodec(conn Conn) ServerCodec &#123; enc := json.NewEncoder(conn) dec := json.NewDecoder(conn) dec.UseNumber() return NewCodec(conn, enc.Encode, dec.Decode)&#125;func NewCodec(conn Conn, encode, decode func(v interface&#123;&#125;) error) ServerCodec &#123; codec := &amp;jsonCodec&#123; closed: make(chan interface&#123;&#125;), encode: encode, decode: decode, conn: conn, &#125; if ra, ok := conn.(ConnRemoteAddr); ok &#123; codec.remoteAddr = ra.RemoteAddr() &#125; return codec&#125; 具体来说是一个jsonCodec对象，用于读写jsonrpc请求与响应的。ServeCodec的第二个参数是一个选项，但是新版本的go-ethereum不在支持该选项，所以弃用。总的来说codec类型对象就代表的是一个个连接请求 具体来说ServeCodec方法是读取一个请求，然后使用合适的callback去处理，最后返回，来看具体代码123456789101112131415// go-ethereum\rpc\server.gofunc (s *Server) ServeCodec(codec ServerCodec, options CodecOption) &#123; defer codec.Close() if atomic.LoadInt32(&amp;s.run) == 0 &#123; return &#125; s.codecs.Add(codec) defer s.codecs.Remove(codec) c := initClient(codec, s.idgen, &amp;s.services) &lt;-codec.Closed() c.Close()&#125; 前面说过run成员是控制运行的，如果等于0就不执行任何操作。然后将codec添加到set集合中，然后初始化一个Client去处理，最后等待codec关闭后，关闭Client。一个client就代表一个连接。初始化客户端代码如下1234567891011121314151617181920212223// go-ethereum\rpc\client.gofunc initClient(conn ServerCodec, idgen func() ID, services *serviceRegistry) *Client &#123; _, isHTTP := conn.(*httpConn) c := &amp;Client&#123; idgen: idgen, isHTTP: isHTTP, services: services, writeConn: conn, close: make(chan struct&#123;&#125;), closing: make(chan struct&#123;&#125;), didClose: make(chan struct&#123;&#125;), reconnected: make(chan ServerCodec), readOp: make(chan readOp), readErr: make(chan error), reqInit: make(chan *requestOp), reqSent: make(chan error, 1), reqTimeout: make(chan *requestOp), &#125; if !isHTTP &#123; go c.dispatch(conn) &#125; return c&#125; 就是简单的初始化，不过通过判断是否是http类型连接来决定是否分发。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// go-ethereum\rpc\client.gofunc (c *Client) dispatch(codec ServerCodec) &#123; var ( lastOp *requestOp reqInitLock = c.reqInit conn = c.newClientConn(codec) reading = true ) defer func() &#123; close(c.closing) if reading &#123; conn.close(ErrClientQuit, nil) c.drainRead() &#125; close(c.didClose) &#125;() go c.read(codec) for &#123; select &#123; case &lt;-c.close: return case op := &lt;-c.readOp: if op.batch &#123; conn.handler.handleBatch(op.msgs) &#125; else &#123; conn.handler.handleMsg(op.msgs[0]) &#125; case err := &lt;-c.readErr: conn.handler.log.Debug("RPC connection read error", "err", err) conn.close(err, lastOp) reading = false case newcodec := &lt;-c.reconnected: log.Debug("RPC client reconnected", "reading", reading, "conn", newcodec.RemoteAddr()) if reading &#123; conn.close(errClientReconnected, lastOp) c.drainRead() &#125; go c.read(newcodec) reading = true conn = c.newClientConn(newcodec) conn.handler.addRequestOp(lastOp) case op := &lt;-reqInitLock: reqInitLock = nil lastOp = op conn.handler.addRequestOp(op) case err := &lt;-c.reqSent: if err != nil &#123; conn.handler.removeRequestOp(lastOp) &#125; reqInitLock = c.reqInit lastOp = nil case op := &lt;-c.reqTimeout: conn.handler.removeRequestOp(op) &#125; &#125;&#125; 大体上来看dispatch方法是一个无限循环，每次循环都借助channel机制实现对不同的情况做不同处理，在循环阻塞时，启动了一个goroutine，去读取rpc请求12345678910111213func (c *Client) read(codec ServerCodec) &#123; for &#123; msgs, batch, err := codec.Read() if _, ok := err.(*json.SyntaxError); ok &#123; codec.Write(context.Background(), errorMessage(&amp;parseError&#123;err.Error()&#125;)) &#125; if err != nil &#123; c.readErr &lt;- err return &#125; c.readOp &lt;- readOp&#123;msgs, batch&#125; &#125;&#125; 这里就很清楚，直接调用ServerCodec的read方法，我们前面说过ServerCodec是一个个连接请求的包装，而这里的ServerCodec实际上是个jsonCodec类型，我们看看它的read方法123456789101112131415161718192021222324func (c *jsonCodec) Read() (msg []*jsonrpcMessage, batch bool, err error) &#123; var rawmsg json.RawMessage if err := c.decode(&amp;rawmsg); err != nil &#123; return nil, false, err &#125; msg, batch = parseMessage(rawmsg) return msg, batch, nil&#125;func parseMessage(raw json.RawMessage) ([]*jsonrpcMessage, bool) &#123; if !isBatch(raw) &#123; msgs := []*jsonrpcMessage&#123;&#123;&#125;&#125; json.Unmarshal(raw, &amp;msgs[0]) return msgs, false &#125; dec := json.NewDecoder(bytes.NewReader(raw)) dec.Token() // skip '[' var msgs []*jsonrpcMessage for dec.More() &#123; msgs = append(msgs, new(jsonrpcMessage)) dec.Decode(&amp;msgs[len(msgs)-1]) &#125; return msgs, true&#125; 这里的decode就是json.NewDecoder(conn)创建的，它将请求中的数据流转为一个json原始格式信息，为的是接下来反序列化。isBatch检查数据中第一个非空字符是否是“[”，如果是的话表示是一个json数据格式。总之最后解析为jsonrpcMessage对象，结构如下12345678type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125; 我们继续回到read方法中，当正确解析请求的内容时，返回值打包为readOp类型，然后写入Client的readOp这个chan字段中，这时触发dispatch中的select，执行下面逻辑：12345if op.batch &#123; conn.handler.handleBatch(op.msgs)&#125; else &#123; conn.handler.handleMsg(op.msgs[0])&#125; op.batch代表是否有多个jsonrpcMessage，以此执行不同逻辑。这里的conn是一个clientConn类型，包装了ServerCodec以及一个handler。我们下面看一下只有一个message的处理逻辑1234567// go-ethereum\rpc\handler.gofunc (h *handler) handleMsg(msg *jsonrpcMessage) &#123; if ok := h.handleImmediate(msg); ok &#123; return &#125; h.startCallProc(....)&#125; 第一行中handleImmediate处理的是不需要回复的请求，如一个通知或一个响应。通过方法名，ID以及参数等综合判断。对于正常请求调用startCallProc开始处理。123456789func (h *handler) startCallProc(fn func(*callProc)) &#123; h.callWG.Add(1) go func() &#123; ctx, cancel := context.WithCancel(h.rootCtx) defer h.callWG.Done() defer cancel() fn(&amp;callProc&#123;ctx: ctx&#125;) &#125;()&#125; h.callWG是一个sync.WaitGroup类型，为的是线程同步，这里加一表示有一个goroutine在运行，后面启动一个goroutine，这里面的实际逻辑是先前传递进来的func，如下12345678910func(cp *callProc) &#123; answer := h.handleCallMsg(cp, msg) h.addSubscriptions(cp.notifiers) if answer != nil &#123; h.conn.Write(cp.ctx, answer) &#125; for _, n := range cp.notifiers &#123; n.activate() &#125; &#125; 这里调用handleCallMsg去处理message：123456789101112131415161718192021func (h *handler) handleCallMsg(ctx *callProc, msg *jsonrpcMessage) *jsonrpcMessage &#123; start := time.Now() switch &#123; case msg.isNotification(): h.handleCall(ctx, msg) h.log.Debug("Served "+msg.Method, "t", time.Since(start)) return nil case msg.isCall(): resp := h.handleCall(ctx, msg) if resp.Error != nil &#123; h.log.Info("Served "+msg.Method, "reqid", idForLog&#123;msg.ID&#125;, "t", time.Since(start), "err", resp.Error.Message) &#125; else &#123; h.log.Debug("Served "+msg.Method, "reqid", idForLog&#123;msg.ID&#125;, "t", time.Since(start)) &#125; return resp case msg.hasValidID(): return msg.errorResponse(&amp;invalidRequestError&#123;"invalid request"&#125;) default: return errorMessage(&amp;invalidRequestError&#123;"invalid request"&#125;) &#125;&#125; 不管是通知类型还是调用类型，都调用的是handleCall方法：1234567891011121314151617181920func (h *handler) handleCall(cp *callProc, msg *jsonrpcMessage) *jsonrpcMessage &#123; if msg.isSubscribe() &#123; return h.handleSubscribe(cp, msg) &#125; var callb *callback if msg.isUnsubscribe() &#123; callb = h.unsubscribeCb &#125; else &#123; callb = h.reg.callback(msg.Method) &#125; if callb == nil &#123; return msg.errorResponse(&amp;methodNotFoundError&#123;method: msg.Method&#125;) &#125; args, err := parsePositionalArguments(msg.Params, callb.argTypes) if err != nil &#123; return msg.errorResponse(&amp;invalidParamsError&#123;err.Error()&#125;) &#125; return h.runMethod(cp.ctx, msg, callb, args)&#125; 分了三种情况：订阅请求，取消订阅请求以及一般请求。我们先看一般请求：h.reg是serviceRegistry，handler的serviceRegistry是前面dispatch方法创建clientConn时创建handle时传入的，来自于client的services字段，而client的services字段是在server的ServeCodec方法中调用initClient传入的，实际上就是Server的services字段。我们上节了解到在server会有一个registerName动作，会解析rpcserver的所有可导出方法，并用callback包装，而在handleCall中，就调用了serviceRegistry方法123456789func (r *serviceRegistry) callback(method string) *callback &#123; elem := strings.SplitN(method, serviceMethodSeparator, 2) if len(elem) != 2 &#123; return nil &#125; r.mu.Lock() defer r.mu.Unlock() return r.services[elem[0]].callbacks[elem[1]]&#125; 首先解析方法名，然后从services中，这里保存了一系列注册的服务，在从各个服务的callbacks集合中寻找对应的callback。继续回到handleCall，若找的callback不为空，则尝试解析参数：1234567891011121314151617181920212223242526272829303132333435363738394041func parsePositionalArguments(rawArgs json.RawMessage, types []reflect.Type) ([]reflect.Value, error) &#123; dec := json.NewDecoder(bytes.NewReader(rawArgs)) var args []reflect.Value tok, err := dec.Token() switch &#123; case err == io.EOF || tok == nil &amp;&amp; err == nil: case err != nil: return nil, err case tok == json.Delim('['): if args, err = parseArgumentArray(dec, types); err != nil &#123; return nil, err &#125; default: return nil, errors.New("non-array args") &#125; for i := len(args); i &lt; len(types); i++ &#123; if types[i].Kind() != reflect.Ptr &#123; return nil, fmt.Errorf("missing value for required argument %d", i) &#125; args = append(args, reflect.Zero(types[i])) &#125; return args, nil&#125;func parseArgumentArray(dec *json.Decoder, types []reflect.Type) ([]reflect.Value, error) &#123; args := make([]reflect.Value, 0, len(types)) for i := 0; dec.More(); i++ &#123; if i &gt;= len(types) &#123; return args, fmt.Errorf("too many arguments, want at most %d", len(types)) &#125; argval := reflect.New(types[i]) if err := dec.Decode(argval.Interface()); err != nil &#123; return args, fmt.Errorf("invalid argument %d: %v", i, err) &#125; if argval.IsNil() &amp;&amp; types[i].Kind() != reflect.Ptr &#123; return args, fmt.Errorf("missing value for required argument %d", i) &#125; args = append(args, argval.Elem()) &#125; _, err := dec.Token() return args, err&#125; 主要逻辑是在parseArgumentArray中，根据方法的参数列表类型一个一个进行解析，对于没有的参数设为该类型的默认空值，最后返回一组参数。在handleCall的最后去执行方法：12345678910111213141516171819202122232425262728293031323334353637func (h *handler) runMethod(ctx context.Context, msg *jsonrpcMessage, callb *callback, args []reflect.Value) *jsonrpcMessage &#123; result, err := callb.call(ctx, msg.Method, args) if err != nil &#123; return msg.errorResponse(err) &#125; return msg.response(result)&#125;func (c *callback) call(ctx context.Context, method string, args []reflect.Value) (res interface&#123;&#125;, errRes error) &#123; fullargs := make([]reflect.Value, 0, 2+len(args)) if c.rcvr.IsValid() &#123; fullargs = append(fullargs, c.rcvr) &#125; if c.hasCtx &#123; fullargs = append(fullargs, reflect.ValueOf(ctx)) &#125; fullargs = append(fullargs, args...) defer func() &#123; if err := recover(); err != nil &#123; const size = 64 &lt;&lt; 10 buf := make([]byte, size) buf = buf[:runtime.Stack(buf, false)] log.Error("RPC method " + method + " crashed: " + fmt.Sprintf("%v\n%s", err, buf)) errRes = errors.New("method handler crashed") &#125; &#125;() results := c.fn.Call(fullargs) if len(results) == 0 &#123; return nil, nil &#125; if c.errPos &gt;= 0 &amp;&amp; !results[c.errPos].IsNil() &#123; err := results[c.errPos].Interface().(error) return reflect.Value&#123;&#125;, err &#125; return results[0].Interface(), nil&#125; 基本上就是补全参数，然后调用callback中保存的func去执行，然后进行错误处理，最后返回结果也就是响应。回到runMethod中，调用response去包装结果123456789// go-ethereum\rpc\json.gofunc (msg *jsonrpcMessage) response(result interface&#123;&#125;) *jsonrpcMessage &#123; enc, err := json.Marshal(result) if err != nil &#123; // TODO: wrap with 'internal server error' return msg.errorResponse(err) &#125; return &amp;jsonrpcMessage&#123;Version: vsn, ID: msg.ID, Result: enc&#125;&#125; 这一步是将结果序列化，最后包装成为一个jsonrpcMessage。到这里handleCall流程结束，回到handleCallMsg，直接返回响应，再往回调，来到startCallProc方法，如果响应不为空，则调用write写入响应，一次rpc普通调用完成！负责写的还是ServerCodec类型对象，具体就是jsonCodec，最后写入响应流中。 总结一下，大致流程就是当接收到一个网络请求时，就启动一个goroutine，同时创建一个ServerCodec去包装过来的连接，在这个goroutine中会初始化一个client对象，代表一个连接，在初始化之后会进行连接的分发，分发就是有一个无限循环，同时再启动一个goroutine去解析请求信息，根据信息去开始注册的服务中查找合适的callback然后传入请求体重的参数执行响应逻辑，最后在利用ServerCodec去写会响应。 服务的关闭123456789func (s *Server) Stop() &#123; if atomic.CompareAndSwapInt32(&amp;s.run, 1, 0) &#123; log.Debug("RPC server shutting down") s.codecs.Each(func(c interface&#123;&#125;) bool &#123; c.(ServerCodec).Close() return true &#125;) &#125;&#125; 首先将标志位run置0，这样后续新的连接就被放弃（参见ServeCodec方法），然后遍历set，对每个ServerCodec执行close方法。123456func (c *jsonCodec) Close() &#123; c.closer.Do(func() &#123; close(c.closed) c.conn.Close() &#125;)&#125; 主要就是关闭channel和连接。channel关闭后影响ServeCodec方法，原来阻塞地方开始执行，然后关闭client12345678910func (c *Client) Close() &#123; if c.isHTTP &#123; return &#125; select &#123; case c.close &lt;- struct&#123;&#125;&#123;&#125;: &lt;-c.didClose case &lt;-c.didClose: &#125;&#125; 这里首先close这个channel获得值，在dispatch的那个无限循环中的到触发，跳出循环，执行defer逻辑，12345678defer func() &#123; close(c.closing) if reading &#123; conn.close(ErrClientQuit, nil) c.drainRead() &#125; close(c.didClose) &#125;() 这里进行最后善后处理，关闭完didClose后，上面Close()方法中最后阻塞得到解除，方法正常执行完毕。 题图来自unsplash：https://unsplash.com/photos/zNNPSqKRR2c]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC5加密]]></title>
    <url>%2F2019%2F03%2F28%2FRC5%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景RC5全称Rivest Cipher5，,是1994年Ron Rivest设计的（原始论文）。AES的候选算法之一RC6就是基于RC5开发的。这种算法具有块可变，秘钥长度可变，加密轮数可变的特点，非常灵活。并且，操作简单，仅需加法、移位、异或即可完成，而且内存占用极少 基本原理首先加密前要确定块长，轮数和秘钥长度，确定后不可改变。其中块长可选16,32或64位。轮数介于1-255之间，秘钥长度介于0-255字节。为了便于记忆，我们定义RC5-w/r/b表示一个实例，w/r/b分别表示一个字的长度（算法以两个字位一单位），轮数和秘钥长。推荐的最低安全标准为RC5-32/16/16 加密时都先将明文块分两部分，用这两部分开始若干轮计算，每轮都涉及相加、移位和异或，最后输出密文 详细流程初始化操作首相将明文分为A,B两部分。然后A与子秘钥S[0]相加，B与子秘钥S[1]相加，结果分别用2^w求模，得到C,D 每一轮细节 C和D异或得E E循环左移D位 E与子秘钥S[2i]相加得F。同样也要模2^w，i表示第几轮 D与F异或得G G循环左移F位 G与子秘钥S[2i+1]相加得H。同样也要模2^w，i表示第几轮 若还有轮数则C=F，D=H 基本可以写成下列形式12345A = A + S[0]B = B + S[1]for i = 1 to r: A = ((A XOR B) &lt;&lt;&lt; B) + S[2i] B = ((B XOR A) &lt;&lt;&lt; A) + S[2i+1] 秘钥计算子秘钥生成首先取两个常亮P、Q。P与Q在不同的w也就是字长下有不同值： W P Q 16 0xB7E1 0x9E37 32 0xB7E15163 0x9E3779B9 64 0xB7E151628AED2A6B 0x9E3779B97F4A7C15 P、Q计算公式分别如下： 第一个公式中的e表示自然常数，即2.71828… 第二个公式中的φ表示黄金比例，即1.618….。odd表示取最接近给定输入的奇数。P、Q都是魔法数字，没有任何来源根据. 得到两个常数后，令S[0] = P，从i=1开始循环，i每个循环递增1，每次循环计算A = S[i-1]+Q，B = A mod 2^w，S[i] = B。一直循环2(r+1)-1次。表示如下123s[0] = Pfor i = 1 to 2(r+1)-1: s[i] = (s[i-1]+Q) mod 2^w 子秘钥混合该阶段将子秘钥S与秘钥L进行混合1234567i = j = 0A = B = 0do 3 * max(2(r+1), (b*8)/w) times: A = S[i] = (S[i] + A + B) &lt;&lt;&lt; 3 B = L[j] = (L[j] + A + B) &lt;&lt;&lt; (A + B) i = (i + 1) mod 2(r+1) j = (j + 1) mod (b*8)/w 解密解密就是将加密过程颠倒123456for i = r to 1: A = ((B - S[2i+1])&gt;&gt;&gt;A) XOR A B = ((A - S[2i])&gt;&gt;&gt;B) XOR BB = B - S[1]A = A - S[0] 安全性12轮RC5(64位块)容易受到使用了2^44的选定的明文的差分攻击。18–20轮加密则被认为可以提供足够的保护。更大的安全性可以通过增加轮数获得，其代价是减少密码的吞吐量。 实现论文附录中作者给出了详细实现，这里不再列出。 题图来自unsplash：https://unsplash.com/photos/WhRsHmFtFXQ]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中ethdb源码学习]]></title>
    <url>%2F2019%2F03%2F27%2Fgo-ethereum%E4%B8%ADethdb%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前面学习了ethereum的编码和数据结构，这里学习一些ethereum的持久化存储也就是数据相关的源码。 背景go-ethereum的数据存储时借助于leveldb数据库，它是Google开发的一种键值对类型的数据库，另外Facebook又基于其开发了RocksDB数据库。简单来说，leveldb具有轻量以及高性能的特点。 原生的leveldb是用c++写的，并不方便直接用到go项目中，好在leveldb的开发者用go重新实现了leveldb，我们可以直接使用(github地址)。 go版本的leveldb需要go1.5以上版本，安装很简单，执行下面命令1go get github.com/syndtr/goleveldb/leveldb go-leveldb使用由于是键值对类型的数据库，所以使用比较简单，下面简单介绍一下基本操作，更高级的操作参见API文档。下面操作示例代码见这里 打开数据库12345db, err := leveldb.OpenFile("db", nil)if(err!=nil)&#123; log.Fatalln(err.Error())&#125;defer db.Close() OpenFile会创建或打开一个数据库。 增删改查123err = db.Put([]byte("key"), []byte("value"), nil)err = db.Delete([]byte("key"), nil)data, err := db.Get([]byte("key"), nil) 基本上就对于put，get，delete几个方法，其中更改一个记录的话也是用put。 普通迭代123456iter := db.NewIterator(nil, nil)for iter.Next() &#123; key := iter.Key() value := iter.Value()&#125;iter.Release() 就是迭代数据库全部键值对 指定起点的迭代首先需要明白的是，leveldb的存储是按key的顺序存储的，所以可以指定一个key，从该key开始遍历1234567iter:=db.NewIterator(nil,nil)for ok:=iter.Seek(key);ok;ok=iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 子集迭代可以指定区间进行迭代1234567iter:=db.NewIterator(&amp;util.Range&#123;Start:[]byte("key2"),Limit:[]byte("key6")&#125;,nil)for iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 前缀迭代只迭代有指定前缀的1234567iter:=db.NewIterator(util.BytesPrefix([]byte(prefix)),nil)for iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 批量写入12345678batch:=new(leveldb.Batch)for i:=0; i&lt;10; i++ &#123; batch.Put([]byte("batch"+strconv.Itoa(i)),[]byte("batch"+strconv.Itoa(i)))&#125;err:=db.Write(batch,nil)if err!=nil &#123; fmt.Println(err)&#125; 源码分析源码集中在ethdb目录内，主要是对leveldb的封装。 interface.go顾名思义就是定义了一些接口，如数据库接口：12345678type Database interface &#123; Putter Deleter Get(key []byte) ([]byte, error) Has(key []byte) (bool, error) Close() NewBatch() Batch&#125; Batch接口。用于批量操作，不能用于并发1234567type Batch interface &#123; Putter Deleter ValueSize() int Write() error Reset()&#125; 上面两个结构又包含了Putter和Deleter接口123456type Putter interface &#123; Put(key []byte, value []byte) error&#125;type Deleter interface &#123; Delete(key []byte) error&#125; database.go构造这就是ethereum所使用的代码，先看结构体1234567891011121314151617type LDBDatabase struct &#123; fn string // filename for reporting db *leveldb.DB // LevelDB instance compTimeMeter metrics.Meter // Meter for measuring the total time spent in database compaction compReadMeter metrics.Meter // Meter for measuring the data read during compaction compWriteMeter metrics.Meter // Meter for measuring the data written during compaction writeDelayNMeter metrics.Meter // Meter for measuring the write delay number due to database compaction writeDelayMeter metrics.Meter // Meter for measuring the write delay duration due to database compaction diskReadMeter metrics.Meter // Meter for measuring the effective amount of data read diskWriteMeter metrics.Meter // Meter for measuring the effective amount of data written quitLock sync.Mutex // Mutex protecting the quit channel access quitChan chan chan error // Quit channel to stop the metrics collection before closing the database log log.Logger // Contextual logger tracking the database path&#125; NewLDBDatabase成员很多，关键的就是一个leveldb.DB对象和几个同步操作的成员。接下来看新建数据库的方法12345678910111213141516171819202122232425262728293031func NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) &#123; logger := log.New("database", file) //从init调用过来时，cache和handles都为0 //默认启动节点，cache为512，handles为0，在node.DefaultConfig配置 if cache &lt; 16 &#123; cache = 16 &#125; if handles &lt; 16 &#123; handles = 16 &#125; logger.Info("Allocated cache and file handles", "cache", common.StorageSize(cache*1024*1024), "handles", handles) db, err := leveldb.OpenFile(file, &amp;opt.Options&#123; OpenFilesCacheCapacity: handles, BlockCacheCapacity: cache / 2 * opt.MiB, WriteBuffer: cache / 4 * opt.MiB, Filter: filter.NewBloomFilter(10), &#125;) if _, corrupted := err.(*errors.ErrCorrupted); corrupted &#123; db, err = leveldb.RecoverFile(file, nil) &#125; if err != nil &#123; return nil, err &#125; return &amp;LDBDatabase&#123; fn: file, db: db, log: logger, &#125;, nil&#125; 逻辑很简单，创建了一个levelDB对象，主要看一下options的内容： OpenFilesCacheCapacity：定义打开的文件缓存大小，默认是500，设为-1或0时表示不缓存 BlockCacheCapacity：定义了一个名为sorted table的缓存容量，默认是8MB，设为-1或0时表示不缓存 WriteBuffer：定义memdb的大小，它是一个内存数据库，默认是4MB. Filter：定义过滤器，优化读性能。这是使用了一个布隆过滤器 put，has，get，delete12345678910111213141516func (db *LDBDatabase) Put(key []byte, value []byte) error &#123; return db.db.Put(key, value, nil)&#125;func (db *LDBDatabase) Has(key []byte) (bool, error) &#123; return db.db.Has(key, nil)&#125;func (db *LDBDatabase) Get(key []byte) ([]byte, error) &#123; dat, err := db.db.Get(key, nil) if err != nil &#123; return nil, err &#125; return dat, nil&#125;func (db *LDBDatabase) Delete(key []byte) error &#123; return db.db.Delete(key, nil)&#125; 都是对leveldb做了封装而已。 Batch及其操作批量读写的封装12345type ldbBatch struct &#123; db *leveldb.DB b *leveldb.Batch size int&#125; put、delete、write、reset1234567891011121314151617181920func (b *ldbBatch) Put(key, value []byte) error &#123; b.b.Put(key, value) b.size += len(value) return nil&#125;func (b *ldbBatch) Delete(key []byte) error &#123; b.b.Delete(key) b.size += 1 return nil&#125;func (b *ldbBatch) Write() error &#123; return b.db.Write(b.b, nil)&#125;func (b *ldbBatch) Reset() &#123; b.b.Reset() b.size = 0&#125; Meter这是用于初始化LDBDatabase的一系列Meter成员用的123456789101112131415func (db *LDBDatabase) Meter(prefix string) &#123; db.compTimeMeter = metrics.NewRegisteredMeter(prefix+"compact/time", nil) db.compReadMeter = metrics.NewRegisteredMeter(prefix+"compact/input", nil) db.compWriteMeter = metrics.NewRegisteredMeter(prefix+"compact/output", nil) db.diskReadMeter = metrics.NewRegisteredMeter(prefix+"disk/read", nil) db.diskWriteMeter = metrics.NewRegisteredMeter(prefix+"disk/write", nil) db.writeDelayMeter = metrics.NewRegisteredMeter(prefix+"compact/writedelay/duration", nil) db.writeDelayNMeter = metrics.NewRegisteredMeter(prefix+"compact/writedelay/counter", nil) db.quitLock.Lock() db.quitChan = make(chan chan error) db.quitLock.Unlock() go db.meter(3 * time.Second)&#125; 这个方法内先初始化各种Meter，然后创建了一个chan，最后启动一个goroutine运行meter，之后每3秒收集一次信息并反馈到Meter。这一段代码比较长，就不贴出来了。主要是利用db.db.GetProperty(“leveldb.stats”)获取信息，信息格式如下：123456// Level | Tables | Size(MB) | Time(sec) | Read(MB) | Write(MB)// -------+------------+---------------+---------------+---------------+---------------// 0 | 0 | 0.00000 | 1.27969 | 0.00000 | 12.31098// 1 | 85 | 109.27913 | 28.09293 | 213.92493 | 214.26294// 2 | 523 | 1000.37159 | 7.26059 | 66.86342 | 66.77884// 3 | 570 | 1113.18458 | 0.00000 | 0.00000 | 0.00000 下面就是解析这个字符串并写入Meter。另外一点这段代周期循环的关键代码如下1234567for i := 1; errc == nil &amp;&amp; merr == nil; i++ &#123; //.... select &#123; case errc = &lt;-db.quitChan: case &lt;-time.After(refresh): &#125;&#125; 到select出会阻塞，3秒后进行下一次循环，退出时向Meter方法中初始化的chan发送信息，导致errc不为nil，就自然退出循环 close12345678910111213141516171819func (db *LDBDatabase) Close() &#123; db.quitLock.Lock() defer db.quitLock.Unlock() if db.quitChan != nil &#123; errc := make(chan error) db.quitChan &lt;- errc if err := &lt;-errc; err != nil &#123; db.log.Error("Metrics collection failed", "err", err) &#125; db.quitChan = nil &#125; err := db.db.Close() if err == nil &#123; db.log.Info("Database closed") &#125; else &#123; db.log.Error("Failed to close database", "err", err) &#125;&#125; 退出代码也很简单，主要就是在加锁环境下，向quitChan写入信息，停止meter，然后等待反馈（在meter发出反馈），最后关闭数据库。 memory_database.go这是一个用于测试的基于内存的数据库。在源码中主要是在geth初始化时，如果最后创建数据库时依旧没有有效的datadir则使用这个数据库代替 构造12345678910type MemDatabase struct &#123; db map[string][]byte lock sync.RWMutex&#125;func NewMemDatabase() *MemDatabase &#123; return &amp;MemDatabase&#123; db: make(map[string][]byte), &#125;&#125; 可见就是基于map的封装。 基础操作123456789101112131415161718192021222324252627282930313233func (db *MemDatabase) Put(key []byte, value []byte) error &#123; db.lock.Lock() defer db.lock.Unlock() db.db[string(key)] = common.CopyBytes(value) return nil&#125;func (db *MemDatabase) Has(key []byte) (bool, error) &#123; db.lock.RLock() defer db.lock.RUnlock() _, ok := db.db[string(key)] return ok, nil&#125;func (db *MemDatabase) Get(key []byte) ([]byte, error) &#123; db.lock.RLock() defer db.lock.RUnlock() if entry, ok := db.db[string(key)]; ok &#123; return common.CopyBytes(entry), nil &#125; return nil, errors.New("not found")&#125;func (db *MemDatabase) Delete(key []byte) error &#123; db.lock.Lock() defer db.lock.Unlock() delete(db.db, string(key)) return nil&#125; 全是基于map操作，只不过进行了加锁 Batch1234567891011121314151617181920212223242526272829303132333435363738394041type memBatch struct &#123; db *MemDatabase writes []kv size int&#125;type kv struct &#123; k, v []byte del bool&#125;func (db *MemDatabase) NewBatch() Batch &#123; return &amp;memBatch&#123;db: db&#125;&#125;func (b *memBatch) Put(key, value []byte) error &#123; b.writes = append(b.writes, kv&#123;common.CopyBytes(key), common.CopyBytes(value), false&#125;) b.size += len(value) return nil&#125;func (b *memBatch) Delete(key []byte) error &#123; b.writes = append(b.writes, kv&#123;common.CopyBytes(key), nil, true&#125;) b.size += 1 return nil&#125;func (b *memBatch) Write() error &#123; b.db.lock.Lock() defer b.db.lock.Unlock() for _, kv := range b.writes &#123; if kv.del &#123; delete(b.db.db, string(kv.k)) continue &#125; b.db.db[string(kv.k)] = kv.v &#125; return nil&#125;func (b *memBatch) Reset() &#123; b.writes = b.writes[:0] b.size = 0&#125; 批量操作先存储在一个KV类型的数组内，等到写入时遍历那个数组，依次存入数据库 table.go与table_batch.go这两个也是对数据的封装，之所以叫table是因为实例化一个table时要指定一个前缀，之后利用table的基本操作都会给key添加指定的前缀。table_batch也类似，直接看一下table.go的源码12345678910111213141516171819202122func NewTable(db Database, prefix string) Database &#123; return &amp;table&#123; db: db, prefix: prefix, &#125;&#125;func (dt *table) Put(key []byte, value []byte) error &#123; return dt.db.Put(append([]byte(dt.prefix), key...), value)&#125;func (dt *table) Has(key []byte) (bool, error) &#123; return dt.db.Has(append([]byte(dt.prefix), key...))&#125;func (dt *table) Get(key []byte) ([]byte, error) &#123; return dt.db.Get(append([]byte(dt.prefix), key...))&#125;func (dt *table) Delete(key []byte) error &#123; return dt.db.Delete(append([]byte(dt.prefix), key...))&#125;]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC4加密与实现]]></title>
    <url>%2F2019%2F03%2F27%2FRC4%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景RC4全名Rivest Cipher 4，是1987年Ron Rivest设计的一种流加密法，属于对称加密算法，曾经是WEP、TLS等使用的加密算法，它速度较快，且设计简单，所以使用较广 基本原理首先RC4的秘钥是可变的，长度在1~256个字节之间，开始前我们需要一个初始化状态向量，在进行初始置换后生产流秘钥进行加密。对于解密则是和加密一样的算法。 详细流程S的初始化 首先定义一个长度为1~256个字节的秘钥K。 初始化一个向量S，S[0] = 0,S[1] = 1, … ,S[255] = 255 创建临时数组T，T的长度是256，T用K填充，填不满的循环用K填充，直到T被填满 S的初始置换T数组的作用是对S进行初始置换，置换规则如下：将S[i]与S[j]交换，其中j = (j + S[i] + T[i]) mod 256。j的初始值是0 流秘钥生成根据如下计算：i = (i+1) mod 256，i初始值为0；j = (j + s[i]) mod 256,j初始值位0。然后交换s[i]和S[j]。令t = (S[i] + S[j]) mod 256。输出S[t]作为秘钥通明文进行一字节一字节的加密（异或运算） 简单实现java代码简单实现如下123456789101112131415161718192021222324252627282930313233public class RC4 &#123; private int[] S = new int[256]; RC4(byte[] keys) throws Exception &#123; int keyLen = keys.length; if (keyLen &lt;1 || keyLen &gt; 256) throw new Exception("秘钥长度错误"); int[] T = new int[256]; for (int i = 0;i&lt;256;i++)&#123; S[i] = i; &#125; int j = 0; for (int i = 0;i&lt;256;i++)&#123; j = (j + S[i] + keys[i % keyLen]) % 256; int temp = S[i]; S[i] = S[j]; S[j] = temp; &#125; &#125; public byte[] encrypt(byte[] msgs)&#123; int i = 0,j = 0; byte[] out = new byte[msgs.length]; for (int k = 0;k&lt;msgs.length;k++)&#123; i = (i+1)%256; j = (j+S[i])%256; int temp = S[i]; S[i] = S[j]; S[j] = temp; out[k] = (byte) (msgs[k] ^ S[(S[i] + S[j])%256]); &#125; return out; &#125;&#125; 验证123456public static void main(String[] args) throws Exception &#123; RC4 rc4 = new RC4("123".getBytes()); byte[] out = rc4.encrypt("abcdefg".getBytes()); Base64.Encoder encoder = Base64.getEncoder(); System.out.println(new String(encoder.encode(out))); &#125; 最后输出：MpLc5oASYw== 使用第三方RC4加密验证： 解密验证，由于说解密算法和加密算法一致，所以我们不必做任何修改，直接如下：1234567public static void main(String[] args) throws Exception &#123; RC4 rc4 = new RC4("123".getBytes()); byte[] out = rc4.encrypt("abcdefg".getBytes()); RC4 rc41 = new RC4("123".getBytes()); System.out.println(new String(rc41.encrypt(out))); &#125; 需要注意的一点是，解密时要新建一个RC4对象，原来的对象在加密时S数组已经发生交换，不能使用。 总结RC4算法通过上面实现来看非常简单，没有什么复杂计算，只有简单的交换和异或运算，秘钥也足够长，是一种比较理想的算法。但是弱密钥会导致算法不安全，另外由于更好的算法出现，RC4目前已经很少使用。 题图来自unsplash：https://unsplash.com/photos/B9j-xgMVf90]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中trie源码学习]]></title>
    <url>%2F2019%2F03%2F26%2Fgo-ethereum%E4%B8%ADtrie%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[MPT（Merkle Patricia Tree），是以太坊实现中广泛使用的一种数据结构，如在区块头中就保存了状态树，交易树和收据树这三棵树的根的hash，而这三棵树就是MPT。MPT是Trie树、Patricia Trie树和Merkle树的变形，下面我们就来详细了解一下 背景Trie树Trie树又称前缀树或字典树。顾名思义一个节点的所有孩子都具有同样的前缀，就像字典一样把单词按前缀分类排序。 在Trie树中，根节点不保存信息，每个节点的最大孩子数量相同（若是保存英文字母，不区分大小写，则最多有26个孩子）。 从根节点开始，到某一节点，路径上的字符组合起来就是该节点对应的字符串 没有重复的节点 语言说起来比较抽象，看一张图就很清楚了 如上图所示，这棵树可能保存了:A,to,tea,ted,ten,i,in,inn这8个字符串（具体某个节点表示的仅仅是前缀还是字符串还要根据节点参数判断）。java实现见这里 Trie树具有查找效率高的特点，但是稀疏现象比较严重，空间利用率低。Trie树常用于搜索提示，如输入前几个字母，就可以很快的提示一些可能匹配的字符串。 Patricia Trie实际上是基数树，或压缩前缀树。根据名字可知，是对前缀进行一定的压缩，为了是缓解Trie树空间利用率不高的问题。如下图 从图中我们可以知道，如果以Trie树存储romane和romanus，对于他们的公共前缀roman我们要创建5个先后依赖的节点，在第5层处分叉，对于us又需要两层节点。而对于基数树，可以把roman合并为一个节点，us也合并为一个节点，这样原本至少7层才能表示的现在2层即可。 关于这种树的实现我们会在后面源码分析提到 Merkle树Merkle Tree，通常也被称作Hash Tree。这种树的的主要作用是验证。它结构上大多情况是一颗二叉树，叶子结点都以数据库的hash值作为标签，其他结点都是其子节点的标签拼接后再做hash。他可以高效的安全的验证大型数据结构的内容。 如上图，数据的每一块都对应一个叶子，叶子内存储该块的hash，之后层层做hash运算，最后得到根节点的一个hash值。我们只需要验证根节点的hash是否相同，就能判断整个文件是否完整或者是否被人恶意篡改。另外，通过重建整个树，可以很快的知道具体哪一部分出错。具体在区块链中，无论比特币还是以太坊，都是只在区块头中存储根节点，从而来判断是否一致。 以太坊的MPT一般而言MPT的存储借鉴的是Patricia Trie。与一般的存储英文字符串不同，MPT存储的是hash值，每一位有0-f共16种可能，不过MPT又对其进行了扩展。 首先，定义了三种节点： branch：分支节点，一个长度为17的list，分别是0-f共16位，再加一个value。最后的value代表该节点可能对某个key是终点，用于存取值 leaf：叶子节点，和Trie树的叶子结点类型 extension：扩展节点，纯粹的路径节点，其中的值时其它节点hash，可以理解为一个指向其他节点的指针 看一张经典的图会比较容易理解： 在图中，右上角四对键值就是图中树所存储的内容。首先他们都有前缀a7，所以根节点就是一个扩展节点，它的指针指向一个分支节点，分支节点用到了1、7、f三个值，1、f分别指向两个叶子节点，因为没有其他key和他们有除a7外的公共前缀，分支节点7指向一个扩展节点，因为右上角第二和第四个还有公共前缀d3，随后在指向一个分支节点，再找值分为两个叶子节点。叶子结点的value就存着每个键值对中的value. 源码分析ethereum关于这部分的源码集中在trie目录下 结点定义见代码：1234567891011121314151617181920// go-ethereum\trie\node.gotype node interface &#123; fstring(string) string cache() (hashNode, bool) canUnload(cachegen, cachelimit uint16) bool&#125;type ( fullNode struct &#123; Children [17]node // Actual trie node data to encode/decode (needs custom encoder) flags nodeFlag &#125; shortNode struct &#123; Key []byte Val node flags nodeFlag &#125; hashNode []byte valueNode []byte) 虽说黄皮书中定义了3种结点，但这里只有两种节点，分别是fullnode和shortnode。fullnode就是分支节点，可见其有一个长度为17的数组。shortnode可以代表扩展节点或叶子节点，因为二者结构是一样的，区分两种节点主要看val的值。另外还有两种节点，虽然是字节数组类型的，但是他们都实现了node接口的全部方法，所以也是节点类型。 树的构造先看一下树的结构：12345type Trie struct &#123; db *Database root node cachegen, cachelimit uint16&#125; root就是根节点，db就是数据库，树的结构最后要存到数据库中，启动时再加载出来。对于cachegen，每次提交其值都会增加，新节点会标记cachegen，如果当前的cachegen - cachelimit大于node的cache时代，那么node会从cache里面卸载，以便节约内存。 创建一棵树12345678910111213141516func New(root common.Hash, db *Database) (*Trie, error) &#123; if db == nil &#123; panic("trie.New called without a database") &#125; trie := &amp;Trie&#123; db: db, &#125; if root != (common.Hash&#123;&#125;) &amp;&amp; root != emptyRoot &#123; rootnode, err := trie.resolveHash(root[:], nil) if err != nil &#123; return nil, err &#125; trie.root = rootnode &#125; return trie, nil&#125; new方法接受一个hash和一个数据库指针，首席确保指针不为空，然后初始化树，之后再判断传入的hash是否为空值，若不是则从数据库加载，否则返回一个空树。 插入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960func (t *Trie) insert(n node, prefix, key []byte, value node) (bool, node, error) &#123; if len(key) == 0 &#123; if v, ok := n.(valueNode); ok &#123; return !bytes.Equal(v, value.(valueNode)), value, nil &#125; return true, value, nil &#125; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) if matchlen == len(n.Key) &#123; dirty, nn, err := t.insert(n.Val, append(prefix, key[:matchlen]...), key[matchlen:], value) if !dirty || err != nil &#123; return false, n, err &#125; return true, &amp;shortNode&#123;n.Key, nn, t.newFlag()&#125;, nil &#125; branch := &amp;fullNode&#123;flags: t.newFlag()&#125; var err error _, branch.Children[n.Key[matchlen]], err = t.insert(nil, append(prefix, n.Key[:matchlen+1]...), n.Key[matchlen+1:], n.Val) if err != nil &#123; return false, nil, err &#125; _, branch.Children[key[matchlen]], err = t.insert(nil, append(prefix, key[:matchlen+1]...), key[matchlen+1:], value) if err != nil &#123; return false, nil, err &#125; if matchlen == 0 &#123; return true, branch, nil &#125; return true, &amp;shortNode&#123;key[:matchlen], branch, t.newFlag()&#125;, nil case *fullNode: dirty, nn, err := t.insert(n.Children[key[0]], append(prefix, key[0]), key[1:], value) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn return true, n, nil case nil: return true, &amp;shortNode&#123;key, value, t.newFlag()&#125;, nil case hashNode: rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.insert(rn, prefix, key, value) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf("%T: invalid node: %v", n, n)) &#125;&#125; 几个参数分别是：n代表当前的结点。prefix代表已经搜索过的前缀，key表示尚未处理的部分，二者拼接到一起就是完整的key。value表示要插入的值。返回值中bool表示是否改变了树，node表示插入后子树的根节点。通过参数可以猜到这是通过递归进行操作的。 代码的第一个if判断中，若key的长度为0，表示key已经遍历完了，同时也找到了一个节点。判断这个节点是否是valueNode类型节点，若是的话，判断要插入的值和结点的值是否相等，来判断是否改变了树。若不是valueNode类型节点，就直接更新value，同时指明树已经改变了。 若还在变量key的途中，则根据当前节点的类型进行判断： 若是shortNode节点，表示是一个叶子节点或扩展节点，则调用prefixLen方法计算公共前缀长度。若公共前缀长度就等于key的长度，说明二者的可以是一样的，则按照需要更新value。若只有部分公共前缀，则需要构造一个分支节点，将原来的节点和要插入的作为新分支节点的孩子插入。最后对刚才的公共前缀进行判断，若为0，表示没有公共前缀，则用新的分支节点替换掉原来的节点，若不为零，则将新的分支节点作为原节点的孩子，并改变原节点的可以。注意给分支节点添加孩子时，也是调用的insert，只不过n为nil，这对应后面的一种情况，稍后分析。 若是fullNode，也就是分支节点，则直接寻找对应的位置尝试插入，注意分支节点对于位置的孩子可能为空，为shortNode或者fullnode，不管为什么，最终继续递归，并按需更新孩子即可 若是nil，这种情况可能会一棵空树时候出现，这是新建一个shortNode节点作为根节点，返回即可。同时，在上文向分支节点插入孩子时也会出现，同样也是新建shortNode结点作为分支节点孩子即可。 若是hashNode，可以理解为一个指针，但是数据都在数据库，需要取数据库取值插入 最后不满足定义的四种节点，报错 最后总结一点，对于shortNode节点，要么进行更新，要么新建扩展节点进行插入，对于fullNode，要么成为其某个孩子，要么更新其值，要么为其添加扩展节点，进行扩展。总之新的叶子节点插入操作都是在扩展节点上完成的。 删除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778func (t *Trie) delete(n node, prefix, key []byte) (bool, node, error) &#123; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) if matchlen &lt; len(n.Key) &#123; return false, n, nil // don't replace n on mismatch &#125; if matchlen == len(key) &#123; return true, nil, nil // remove n entirely for whole matches &#125; dirty, child, err := t.delete(n.Val, append(prefix, key[:len(n.Key)]...), key[len(n.Key):]) if !dirty || err != nil &#123; return false, n, err &#125; switch child := child.(type) &#123; case *shortNode: return true, &amp;shortNode&#123;concat(n.Key, child.Key...), child.Val, t.newFlag()&#125;, nil default: return true, &amp;shortNode&#123;n.Key, child, t.newFlag()&#125;, nil &#125; case *fullNode: dirty, nn, err := t.delete(n.Children[key[0]], append(prefix, key[0]), key[1:]) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn pos := -1 //遍历后，若pos大于等于0，表示只有一个孩子 //若pos等于-2则孩子数量大于一个 for i, cld := range &amp;n.Children &#123; if cld != nil &#123; if pos == -1 &#123; pos = i &#125; else &#123; pos = -2 break &#125; &#125; &#125; if pos &gt;= 0 &#123; if pos != 16 &#123; cnode, err := t.resolve(n.Children[pos], prefix) if err != nil &#123; return false, nil, err &#125; if cnode, ok := cnode.(*shortNode); ok &#123; k := append([]byte&#123;byte(pos)&#125;, cnode.Key...) return true, &amp;shortNode&#123;k, cnode.Val, t.newFlag()&#125;, nil &#125; &#125; return true, &amp;shortNode&#123;[]byte&#123;byte(pos)&#125;, n.Children[pos], t.newFlag()&#125;, nil &#125; return true, n, nil case valueNode: return true, nil, nil case nil: return false, nil, nil case hashNode: rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.delete(rn, prefix, key) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf("%T: invalid node: %v (%v)", n, n, key)) &#125;&#125; 参数和返回值和插入操作类似，不在赘述。依旧是判断当前节点类型： 若为shortNode结点，首先也是计算公共前缀。若公共前缀的长度小于当前节点key的长度，表示没有匹配到。若公共前缀的长度等于要删除的key的长度，表示匹配到子树，直接删除该节点为根的子树。若公共前缀的长度等于当前节点key的长度，也就是当前节点的key是要删除key的一部分，说明还要向下查找。但是删除完后要对节点做处理，若子节点fullnode节点删除孩子后孩子数量大于1个，则只改变当前节点的flag。若删除后孩子数量小于等于一个，则要对节点进行合并，也就是对前缀进行合并 若为fullnode结点，则直接根据key的第一个字符取尝试删除某个孩子。然后遍历孩子，判断非空的数量，若大于两个则不做处理，若只有一个，进行节点的合并。 若为valueNode节点，直接删除，返回 若为nil，一般在阐述fullnode的孩子时遇到，表示没有匹配，不做处理 若为hashNode，表示还在数据库中，则先加载，在尝试删除 查询也就是Get方法，见代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func (t *Trie) Get(key []byte) []byte &#123; res, err := t.TryGet(key) if err != nil &#123; log.Error(fmt.Sprintf("Unhandled trie error: %v", err)) &#125; return res&#125;func (t *Trie) TryGet(key []byte) ([]byte, error) &#123; key = keybytesToHex(key) //转为16进制半字节 value, newroot, didResolve, err := t.tryGet(t.root, key, 0) if err == nil &amp;&amp; didResolve &#123; t.root = newroot &#125; return value, err&#125;func (t *Trie) tryGet(origNode node, key []byte, pos int) (value []byte, newnode node, didResolve bool, err error) &#123; switch n := (origNode).(type) &#123; case nil: return nil, nil, false, nil case valueNode: return n, n, false, nil case *shortNode: if len(key)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, key[pos:pos+len(n.Key)]) &#123; // key not found in trie return nil, n, false, nil &#125; value, newnode, didResolve, err = t.tryGet(n.Val, key, pos+len(n.Key)) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.Val = newnode n.flags.gen = t.cachegen &#125; return value, n, didResolve, err case *fullNode: value, newnode, didResolve, err = t.tryGet(n.Children[key[pos]], key, pos+1) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.flags.gen = t.cachegen n.Children[key[pos]] = newnode &#125; return value, n, didResolve, err case hashNode: child, err := t.resolveHash(n, key[:pos]) if err != nil &#123; return nil, n, true, err &#125; value, newnode, _, err := t.tryGet(child, key, pos) return value, newnode, true, err default: panic(fmt.Sprintf("%T: invalid node: %v", origNode, origNode)) &#125;&#125; 查找的逻辑也很简单，首先要把byte数组转为16进制半字节的数组形式，使用keybytesToHex方法（后面会讲）。之后从根节点开始，调用tryGet递归查询，也分一下几种情况： 若为空，表示没有找到 若为valueNode节点，直接返回即可 若为shortNode，如果当前节点的key长度大于本次递归要查找的或即使长度相等但内容不一样的，则表示没有匹配的，否则继续递归查找 若为fullNode结点，则递归到孩子中寻找 若为hashNode结点，则先从数据库中加载，在尝试递归查询 编码主要是encoding.go，处理树的三种编码格式的互相转换。 keybytes：原始字节数组，大部分trie的函数都用这种格式 hex：hex编码，将一个字节用两个字节表示，编码时，将8位二进制码重新分组成两个4位的字节，其中一个字节的低4位是原字节的高四位，另一个字节的低4位是原数据的低4位，高4位都补0。编码后再在尾部跟上一个标志位0x10，标识是叶子节点或者扩展节点 compact：compact编码，就是Hex-Prefix Encoding，在黄皮书中的附录C有说明。是hex编码的变体。第一个字节的高位存储标志位，低位存储0（长度为偶数）或hex编码的第一个半字节（长度为奇数）。总之最后长度是偶数。数学描述如下（f(t)表示hex编码的标志位是否存在）： 下面具体看源码： hexToCompacthex编码转compact编码12345678910111213141516func hexToCompact(hex []byte) []byte &#123; terminator := byte(0) if hasTerm(hex) &#123; terminator = 1 hex = hex[:len(hex)-1] &#125; buf := make([]byte, len(hex)/2+1) buf[0] = terminator &lt;&lt; 5 // the flag byte if len(hex)&amp;1 == 1 &#123; buf[0] |= 1 &lt;&lt; 4 // odd flag buf[0] |= hex[0] // first nibble is contained in the first byte hex = hex[1:] &#125; decodeNibbles(hex, buf[1:]) return buf&#125; hasTerm判断最后一字节是否是16，也就是有没有标志位，若是则terminator标记为1，并去除hex编码的标志位。接下来写入compat编码的标志位，首先terminator右移5位，再判断hex编码长度的奇偶性，并根据情况改下标志位。然后解码hex编码改为compat编码，流程和黄皮书一致。 compactToHexcompact编码转hex编码12345678910111213func compactToHex(compact []byte) []byte &#123; if len(compact) == 0 &#123; return compact &#125; base := keybytesToHex(compact) // delete terminator flag if base[0] &lt; 2 &#123; base = base[:len(base)-1] &#125; // apply odd flag chop := 2 - base[0]&amp;1 return base[chop:]&#125; 可见先看做一般字节数组，然后转为hex编码。然后判断是否有标志位。首先根据黄皮书规定，compact编码的第一字节的高四位有这几种情况：12340000 hex编码没有标志位，且长度为偶数0001 hex编码没有标志位，且长度为奇数0010 hex编码有标志位，且长度为偶数0011 hex编码有标志位，且长度为奇数 根据上面四种情况，删除最后的标志位。然后在根据第一位的值，决定是删除前两位还是第一位 keybytesToHex原始数组转hex编码12345678910func keybytesToHex(str []byte) []byte &#123; l := len(str)*2 + 1 var nibbles = make([]byte, l) for i, b := range str &#123; nibbles[i*2] = b / 16 nibbles[i*2+1] = b % 16 &#125; nibbles[l-1] = 16 return nibbles&#125; 很简单，就是一个字节拆为两个字节，利用整除和取余，最后加一个标志位。 hexToKeybyteshex编码还原12345678910111213141516func hexToKeybytes(hex []byte) []byte &#123; if hasTerm(hex) &#123; hex = hex[:len(hex)-1] &#125; if len(hex)&amp;1 != 0 &#123; panic("can't convert hex key of odd length") &#125; key := make([]byte, len(hex)/2) decodeNibbles(hex, key) return key&#125;func decodeNibbles(nibbles []byte, bytes []byte) &#123; for bi, ni := 0, 0; ni &lt; len(nibbles); bi, ni = bi+1, ni+2 &#123; bytes[bi] = nibbles[ni]&lt;&lt;4 | nibbles[ni+1] &#125;&#125; 先根据需求去除标志位，再具体转换。可见将两字节还原为一字节时就是利用移位和或逻辑。 序列化序列化就是将一课树存储到数据库中123456789101112131415161718192021// go-ethereum\trie\trie.gofunc (t *Trie) Commit(onleaf LeafCallback) (root common.Hash, err error) &#123; if t.db == nil &#123; panic("commit called on trie with nil database") &#125; hash, cached, err := t.hashRoot(t.db, onleaf) if err != nil &#123; return common.Hash&#123;&#125;, err &#125; t.root = cached t.cachegen++ return common.BytesToHash(hash.(hashNode)), nil&#125;func (t *Trie) hashRoot(db *Database, onleaf LeafCallback) (node, node, error) &#123; if t.root == nil &#123; return hashNode(emptyRoot.Bytes()), nil, nil &#125; h := newHasher(t.cachegen, t.cachelimit, onleaf) defer returnHasherToPool(h) return h.hash(t.root, db, true)&#125; 这一部分主要是创建了hasher，然后利用hash方法去实现。进入hasher的代码123456// go-ethereum\trie\hasher.gofunc newHasher(cachegen, cachelimit uint16, onleaf LeafCallback) *hasher &#123; h := hasherPool.Get().(*hasher) h.cachegen, h.cachelimit, h.onleaf = cachegen, cachelimit, onleaf return h&#125; hasherPool是一个对象池，newHasher方法主要是从中尝试取或者创建一个hasher对象。下面看hash方法：123456789101112131415161718192021222324252627282930313233343536func (h *hasher) hash(n node, db *Database, force bool) (node, node, error) &#123; if hash, dirty := n.cache(); hash != nil &#123; if db == nil &#123; return hash, n, nil &#125; if n.canUnload(h.cachegen, h.cachelimit) &#123; cacheUnloadCounter.Inc(1) return hash, hash, nil &#125; if !dirty &#123; return hash, n, nil &#125; &#125; collapsed, cached, err := h.hashChildren(n, db) if err != nil &#123; return hashNode&#123;&#125;, n, err &#125; hashed, err := h.store(collapsed, db, force) if err != nil &#123; return hashNode&#123;&#125;, n, err &#125; cachedHash, _ := hashed.(hashNode) switch cn := cached.(type) &#123; case *shortNode: cn.flags.hash = cachedHash if db != nil &#123; cn.flags.dirty = false &#125; case *fullNode: cn.flags.hash = cachedHash if db != nil &#123; cn.flags.dirty = false &#125; &#125; return hashed, cached, nil&#125; 第一个if我们后面再解释，接下来的hashChildren是一个关键点，它将所有的子节点换为他们的hash1234567891011121314151617181920212223242526272829303132333435func (h *hasher) hashChildren(original node, db *Database) (node, node, error) &#123; var err error switch n := original.(type) &#123; case *shortNode: collapsed, cached := n.copy(), n.copy() collapsed.Key = hexToCompact(n.Key) cached.Key = common.CopyBytes(n.Key) if _, ok := n.Val.(valueNode); !ok &#123; collapsed.Val, cached.Val, err = h.hash(n.Val, db, false) if err != nil &#123; return original, original, err &#125; &#125; return collapsed, cached, nil case *fullNode: subtrees collapsed, cached := n.copy(), n.copy() for i := 0; i &lt; 16; i++ &#123; if n.Children[i] != nil &#123; collapsed.Children[i], cached.Children[i], err = h.hash(n.Children[i], db, false) if err != nil &#123; return original, original, err &#125; &#125; &#125; cached.Children[16] = n.Children[16] return collapsed, cached, nil default: return n, original, nil &#125;&#125; 主要也是根据结点类型进行操作。 对于shortNode节点，先对key从hex编码转为compact编码，然后递归调用hash把子节点也改为hash 对于fullNode结点，遍历所有孩子，递归调用hash方法 对于其他类型节点原样返回 再回到hash方法，接下来调用store方法。12345678910111213141516171819202122232425262728293031323334353637383940func (h *hasher) store(n node, db *Database, force bool) (node, error) &#123; if _, isHash := n.(hashNode); n == nil || isHash &#123; return n, nil &#125; h.tmp.Reset() if err := rlp.Encode(&amp;h.tmp, n); err != nil &#123; panic("encode error: " + err.Error()) &#125; if len(h.tmp) &lt; 32 &amp;&amp; !force &#123; return n, nil // Nodes smaller than 32 bytes are stored inside their parent &#125; database. hash, _ := n.cache() if hash == nil &#123; hash = h.makeHashNode(h.tmp) &#125; if db != nil &#123; cache hash := common.BytesToHash(hash) db.lock.Lock() db.insert(hash, h.tmp, n) db.lock.Unlock() if h.onleaf != nil &#123; switch n := n.(type) &#123; case *shortNode: if child, ok := n.Val.(valueNode); ok &#123; h.onleaf(child, hash) &#125; case *fullNode: for i := 0; i &lt; 16; i++ &#123; if child, ok := n.Children[i].(valueNode); ok &#123; h.onleaf(child, hash) &#125; &#125; &#125; &#125; &#125; return hash, nil&#125; 首先判断节点类型，若本身就是hashNode或为空不存储。然后对节点编码。详细流程不在赘述，参考RLP编码学习。编码之后的结果存在tmp这个字节数组中。接下来判断是否强制存储，然后计算根节点编码后结果hash，最后存储到数据库，键就是刚才计算的hash。 再次回到hash方法，存储成功后。将存储的键转为hashNode类，然后判断cached（实际是跟节点的copy）的类型，对于是shortNode和fullNode类型，将其flags成员的hash值进行修改，然后返回hash值和cached。 反序列化不同于序列化，反序列化在trie的源码中就多次出现，主要是下面方法123456789func (t *Trie) resolveHash(n hashNode, prefix []byte) (node, error) &#123; cacheMissCounter.Inc(1) hash := common.BytesToHash(n) if node := t.db.node(hash, t.cachegen); node != nil &#123; return node, nil &#125; return nil, &amp;MissingNodeError&#123;NodeHash: hash, Path: prefix&#125;&#125; 主要逻辑在node方法中123456789101112131415161718192021222324252627// go-ethereum\trie\database.gofunc (db *Database) node(hash common.Hash, cachegen uint16) node &#123; if db.cleans != nil &#123; if enc, err := db.cleans.Get(string(hash[:])); err == nil &amp;&amp; enc != nil &#123; memcacheCleanHitMeter.Mark(1) memcacheCleanReadMeter.Mark(int64(len(enc))) return mustDecodeNode(hash[:], enc, cachegen) &#125; &#125; db.lock.RLock() dirty := db.dirties[hash] db.lock.RUnlock() if dirty != nil &#123; return dirty.obj(hash, cachegen) &#125; enc, err := db.diskdb.Get(hash[:]) if err != nil || enc == nil &#123; return nil &#125; if db.cleans != nil &#123; db.cleans.Set(string(hash[:]), enc) memcacheCleanMissMeter.Mark(1) memcacheCleanWriteMeter.Mark(int64(len(enc))) &#125; return mustDecodeNode(hash[:], enc, cachegen)&#125; 这也是一个典型的二级缓存的例子，首先尝试从内存缓存中获取，若没有，则从磁盘的数据库中获取，最后实际反序列化操作都在mustDecodeNode方法中123456789101112131415161718192021222324252627// go-ethereum\trie\node.gofunc mustDecodeNode(hash, buf []byte, cachegen uint16) node &#123; n, err := decodeNode(hash, buf, cachegen) if err != nil &#123; panic(fmt.Sprintf("node %x: %v", hash, err)) &#125; return n&#125;func decodeNode(hash, buf []byte, cachegen uint16) (node, error) &#123; if len(buf) == 0 &#123; return nil, io.ErrUnexpectedEOF &#125; elems, _, err := rlp.SplitList(buf) if err != nil &#123; return nil, fmt.Errorf("decode error: %v", err) &#125; switch c, _ := rlp.CountValues(elems); c &#123; case 2: n, err := decodeShort(hash, elems, cachegen) return n, wrapError(err, "short") case 17: n, err := decodeFull(hash, elems, cachegen) return n, wrapError(err, "full") default: return nil, fmt.Errorf("invalid number of list elements: %v", c) &#125;&#125; 首先解释一下涉及到的几个rlp方法，通过学习rlp编码我们知道，rlp编码一般由一个标志位+前缀+内容组成，SplitList方法返回的就是内容以及剩余内容（未被解析的）。对于复合类型，也就是编码中的第二种数据来源–多维数组类型，它的rlp编码内容部分是由多个单独的子类型rlp编码组合而成的，CountValues就是统计有多少个子部分。 接下来一个switch就是根据有多少子内容区分节点的类型，如代码中所述，2个子内容的就是shortNode，17个的就是fullNode，注意这点可能会有些人有疑问，我们定义节点的时候，这两类节点可不止这几个成员变量，这是因为在存储时节点都被转化为rawShortNode和rawFullNode两种简单类型（ go-ethereum\trie\database.go），只保留关键信息。我们接下来再看具体的反序列化方法123456789101112131415161718192021222324252627282930313233343536373839404142func decodeShort(hash, elems []byte, cachegen uint16) (node, error) &#123; kbuf, rest, err := rlp.SplitString(elems) if err != nil &#123; return nil, err &#125; flag := nodeFlag&#123;hash: hash, gen: cachegen&#125; key := compactToHex(kbuf) if hasTerm(key) &#123; val, _, err := rlp.SplitString(rest) if err != nil &#123; return nil, fmt.Errorf("invalid value node: %v", err) &#125; return &amp;shortNode&#123;key, append(valueNode&#123;&#125;, val...), flag&#125;, nil &#125; r, _, err := decodeRef(rest, cachegen) if err != nil &#123; return nil, wrapError(err, "val") &#125; return &amp;shortNode&#123;key, r, flag&#125;, nil&#125;func decodeRef(buf []byte, cachegen uint16) (node, []byte, error) &#123; kind, val, rest, err := rlp.Split(buf) if err != nil &#123; return nil, buf, err &#125; switch &#123; case kind == rlp.List: if size := len(buf) - len(rest); size &gt; hashLen &#123; err := fmt.Errorf("oversized embedded node (size is %d bytes, want size &lt; %d)", size, hashLen) return nil, buf, err &#125; n, err := decodeNode(nil, buf, cachegen) return n, rest, err case kind == rlp.String &amp;&amp; len(val) == 0: return nil, rest, nil case kind == rlp.String &amp;&amp; len(val) == 32: return append(hashNode&#123;&#125;, val...), rest, nil default: return nil, nil, fmt.Errorf("invalid RLP string size %d (want 0 or 32)", len(val)) &#125;&#125; 逻辑还是很清晰的，首先使用SplitString，分理处内容和剩余数据，然后将内容转为hex编码，再判断value是否有标志位来决定是否是叶子节点，若是叶子节点，则解析剩余的内容。若不是，则使用decodeRef来解析剩余内容。decodeRef首先也是分离出rlp编码各部分，先判断类型，再根据类型生成具体的节点。最后回到decodeShort构造出一个完整的节点。另外decodeFull流程也类似，不在赘述。主要思想就是一层一层剥开rlp编码，根据具体类型生成具体节点。 trie的cachetrie除了有数据库和根节点这两个成员变量，还有cachegen, cachelimit用于缓存管理的变量。trie树在每次commit时都会将cachegen加1（见上面序列化部分源码），然后在每次插入节点时都会把cachegen写入新节点，利用的是newFlag方法123func (t *Trie) newFlag() nodeFlag &#123; return nodeFlag&#123;dirty: true, gen: t.cachegen&#125;&#125; 当trie.cachegen - node.cachegen &gt; cachelimit时，就会把节点从内存中卸载（删除），用的是canUnload方法判断，每个继承node接口的类都实现了该方法：1234func (n *fullNode) canUnload(gen, limit uint16) bool &#123; return n.flags.canUnload(gen, limit) &#125;func (n *shortNode) canUnload(gen, limit uint16) bool &#123; return n.flags.canUnload(gen, limit) &#125;func (n hashNode) canUnload(uint16, uint16) bool &#123; return false &#125;func (n valueNode) canUnload(uint16, uint16) bool &#123; return false &#125; 卸载的作用是节省内存，所以说经过几次commit后，就会有节点被从内存中删除，删除是在hash方法中，也就是那个方法的第一个if1234567891011121314func (h *hasher) hash(n node, db *Database, force bool) (node, node, error) &#123; if hash, dirty := n.cache(); hash != nil &#123; if db == nil &#123; return hash, n, nil &#125; if n.canUnload(h.cachegen, h.cachelimit) &#123; cacheUnloadCounter.Inc(1) return hash, hash, nil &#125; if !dirty &#123; return hash, n, nil &#125; &#125; .... 获取hash是首先从节点的cache中获取，若存在的话，先不急着返回，首先判断是否可卸载，若可以，则卸载，注意卸载方式很有意思，不返回节点实例，而是返回一个hash表示节点，然后需要的时候在反序列化即可。注意若节点没有缓存hash值，则一定不进行卸载。 SecureTrie最后还有一个SecureTrie，是为了避免使用很长的key导致性能下降。SecureTrie包装了trie，所有的key都转化为keccak256计算的hash，但在数据库中存储原始key123456type SecureTrie struct &#123; trie Trie hashKeyBuf [common.HashLength]byte secKeyCache map[string][]byte //hash值和key值的映射 secKeyCacheOwner *SecureTrie &#125; database.go这也是trie包中的，是比较贴近实际使用的。源码注释中介绍它是一个介于内存中的trie数据和硬盘的中间层，作用是不将每次树的操作都写入内存，而是周期性的写入。 先看初始化，在其他地方源码中用的较多的是NewDatabase与NewDatabaseWithCache两个方法，均可以获得一个database对象12345678910111213141516171819202122func NewDatabase(diskdb ethdb.Database) *Database &#123; return NewDatabaseWithCache(diskdb, 0)&#125;func NewDatabaseWithCache(diskdb ethdb.Database, cache int) *Database &#123; var cleans *bigcache.BigCache if cache &gt; 0 &#123; cleans, _ = bigcache.NewBigCache(bigcache.Config&#123; Shards: 1024, LifeWindow: time.Hour, MaxEntriesInWindow: cache * 1024, MaxEntrySize: 512, HardMaxCacheSize: cache, &#125;) &#125; return &amp;Database&#123; diskdb: diskdb, cleans: cleans, dirties: map[common.Hash]*cachedNode&#123;&#123;&#125;: &#123;&#125;&#125;, preimages: make(map[common.Hash][]byte), &#125;&#125; 通过参考BlockChain源码我们可以知道，为了获得一个statedb对象，会使用statedb.New方法，其中需要一个Database对象，一般都是通过state包中的NewDatabase或者NewDatabaseWithCache方法，但是需要一个参数，所以由调用了trie包中的NewDatabase或者NewDatabaseWithCache方法，如下：1234567891011state, err := state.New(parent.Root(), bc.stateCache)stateCache: state.NewDatabaseWithCache(db, cacheConfig.TrieCleanLimit),func NewDatabaseWithCache(db ethdb.Database, cache int) Database &#123; csc, _ := lru.New(codeSizeCacheSize) return &amp;cachingDB&#123; db: trie.NewDatabaseWithCache(db, cache), codeSizeCache: csc, &#125;&#125; 通过层层引用，只有到trie包中的database对象才持有真正的数据库对象。 InsertBlob这个方法出现在statedb的commit中，如果一个stateObject的code字段不为空且被设置过，则将code进行插入12345678910111213141516171819202122232425262728293031323334s.db.TrieDB().InsertBlob(common.BytesToHash(stateObject.CodeHash()), stateObject.code)func (db *Database) InsertBlob(hash common.Hash, blob []byte) &#123; db.lock.Lock() defer db.lock.Unlock() db.insert(hash, blob, rawNode(blob))&#125;func (db *Database) insert(hash common.Hash, blob []byte, node node) &#123; if _, ok := db.dirties[hash]; ok &#123; return &#125; entry := &amp;cachedNode&#123; node: simplifyNode(node), size: uint16(len(blob)), flushPrev: db.newest, &#125; for _, child := range entry.childs() &#123; if c := db.dirties[child]; c != nil &#123; c.parents++ &#125; &#125; db.dirties[hash] = entry if db.oldest == (common.Hash&#123;&#125;) &#123; db.oldest, db.newest = hash, hash &#125; else &#123; db.dirties[db.newest].flushNext, db.newest = hash, hash &#125; db.dirtiesSize += common.StorageSize(common.HashLength + entry.size)&#125; InsertBlob我们传入要存储的数据及其hash，之后调用insert方法，将要传入的数据又包装成一个rawNode类型。在insert方法中，首先检测要传入的数据是否被缓存过，是的话直接结束操作。 之后构建了一个cacheNode类型。然后调用了childs遍历其所有孩子并将其组成一个Hash类型的数组，之后遍历这个数组，看是否有引入该节点的项，有的话将其对应的parents字段加一。最后将刚才生成的cacheNode放入dirties中。 再往下有一个修改oldest与newest的逻辑，这里解释一下，源码这这里构建了一个刷新列表，实际为一个链表，oldest表示列表中最旧的节点，在列表头部；newest表示最新的节点，位于列表尾部。而cachedNode的flushNext表示该节点之后下一个要刷入数据库的节点，对应的还有flushPrev，在构造cachedNode时被设为newest。这里，如果oldest为空，表示列表为空，则oldest与newest都为当前该节点。否则只修改newest和该节点的flushNext字段。 接着修改database的dirtiesSize表示已缓存的数据量。 Commit可以看到之前的insert方法并没有将数据存入数据库，而是放入dirties中，我们这里看一下commit方法，他要求传入一个节点hash：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (db *Database) Commit(node common.Hash, report bool) error &#123; db.lock.RLock() start := time.Now() batch := db.diskdb.NewBatch() for hash, preimage := range db.preimages &#123; if err := batch.Put(db.secureKey(hash[:]), preimage); err != nil &#123; log.Error("Failed to commit preimage from trie database", "err", err) db.lock.RUnlock() return err &#125; if batch.ValueSize() &gt; ethdb.IdealBatchSize &#123; if err := batch.Write(); err != nil &#123; db.lock.RUnlock() return err &#125; batch.Reset() &#125; &#125; nodes, storage := len(db.dirties), db.dirtiesSize if err := db.commit(node, batch); err != nil &#123; log.Error("Failed to commit trie from trie database", "err", err) db.lock.RUnlock() return err &#125; if err := batch.Write(); err != nil &#123; log.Error("Failed to write trie to disk", "err", err) db.lock.RUnlock() return err &#125; db.lock.RUnlock() db.lock.Lock() defer db.lock.Unlock() db.preimages = make(map[common.Hash][]byte) db.preimagesSize = 0 db.uncache(node) memcacheCommitTimeTimer.Update(time.Since(start)) memcacheCommitSizeMeter.Mark(int64(storage - db.dirtiesSize)) memcacheCommitNodesMeter.Mark(int64(nodes - len(db.dirties))) logger := log.Info if !report &#123; logger = log.Debug &#125; logger("Persisted trie from memory database", "nodes", nodes-len(db.dirties)+int(db.flushnodes), "size", storage-db.dirtiesSize+db.flushsize, "time", time.Since(start)+db.flushtime, "gcnodes", db.gcnodes, "gcsize", db.gcsize, "gctime", db.gctime, "livenodes", len(db.dirties), "livesize", db.dirtiesSize) db.gcnodes, db.gcsize, db.gctime = 0, 0, 0 db.flushnodes, db.flushsize, db.flushtime = 0, 0, 0 return nil&#125; 这里首先创建了一个数据库的batch对象，用于后面批量操作。首先放入batch中的是preimages数据，这个稍后再说。每放入一个就检查是否超过batch规定的最大容量（100KB），超过的话先执行一次写入操作再进行后续的数据放入。在往下调用了commit方法：12345678910111213141516171819202122func (db *Database) commit(hash common.Hash, batch ethdb.Batch) error &#123; node, ok := db.dirties[hash] if !ok &#123; return nil &#125; for _, child := range node.childs() &#123; if err := db.commit(child, batch); err != nil &#123; return err &#125; &#125; if err := batch.Put(hash[:], node.rlp()); err != nil &#123; return err &#125; if batch.ValueSize() &gt;= ethdb.IdealBatchSize &#123; if err := batch.Write(); err != nil &#123; return err &#125; batch.Reset() &#125; return nil&#125; 这个方法很简单就是从指定的节点开始递归遍历节点的所有孩子，将节点经过rlp编码后存入数据库。回到Commit中，调用了一次batch的write方法确保所有数据都被写入数据库。最后初始化一些变量。 Reference123456789101112131415161718192021func (db *Database) Reference(child common.Hash, parent common.Hash) &#123; db.lock.RLock() defer db.lock.RUnlock() db.reference(child, parent)&#125;func (db *Database) reference(child common.Hash, parent common.Hash) &#123; node, ok := db.dirties[child] if !ok &#123; return &#125; if db.dirties[parent].children == nil &#123; db.dirties[parent].children = make(map[common.Hash]uint16) &#125; else if _, ok = db.dirties[parent].children[child]; ok &amp;&amp; parent != (common.Hash&#123;&#125;) &#123; return &#125; node.parents++ db.dirties[parent].children[child]++&#125; Reference是建立一个从父结点到子节点的引用。首先检查了是否缓存有子节点，有的话再看要建立引入的父节点的孩子是否为空，再检查是否已经建立的引用，没有的将孩子节点的父节点树加一，然后将父节点对应的孩子节点引用树加一。 Cap这个方法在BlockChain中实际写入一个区块后，如果是带缓存模式时，先检查已缓存是否超过的现在，超过的话利用此方法写入数据库12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182func (db *Database) Cap(limit common.StorageSize) error &#123; db.lock.RLock() nodes, storage, start := len(db.dirties), db.dirtiesSize, time.Now() batch := db.diskdb.NewBatch() size := db.dirtiesSize + common.StorageSize((len(db.dirties)-1)*2*common.HashLength) flushPreimages := db.preimagesSize &gt; 4*1024*1024 if flushPreimages &#123; for hash, preimage := range db.preimages &#123; if err := batch.Put(db.secureKey(hash[:]), preimage); err != nil &#123; log.Error("Failed to commit preimage from trie database", "err", err) db.lock.RUnlock() return err &#125; if batch.ValueSize() &gt; ethdb.IdealBatchSize &#123; if err := batch.Write(); err != nil &#123; db.lock.RUnlock() return err &#125; batch.Reset() &#125; &#125; &#125; oldest := db.oldest for size &gt; limit &amp;&amp; oldest != (common.Hash&#123;&#125;) &#123; node := db.dirties[oldest] if err := batch.Put(oldest[:], node.rlp()); err != nil &#123; db.lock.RUnlock() return err &#125; if batch.ValueSize() &gt;= ethdb.IdealBatchSize &#123; if err := batch.Write(); err != nil &#123; log.Error("Failed to write flush list to disk", "err", err) db.lock.RUnlock() return err &#125; batch.Reset() &#125; size -= common.StorageSize(3*common.HashLength + int(node.size)) oldest = node.flushNext &#125; if err := batch.Write(); err != nil &#123; log.Error("Failed to write flush list to disk", "err", err) db.lock.RUnlock() return err &#125; db.lock.RUnlock() db.lock.Lock() defer db.lock.Unlock() if flushPreimages &#123; db.preimages = make(map[common.Hash][]byte) db.preimagesSize = 0 &#125; for db.oldest != oldest &#123; node := db.dirties[db.oldest] delete(db.dirties, db.oldest) db.oldest = node.flushNext db.dirtiesSize -= common.StorageSize(common.HashLength + int(node.size)) &#125; if db.oldest != (common.Hash&#123;&#125;) &#123; db.dirties[db.oldest].flushPrev = common.Hash&#123;&#125; &#125; db.flushnodes += uint64(nodes - len(db.dirties)) db.flushsize += storage - db.dirtiesSize db.flushtime += time.Since(start) memcacheFlushTimeTimer.Update(time.Since(start)) memcacheFlushSizeMeter.Mark(int64(storage - db.dirtiesSize)) memcacheFlushNodesMeter.Mark(int64(nodes - len(db.dirties))) log.Debug("Persisted nodes from memory database", "nodes", nodes-len(db.dirties), "size", storage-db.dirtiesSize, "time", time.Since(start), "flushnodes", db.flushnodes, "flushsize", db.flushsize, "flushtime", db.flushtime, "livenodes", len(db.dirties), "livesize", db.dirtiesSize) return nil&#125; 同样先获取了batch，然后计算了几个数据：dirties的长度，dirties内容大小以及总的大小（包含dirties的内容大小dirties自身大小）。接着判断了preimages是否超过了4MB，超过的话将其写入数据库。 接着获取要刷入列表的头部，也就是oldest指向的节点。此时如果刚才计算的总大小超过了限制，则从oldest开始，沿着那个刷新链表将每个节点写入数据库，直到链表结束或总的大小不超过限制为止。接着又调用了一次Write方法确保数据被写入数据库。最后更新了几个变量。 Preimage这个和SecureTrie有关，每当SecureTrie利用Update或TryUpdate向树中插入数据时，都会将要存储的键值对在secKeyCache从缓存一份，在SecureTrie的的commit方法中，在调用trie的commit之前，secKeyCache中的数据通过insertPreimage插入1234567func (db *Database) insertPreimage(hash common.Hash, preimage []byte) &#123; if _, ok := db.preimages[hash]; ok &#123; return &#125; db.preimages[hash] = common.CopyBytes(preimage) db.preimagesSize += common.StorageSize(common.HashLength + len(preimage))&#125; secKeyCache表示一个树的阶段性状态，在调用commit后会对secKeyCache清空。 在database中提交时，无论是调用commit或者cap方法，都是先提交preimages，在提交节点数据。其中preimages实际上相当于存储着树中的原始数据，而存储节点时而存储的是节点(指cachedNode)rlp编码后的数据。 题图来自unsplash：https://unsplash.com/photos/hnw3Al47-KE]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA加密与实现]]></title>
    <url>%2F2019%2F03%2F26%2FIDEA%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景IDEA全称International Data Encryption Algorithm，即国际数据加密算法。也是一种强大的加密算法，原本目的是取代DES，但是由于专利的存在，IDEA并没有DES使用广泛，但是如PGP加密程序就是用的IDEA。 IDEA和DES一样，都是可逆的，加解密算法相同，也利用了扩展和混淆思想 基本原理加密前明文进行分块，每块64位，秘钥位128位。加密时，首先将明文分为4组，每组16位，作为第一轮的输入，总共需要8轮。在每一轮中，从128位的秘钥中产生6组子秘钥，每组16位，用这6组子秘钥对输入的4组明文进行一系列操作，产生一轮的输出，并作为下一轮输入。8轮结束后进行一次变换，这次变换需要4个子秘钥，组合起来得到64位密文。 轮次每一轮有14步，基本流程如下（我们将4组输入定义为P1-P4，6组秘钥定义为k1-K6）： P1与K1相乘 P2与K2相加 P3与K3相加 P4与K4相乘 第1步结果与第2步结果异或 第2步结果与第4步结果异或 第5步结果与K5相乘 第6步结果和第7步结果相乘 第8步与K6相乘 第7步与第9步相加 第1步结果与第9步结果异或 第3步结果与第9步结果异或 第2步结果与第10步结果异或 第4步结果与第10步结果异或 第11，13，12，14分别为输出的第1-4组，示意图如下（图中红圈代表相乘运算，篮圈代表异或运算，绿圈代表相加运算： 注意步骤中的加或乘并不是简单的加与乘。对于加法，加之后用2^16(即65536)求模。对于乘法，乘之后用2^16 + 1(即65537)求模。求模主要是为了保证输出为16位。 子秘钥生成总体来看，前8轮每轮需要8个子秘钥，最后一个输出变换需要4个子秘钥 第一轮第一轮开始前我们有一组128位的原始秘钥，第一轮用前96位，每16位一组，公6组 第二轮第二轮先使用没有用的32位，共两组，还差4组64位秘钥。然后将原始秘钥循环左移25位，再取前64位，作为后四组秘钥。 第三轮上一轮还剩64位，作为该轮的前四组秘钥，然后再左移25位，选前32位作为剩下两组子秘钥。 后面几轮一次类推，每次都先使用上一轮未使用的，对于不够的先循环左移，再取秘钥 输出变换第8轮之后，有四组输出，然后进行输出变换，具体过程如下(将4组输出定义为R1-R4，4组秘钥定义为K1-K4)： R1与K1相乘 R2与K2相加 R3与K3相加 R4与K4相乘 注意，相加相乘还是和之前8轮里的加和乘一样操作。对于子秘钥，第8轮是刚好把128位的后96位用完。这一次，依旧先左移25位，然后取前64位作为4组秘钥 解密解密算法和加密算法是一样的，只是秘钥有所不同。 第i(1-9)轮的解密秘钥的前4四个子秘钥由加密过程中第10-i轮的前四个子秘钥得出 其中第1与第4个子秘钥为对应子秘钥关于2^16 + 1的乘法逆元 第 2 个和第 3 个子密钥的取法为：1.当轮数为 2，…，8 时，取相应的第 3 个和第 2 个的子密钥的2^16加法逆元 2.当轮数为 1 或 9 时，取相应的第 2 个和第 3 个子密钥对应的2^16加法逆元 第 5 和第 6 个密钥不变 简单实现java代码见这里 题图来自unsplash：https://unsplash.com/photos/WDOJ5256Cvk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DES加密与实现]]></title>
    <url>%2F2019%2F03%2F25%2FDES%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[DES加密基本上属于学习加密算法的必修内容，这里也来梳理一下整个算法 背景DES全称Data Encryption Standard，也就是数据加密标准，也被称作Data Encryption ALgorithm，DEA，数据加密算法。分类上，它属于对称秘钥加密块密码。1976年被被美国联邦政府的国家标准局确定为联邦资料处理标准，随后再全世界广泛应用，成为一种通用加密算法。虽然现在这种算法已经不安全了，但是它使用的一些思想和理念深深影响可后来许多加密算法。这个算法的官方文档见这里 基本原理首先这是一种块加密算法，以64位为一块，输出的密文也是64位，加解密使用相同的秘钥，秘钥的长度是56位。对于秘钥，最初是64位的，不过在算法开始前会丢弃8位（第8,16,24,32,40,48,56,64位）。 之后算法的主要思想是对明文进行替换和变换（也称混淆和扩散），这是香农提出的思想，对后世的密码算法有重要影响。混淆是为了保证密文中不会出现明文线索，扩散则是增加明文的冗余度。 DES主要步骤如下： 将明文进行初始置换（IP） 将置换后的块分为左右两部分 对每一部分进行16轮加密 将加密后的两部分拼接起来，进行最终置换（FP），得到密文 如下图： 详细过程初始置换在加密前需要进行一次初始置换，称为IP，结束后有一个最终置换，FP，这两个操作在密码学上几乎没有任何意义，只是在最初设计时，为了简化输入输出数据库的过程而被纳入加密流程。 初始置换借助的是一个置换表，如下表： 表中数字代表明文中该位的位置，如第一个是58，则代表将明文中的第58位放到置换后的第一位，依次类推 DES的一轮每一轮包含秘钥变换，扩展置换，S盒替换，P盒替换和异或交换这几步。也被统称为费斯妥函数，也就是开始那张图中的F函数 秘钥变换首先秘钥有56位，这一步是从这56位中选取48位，作为这一轮的子秘钥。变换的基本规则是，将56位分为两部分，各28位，每一轮循环左移一位或两位，具体情况如下表： 移位后，具体如何挑选48位，是根据下表挑选： 和初始置换类似，表中数字也是表示的该位在原秘钥中的位置，如第一位14表示将秘钥的第14位写在这里，后面依次类推 由于是将56位变为48位，这一步也称为压缩置换 扩展置换经过初始置换后，得到两个32位的明文部分，称为左右明文，而这一步就是将右明文扩展到48位。具体过程如下 将32位明文分为8组，每组4位 将每组的4位扩展为6位，实际上是重复每组的第一和第4位，但不是简单的重复，每组之间是有依赖的，简单描述就是，原来每位右移移位，第一位由上一组的第四位填充（第一组由最后一组填充），第六位由下一组的第一位填充（最后一组由第一组填充） 由于这一步极有规律，可以表示为下面的变换表： 这个表使用和前面的一样，不在赘述 S盒替换前一步将32位明文变为48位，这样就可以和秘钥进行异或操作，最后得到48位的输出，S盒的作用就是将这48位变为32位，总共有8个S盒，每个盒接受6位输入，产生4位输出，随后将48位变为32位。 8个S盒如下 关于S盒的使用如下，首先把一个S和看做4行16列的表格，首先输入有6位，将其中间四位看做列号，首尾两位看做行号。如输入101101，则行号就是11=3，列号就是0110=6，则就取s盒第3行第6位（行列都从0开始计数），如使用第二个S盒就输出2，转为4位二进制就是0010 P盒替换经s盒替换后，输出32位结果，之后进行一次简单的P和置换，置换表如下： 异或与交换P和置换不改变位数，输出还是32位，之后将输出的32位与左明文进行异或（前面一系列步骤都是再对右明文处理），运算结果成为下一轮的右明文，而原来的有明文变成下一轮的左明文，这就是所谓的交换 最后一张图总结这几步： 最终置换这样重复16轮之后，得到一个64位的密文。然后在进行最终置换，置换表如下： 解密通过前文可知，加密过程是极其繁琐和复杂的，许多替换不深入研究是不能了解其意义的，但是对于解密而言，就体现了DES算法的强大之处，它的加密算法和解密算法是一样的，唯一区别就是那16轮中用的秘钥要反过来，如第1轮解密要用第16轮加密秘钥。不过由于秘钥是独立运算的，所以可以事先计算好16轮加密所使用的全部秘钥。 DES变体双重DES从字面意思很好理解，就是使用两个秘钥，进行两次加密。解密时反向操作两次即可。如果说单一DES加密破解需要搜索2^56个秘钥，则双重DES就需要搜索2^112个秘钥 双重DES的中间人攻击这是一种理论上的攻击，我们假设攻击者知道明文和密文，需要找到加密的两个秘钥。首先创建两张表，第一张表存储所有可能的密码对明文块加密后的结果，第二张表存储所有可能的密码对密文块解密后的结果，比对两张表的结果，相同的那两行所用的秘钥就是加密过程中用的秘钥。 三重DES三个秘钥的三重DES比较简单，就是用三个秘钥，加密三次 两个秘钥的三重DES使用两个秘钥，首先用秘钥K1执行加密，再用K2解密，再用K1加密，这种模式成为加解加模式（EDE） DES的实现我们这里用java实现一下DES，完整源码见这里 注意在下面移位操作中，对于二进制字符串，我们认为最左边为第1位。 构造函数和构造密钥组对于构造函数要求出入一个字节数组作为密钥，长度必须是8字节，然后准备两个long类型数组存储加密和解密子密钥，由于子密钥是48位，所以用64位的long类型存储1234567891011121314151617181920212223242526private long[] encryptKeys = new long[16];private long[] decryptKeys = new long[16];MyDES(byte[] bytes) throws Exception &#123; if (bytes.length!=8) throw new Exception("密钥长度错误"); generateSubKey(bytes);&#125;private void generateSubKey(byte[] keyBytes) &#123; long key = bytesToLong(keyBytes); //64位密钥转为64位long类型表示 long pc1Result = permute(PC1,key,64); //从64位中选56位 int l = (int) (pc1Result &gt;&gt;&gt; 28); //密钥左半部分 int r = (int) (pc1Result &amp; 0xfffffff); //密钥右半部分 for (int i = 0; i&lt;16;i++)&#123; //左右部分分别循环左移 l = (l &lt;&lt; KEY_ROTATE[i]) | (l &gt;&gt;&gt; (28-KEY_ROTATE[i])); r = (r &lt;&lt; KEY_ROTATE[i]) | (r &gt;&gt;&gt; (28-KEY_ROTATE[i])); //拼接密钥 long temp = ((l &amp; 0xfffffffL) &lt;&lt; 28) | (r &amp; 0xfffffffL); //从56位密钥中选择48位 encryptKeys[i] = permute(PC2,temp,56); //解密密钥组是加密密钥组的倒序 decryptKeys[15-i] = encryptKeys[i]; &#125;&#125; 轮次操作详细代码如下，关键步骤见注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private byte[] des(byte[] bytes,long[] subkeys)&#123; long msg = bytesToLong(bytes); //将64位明文块用long类型表示 long IPResult = permute(IP,msg,64); //初始置换 //明文块分为左右两部分 int l = (int) (IPResult &gt;&gt;&gt; 32); int r = (int) (IPResult &amp; 0xffffffff); int temp = 0; for (int i = 0;i&lt;16;i++)&#123; temp = r; //暂存右半部分，作为下一轮的左半部分输入 r = l ^ f(r, subkeys[i]); //左半部分和右半部分经费斯妥函数运算后异或 l = temp; //新一轮的左半部分为该轮输入的右半部分 &#125; //最终置换，注意由于最后一轮不需要左右交换， //而我们上面代码进行了左右交换，所以这里要在进行一次左右交换 long FPResult = permute(FP,((r &amp; 0xffffffffL) &lt;&lt; 32) | (l &amp; 0xffffffffL),64); //将long类型转换为64位字节数组 return longTobytes(FPResult);&#125;//费斯妥函数private int f(int src, long subkey) &#123; //32位扩展为48位 long rExpand = permute(EXPAND,src&amp;0xffffffffL,32); //与子密钥异或 long sIn = rExpand ^ subkey; //s盒置换 long sOut = sBox(sIn); //P盒置换 int pResult = (int) permute(P,sOut,32); return pResult;&#125;//S盒置换private long sBox(long sIn) &#123; long result = 0; int r = 0,c = 0; for (int i = 0; i&lt; 8;i++)&#123; //取低6位 byte input = (byte) (sIn &amp; 0x3f); //取6位输入的首位两位计算行数 r = ((input &amp; 0x20)&gt;&gt;&gt;4) | (input &amp;0x1); //取6位输入的中间4位计算列数 c = (input &amp; 0x1e) &gt;&gt;&gt; 1; //生成的4位输出进行适当移位 result |= (S[7-i][r][c] &amp; 0xffL) &lt;&lt; (i*4); //输出右移6位，一般下一次循环取低6位 sIn &gt;&gt;&gt;= 6; &#125; return result;&#125; 测试与验证1234567public static void main(String[] args) throws Exception &#123; MyDES myDES = new MyDES("12345678".getBytes()); byte[] enc = myDES.encrypt("abcdefgh".getBytes()); System.out.println(byteToHexString(enc)); byte[] dec = myDES.decrypt(enc); System.out.println(new String(dec));&#125; 上面加密结果转为16进制字符串之后为94d4436bc3b5b693，与网上在线加密（注意比对时要选择ECB模式，而且大多数都会默认填充，即使明文已经达到了64位，所以要将网上结果去除尾部16个十六进制字符）测试结果一致，解密也可以正常得出原文。 题图来自unsplash：https://unsplash.com/photos/E7PlRr9ZfoM]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分组密码中的算法模式]]></title>
    <url>%2F2019%2F03%2F24%2F%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E4%B8%AD%E7%9A%84%E7%AE%97%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[算法模式是块加密中一系列步骤中基本，同一种加密方法采用不同的模式会产生不同的密文，安全性也不尽相同 电子密码薄（ECB）模式这是块加密中最简单的模式，如定义每块为64位，则将明文每64位分一组，之后对每组使用相同的秘钥和加密算法进行单独加密。解密时也是按64位分组，用同样的秘钥和加密方法进行解密即可。这种方法只适合于短消息，因为如果有重复信息，密文也会产生重复，易被攻击。加解密示意图如下： 加密块链接（CBC）模式这种模式的特点是对前一个块加密的结果会影响当前块的加密，确保了每条消息的唯一性。基本过程如下： 首先随机出一个与分组等长的初始文本块，然后用该文本块和第一个要加密的块做异或运算，并对运算结果进行加密 加密第二个块时，用第一个块加密之后的密文与第二个块进行异或运算，并对运算结果使用和第一块相同的算法和秘钥进行加密 依次类推，关键点是，在加密前使用上一块的密文与当前块做异或运算，之后再加密 可以抽象为下面数学表达(Ek表示加密函数，Ci表示明文的第几块)： 示意图如下： 对于解密，首先要了解一下异或运算的一个重要性质，就是连用两次异或后能恢复原值，即 A = A XOR B XOR B。由于这个性质异或就天然的有隐藏和还原信息的功能，所以解密算法如下 首先对密文块1进行解密，解密后再和加密时使用的初始文本块做异或运算就得到了原文. 对其他密文块也是一样，先解密，再与前一个密文块做异或，就得到原文 可以抽象为下面数学表达(Dk表示解密函数，Ci表示明文的第几块)： 示意图如下： 这种模式虽然很好的隐藏了信息，但是由于加密时都要依赖前面的信息，所以只能串行加密。不能并行运算。但是解密时可以并行运算 加密反馈（CFB）模式首先并不是所有程序都能处理数据库，如一个输入系统，需要以安全方式在信道中立即传输信息，这就要求数据用更小的单元进行加密（如8位，以byte长度）。所以出现了CFB模式。基本流程如下： 首先也需要一个64位的初始化向量，并将其放在移位寄存器中，并对该初始化向量进行加密，得到64位的初始密文 将加密过的初始化向量前j位和明文前j为进行异或，作为密文输出 将寄存器中的初始化向量左移j位，并将刚才加密的j位拼接到初始化向量尾部 然后重复上面步骤，即再对寄存器中的新初始化向量加密，随后再加密明文前j位，再进行左移个补充操作，最后再循环 示意图如下： 解密也很简单，由于明文是和移位寄存器中加密过的内容做异或后得到的密文，所以根据异或的性质，只需把密文和移位寄存器（初始内容还是加密时选定初始内容）中加密过的内容再做一次异或就得到明文（注意解密之后，寄存器中内容也要同步移位）示意图如下： 这种模式虽然和CBC很像，但是有一个优点，就是明文是不需要填充为分组的整数倍数长度的，明文和密文有相等长度，且较为灵活。 输出反馈（OFB）模式这种模式和CFB模型类似，但是没有CFB那么复杂，直接看一下示意图比较清晰： 可见主要区别是移位寄存器中的内容不再受密文的影响，而是每次独立进行加密。这样做的一大好处是某一位出错后，仅影响该位的密文，而和后面无关，前面CBC和CFB每次加密都会用到前面的信息，某一位出错将会影响后面所有输出。 解密过程也就相对较简单，将密文和初始向量加密后的信息做异或处理即可，随后也同步更新移位寄存器中内容。示意图如下 计数器(CTR)模式这种模式也被成为ICM(Integer Counter Mode)或SIC模式(Segmented Integer Counter) 这种模式类似于OFB模式，只不过将寄存器中的值换做一个计数器，计数器在任意时间产生不同的输出，之后对该输出进行加密，并用加密过的结果和明文异或，得到的结果作为密文。示意图（注意图中计数器的输出采用的是一个初始化向量和整数拼接的方式）如下： 解密方法和OFB类似，不在赘述，直接看示意图 这种方式的一大特点是可以并行加密，由于不同块的计数器输出是可以事先预测的，所以可以实现并行加密。 题图来自unsplash: https://unsplash.com/photos/pdRsf77OBoo]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protobuf学习及编码深入]]></title>
    <url>%2F2019%2F03%2F22%2FProtobuf%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%BC%96%E7%A0%81%E6%B7%B1%E5%85%A5%2F</url>
    <content type="text"><![CDATA[简介按照官方的介绍，Protocol buffers是一种与具体平台或者编程语言无关的可扩展的序列化语言，类似于XML或者JSON，由其对比XML而言，具有更小更快更简单的特点。接下来我们就来了解一下这个东西。 简单使用一般而言，使用步骤有三步。首先定义Protobuf模板文件，以.proto为后缀；然后生成特定语言的接口代码；最后利用接口代码进行序列化或者反序列操作。整体步骤和我们利用一些第三方库如Gson去操作json文件类似，下面就具体看一下这几个过程： 定义Protobuf文件下面这个例子是官方文档给出，定义了一个地址簿的数据结构：12345678910111213141516syntax = &quot;proto2&quot;;package tutorial;option java_package = &quot;code.protobuf&quot;;option java_outer_classname = &quot;AddressBookProtos&quot;;message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3;&#125;message AddressBook &#123; repeated Person people = 1;&#125; 具体语法我们稍后再介绍，首先可以看到，Protobuf文件的格式很像一些面向对象语言中类的定义，上面例子一个message就像一个类定义，类之间可以嵌套。AddressBook中有Person对象，Person中又有PhoneNumber对象。Person中也有一些基本类型如string和int。用过Gson之类的库解析json的应该感觉这和解析json时定义的类很像。 编译写好Protobuf文件后，就相当于写好一个模板文件，在不同平台或者不同语言间交互时都以这个文件为标准，但是还不能直接，根据具体的编程语言，我们还要有接口文件，我们可以利用官方给的编译工具生成我们需要的接口代码，以java语言为例：1protoc --java_out=src\ src\code\protobuf\addressbook.proto –java_out表示生成的接口文件路径，由于我们在Protobuf文件文件中定义了java_package，所以只需指定包所在目录即可，生成的文件会自动放在具体包下，最后指定Protobuf文件具体路径。生成的文件名在Protobuf文件中java_outer_classname字段定义。 接口操作执行完命令后，在code.protobuf包下生成了AddressBookProtos.java文件(要使用这个代码还需要导入相关库)。代码还是很长的，我们仅仅定义了一个简单的地址簿数据结构，就生成了近2000行代码，但是对于我们所使用的接口而言，生成的这个代码其实就是一个JavaBean类，它使用了建造者模式，当我们要构造一个Person对象时，如下：12345678AddressBookProtos.Person john = AddressBookProtos.Person.newBuilder().setId(1234) .setName("John") .setEmail("john@163.com") .addPhones(AddressBookProtos.Person.PhoneNumber.newBuilder() .setNumber("15463") .setType(AddressBookProtos.Person.PhoneType.HOME) .build()) .build(); 除了常用的get与set方法，还提供了：toString()方法用于转为有意义的字符串形式；isInitialized()方法用于检测所有必需字段是否设置；clear()方法用于清空所有字段；mergeFrom(Message other)用于合并两个对象。 当然作为序列化工具，生成的对象也提供了序列化和反序列化相关的方法：toByteArray()和parseFrom(byte[] data)。另外还可以直接操作流：writeTo(OutputStream output)和parseFrom(InputStream input)。 简单示例这里演示一个简单的跨语言的传输数据的例子。使用Go语言编写服务端，java编写客户端，从客户端向服务端发送数据。protobuf文件还使用上面的例子，这里在使用编译工具编译go语言的接口文件，protobuf文件不用做任何修改：1protoc --go_out=.\ src\code\protobuf\addressbook.proto java的客户端代码如下：123456789101112131415161718public static void main(String[] args) &#123; AddressBookProtos.Person person = AddressBookProtos.Person.newBuilder() .setName("jack") .setId(1) .setEmail("jack@163.com") .build(); AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .addPeople(person) .build(); try (Socket socket = new Socket("127.0.0.1",1234))&#123; OutputStream out = socket.getOutputStream(); out.write(book.toByteArray()); socket.shutdownOutput(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; go的服务端代码如下12345678910111213141516171819func main() &#123; listener,err:=net.Listen("tcp",":1234") if err!=nil&#123; log.Fatalln("Listen：",err.Error()) &#125; con,err:=listener.Accept() if err!=nil&#123; log.Fatalln("Accept：",err.Error()) &#125; result,err:=ioutil.ReadAll(con) if err!=nil&#123; log.Fatalln("ReadAll：",err.Error()) &#125; book := &amp;tutorial.AddressBook&#123;&#125; if err := proto.Unmarshal(result, book); err != nil &#123; log.Fatalln("Failed to parse address book:", err) &#125; fmt.Println(*book.People[0].Email)&#125; 详细语法首先在文件第一行在指定语法版本，如：syntax = “proto2”; 基本字段类型message中每个字段都要指定数据类型。如下表： 分配字段编号如例子中所示，每个字段都要分配一个独一无二编号，编号范围在1~536,870,911，主要是为了标记字段，并且不能改变，需要注意的是19000到19999是不能使用的。关于编号，官方文档建议，对于频繁使用的元素应当使用1到15的编号，因为这些序号被编码为1byte，而16到2047被编码为2byte。 字段约束有以下几个修饰词:123required：使用时必须被指定的字段optional：可以不被指定，但是最多只能指定一个repeated：可以出现次的，也可以不出现，相当于数组的概念。官方建议使用[packed=true]选项提高编码效率：repeated int32 samples = 4 [packed=true]; 了解完字段类型，编号，约束词以后，我们可以得到message中一个字段的完整定义:12字段约束 类型 名称 = 字段编号;required string query = 1; 注释类似于java等语言的注释风格：使用// 或/**/ 保留字对于以删除的字段，若是后面再被使用，可能会导致问题，所以可以用reserved标记出来，若被使用编译器将报错。reserved使用方法如下：1234message Foo &#123; reserved 2, 15, 9 to 11; reserved &quot;foo&quot;, &quot;bar&quot;;&#125; 注意字段和编号不能混合在一起用reserved标记 可选字段的默认值对于optional修饰的字段，若未定义，会有一个与字段类型对应的默认值，如string为空，bool为false等，我们也可以指定默认值如下所示：1optional int32 result_per_page = 3 [default = 10]; 枚举类型定义如下：123456789enum Corpus &#123; UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; &#125; 在一个枚举中，可以指定一些相同值的成员，这样会被解析为别名，同时需要加上option allow_alias = true123456enum EnumAllowingAlias &#123; option allow_alias = true; UNKNOWN = 0; STARTED = 1; RUNNING = 1;&#125; 若在一个message中使用另一个message的enum可以以MessageType.EnumType的形式调用 导包protobuf也有导包的概念，如果要从一个proto文件中引用另一个proto文件中的一个message，需要使用import关键字进行导包。注意在编译时使用-I指定搜索包的路径，否则只会默认搜索当前目录下的文件 嵌套定义12345678message SearchResponse &#123; message Result &#123; required string url = 1; optional string title = 2; repeated string snippets = 3; &#125; repeated Result result = 1;&#125; 上面例子在一个message中定义了另一个message，使用时利用SearchResponse.Result引用内部定义的message Extensions扩展实际上是一个占位符，它代表未在原始文件中定义的字段123message Foo &#123; extensions 100 to 199;&#125; 其他用户可以使用extensions指定的字段为原来的message添加新字段123extend Foo &#123; optional int32 bar = 126;&#125; 访问extension也有特殊的api，示例：123456789101112//序列化AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .setExtension(AddressBookProtos.bar,10) .build();byte[] out = book.toByteArray();//反序列化ExtensionRegistry registry = ExtensionRegistry.newInstance();registry.add(AddressBookProtos.bar);AddressBookProtos.AddressBook ob = AddressBookProtos.AddressBook.parseFrom(out,registry);System.out.println(ob.hasExtension(AddressBookProtos.bar)); 注意在反序列化时候要注册需要解析的extension，并作为参数传入parseFrom Oneofoneof的出现是为了实现这样的需求：一个message中有多个成员，但同一时间只能有一个成员被赋值。12345oneof test&#123; string a = 4; string b = 5; string c = 6; &#125; 1234567891011121314AddressBookProtos.Person p2 = AddressBookProtos.Person.newBuilder() .setName("tom") .setId(2) .setEmail("tom@163.com") .setA("hello") .setB("world") .build();AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .addPeople(p2) .build(); byte[] out = book.toByteArray();AddressBookProtos.AddressBook ob = AddressBookProtos.AddressBook.parseFrom(out);System.out.println(ob.getPeople(0).hasA());System.out.println(ob.getPeople(0).hasB()); 可见我们虽然同时对A，B都进行了赋值，但是只有B被赋值成功，也就是同时只有一个成员可以被赋值需要有以下几点注意： 对一个成员赋值，会自动清除其他已赋值的成员 extension不支持oneof oneof不能被修饰为repeated 实际上对于oneof修饰的一组成员，完全可以把它们当做普通的optional成员看待，只不过这几个成员之间又互相依赖关系 另外，oneof： 安全的移除或添加字段，但会可能会导致数据丢失 可以删除一个oneof，也可能会导致数据丢失 可以分割或合并oneof，效果类似移除或添加字段 maps一般意义上的映射数据类型。1map&lt;string, Project&gt; projects = 3; key可以使任何整数或string（也就是浮点和字节类型除外），枚举也不能做为key。value可以是除map外的任何类型。注意事项： extension不支持map map不能有repeated, optional, 或 required修饰 map是无序的 map等效于下面的实现：123456message MapFieldEntry &#123; optional key_type key = 1; optional value_type value = 2;&#125;repeated MapFieldEntry map_field = N; Message更新更新需要遵循以下规则 不要改变已有字段的编号 新字段只能使用optional或repeated修饰。这样也很好理解，旧的代码序列化的数据仍然可以被新代码解析，否则会由于缺少required而报错 非required修饰的字段可以被移除，但是注意被删除的字段所使用的编号不能再次使用 只要类型或者编号不便，非required字段可以转为extension int32, uint32, int64, uint64 和 bool 是可以互相兼容的，也就是可以互相转换 sint32和sint64彼此兼容，但不和其他整数类型兼容 string和bytes互相兼容，前提是使用UTF-8编码 fixed32和sfixed32、fixed64、sfixed64是兼容的 optional与repeated是兼容的，若输入的是repeated，在解析为optional时，以最后一个输入为主，或合并输入 可以改变默认值，但要注意不同版本的protobuf文件的默认不同时会在带来潜在的冲突 enum 和 int32, uint32, int64, uint64是兼容的 将optional改为oneof是安全的 packages在proto文件中指定package字段来防止名字冲突。在java中，除非指定java_package字段，否则会以package作为包名 自定义选项 java_package ：指定生成的java文件所在的包 java_outer_classname ：指定生成的java文件名 optimize_for ：优化选项，有SPEED, CODE_SIZE, 和 LITE_RUNTIME三种选择。SPEED是默认选项，对代码进行优化。CODE_SIZE可以减小生成代码量，但解析速度会下降，LITE_RUNTIME生成的代码最少，但会失去一些特性4.deprecated：被标记为true的字段表示不再使用：optional int32 old_field = 6 [deprecated=true]; proto3语法proto3的语法和2有很多相似之处，所以这里只介绍一些不同点 版本号当然版本号要更改为proto31syntax = &quot;proto3&quot;; 修饰词移除了required修饰词；所有字段默认都是singular，也就是原来的optional，但是不能显式的指定为singularrepeated被保留了 正常情况下一个message书写如下：1234567syntax = &quot;proto3&quot;;message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3;&#125; 默认值取消了default选项，也就是说默认值只能有系统默认指定，如字符串为空串，bool型为false，数字为0等。还有对于枚举类，默认是编号为0的成员。 枚举类型必须有一个编号为0的成员来作为其第一个成员。 未知字段在3.5版本之前，不能被解析的字段会被直接抛弃，但是在3.5版本之后，这种特性又回归到proto2上，即不能被解析的字段仍然会保留到下次序列化的输出中 any用于替代extensions，不过尚在开发中 编码Varints规则protobuf的编码基础是Varints，它是将整数序列化为一个或多个byte的方法。 Varints规则是用每byte的第7位存储值，第8位为标志位，若标志位为1，表示后面还有数据，若为0，表示该byte为最后一个。最后Varints采用小端存储。下面举一个例子：123456以整数300为例，300的二进制表示如下： 100101100按小端存储并每7位一组： 0101100 0000010再加上标志位，最终表示如下： 10101100 00000010 Varints的优点是，由于标志位存在，省去了编码长度的表示，其次越小的数编码越短，但是由于标志位的存在，也牺牲了容量，如4byte实际可用表示数值的只有28位 基本编码规则我们首先看一下message中每个成员变量的定义1int32 a = 1; 有三部分组成，变量类型，变量名和变量序号。其中变量名只是为了帮助我们做识别，在编码时不会写入，仅仅用变量序号作为标识，所以也就有了在更新message时序号不能复用的规则，以及可以安全地添加新成员（没有被识别的会直接跳过）。 在编码中，成员变量是以键值对形式出现的，键有两部分组成：成员序号加上成员类型代码，具体代码如下 总共有6种代码，其中group使用的两个代码已被弃用，但是依旧保留。这6个代码需要3位二进制表示，所以键的组成是：字段编号+类型代码（加好表示拼接，并不是运算），示例如下：123456789当我们有一个inst32类型的成员a，编号为1，被赋值为150时由于是int32类型，根据上图采用varint规则，首先对150进行Varints规则编码（过程略）： 10010110 00000001由于是int32类型，类型代码为0，编号为1，类型代码采用三位二进制表示为000，二者拼接之后如下： 0001000所以a的最终编码为 0001000 10010110 00000001改用16进制表示如下 08 96 01 其他类型规则sint32, sint64对于Varints规则不适用与存储负数，负数最高位为1，造成编码极大的浪费，为了节省空间，引入了ZigZag编码格式，基本思想就是将有符号整数转为无符号整数。转换规则如下：12(n &lt;&lt; 1) ^ (n &gt;&gt; 31) #sint32(n &lt;&lt; 1) ^ (n &gt;&gt; 63) #sint64 示例如下： 转为无符号的整数后，再用varints编码即可。 64-bit 和 32-bit 类型这两种分有不同的类型代码，而且编码时不进行其他转换，直接以64位或32位原始存储（注意也是小端存储），读取时根据类型代码直接读取64位或32位 Strings类型代码2表示一类Length-delimited数据。这种编码类型还附带有长度信息，就是在键值之间附加一个用varints编码的长度编码，例子如下：123456789我们有一个string类型的变量b，编号为2，赋值为testing首先testing的utf-8编码如下： 74 65 73 74 69 6e 67长度为7，varints格式编码如下： 00000111编号加类型代码拼接后如下： 00010010最后组合在一起用十六进制表示如下： 12 07 74 65 73 74 69 6e 67 除了表示字符串这种简单信息，还可以表示其他message，如下：123456789101112message Test3 &#123; optional Test1 c = 3;&#125;其中Test1：message Test1 &#123; optional int32 a = 1;&#125;我们对Test1中a赋值为150，上面已经计算过，最后编码为 08 96 01对于Test1类型的变量c表示如下：首先原始数据就是08 96 01，长度为3，编号为3，类型代码为2，组合起来就是 1a 03 08 96 01 packed在proto3中packed为默认的，在proto2中需要手动指定。使用proto3 模式将会使编码更加紧凑（主要针对repeated 类型）。设想，对于一个repeated类型的成员，他们有多个值时，虽然值不同，前键都是相同的，我们可以减少键的数量，如下例：12345假设有一个int32类型的变量d，序号为4，是一个repeated类型，我们赋了4个值，分别是3,270,86942.使用packed模式后，如下22 06 03 8E 02 9E A7 05注意22是编号加类型代码（为2，指packed repeated fields），06表示数据长度后面实际数据，都是varints编码，但是互有区分 顺序编解码顺序和字段顺序无关，由键值对保证即可。未知字段会写在已知字段后。]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Playfair密码与实现]]></title>
    <url>%2F2019%2F03%2F20%2FPlayfair%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[背景这种加密方法是1854年Charles Wheatstone发明的，由Lord Playfair推广，所以命名为Playfair密码。它在一战和二战中都有使用，虽然在一战中就被破译，但是由于使用简单，可以用来保护一些敏感但不很关键的信息，即使被破译，信息也已经过时。 详细流程创建矩阵这种密码使用一个5*5的矩阵作为一个密码表，用作加密解密时的秘钥。这个矩阵由一个关键词生成，首先将关键词从左到右，从上到下填入矩阵，遇到重复元素则省略，写完之后按照字母表顺序，将未出现的字母填充到剩余位置，知道整个矩阵被填满。 如以PLAYFAIREXAMPLE为关键词，生成的矩阵如下： 你可能注意到，密码表中缺少J，由于只有25个空位，对于字母大于25的语言，可以将某两个合并，或者省去出现频率少的，这里把i和j进行了合并 加密加密之前首先将明文两两分组），对每一组分别进行以下处理 在密码表中找到每组中两个字母的位置 若果两个字母相同或组中只有一个字母，则插入一个字母，如X或Q（如果最后一个字母或者重复的字母是X，可以添加Q，替换方法可自定义） 如果两个字母在密码表的同一行，则用这两个字母右边的字母进行替换，如(I,E)替换为(R,X)。我们定义第一列是最后一列的右边 如果两个字母在密码表的同一列，则用这两个字母的下方字母进行替换，如(E,O)替换为(D,V)。我们定义第一行是最后一行的下边 如果两个字母不在同一行同一列，则用对角线上的字母进行替换，至于是行替换或列替换可以自行定义。如(M,Y)替换为(X,F)，使用的是行替换 解密解密就很简单了，基本就是加密的逆过程，还是利用密码表，如在同一行的话，用左边替换，同一列用上面的替换，在对角线上的还是不变。具体过程见后面实现。 示例如还以PLAYFAIREXAMPLE为关键词，明文为MYNAMEISTOM，加密过程如下： 生成矩阵，如上图 分组：MY NA ME IS TO MX (最后一个单独字母补X) 根据密码表替换 XF OL IX MK VK IM 最后密文为： XFOLIXMKVKIM 简单实现这里只是简单实现了Playfair密码原理，有些地方如包含标点符号，非英文字母的情况并没有处理，有兴趣的可以自行修改123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125public class PlayFair &#123; char[][] table = new char[5][5]; //密码表 PlayFair(String key)&#123; generateTable(key);//根据关键字生成密码表 &#125; private void generateTable(String key)&#123; key = key.replaceAll(" ","").toUpperCase(); char[] keys = key.toCharArray(); int count = 0; char alphabet = 'A'; ArrayList&lt;Character&gt; list = new ArrayList&lt;&gt;(); for (int i = 0;i&lt;5;i++)&#123; for (int j = 0;j&lt;5;j++)&#123; while(count &lt; keys.length &amp;&amp; list.contains(keys[count]))&#123; //寻找关键字中不重复的字母 count++; &#125; if (count &lt; keys.length)&#123; table[i][j] = keys[count]; list.add(keys[count]); count++; &#125;else&#123; while (alphabet &lt;= 'Z' &amp;&amp; (list.contains(alphabet) || alphabet == 'J'))&#123; //按顺序从字母表中填充 alphabet++; &#125; table[i][j] = alphabet; alphabet++; &#125; &#125; &#125; &#125; public String encryption(String msg)&#123; //加密算法 msg = msg.replaceAll(" ","").toUpperCase(); char[] msgs = msg.toCharArray(); StringBuffer result = new StringBuffer(); for (int i = 0;i&lt;msgs.length;i++)&#123; char a = msgs[i];//获取分组第一个字母 i++; char b; if (i&lt;msgs.length)&#123; //判读是否越界 if (msgs[i] == a)&#123; //是否重复 if (a == 'X')&#123; //若是X重复，添加Q b = 'Q'; &#125;else&#123; b = 'X'; &#125; i--; &#125;else&#123; b = msgs[i]; &#125; &#125;else&#123; //越界，就是最后只剩一个字母 if (a == 'X')&#123; //若最后一个是X，补Q b = 'Q'; &#125;else&#123; b = 'X'; &#125; &#125; int[] locA = find(a); //寻找分组第一个字母位置 int[] locB = find(b); //寻找分组第二个字母位置 if(locA[0] == locB[0])&#123; //若在同一行 a = locA[1]+1&lt;5?table[locA[0]][locA[1]+1]:table[locA[0]][0]; b = locB[1]+1&lt;5?table[locB[0]][locB[1]+1]:table[locB[0]][0]; &#125;else if(locA[1] == locB[1])&#123; //若在同一列 a = locA[0]+1&lt;5?table[locA[0]+1][locA[1]]:table[0][locA[1]]; b = locB[0]+1&lt;5?table[locB[0]+1][locB[1]]:table[0][locB[1]]; &#125;else&#123; //不在同一行同一列，行替换 a = table[locA[0]][locB[1]]; b = table[locB[0]][locA[1]]; &#125; result.append(a); result.append(b); &#125; return result.toString(); &#125; public String decrypt(String msg)&#123; //解密算法 msg = msg.replaceAll(" ","").toUpperCase(); char[] msgs = msg.toCharArray(); if (msgs.length%2!=0)&#123; //密文不是偶数个，报错 return "error: The length of ciphertext is odd"; &#125; StringBuffer result = new StringBuffer(); for (int i = 0;i&lt;msgs.length;i++)&#123; char a = msgs[i]; i++; char b = msgs[i]; int[] locA = find(a);//寻找分组第一个字母位置 int[] locB = find(b);//寻找分组第二个字母位置 if(locA[0] == locB[0])&#123; //若在同一行 a = locA[1]-1&gt;-1?table[locA[0]][locA[1]-1]:table[locA[0]][4]; b = locB[1]-1&gt;-1?table[locB[0]][locB[1]-1]:table[locB[0]][4]; &#125;else if(locA[1] == locB[1])&#123; //若在同一列 a = locA[0]-1&gt;-1?table[locA[0]-1][locA[1]]:table[4][locA[1]]; b = locB[0]-1&gt;-1?table[locB[0]-1][locB[1]]:table[4][locB[1]]; &#125;else&#123; //不在同一行同一列 a = table[locA[0]][locB[1]]; b = table[locB[0]][locA[1]]; &#125; result.append(a); result.append(b); &#125; return result.toString(); &#125; private int[] find(char c)&#123; //寻找字母在表中位置 if (c == 'J')//对于J当做I处理 c = 'I'; for (int i = 0;i&lt;5;i++)&#123; for (int j = 0;j&lt;5;j++)&#123; if (table[i][j] == c) return new int[]&#123;i,j&#125;; &#125; &#125; return new int[]&#123;-1,-1&#125;; &#125; public static void main(String[] args) &#123;//测试代码 PlayFair p = new PlayFair("PLAYFAIREXAMPLE"); String msg = p.encryption("MYNAMEISTOM"); System.out.println("ciphertext：" + msg); System.out.println("plaintext：" + p.decrypt(msg)); &#125;&#125; 小结本质上Playfair密码仍然是替换型的密码算法。与一般的替换算法相比，他的替换不固定，每个字母都有可能替换为任意一个其他字母。另外实现简单，一个不同秘钥生成不同密码表，产生不同的替换可能。但是它依然可以被破解，首先它是按照顺序读取的，密文与明文基本上一一对应，从而也暴露的密文结构；其次，密码表最后填充时是按照字母表顺序填充，可借助字母出现频率构造密码表，一旦一部分被构造出来，剩下的很容易破解；]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rlp编码学习]]></title>
    <url>%2F2019%2F03%2F19%2Frlp%E7%BC%96%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[RLP的全称是Recursive Length Prefix，是以太坊实现中普遍使用的一种序列化方法，在黄皮书的附录B中有详细的定义，我们这里也简要学习一下 源数据RLP定义了两种源数据，一种是一维的字节数组；另外一种是多维字节数组，也就是一维数组的嵌套。所有要序列化的数据类型，都要有一定的方法转为上述两种格式，转换的方法可以根据不同的实现自己定义。在黄皮书中给出了源数据的定义： RLP定义函数定义如下： 可见分别定义了两个函数，对应了上一节中的两种源数据，分别解释一下这两个函数 源数据为一维字节数组当数据为简单的一维字节数组时，有以下三种序列化规则: 当只含有一个字节时，而且这个字节又小于128，则不做任何处理，直接输出，对应上图第一种情况 当字节数组的长度小于56时，则加上一个前缀，这个前缀等于128+字节数组长度，对应上图第二种情况 若不符合上述两种情况，则加上这样两个前缀，第一个前缀等于183+字节数组长度在大端表示时的长度，第二个前缀为字节数组长度的大端表示，对应上图第三种情况（所谓大端表示就是将高位字节排放在内存的低地址端，0x1234表示为00 00 12 34，BE函数就是去除前面的零，也可以理解为实际长度） 源数据为嵌套的多维字节数组当数据为嵌套的多维数组形式时，有以下两种序列化规则： 首先对数组中每一个子元素都递归使用上一小节中的规则序列化，注意序列化时对象都要为一维字节数组，若子元素也是嵌套格式，则递归调用，之后将每个子元素序列化结果拼接起来。对于拼接后的长度： 若长度小于56，则加上这样一个前缀，这个前缀等于192+拼接后的长度，对应上图第一种情况 若长度大于等于56，则加上这样两个前缀，第一个前缀等于247+拼接后字节数组长度在大端表示时的长度，第二个前缀为拼接后的长度的大端表示，对应上图第二种情况 源数据是标量数据首先RLP只能用于处理正整数，处理是要先用BE函数处理，去掉前导0后，当做字节数组处理，如下图： 解码实际上了解到编码规则后，解码就很简单，关键就是第一个字节，这个字节标识使用哪种情况编码 当位于[0,128)区间时，对应源数据是一维字节数组的第一种情况，就是单一字节 当位于[128,184)区间时，对应源数据是一维字节数组的第二种情况，就是长度小于56的一维字节数组 当位于[184,192)区间时，对应源数据是一维字节数组的第三种情况，这时观察第二个前缀，第二个前缀长度等于第一个字节减去183，然后计算原始数据的真正长度 当位于[192,247)区间时，对于源数据是多维字节数组的第一种情况，就是拼接长度小于56，递归解析其后数据 当位于[247,256)区间时，对于源数据是多维字节数组的第二种情况，类似于第三条规则，先实际计算出第二个前缀的长度，在解析数原始数据长度，在递归解析出原始数据 源码解析源码主要集中在go-ethereum\rlp目录下，再去除一些测试代码，实际功能代码并不多，关键如下：1234decode.go //解码器，就是反序列化encode.go //编码器，就是序列化raw.go //未解码的RLP数据typecache.go //类型缓存， 类型缓存记录了类型-&gt;(编码器|解码器)的内容。 typecache由于go-ethereum是用go语言实现的，而go语言没有方法重载，所以对于不同类型的数据要手动指定需要的编解码器。这个类主要功能是给我们返回一个typeinfo类型的对象，这个对象保存在对应数据类型的编解码方法1234type typeinfo struct &#123; decoder writer&#125; 去创建一个typeinfo需要从cachedTypeInfo方法开始：1234567891011121314151617181920212223242526272829303132333435363738// go-ethereum\rlp\typecache.gofunc cachedTypeInfo(typ reflect.Type, tags tags) (*typeinfo, error) &#123; typeCacheMutex.RLock() info := typeCache[typekey&#123;typ, tags&#125;] //尝试从缓存中国区 typeCacheMutex.RUnlock() if info != nil &#123; //获取成功 return info, nil &#125; typeCacheMutex.Lock() //加锁，避免多线程多次创建 defer typeCacheMutex.Unlock() return cachedTypeInfo1(typ, tags)&#125;func cachedTypeInfo1(typ reflect.Type, tags tags) (*typeinfo, error) &#123; key := typekey&#123;typ, tags&#125; info := typeCache[key]//再次尝试获取，确保只创建一次 if info != nil &#123; //获取成功 return info, nil &#125; typeCache[key] = new(typeinfo) //创建一个空对象 info, err := genTypeInfo(typ, tags) //实际创建对象 if err != nil &#123; //创建失败 delete(typeCache, key) return nil, err &#125; *typeCache[key] = *info //存储到map中 return typeCache[key], err&#125;func genTypeInfo(typ reflect.Type, tags tags) (info *typeinfo, err error) &#123; info = new(typeinfo) if info.decoder, err = makeDecoder(typ, tags); err != nil &#123; return nil, err &#125; if info.writer, err = makeWriter(typ, tags); err != nil &#123; return nil, err &#125; return info, nil&#125; 可见对每种类型，都是单例模式。上述代码中实际创建编解码器的方法是makeDecoder和makeWriter。这两个方法详见下文 encode对于编码器的使用，一般调用Encode函数：123456789101112func Encode(w io.Writer, val interface&#123;&#125;) error &#123; if outer, ok := w.(*encbuf); ok &#123;//判断是否是encbuf类型的writer return outer.encode(val) &#125; eb := encbufPool.Get().(*encbuf) //从并发变量池中获取一个encbuf对象 defer encbufPool.Put(eb) eb.reset() //清空原有数据 if err := eb.encode(val); err != nil &#123; //编码 return err &#125; return eb.toWriter(w)&#125; 编码的核心操作在encbuf的encode方法：12345678func (w *encbuf) encode(val interface&#123;&#125;) error &#123; rval := reflect.ValueOf(val) ti, err := cachedTypeInfo(rval.Type(), tags&#123;&#125;) if err != nil &#123; return err &#125; return ti.writer(rval, w)&#125; 这里就接上了上一节typecache中的方法，这里通过makeWriter确定编码器1234567891011121314151617181920212223242526272829303132333435func makeWriter(typ reflect.Type, ts tags) (writer, error) &#123; kind := typ.Kind() switch &#123; case typ == rawValueType: return writeRawValue, nil case typ.Implements(encoderInterface): return writeEncoder, nil case kind != reflect.Ptr &amp;&amp; reflect.PtrTo(typ).Implements(encoderInterface): return writeEncoderNoPtr, nil case kind == reflect.Interface: return writeInterface, nil case typ.AssignableTo(reflect.PtrTo(bigInt)): return writeBigIntPtr, nil case typ.AssignableTo(bigInt): return writeBigIntNoPtr, nil case isUint(kind): return writeUint, nil case kind == reflect.Bool: return writeBool, nil case kind == reflect.String: return writeString, nil case kind == reflect.Slice &amp;&amp; isByte(typ.Elem()): return writeBytes, nil case kind == reflect.Array &amp;&amp; isByte(typ.Elem()): return writeByteArray, nil case kind == reflect.Slice || kind == reflect.Array: return makeSliceWriter(typ, ts) case kind == reflect.Struct: return makeStructWriter(typ) case kind == reflect.Ptr: return makePtrWriter(typ) default: return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ) &#125;&#125; 就是简单的根据不同的类型创建不同的编码方法，以string为例：1234567891011121314151617181920func writeString(val reflect.Value, w *encbuf) error &#123; s := val.String() if len(s) == 1 &amp;&amp; s[0] &lt;= 0x7f &#123;//只有一个字符，且小于128 w.str = append(w.str, s[0]) &#125; else &#123; w.encodeStringHeader(len(s))//添加前缀 w.str = append(w.str, s...) &#125; return nil&#125;func (w *encbuf) encodeStringHeader(size int) &#123; if size &lt; 56 &#123; //长度小于56 w.str = append(w.str, 0x80+byte(size))//前缀是128+长度 &#125; else &#123; //其他情况 sizesize := putint(w.sizebuf[1:], uint64(size)) //将长度的大端表示写入sizebuf w.sizebuf[0] = 0xB7 + byte(sizesize) //第一个前缀183+字符串长度在大端表示后的长度 w.str = append(w.str, w.sizebuf[:sizesize+1]...)//拼接第二个前缀，字符串长度的大端表示 &#125;&#125; 详细过程见注释，基本过程和RLP定义的一样。对于结构体可能有些特殊：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func makeStructWriter(typ reflect.Type) (writer, error) &#123; fields, err := structFields(typ) //分析结构体每个字段，根据情况指定每个字段的编码方法 if err != nil &#123; return nil, err &#125; writer := func(val reflect.Value, w *encbuf) error &#123; //编码器具体方法 lh := w.list() for _, f := range fields &#123; if err := f.info.writer(val.Field(f.index), w); err != nil &#123; return err &#125; &#125; w.listEnd(lh) return nil &#125; return writer, nil&#125;// go-ethereum\rlp\typecache.gofunc structFields(typ reflect.Type) (fields []field, err error) &#123; for i := 0; i &lt; typ.NumField(); i++ &#123; if f := typ.Field(i); f.PkgPath == "" &#123; // 若果是可导出的，也就是首字母大写，PkgPath为空，不可导出会返回包名 tags, err := parseStructTag(typ, i)//解析每个字段的标签，就是字段后``中定义的 if err != nil &#123; return nil, err &#125; if tags.ignored &#123; continue &#125; info, err := cachedTypeInfo1(f.Type, tags)//根据类型获取cachedTypeInfo，包含编解码器 if err != nil &#123; return nil, err &#125; fields = append(fields, field&#123;i, info&#125;) &#125; &#125; return fields, nil&#125;func parseStructTag(typ reflect.Type, fi int) (tags, error) &#123; f := typ.Field(fi) var ts tags for _, t := range strings.Split(f.Tag.Get("rlp"), ",") &#123; switch t = strings.TrimSpace(t); t &#123; case "": case "-": ts.ignored = true case "nil": ts.nilOK = true case "tail": ts.tail = true if fi != typ.NumField()-1 &#123; return ts, fmt.Errorf(`rlp: invalid struct tag "tail" for %v.%s (must be on last field)`, typ, f.Name) &#125; if f.Type.Kind() != reflect.Slice &#123; return ts, fmt.Errorf(`rlp: invalid struct tag "tail" for %v.%s (field type is not slice)`, typ, f.Name) &#125; default: return ts, fmt.Errorf("rlp: unknown struct tag %q on %v.%s", t, typ, f.Name) &#125; &#125; return ts, nil&#125; 结构体类型的虽然复杂，但也是具体到每个字段执行不同的序列化方法，最后进行拼接。 decode对于解码器一般调用Decode函数：1234567891011121314151617181920212223242526func Decode(r io.Reader, val interface&#123;&#125;) error &#123; return NewStream(r, 0).Decode(val)&#125;func (s *Stream) Decode(val interface&#123;&#125;) error &#123; if val == nil &#123; return errDecodeIntoNil &#125; rval := reflect.ValueOf(val) rtyp := rval.Type() if rtyp.Kind() != reflect.Ptr &#123; //判断是否为指针类型 return errNoPointer &#125; if rval.IsNil() &#123; return errDecodeIntoNil &#125; info, err := cachedTypeInfo(rtyp.Elem(), tags&#123;&#125;) //获取编解码方法 if err != nil &#123; return err &#125; err = info.decoder(s, rval.Elem())//解码 if decErr, ok := err.(*decodeError); ok &amp;&amp; len(decErr.ctx) &gt; 0 &#123; decErr.ctx = append(decErr.ctx, fmt.Sprint("(", rtyp.Elem(), ")")) &#125; return err&#125; 注意decode的逻辑是从Stream中获取源数据，最后解析到val中，所以需要val是一个指针类型，接下来又回到typecache中，通过判断val的类型获取所需的解码器。12345678910111213141516171819202122232425262728293031323334func makeDecoder(typ reflect.Type, tags tags) (dec decoder, err error) &#123; kind := typ.Kind() switch &#123; case typ == rawValueType: return decodeRawValue, nil case typ.Implements(decoderInterface): return decodeDecoder, nil case kind != reflect.Ptr &amp;&amp; reflect.PtrTo(typ).Implements(decoderInterface): return decodeDecoderNoPtr, nil case typ.AssignableTo(reflect.PtrTo(bigInt)): return decodeBigInt, nil case typ.AssignableTo(bigInt): return decodeBigIntNoPtr, nil case isUint(kind): return decodeUint, nil case kind == reflect.Bool: return decodeBool, nil case kind == reflect.String: return decodeString, nil case kind == reflect.Slice || kind == reflect.Array: return makeListDecoder(typ, tags) case kind == reflect.Struct: return makeStructDecoder(typ) case kind == reflect.Ptr: if tags.nilOK &#123; return makeOptionalPtrDecoder(typ) &#125; return makePtrDecoder(typ) case kind == reflect.Interface: return decodeInterface, nil default: return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ) &#125;&#125; 以string为例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192func decodeString(s *Stream, val reflect.Value) error &#123; b, err := s.Bytes() if err != nil &#123; return wrapStreamError(err, val.Type()) &#125; val.SetString(string(b)) //还原为string return nil&#125;func (s *Stream) Bytes() ([]byte, error) &#123; kind, size, err := s.Kind() if err != nil &#123; return nil, err &#125; switch kind &#123; case Byte: s.kind = -1 return []byte&#123;s.byteval&#125;, nil case String: b := make([]byte, size) //根据数据长度指定byte数组 if err = s.readFull(b); err != nil &#123; //读取原始数据 return nil, err &#125; if size == 1 &amp;&amp; b[0] &lt; 128 &#123; return nil, ErrCanonSize &#125; return b, nil default: return nil, ErrExpectedString &#125;&#125;func (s *Stream) Kind() (kind Kind, size uint64, err error) &#123; var tos *listpos if len(s.stack) &gt; 0 &#123; tos = &amp;s.stack[len(s.stack)-1] &#125; if s.kind &lt; 0 &#123; s.kinderr = nil if tos != nil &amp;&amp; tos.pos == tos.size &#123; return 0, 0, EOL &#125; s.kind, s.size, s.kinderr = s.readKind() //读取原始数据类型以及长度 if s.kinderr == nil &#123; if tos == nil &#123; if s.limited &amp;&amp; s.size &gt; s.remaining &#123; s.kinderr = ErrValueTooLarge &#125; &#125; else &#123; if s.size &gt; tos.size-tos.pos &#123; s.kinderr = ErrElemTooLarge &#125; &#125; &#125; &#125; return s.kind, s.size, s.kinderr&#125;func (s *Stream) readKind() (kind Kind, size uint64, err error) &#123; b, err := s.readByte() //读第一个byte if err != nil &#123; if len(s.stack) == 0 &#123; switch err &#123; case io.ErrUnexpectedEOF: err = io.EOF case ErrValueTooLarge: err = io.EOF &#125; &#125; return 0, 0, err &#125; s.byteval = 0 switch &#123; //根据第一字节的只判断原始数据类型 case b &lt; 0x80: //原始数据只有一个byte，且小于128 s.byteval = b return Byte, 0, nil case b &lt; 0xB8: //原始数据长度小于56 //返回的第二个数据获得原始数据长度 return String, uint64(b - 0x80), nil case b &lt; 0xC0: size, err = s.readUint(b - 0xB7) if err == nil &amp;&amp; size &lt; 56 &#123; err = ErrCanonSize &#125; return String, size, err case b &lt; 0xF8: return List, uint64(b - 0xC0), nil default: size, err = s.readUint(b - 0xF7) if err == nil &amp;&amp; size &lt; 56 &#123; err = ErrCanonSize &#125; return List, size, err &#125;&#125; 可见流程就是rlp编码的逆向过程，和我们之前讲的解码方法一样，关键是通过第一个字节获取原始数据的类型，然后推算出原始数据的长度，最后解析即可 小结最后，go-ethereum源码中rlp实现部分还是很完整的，并且没有什么其他依赖，都使用的是go标准包，所以可以单独拿出来做一个库，以后遇到需要用rlp编码的地方，可以直接拿来使用。还有这一部分源码大量的使用了反射，对于学习go语言反射也是很好的一个素材]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>go</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言signal包使用指南]]></title>
    <url>%2F2019%2F02%2F27%2FGo%E8%AF%AD%E8%A8%80signal%E5%8C%85%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[go语言学习笔记：signal包 os/signal主要用于实现对信号的处理(官方文档) 信号类型首先关于linux信号机制课自行查找资料，这里不再赘述。linux中的全部信号如下图： 在go中预定义了几种信号：1234567891011121314151617//"syscall"const ( // More invented values for signals SIGHUP = Signal(0x1) SIGINT = Signal(0x2) SIGQUIT = Signal(0x3) SIGILL = Signal(0x4) SIGTRAP = Signal(0x5) SIGABRT = Signal(0x6) SIGBUS = Signal(0x7) SIGFPE = Signal(0x8) SIGKILL = Signal(0x9) SIGSEGV = Signal(0xb) SIGPIPE = Signal(0xd) SIGALRM = Signal(0xe) SIGTERM = Signal(0xf)) 首先在这么多信号中，SIGKILL和SIGSTOP是无法被程序捕获的，其中SIGKILL就是我们常用的kill -9 pid方法锁触发的。其次一些有程序执行中的错误所触发的同步信号如SIGBUS，SIGFPE和SIGSEGV，go会将其转为panic，不过若是我们通过kill方式触发也是可以被捕获的。 除了那些同步信号，其余都是异步信号，是由内核或其他程序发送的，我们都可以捕获。 在异步信号中，当程序丢失终端时收到SIGHUP，在终端按下中断字符(一般为ctrl+c)时收到SIGINT，在终端按下退出字符(一般为^\)时收到SIGQUIT。 正常的，信号都是有默认动作的，最常见的如按下ctrl+c退出程序。其余的SIGHUP，SIGINT或SIGTERM信号导致程序退出。SIGQUIT，SIGILL，SIGTRAP，SIGABRT，SIGSTKFLT，SIGEMT或SIGSYS信号导致程序以堆栈转储退出。SIGTSTP，SIGTTIN或SIGTTOU信号获取系统默认行为（shell使用这些信号进行作业控制）。SIGPROF会被go运行时捕获实现runtime.CPUProfile. 捕获信号signal包中提供了Notify方法，用于注册所要监听的信号。1func Notify(c chan&lt;- os.Signal, sig ...os.Signal) 该方法需要提供一个Signal类型的channel，以及要监听的信号(当不指定时会监听所有信号)。当有信号到来时，会被写入所传入的channel中，之后拿出来即可。下例是一个监听ctrl+c退出的程序：1234567func main() &#123; c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGINT) s := &lt;-c fmt.Println("Got signal:", s)&#125; 上述程序会在第五行阻塞，直到有一个信号过来。运行结果如下： 其余apifunc Stop(c chan&lt;- os.Signal)这个方法用于停止监听信号，之后不会再往所指定的channel中写入任何内容。搭配Notify使用如下：12345678go func() &#123; sigc := make(chan os.Signal, 1) signal.Notify(sigc, syscall.SIGINT, syscall.SIGTERM) //监听信号 defer signal.Stop(sigc) //确保关闭 &lt;-sigc //线程阻塞 log.Info("Got interrupt, shutting down...") go Stop() //执行程序停止逻辑 &#125;() func Ignore(sig …os.Signal)忽略指定的信号，同理，若是未指定，忽略所有信号 func Ignored(sig os.Signal) bool检查某个信号是否被忽略 func Reset(sig …os.Signal)重置之前调用Notify时的处理。也就是不在捕获信号，进行默认操作。注意和Ignore的区别，Ignore是不对信号做任何操作，Reset是恢复默认操作。 附录部分信号说明(图片来源于网络)：]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum编译流程简单学习]]></title>
    <url>%2F2019%2F02%2F21%2Fgo-ethereum%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[go-ethereum源码学习：源码编译流程 一般，在根目录下执行make geth 或者 make all编译go-ethereum。前者仅编译go-ethereum主程序，后者编译所有模块。详见go-ethereum的README 以make geth为例，进入go-ethereum根目录下，打开Makefile文件，执行的逻辑是1234geth: build/env.sh go run build/ci.go install ./cmd/geth @echo "Done building." @echo "Run \"$(GOBIN)/geth\" to launch geth." 可见直接执行了build/env.sh脚本，传入的参数为go run build/ci.go install ./cmd/geth 进入这个脚本文件，签名若干行都是在进行目录和环境设置，只有最后一行起到编译作用1exec "$@" exec指执行后面的跟的命令，$@是一个变量，存储着传给这个脚本的所有参数，这里的参数就是上面说的go run build/ci.go install ./cmd/geth ./cmd/geth，这就是go的编译命令，他编译运行的是build/ci.go文件，顺便还传入了参数install ./cmd/geth 首先在这个文件开头，我们可以知道这也是一个CLI程序，和我们编译生成的geth类似，在开头列出了一些命令的格式，如第一行就是我们流程中将要执行的1234Available commands are: install [ -arch architecture ] [ -cc compiler ] [ packages... ] ... 我们所要执行的就是 install ./cmd/geth，没有任何附加参数。 先从main函数开始，在这里的switch结构中，判断了第一个参数，我们这里为install，执行doInstall(os.Args[2:])，传入的参数自然为./cmd/geth。doInstall这个方法也比较简单，首先，利用flag进行参数解析，然后判断了go的版本后，最后根据需求拼凑编译指令。这一部分关键步骤注释见这里]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go的CLI程序开发]]></title>
    <url>%2F2019%2F02%2F21%2Fgo%E7%9A%84CLI%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[go语言学习笔记：CLI程序开发 CLI(command-line interface)就是命令行界面，我们在linux命令行中输入的一个个指令都是CLI程序，典型如tar命令，一般使用go开发一个命令行程序有以下几种方法 Arguments这个算是最基本的方法，但也是最繁琐的。主要借助os.Args，查看源码，介绍如下 12// Args hold the command-line arguments, starting with the program name.var Args []string 这里告诉我们这个数组切片保存了命令行的参数，且第一个参数程序名。这里需要注意的一点是，就算一个参数不附加，os.Args这个数组也是有一个值的，就是当前的程序，所以我们在通过len(os.Args)判断是否有额外参数时，len(os.Args)&gt;1才能说明有额外参数 既然我们可以通过这个数组获取所有参数，那么就可以通过一系列参数判断，开发出一个命令行程序，但无疑是很繁琐的，所以go标准库中提供了一个简单的库来帮助我们 flag我们先引入一个小例子 12345func main() &#123; dir := flag.String("dir","/home/user","data directory") flag.Parse() fmt.Println(*dir)&#125; 之后再命令行输入下面命令去运行，123456789101112131415161718go run example.go 输出/home/usergo run example.go -dir /etc/opt 输出/etc/optgo run in.go -h输出：Usage of .../example.exe -dir string data directory (default &quot;/home/user&quot;) go run example.go -dirs /etc输出：flag provided but not defined: -dirsUsage of .../example.exe -dir string data directory (default &quot;/home/user&quot;) 可以看出这已经是一个比较完善的命令程序，我们指定了参数名：dir，默认值：”/home/user”，以及参数解释：”data directory”。之后flag包自动帮我们解析参数，并附带了-h帮助信息，以及未定义参数的提示信息 通过上面的例子基本可以了解flag大体使用方法，首先定义一些参数，之后flag.Parse()进行解析，最后使用解析到的数据即可，关于Parse()源码如下 123func Parse() &#123; CommandLine.Parse(os.Args[1:])&#125; 可见也是用的os.Args[1:]作为输入，只不过这个包帮我们做好了匹配及错误处理而已。接下来详细学习一下用法 flag定义基本上分三大类： flag.Xxx(name,value,usage) *Xxx Xxx表示相应的数据类型，如Bool，Float64，Int，String等等，参数都是三个：名称，默认值，用法介绍。返回值1是相应类型的一个指针变量。例子如下： 1dir := flag.String("dir","/home/user","data directory") flag.XxxVar(p,name,value,usage) Xxx也是表示相应的数据类型，和上面那个一样，区别是多了一个参数，需要传入一个变量的引用，然后解析时会把值赋给这个变量，没有返回值，例子如下 12var dir stringflag.StringVar(&amp;dir,"dir","/home/user","data directory") flag.Var(value,name,usage) 当包中预定义的数据类型不能满足要求时，就需要这个方法了，第一个参数是一个引用，其类是实现flag.Value 接口，剩下的两个参数意义和上边的一样。先看一下这个接口 1234type Value interface &#123; String() string Set(string) error&#125; 基本上就是要定义存取方法，只不过存取的值都必须是string类型，举一个简单的例子 1234567891011121314151617181920212223242526272829303132type student struct &#123; name string age int64&#125;func (s *student) String()string&#123; return s.name+string(s.age)&#125;func (s *student) Set(str string)error&#123; slice:=strings.Split(str,",") if len(slice)!=2 &#123; return errors.New("bad format") &#125; i,err:=strconv.ParseInt(slice[1],10,64) if err!=nil &#123; return err &#125; s.name = slice[0] s.age = i return nil&#125;func main() &#123; var dir student flag.Var(&amp;dir,"stu","student info") flag.Parse() fmt.Println(dir.name,"+++",dir.age)&#125;//用法//go run example.go -stu wang,21 flag格式一般形式如下： 123-flag-flag = x-flag x //仅适用于非boolean类型flag 其中-和–都是允许的 flag解析会在遇到第一个非flag参数或单独的–之后停止，例 123456func main() &#123; n := flag.Int("n",0,"number") flag.Parse() fmt.Println(*n) fmt.Println(flag.NArg())&#125; 下面的命令都会由于提前停止解析得不到所要的值 123go run example.go 45 -n 1 //flag.NArg()会返回3go run example.go - -n 1 //flag.NArg()会返回3go run example.go -- -n 1 //flag.NArg()会返回2，--被当做终止符 其他方法 Arg(i int)string ， Args()[]string ， NArg()int ， NFlag()int Arg(i int)返回的是在被flag解析后，第i个剩余的参数，没有的话返回空字符串 Args()返回的是被flag解析后，剩余参数数组切片 NArg()返回的是被flag解析后，剩余参数的个数 NFlag()返回的是接收到的flag参数个数（并不是定义的个数） 12345678910111213n := flag.Int("n",0,"number")flag.Parse()fmt.Println(n)fmt.Println(flag.Arg(1))//输入&gt;go run example.go -n 1 454 555，返回555 //输入&gt;go run example.go -n 1 454 ，返回空 fmt.Println(flag.Args())//输入&gt;go run example.go -n 1 454 555，返回[454,555]fmt.Println(flag.NArg())//输入&gt;go run example.go -n 1 454 555,返回2fmt.Println(flag.NFlag())//输入&gt;go run example.go -n 1 454 555，返回1 //输入&gt;go run example.go 454 555，返回0 flag.Parsed()bool 判断参数是否解析过 Set(name, value string) error 给指定的flag赋值 flag.Usage 库里已经帮我们自动生成了一套帮助信息，可以使用-h或-help查看，另外我们也可以自己定制，重写Usage例 123 flag.Usage = func() &#123; fmt.Println("hello world")&#125; 另外我们也可以看一下源码，原来的帮助信息是怎么生成的 1234var Usage = func() &#123; fmt.Fprintf(CommandLine.Output(), "Usage of %s:\n", os.Args[0]) PrintDefaults()&#125; 可见，先是打印了os.Args[0]，也就是程序信息，之后调用了PrintDefaults()，打印了所有flag的信息 urfave/cli其实官方给出的flag已能满足大部分要求，如果有更复杂的需要，可以借助这个强大的第三方包urfave/cli 安装与导包1go get github.com/urfave/cli 123import ( "gopkg.in/urfave/cli.v1") 简单使用该包的github主页有详细的使用说明，这里就不一一赘述了，只简单说一下常用的使用流程 实例化App对象 1app := cli.NewApp() 配置App信息 123456789101112131415161718192021222324252627282930313233343536//这个包可以配置丰富的App描述信息，如名称，版本号，作者，版权信息，程序简介等app.Name = "HelloWorld"app.Version = "1.0.0"app.Authors = []cli.Author&#123; cli.Author&#123; Name: "Tom", Email: "Tom@example.com", &#125;,&#125;app.Copyright = "(c) 1999 Serious Enterprise"app.Usage = "greet"app.UsageText = "Example program"//输入go run example.go -h后显示如下/*NAME: HelloWorld - greetUSAGE: Example programVERSION: 1.0.0AUTHOR: Tom &lt;Tom@example.com&gt;COMMANDS: help, h Shows a list of commands or help for one commandGLOBAL OPTIONS: --help, -h show help --version, -v print the versionCOPYRIGHT: (c) 1999 Serious Enterprise*/ 定义程序执行逻辑 这里是指程序运行的逻辑。主要是配置app.Action，例：12345app.Action = func(c *cli.Context) &#123; fmt.Println("hello world") &#125;//go run example.go //输出hello world 当然我们也可以不在这里定义主程序逻辑，在这里定义的一个好处是cli.Context携带了许多有用的上下文环境变量供我们使用，后面可以见到。 app.Action是执行程序时执行的逻辑，我们也可以定义在程序执行前后所要插入的逻辑，定义app.Before与app.After即可，例123456789101112131415161718192021222324func main() &#123; app := cli.NewApp() app.Before = func(context *cli.Context) error &#123; fmt.Println("before hello world") return nil; &#125; app.Action = func(c *cli.Context) &#123; fmt.Println("hello world") &#125; app.After = func(context *cli.Context) error &#123; fmt.Println("after hello world") return nil; &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125;//执行go run example.go/* 输出：before hello worldhello worldafter hello world*/ 注意：如果app.Before返回的error不为空，app.Action的内容将不会执行，而不管app.Action与app.Before中是否有错误发生，app.After的内容都会执行，app.After可用于收尾工作。 定义flag 这里的flag概念和上文中go的标准包中flag类似，直接看一个例子：12345678910111213141516171819202122func main() &#123; app := cli.NewApp() app.Flags = []cli.Flag&#123; cli.StringFlag&#123; Name:"path", Value:"/home/", Usage:"setting path", &#125;, &#125; app.Action = func(c *cli.Context) &#123; fmt.Println(c.String("path")) &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal("aaa",err) &#125;&#125;//输入go run example.go -path /home/base//输出：/home/base//输入go run example.go//输出：/home/ 定义起来很简单，关键几个要素就是Name和Value，取值时使用cli.Context提供的对应取值方法即可。包内预定义了许多种类型的flag，基本涵盖了所有基本类型，详见这里 另外在取值时，除了调用如c.Int(),c.String()之类的方法，还可以在定义flag时直接绑定到某些变量上，如：123456var age intcli.IntFlag&#123; Name:"age", Value:100, Destination:&amp;age,&#125; 另外，还可以配置flag的简写或别名，只需在定义Name时定义多个名称，中间用逗号隔开即可，例：123456cli.IntFlag&#123; Name:"age,a,ege", Value:100, Destination:&amp;age,&#125;,//-age -a -ege 都是有效的 配置子命令 如git push …中push就是一个子命令，这个包为我们提供了便捷定义子命令及其动作的方法12345678910111213app.Commands = []cli.Command&#123; &#123; Name: "push", Aliases: []string&#123;"p"&#125;, Usage: "push a file to the server", Action: func(c *cli.Context) error &#123; fmt.Println("push flie: ", c.Args().First())//c.Args().First()取命令后的第一个参数 return nil &#125;, &#125;, &#125;//执行go run example.go push test.txt//输出：push flie: test.txt 用法很简单，指定命名名，别名用法，以及相应动作即可。另外子命令可以像它的一个程序一样，有自己flag，Before，After，甚至是自己的子命令，使用Subcommands定义 注意，如果即定义了app的action，又定义了子命令的action，同一时间只能执行一个，如调用子命令时，app的action就不会执行 启动程序 所有配置都配置完成后，就需要启动程序，不然是不会生效的1234err := app.Run(os.Args)if err != nil &#123; log.Fatal("aaa",err)&#125; 最后给出一个详细例子，这是给出的，基本上涵盖了所有配置要点:例子]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F20%2Fhello-world%2F</url>
    <content type="text"><![CDATA[一切都从Hello World开始！ Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
