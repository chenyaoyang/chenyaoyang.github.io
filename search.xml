<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[通过RPC与太坊节点交互]]></title>
    <url>%2F2019%2F05%2F13%2F%E9%80%9A%E8%BF%87RPC%E4%B8%8E%E5%A4%AA%E5%9D%8A%E8%8A%82%E7%82%B9%E4%BA%A4%E4%BA%92%2F</url>
    <content type="text"><![CDATA[背景geth提供了一整套的rpc接口，分为标准接口和扩展接口，平时我们打开geth客户端默认开放的就是标准接口，关于标准接口中所有接口的详细内容见这里，除了标准接口之外geth又添加了一系列扩展接口，如用于节点管理的admin系列接口，管理挖矿miner系列接口等，详细说明见这里，要想使用这一类rpc接口，需要在启动geth客户端时使用指定所开放的接口。 以太坊实现rpc的方法有多种，外部可以使用的有http，ipc和ws。下面分别介绍一下 HTTP-RPC要使用这种rpc需要在启动时使用–rpc开启，默认开放在8545端口上，可以使用–rpcport修改，另外还可以用–rpcaddr指定监听地址，默认为localhost，修改外外网ip就可以在外网访问本地节点；用–rpcapi指定所开放的api。（后面的ipc和ws模式都有相关参数设置） curl命令由于是jsonrpc类型的接口，所以我们需要向目标地址端口发送json格式数据来，首先可以根据官方文档说明的使用curl命令体验一下，命令如下：1curl -X POST --data '&#123;"jsonrpc":"2.0","method":"rpc_modules","params":[],"id":67&#125;' 127.0.0.1:8545 -X POST指定使用post方式发送数据，–data指定发送的Jason数据，其中需要指定的几个字段我们稍后介绍，最后跟上地址和端口。最后返回下面数据，这里我们请求的是服务端开发的api接口：123456789101112&#123; "id": 67, "jsonrpc": "2.0", "result": &#123; "eth": "1.0", "evm": "1.0", "net": "1.0", "personal": "1.0", "rpc": "1.0", "web3": "1.0" &#125;&#125; 还有一点需要注意的是，如果使用ganache测试上面的命令基本可以通过，如果用geth测试，需要加上-H “Content-Type: application/json” 代码调用除了使用命令行的方法，我们还可以使用代码调用：12345678910111213141516171819202122package mainimport ( "fmt" "io/ioutil" "log" "net/http" "strings")func main() &#123; resp,err:=http.Post("http://127.0.0.1:8545","application/x-www-form-urlencoded",strings.NewReader(`&#123;"jsonrpc":"2.0","method":"rpc_modules","params":[],"id":67&#125;`)) if err!=nil&#123; log.Fatal(err) &#125; defer resp.Body.Close() body,err:=ioutil.ReadAll(resp.Body) if err!=nil&#123; log.Fatal(err) &#125; fmt.Println(string(body))&#125; 和前面使用的curl命令效果一样，发送一个post请求，注意contentType要为”application/x-www-form-urlencoded”，但是在geth测试中要改为application/json，为了谨慎起见建议无论用什么测试都将contentType设为application/json。 既然是发送的json数据，我们实际使用时候并不想每次都直接写入json字符串，我们还可以使用json对象形式，关于json对象的数据结构，我们通过翻阅源码（详见这里）可知go-ethereum的jsonrpc数据结构如下1234567891011121314type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125;type jsonError struct &#123; Code int `json:"code"` Message string `json:"message"` Data interface&#123;&#125; `json:"data,omitempty"`&#125; 无论收发都用的是jsonrpcMessage，这里也可以发现我们请求的时候需要指定一下内容：Version：版本号，字段是jsonrpc；ID：本次请求的ID，字段是id；Method：本次请求的方法，字段是method；Params：本次请求的方法参数列表，字段是params。剩余的Error和Result是响应中包含的。既然知道了json对象，我们就可以构建一个对象然后像上面一样发送请求，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( "bytes" "encoding/json" "fmt" "io/ioutil" "log" "net/http")type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125;type jsonError struct &#123; Code int `json:"code"` Message string `json:"message"` Data interface&#123;&#125; `json:"data,omitempty"`&#125;func main() &#123; msg:=jsonrpcMessage&#123;Version:"2.0",Method:"rpc_modules",Params:json.RawMessage&#123;&#125;,ID:json.RawMessage("5")&#125; data,err:=json.Marshal(msg) if err!=nil&#123; log.Fatal("Marshal:",err) &#125; resp,err:=http.Post("http://127.0.0.1:8545","application/json",bytes.NewReader(data)) if err!=nil&#123; log.Fatal("Post:",err) &#125; defer resp.Body.Close() body,err:=ioutil.ReadAll(resp.Body) if err!=nil&#123; log.Fatal("ReadAll:",err) &#125; var result jsonrpcMessage err=json.Unmarshal(body,&amp;result) if err!=nil&#123; log.Fatal("Unmarshal:",err) &#125; fmt.Println(string(result.Result))&#125; 上面举得都是不带参数的例子，对于带参数的主要问题是在源码中jsonrpcMessage的Params字段是一个json.RawMessage类型，当然我们可以给他改为[]string，不过不修改也可以使用，json.RawMessage主要作用就是在序列化或反序列化时保持数据原样，而json.RawMessage本身实际上就是一个字节数组，详细信息可见json源码。所以我们在给结构体中json.RawMessage类型字段赋值时要先对数据进行一次序列化，即变为字节数组后再赋值，如下调用了web3_sha3方法12params,_:=json.Marshal([]string&#123;"0x68656c6c6f20776f726c64"&#125;)msg:=jsonrpcMessage&#123;Version:"2.0",Method:"web3_sha3",Params:params,ID:json.RawMessage("5")&#125; IPC-RPC不同于http-rpc，ipc形式的rpc在geth户客户端是默认开启的，默认文件路径是datadir/geth.ipc，在linux中使用的是unix socket形式 nc命令根据官方文档提示，我们可以用nc命令实现调用，还是发送一段json数据，如下1echo '&#123;"jsonrpc":"2.0","method":"rpc_modules","params":[],"id":1&#125;' | nc -U mychain/chain1/geth.ipc 代码调用go语言版本的代码调用如下12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package mainimport ( "bytes" "encoding/json" "fmt" "log" "net")type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125;type jsonError struct &#123; Code int `json:"code"` Message string `json:"message"` Data interface&#123;&#125; `json:"data,omitempty"`&#125;func main() &#123; msg:=jsonrpcMessage&#123;Version:"2.0",Method:"rpc_modules",Params:json.RawMessage&#123;&#125;,ID:json.RawMessage("5")&#125; data,err:=json.Marshal(msg) if err!=nil &#123; log.Fatalln("Marshal: ",err) &#125; conn,err:=net.Dial("unix","/home/chenw/chenyy/mychain/chain1/geth.ipc") defer conn.Close() if err!=nil &#123; log.Fatalln("dial: ",err) &#125; _,err=conn.Write(data) if err!=nil &#123; log.Fatalln("write: ",err) &#125; temp := make([]byte,1024) var buf bytes.Buffer var result jsonrpcMessage count:=0 for&#123; n,err:=conn.Read(temp) if err!=nil &#123; log.Fatalln("read: ",err) &#125; count+=n buf.Write(temp) if json.Valid(buf.Bytes()[:count]) &#123; break &#125; &#125; json.Unmarshal(buf.Bytes()[:count],&amp;result) fmt.Println(string(result.Result))&#125; websocket-RPC最后再演示一下websocket的rpc调用，首先要注意的是go的标准包并不支持websocket，go-ethereum使用的是golang官方维护的一个net包–”golang.org/x/net/websocket”，其中有websocket实现，但是该包并不完善，官方推荐使用Gorilla WebSocket，所以首先要安装该包1go get github.com/gorilla/websocket 其次要测试ws，要在启动以太坊节点时加上–ws参数，完整客户端测试代码如下1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( "encoding/json" "fmt" "github.com/gorilla/websocket" "log" "net/url")type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125;type jsonError struct &#123; Code int `json:"code"` Message string `json:"message"` Data interface&#123;&#125; `json:"data,omitempty"`&#125;func main() &#123; msg:=jsonrpcMessage&#123;Version:"2.0",Method:"rpc_modules",Params:json.RawMessage&#123;&#125;,ID:json.RawMessage("5")&#125; u:=url.URL&#123;Scheme:"ws",Host:"127.0.0.1:8546"&#125; c,_,err:=websocket.DefaultDialer.Dial(u.String(),nil); if err!=nil&#123; log.Fatal("Dial:",err) &#125; defer c.Close() err=c.WriteJSON(msg) if err!=nil&#123; log.Fatal("WriteJSON:",err) &#125; var result jsonrpcMessage err=c.ReadJSON(&amp;result) if err!=nil&#123; log.Fatal("ReadJSON:",err) &#125; fmt.Println(string(result.Result))&#125; web3.js像前面那样直接通过以太坊的rpc接口进行交互也行的通，但是还是比较麻烦，于是以太坊官方推出了一个库–web3.js，他是用js实现的API，用于和以太坊节点通信，底层还是rpc调用，只是帮我们封装了一系列方法，我们直接调用即可。 使用起来很简单，首先在工程目录下安装web3（当然前提是安装了node.js）：1npm install web3 然后开启以太坊节点，如ganache-cli，下面提供一个示例获取节点上的所有账户和某些账户的余额：1234var Web3 = require("web3");var web3 = new Web3(new Web3.providers.HttpProvider("http://localhost:8545"));web3.eth.getAccounts().then(console.log);web3.eth.getBalance("0x383edc3e6721b037263a92bf7218cc71fe617cd9").then(console.log); 使用起来很简单，首先获取web3模块，然后创建web3对象，创建时使用HttpProvider也就是http-rpc的方式连接以太坊节点，当然也可以使用websocket的方法连接，这时首先要开启节点的websocket功能（使用–ws），然后创建web3对象时用一下方式：1var web3 = new Web3(new Web3.providers.WebsocketProvider('ws://localhost:8546')); 另外关于web3.js的api问题，由于不同版本的api变化较大，详细信息参考官方文档。 当然web3.js是是为js语言服务的，相应的还有python版、java版的类似库供我们使用。 题图来自unsplash：https://unsplash.com/photos/8pgK9350lv4]]></content>
      <categories>
        <category>以太坊</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中eth-Fetcher源码学习]]></title>
    <url>%2F2019%2F05%2F10%2Fgo-ethereum%E4%B8%ADeth-Fetcher%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[数据结构fetcher负责收集来自各个对等点的块通知并进行处理。前面在介绍ProtocolManager时就出现过，我们先看数据结构1234567891011type announce struct &#123; hash common.Hash // Hash of the block being announced number uint64 // Number of the block being announced (0 = unknown | old protocol) header *types.Header // Header of the block partially reassembled (new protocol) time time.Time // Timestamp of the announcement origin string // Identifier of the peer originating the notification fetchHeader headerRequesterFn // Fetcher function to retrieve the header of an announced block fetchBodies bodyRequesterFn // Fetcher function to retrieve the body of an announced block&#125; announce是一个通知，表示网络中有新块出现。1234type inject struct &#123; origin string block *types.Block&#125; inject表示要插入一个区块。1234567891011121314151617181920212223242526272829303132333435363738type Fetcher struct &#123; // Various event channels notify chan *announce inject chan *inject headerFilter chan chan *headerFilterTask bodyFilter chan chan *bodyFilterTask done chan common.Hash quit chan struct&#123;&#125; // Announce states announces map[string]int // Per peer announce counts to prevent memory exhaustion announced map[common.Hash][]*announce // Announced blocks, scheduled for fetching fetching map[common.Hash]*announce // Announced blocks, currently fetching fetched map[common.Hash][]*announce // Blocks with headers fetched, scheduled for body retrieval completing map[common.Hash]*announce // Blocks with headers, currently body-completing // Block cache queue *prque.Prque // Queue containing the import operations (block number sorted) queues map[string]int // Per peer block counts to prevent memory exhaustion queued map[common.Hash]*inject // Set of already queued blocks (to dedupe imports) // Callbacks getBlock blockRetrievalFn // Retrieves a block from the local chain verifyHeader headerVerifierFn // Checks if a block's headers have a valid proof of work broadcastBlock blockBroadcasterFn // Broadcasts a block to connected peers chainHeight chainHeightFn // Retrieves the current chain's height insertChain chainInsertFn // Injects a batch of blocks into the chain dropPeer peerDropFn // Drops a peer for misbehaving // Testing hooks announceChangeHook func(common.Hash, bool) // Method to call upon adding or deleting a hash from the announce list queueChangeHook func(common.Hash, bool) // Method to call upon adding or deleting a block from the import queue fetchingHook func([]common.Hash) // Method to call upon starting a block (eth/61) or header (eth/62) fetch completingHook func([]common.Hash) // Method to call upon starting a block body fetch (eth/62) importedHook func(*types.Block) // Method to call upon successful block import (both eth/61 and eth/62)&#125; New在创建ProtocolManager时使用了NewProtocolManager方法，在最后使用fetcher的new方法创建了一个fetcher：1234567891011121314151617181920212223242526manager.fetcher = fetcher.New(blockchain.GetBlockByHash, validator, manager.BroadcastBlock, heighter, inserter, manager.removePeer)func New(getBlock blockRetrievalFn, verifyHeader headerVerifierFn, broadcastBlock blockBroadcasterFn, chainHeight chainHeightFn, insertChain chainInsertFn, dropPeer peerDropFn) *Fetcher &#123; return &amp;Fetcher&#123; notify: make(chan *announce), inject: make(chan *inject), headerFilter: make(chan chan *headerFilterTask), bodyFilter: make(chan chan *bodyFilterTask), done: make(chan common.Hash), quit: make(chan struct&#123;&#125;), announces: make(map[string]int), announced: make(map[common.Hash][]*announce), fetching: make(map[common.Hash]*announce), fetched: make(map[common.Hash][]*announce), completing: make(map[common.Hash]*announce), queue: prque.New(nil), queues: make(map[string]int), queued: make(map[common.Hash]*inject), getBlock: getBlock, verifyHeader: verifyHeader, broadcastBlock: broadcastBlock, chainHeight: chainHeight, insertChain: insertChain, dropPeer: dropPeer, &#125;&#125; new方法并没有什么实际逻辑，只是创建了一个对象，只不过传入了几个方法：getBlock表示根据hash值获取对应区块，verifyHeader用来验证区块头，broadcastBlock表示给peer广播区块，chainHeight用来获取区块链高度，insertChain用来插入区块，dropPeer用来删除一个peer。 上面几个方法中getBlock、chainHeight和insertChain都是BlockChain的方法，verifyHeader是共识引擎的方法，broadcastBlock和dropPeer都是ProtocolManager的方法。 Start &amp; loop在ProtocolManager调用Start方法启动后，会调用syncer方法，此时启动fetcher，使用的是Start方法：123func (f *Fetcher) Start() &#123; go f.loop()&#125; 可见只是启动了一个goroutine去执行loop12345678910111213141516171819202122232425262728293031323334353637383940func (f *Fetcher) loop() &#123; fetchTimer := time.NewTimer(0) completeTimer := time.NewTimer(0) for &#123; for hash, announce := range f.fetching &#123; if time.Since(announce.time) &gt; fetchTimeout &#123; f.forgetHash(hash) &#125; &#125; height := f.chainHeight() for !f.queue.Empty() &#123; op := f.queue.PopItem().(*inject) hash := op.block.Hash() if f.queueChangeHook != nil &#123; f.queueChangeHook(hash, false) &#125; number := op.block.NumberU64() if number &gt; height+1 &#123; f.queue.Push(op, -int64(number)) if f.queueChangeHook != nil &#123; f.queueChangeHook(hash, true) &#125; break &#125; if number+maxUncleDist &lt; height || f.getBlock(hash) != nil &#123; f.forgetBlock(hash) continue &#125; f.insert(op.origin, op.block) &#125; select &#123; .... &#125; &#125;&#125; 既然是loop就还是一样的套路，里面有一个死循环，再嵌套一个select结构用来触发相应事件。在loop首先定义了两个定时器，不过此时定时时间都是0，也就是立即会触发。 然后进入for循环，先遍历所有正在fetcher的announce，对于那些fetcher超过5秒的进行抛弃。然后获取了区块链高度，接着遍历了queue队列，这是一个优先级队列，优先级是其区块编号的负数，这样编号越小的区块优先级越高。每次从队列顶端取一个，这个是inject对象，如果他的编号大于当前区块高度加一，就先放回队列然后退出循环，否则如果区块过于旧，即比当前区块高度减7还小就抛弃，最后如果合适就插入。 遍历完queue后进入select结构。其中一些case我们后面会陆续介绍。在loop中会通过四个map记录announce状态：announced表示等待fetch，fetching表示正在fetch；fetched表示fetch完头部等待fetch区块体；completing表示完全结束。 FilterHeaders在pm中如果收到code为BlockHeadersMsg的消息时，这个消息是在请求方发送GetBlockHeadersMsg消息后收到响应的消息，表示接收到了区块头，这时会调用fetcher的FilterHeaders方法去处理123456789101112131415161718192021222324func (f *Fetcher) FilterHeaders(peer string, headers []*types.Header, time time.Time) []*types.Header &#123; log.Trace("Filtering headers", "peer", peer, "headers", len(headers)) filter := make(chan *headerFilterTask) select &#123; case f.headerFilter &lt;- filter: case &lt;-f.quit: return nil &#125; select &#123; case filter &lt;- &amp;headerFilterTask&#123;peer: peer, headers: headers, time: time&#125;: case &lt;-f.quit: return nil &#125; select &#123; case task := &lt;-filter: return task.headers case &lt;-f.quit: return nil &#125;&#125; 首先给headerFilter赋值，触发loop中对应逻辑1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465case filter := &lt;-f.headerFilter: var task *headerFilterTask select &#123; case task = &lt;-filter: case &lt;-f.quit: return &#125; headerFilterInMeter.Mark(int64(len(task.headers))) unknown, incomplete, complete := []*types.Header&#123;&#125;, []*announce&#123;&#125;, []*types.Block&#123;&#125; for _, header := range task.headers &#123; hash := header.Hash() if announce := f.fetching[hash]; announce != nil &amp;&amp; announce.origin == task.peer &amp;&amp; f.fetched[hash] == nil &amp;&amp; f.completing[hash] == nil &amp;&amp; f.queued[hash] == nil &#123; if header.Number.Uint64() != announce.number &#123; log.Trace("Invalid block number fetched", "peer", announce.origin, "hash", header.Hash(), "announced", announce.number, "provided", header.Number) f.dropPeer(announce.origin) f.forgetHash(hash) continue &#125; if f.getBlock(hash) == nil &#123; announce.header = header announce.time = task.time if header.TxHash == types.DeriveSha(types.Transactions&#123;&#125;) &amp;&amp; header.UncleHash == types.CalcUncleHash([]*types.Header&#123;&#125;) &#123; log.Trace("Block empty, skipping body retrieval", "peer", announce.origin, "number", header.Number, "hash", header.Hash()) block := types.NewBlockWithHeader(header) block.ReceivedAt = task.time complete = append(complete, block) f.completing[hash] = announce continue &#125; incomplete = append(incomplete, announce) &#125; else &#123; log.Trace("Block already imported, discarding header", "peer", announce.origin, "number", header.Number, "hash", header.Hash()) f.forgetHash(hash) &#125; &#125; else &#123; unknown = append(unknown, header) &#125; &#125; headerFilterOutMeter.Mark(int64(len(unknown))) select &#123; case filter &lt;- &amp;headerFilterTask&#123;headers: unknown, time: task.time&#125;: case &lt;-f.quit: return &#125; for _, announce := range incomplete &#123; hash := announce.header.Hash() if _, ok := f.completing[hash]; ok &#123; continue &#125; f.fetched[hash] = append(f.fetched[hash], announce) if len(f.fetched) == 1 &#123; f.rescheduleComplete(completeTimer) &#125; &#125; for _, block := range complete &#123; if announce := f.completing[block.Hash()]; announce != nil &#123; f.enqueue(announce.origin, block) &#125; &#125; 在对应case中，首先就是一个select结构，这里代码优点特殊，首先headerFilter这个channel里面存储的也是一个channel，回到FilterHeaders的第二个select中，给filter赋值headerFilterTask对象，其中包装了peerID，区块头和当前时间，再回到loop的case中，这里select阻塞得到释放，task得到赋值，是一个headerFilterTask对象。 接着定义了三个数组：unknown, incomplete, complete，然后遍历刚才传过来的一些区块头。先进行了许多判断，主要是确定这个头正在在fetch，接着如果返回的高度和我们请求的区块高度不一样，则删除这个peer并删除这个hash，然后判断下一个head。接着如果一样的话，尝试从本地取区块，如果取不到，在接下来的一个判断中判断这个块是否为空，也就是没有交易且没有叔块，这时创建一个空的区块放入complete中，并将对应的announce放入completing表示fetch完成，若能从本地取到对应区块，则表示已经fetch过了，则抛弃这个hash。再往下，如果不满足最开始的判断，则将对于头放入unknown中。 在遍历完所有head后，再构造一个headerFilterTask将unknown放入其中，然后将这个headerFilterTask赋值给filter，这时触发FilterHeaders的第三个select，在那里面将task的heads返回，也就是刚才放入unknown中的，随后交给Downloader处理。 在loop的对应case中还有操作，首先遍历所有incomplete，这个里面的表示那些在fetch的，而且没有fetch完的，而且对应区块也不是空的announce，首先看其是否在completing中，也就是fetch完的，这时进行忽略，否则将announce放入fetched中对于hash的数组中。接着如果fetched只有一个等待fetch区块体的任务，则调用rescheduleComplete重置completeTimer定时器。 接着遍历complete数组，如果对应区块的announce在completing中也就是以及fetch完成的，则调用enqueue方法插入区块，这个方法稍后介绍。 FilterBodies和上一个类似，这个方法是在请求一个区块体收到响应后进行了调用：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677func (f *Fetcher) FilterBodies(peer string, transactions [][]*types.Transaction, uncles [][]*types.Header, time time.Time) ([][]*types.Transaction, [][]*types.Header) &#123; log.Trace("Filtering bodies", "peer", peer, "txs", len(transactions), "uncles", len(uncles)) filter := make(chan *bodyFilterTask) select &#123; case f.bodyFilter &lt;- filter: case &lt;-f.quit: return nil, nil &#125; select &#123; case filter &lt;- &amp;bodyFilterTask&#123;peer: peer, transactions: transactions, uncles: uncles, time: time&#125;: case &lt;-f.quit: return nil, nil &#125; select &#123; case task := &lt;-filter: return task.transactions, task.uncles case &lt;-f.quit: return nil, nil &#125;&#125; case filter := &lt;-f.bodyFilter: var task *bodyFilterTask select &#123; case task = &lt;-filter: case &lt;-f.quit: return &#125; bodyFilterInMeter.Mark(int64(len(task.transactions))) blocks := []*types.Block&#123;&#125; for i := 0; i &lt; len(task.transactions) &amp;&amp; i &lt; len(task.uncles); i++ &#123; matched := false for hash, announce := range f.completing &#123; if f.queued[hash] == nil &#123; txnHash := types.DeriveSha(types.Transactions(task.transactions[i])) uncleHash := types.CalcUncleHash(task.uncles[i]) if txnHash == announce.header.TxHash &amp;&amp; uncleHash == announce.header.UncleHash &amp;&amp; announce.origin == task.peer &#123; matched = true if f.getBlock(hash) == nil &#123; block := types.NewBlockWithHeader(announce.header).WithBody(task.transactions[i], task.uncles[i]) block.ReceivedAt = task.time blocks = append(blocks, block) &#125; else &#123; f.forgetHash(hash) &#125; &#125; &#125; &#125; if matched &#123; task.transactions = append(task.transactions[:i], task.transactions[i+1:]...) task.uncles = append(task.uncles[:i], task.uncles[i+1:]...) i-- continue &#125; &#125; bodyFilterOutMeter.Mark(int64(len(task.transactions))) select &#123; case filter &lt;- task: case &lt;-f.quit: return &#125; for _, block := range blocks &#123; if announce := f.completing[block.Hash()]; announce != nil &#123; f.enqueue(announce.origin, block) &#125; &#125; &#125; 逻辑和上面的类似，这次是过滤body，主要是滤掉那些已经fetch完成的，剩余的返回交给Downloader处理，这里不再详述。 NotifyNotify方法是在pm收到NewBlockHashesMsg消息时得到调用，NewBlockHashesMsg是自己向其他peer发送新区快消息时用的code。接收方收到这个code表示有新的区块，在检测自己是否有相应区块后，将每个未知区块fetcher处理1234567891011121314151617func (f *Fetcher) Notify(peer string, hash common.Hash, number uint64, time time.Time, headerFetcher headerRequesterFn, bodyFetcher bodyRequesterFn) error &#123; block := &amp;announce&#123; hash: hash, number: number, time: time, origin: peer, fetchHeader: headerFetcher, fetchBodies: bodyFetcher, &#125; select &#123; case f.notify &lt;- block: return nil case &lt;-f.quit: return errTerminated &#125;&#125; 这里主要是构建了一个announce对象，表示有新区块的通知，然后传递给notify触发loop的逻辑：1234567891011121314151617181920212223242526272829303132case notification := &lt;-f.notify: propAnnounceInMeter.Mark(1) count := f.announces[notification.origin] + 1 if count &gt; hashLimit &#123; log.Debug("Peer exceeded outstanding announces", "peer", notification.origin, "limit", hashLimit) propAnnounceDOSMeter.Mark(1) break &#125; if notification.number &gt; 0 &#123; if dist := int64(notification.number) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist &#123; log.Debug("Peer discarded announcement", "peer", notification.origin, "number", notification.number, "hash", notification.hash, "distance", dist) propAnnounceDropMeter.Mark(1) break &#125; &#125; if _, ok := f.fetching[notification.hash]; ok &#123; break &#125; if _, ok := f.completing[notification.hash]; ok &#123; break &#125; f.announces[notification.origin] = count f.announced[notification.hash] = append(f.announced[notification.hash], notification) if f.announceChangeHook != nil &amp;&amp; len(f.announced[notification.hash]) == 1 &#123; f.announceChangeHook(notification.hash, true) &#125; if len(f.announced) == 1 &#123; f.rescheduleFetch(fetchTimer) &#125; 首先将来源的announce数量加1，然后判断是否超出最大数量，在检查区块高度是否太低或太高，也就是区块太旧或太新。然后检查该announce是否正在fetch或者已经完成。若都不是，则将其添加到announced中等待fetch，另外若添加完announced长度为1则立即重置fetchTimer进行fetch。 EnqueueEnqueue方法是在pm收到NewBlockMsg消息后执行，NewBlockMsg也是自己向其他佩尔发送新的区块信息时的code，Enqueue实现如下：123456789101112func (f *Fetcher) Enqueue(peer string, block *types.Block) error &#123; op := &amp;inject&#123; origin: peer, block: block, &#125; select &#123; case f.inject &lt;- op: return nil case &lt;-f.quit: return errTerminated &#125;&#125; 构建了一个inject对象，然后赋值给inject触发loop的逻辑：123case op := &lt;-f.inject: propBroadcastInMeter.Mark(1) f.enqueue(op.origin, op.block) enqueue逻辑如下：1234567891011121314151617181920212223242526272829303132func (f *Fetcher) enqueue(peer string, block *types.Block) &#123; hash := block.Hash() count := f.queues[peer] + 1 if count &gt; blockLimit &#123; log.Debug("Discarded propagated block, exceeded allowance", "peer", peer, "number", block.Number(), "hash", hash, "limit", blockLimit) propBroadcastDOSMeter.Mark(1) f.forgetHash(hash) return &#125; if dist := int64(block.NumberU64()) - int64(f.chainHeight()); dist &lt; -maxUncleDist || dist &gt; maxQueueDist &#123; log.Debug("Discarded propagated block, too far away", "peer", peer, "number", block.Number(), "hash", hash, "distance", dist) propBroadcastDropMeter.Mark(1) f.forgetHash(hash) return &#125; if _, ok := f.queued[hash]; !ok &#123; op := &amp;inject&#123; origin: peer, block: block, &#125; f.queues[peer] = count f.queued[hash] = op f.queue.Push(op, -int64(block.NumberU64())) if f.queueChangeHook != nil &#123; f.queueChangeHook(op.block.Hash(), true) &#125; log.Debug("Queued propagated block", "peer", peer, "number", block.Number(), "hash", hash, "queued", f.queue.Size()) &#125;&#125; 和Notify逻辑类似，也是给来源加一，再判断是否超出最大值，然后判断区块是否太旧或太新。对于符合条件的，判断是否添加到queued中，若没有，则重新创建一个inject对象添加到queued和queue中。 fetchTimer前面的种种方法基本上都是对到来的announce进行分类，而在开头的两个定时器则真正担负了驱动作用，先看fetchTimer，由于开始设置的时间为0，所以立即触发：1234567891011121314151617181920212223242526272829case &lt;-fetchTimer.C: request := make(map[string][]common.Hash) for hash, announces := range f.announced &#123; if time.Since(announces[0].time) &gt; arriveTimeout-gatherSlack &#123; announce := announces[rand.Intn(len(announces))] f.forgetHash(hash) if f.getBlock(hash) == nil &#123; request[announce.origin] = append(request[announce.origin], hash) f.fetching[hash] = announce &#125; &#125; &#125; for peer, hashes := range request &#123; log.Trace("Fetching scheduled headers", "peer", peer, "list", hashes) fetchHeader, hashes := f.fetching[hashes[0]].fetchHeader, hashes go func() &#123; if f.fetchingHook != nil &#123; f.fetchingHook(hashes) &#125; for _, hash := range hashes &#123; headerFetchMeter.Mark(1) fetchHeader(hash) // Suboptimal, but protocol doesn't allow batch header retrievals &#125; &#125;() &#125; f.rescheduleFetch(fetchTimer) 首先遍历announced，announced存储了对于同一个区块来自不同peer的announce，它的第一个announce则是最早的哪一个，如果400毫秒，则随机取一个announce，然后删除该hash，如果这个hash还未fetch到，则将其添加到fetching中，并在request中记录，request记录了同一个来源的多个hash。随后遍历所有request，获得每个来源的fetchHeader方法，这个方法在调用Notify方法构建一个announce时被传入，是peer的一个方法，只要是发送一个GetBlockHeadersMsg消息去获取区块头，之后在每次循环后启动一个goroutine去变量该来源的所有hash然后请求。最后重置fetchTimer。 发送GetBlockHeadersMsg后，如果顺利会收到BlockHeadersMsg消息，这时也就触发FilterHeaders，这是回到前面分析的逻辑，将所有head分三类，unknown的交给download处理，incomplete的存放到fetched中等待fetch区块体，complete的且fetch完成的交给enqueue处理。 completeTimer1234567891011121314151617181920212223case &lt;-completeTimer.C: request := make(map[string][]common.Hash) for hash, announces := range f.fetched &#123; announce := announces[rand.Intn(len(announces))] f.forgetHash(hash) if f.getBlock(hash) == nil &#123; request[announce.origin] = append(request[announce.origin], hash) f.completing[hash] = announce &#125; &#125; for peer, hashes := range request &#123; log.Trace("Fetching scheduled bodies", "peer", peer, "list", hashes) if f.completingHook != nil &#123; f.completingHook(hashes) &#125; bodyFetchMeter.Mark(int64(len(hashes))) go f.completing[hashes[0]].fetchBodies(hashes) &#125; f.rescheduleComplete(completeTimer) completeTimer的逻辑和fetchTimer类似，只不过前一个是fetch区块头，这个是fetch区块体。首先是从fetched中取一组announce，他们都对应一个区块。然后从中随机取一个announce，若果本地没有该区块则添加到reuqest，这个同意也是存储一个来源的多个announce，然后变量request，调用announce的fetchBodies方法去请求一个来源的多个区块，fetchBodies也是在创建announce时传入的，他会发送GetBlockBodiesMsg消息，同样如果顺利的话会收到BlockBodiesMsg消息，触发FilterBodies方法，又回到前面的逻辑。 insert之前许多方法中我们都调用了enqueue方法，这里将一个个inject对象放入queue队列里，然后在loop的每个循环开始，处理queue队列里的东西，对于符合规定的，调用insert方法：12345678910111213141516171819202122232425262728293031323334353637func (f *Fetcher) insert(peer string, block *types.Block) &#123; hash := block.Hash() log.Debug("Importing propagated block", "peer", peer, "number", block.Number(), "hash", hash) go func() &#123; defer func() &#123; f.done &lt;- hash &#125;() parent := f.getBlock(block.ParentHash()) if parent == nil &#123; log.Debug("Unknown parent of propagated block", "peer", peer, "number", block.Number(), "hash", hash, "parent", block.ParentHash()) return &#125; switch err := f.verifyHeader(block.Header()); err &#123; case nil: propBroadcastOutTimer.UpdateSince(block.ReceivedAt) go f.broadcastBlock(block, true) case consensus.ErrFutureBlock: default: log.Debug("Propagated block verification failed", "peer", peer, "number", block.Number(), "hash", hash, "err", err) f.dropPeer(peer) return &#125; if _, err := f.insertChain(types.Blocks&#123;block&#125;); err != nil &#123; log.Debug("Propagated block import failed", "peer", peer, "number", block.Number(), "hash", hash, "err", err) return &#125; propAnnounceOutTimer.UpdateSince(block.ReceivedAt) go f.broadcastBlock(block, false) if f.importedHook != nil &#123; f.importedHook(block) &#125; &#125;()&#125; 直接启动了一个goroutine，先获取要插入区块的父块，如果不存在停止插入，然后验证区块头，出错的话而且不是consensus.ErrFutureBlock错误的话，抛弃来源的peer，没有错的话启动一个goroutine调用broadcastBlock方法。之后调用insertchain方法插入一个区块，如果插入成功再次调用broadcastBlock方法，这里第二个参数为true，关于broadcastBlock在ProtocolManager分析中有介绍。另外insertChain方法是blockchain的方法，后面会涉及到。 rescheduleFetch前面也多次涉及到了这个方法，在定时器触发时最后会用到，在notify添加完一个announce后如果announced长度为一，表示之前announced都已处理过，这是要重新启动定时器。12345678910111213func (f *Fetcher) rescheduleFetch(fetch *time.Timer) &#123; if len(f.announced) == 0 &#123; return &#125; // Otherwise find the earliest expiring announcement earliest := time.Now() for _, announces := range f.announced &#123; if earliest.After(announces[0].time) &#123; earliest = announces[0].time &#125; &#125; fetch.Reset(arriveTimeout - time.Since(earliest))&#125; 首先announced长度为0，表示没有要fetch的任务，则返回，前面说过，在notify中向announced新添加时会触发此方法重设定时器。之后遍历所有announced，每个hash对应的那组取第一个也就时间最早的那个announce尝试更新earliest，最后earliest为所有announce最早的那一个，然后重设fetchTimer定时器。 类似的还有一个rescheduleComplete，大致逻辑一样，不在赘述 forgetHash这个也多次出现，出钥匙删除一个hash对应的announce1234567891011121314151617181920212223242526272829303132333435363738func (f *Fetcher) forgetHash(hash common.Hash) &#123; for _, announce := range f.announced[hash] &#123; f.announces[announce.origin]-- if f.announces[announce.origin] == 0 &#123; delete(f.announces, announce.origin) &#125; &#125; delete(f.announced, hash) if f.announceChangeHook != nil &#123; f.announceChangeHook(hash, false) &#125; if announce := f.fetching[hash]; announce != nil &#123; f.announces[announce.origin]-- if f.announces[announce.origin] == 0 &#123; delete(f.announces, announce.origin) &#125; delete(f.fetching, hash) &#125; for _, announce := range f.fetched[hash] &#123; f.announces[announce.origin]-- if f.announces[announce.origin] == 0 &#123; delete(f.announces, announce.origin) &#125; &#125; delete(f.fetched, hash) if announce := f.completing[hash]; announce != nil &#123; f.announces[announce.origin]-- if f.announces[announce.origin] == 0 &#123; delete(f.announces, announce.origin) &#125; delete(f.completing, hash) &#125;&#125; 首先遍历announced对应hash的所有announce，然后将对应来源的计数器减1，如果减到0则删除该来源的计数器。然后从announced删除hash对应的值。结合如果fetching、fetched及completing有对应的键值对，也相应的删除。 stop123func (f *Fetcher) Stop() &#123; close(f.quit)&#125; 这个就是关闭方法，关闭quit这个通道，触发多个地方的逻辑，第一个就是loop中，这里面退出了无限循环，其次还有其他涉及select阻塞的地方，如notify、FilterHeaders等，都是直接退出。 题图来自unsplash：https://unsplash.com/photos/m6tAqZvy4RM]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中eth-ProtocolManager源码学习]]></title>
    <url>%2F2019%2F04%2F29%2Fgo-ethereum%E4%B8%ADeth-ProtocolManager%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[NewProtocolManager在eth的创建过程中初始化了一个protocolManager成员，从名称上看是协议管理者，实际上它是用来管理Ethereum的子协议的，也是上层消息的处理分发的类。由于和上一篇P2P有很大的联系，所以单独拿出来分析一下。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// go-ethereum\eth\handler.gofunc NewProtocolManager(config *params.ChainConfig, mode downloader.SyncMode, networkID uint64, mux *event.TypeMux, txpool txPool, engine consensus.Engine, blockchain *core.BlockChain, chaindb ethdb.Database, whitelist map[uint64]common.Hash) (*ProtocolManager, error) &#123; manager := &amp;ProtocolManager&#123; networkID: networkID, eventMux: mux, txpool: txpool, blockchain: blockchain, chainconfig: config, peers: newPeerSet(), whitelist: whitelist, newPeerCh: make(chan *peer), noMorePeers: make(chan struct&#123;&#125;), txsyncCh: make(chan *txsync), quitSync: make(chan struct&#123;&#125;), &#125; if mode == downloader.FastSync &amp;&amp; blockchain.CurrentBlock().NumberU64() &gt; 0 &#123; log.Warn("Blockchain not empty, fast sync disabled") mode = downloader.FullSync &#125; if mode == downloader.FastSync &#123; manager.fastSync = uint32(1) &#125; manager.SubProtocols = make([]p2p.Protocol, 0, len(ProtocolVersions)) for i, version := range ProtocolVersions &#123; if mode == downloader.FastSync &amp;&amp; version &lt; eth63 &#123; continue &#125; version := version manager.SubProtocols = append(manager.SubProtocols, p2p.Protocol&#123; Name: ProtocolName, Version: version, Length: ProtocolLengths[i], Run: func(p *p2p.Peer, rw p2p.MsgReadWriter) error &#123; peer := manager.newPeer(int(version), p, rw) select &#123; case manager.newPeerCh &lt;- peer: manager.wg.Add(1) defer manager.wg.Done() return manager.handle(peer) case &lt;-manager.quitSync: return p2p.DiscQuitting &#125; &#125;, NodeInfo: func() interface&#123;&#125; &#123; return manager.NodeInfo() &#125;, PeerInfo: func(id enode.ID) interface&#123;&#125; &#123; if p := manager.peers.Peer(fmt.Sprintf("%x", id[:8])); p != nil &#123; return p.Info() &#125; return nil &#125;, &#125;) &#125; if len(manager.SubProtocols) == 0 &#123; return nil, errIncompatibleConfig &#125; manager.downloader = downloader.New(mode, chaindb, manager.eventMux, blockchain, nil, manager.removePeer) validator := func(header *types.Header) error &#123; return engine.VerifyHeader(blockchain, header, true) &#125; heighter := func() uint64 &#123; return blockchain.CurrentBlock().NumberU64() &#125; inserter := func(blocks types.Blocks) (int, error) &#123; if atomic.LoadUint32(&amp;manager.fastSync) == 1 &#123; log.Warn("Discarded bad propagated block", "number", blocks[0].Number(), "hash", blocks[0].Hash()) return 0, nil &#125; atomic.StoreUint32(&amp;manager.acceptTxs, 1) // Mark initial sync done on any fetcher import return manager.blockchain.InsertChain(blocks) &#125; manager.fetcher = fetcher.New(blockchain.GetBlockByHash, validator, manager.BroadcastBlock, heighter, inserter, manager.removePeer) return manager, nil&#125; 在初始化对象后，先判断了节点同步方法，如果是FastSync而当前节点又不是0，就改为FullSync，这也就是FastSync模式只在第一次有效的原因。然后配置了manager的同步方式。接下来我们可以看到他所管理的子协议实际上就是p2p协议，这里在pm初始化的同时就创建了一个p2p的Protocol数组SubProtocols。然后遍历ProtocolVersions，这个代表协议版本号。在我当前的版本中支持{eth63, eth62}，关于eth63、eth62及以太坊网络协议的更多说明见这里。 对于每个版本都向SubProtocols中添加一个Protocol对象，其名字就是eth，ProtocolLengths长度对于eth63而言是17，对于eth62是8；接下来定义一个Run方法，前文在分析p2p-peer时，对于每个peer都会启动所有协议，启动时会在一个独立的goroutine中运行run方法。在run方法中先用newPeer创建了一个peer（p2p-peer的封装）：12345678910111213141516171819func (pm *ProtocolManager) newPeer(pv int, p *p2p.Peer, rw p2p.MsgReadWriter) *peer &#123; return newPeer(pv, p, newMeteredMsgWriter(rw))&#125;// go-ethereum\eth\peer.gofunc newPeer(version int, p *p2p.Peer, rw p2p.MsgReadWriter) *peer &#123; return &amp;peer&#123; Peer: p, rw: rw, version: version, id: fmt.Sprintf("%x", p.ID().Bytes()[:8]), knownTxs: mapset.NewSet(), knownBlocks: mapset.NewSet(), queuedTxs: make(chan []*types.Transaction, maxQueuedTxs), queuedProps: make(chan *propEvent, maxQueuedProps), queuedAnns: make(chan *types.Block, maxQueuedAnns), term: make(chan struct&#123;&#125;), &#125;&#125; handle接着给manager的newPeerCh赋值，执行handle方法,用来处理连接12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func (pm *ProtocolManager) handle(p *peer) error &#123; if pm.peers.Len() &gt;= pm.maxPeers &amp;&amp; !p.Peer.Info().Network.Trusted &#123; return p2p.DiscTooManyPeers &#125; p.Log().Debug("Ethereum peer connected", "name", p.Name()) var ( genesis = pm.blockchain.Genesis() head = pm.blockchain.CurrentHeader() hash = head.Hash() number = head.Number.Uint64() td = pm.blockchain.GetTd(hash, number) ) if err := p.Handshake(pm.networkID, td, hash, genesis.Hash()); err != nil &#123; p.Log().Debug("Ethereum handshake failed", "err", err) return err &#125; if rw, ok := p.rw.(*meteredMsgReadWriter); ok &#123; rw.Init(p.version) &#125; if err := pm.peers.Register(p); err != nil &#123; p.Log().Error("Ethereum peer registration failed", "err", err) return err &#125; defer pm.removePeer(p.id) if err := pm.downloader.RegisterPeer(p.id, p.version, p); err != nil &#123; return err &#125; pm.syncTransactions(p) if daoBlock := pm.chainconfig.DAOForkBlock; daoBlock != nil &#123; if err := p.RequestHeadersByNumber(daoBlock.Uint64(), 1, 0, false); err != nil &#123; return err &#125; p.forkDrop = time.AfterFunc(daoChallengeTimeout, func() &#123; p.Log().Debug("Timed out DAO fork-check, dropping") pm.removePeer(p.id) &#125;) defer func() &#123; if p.forkDrop != nil &#123; p.forkDrop.Stop() p.forkDrop = nil &#125; &#125;() &#125; for number := range pm.whitelist &#123; if err := p.RequestHeadersByNumber(number, 1, 0, false); err != nil &#123; return err &#125; &#125; for &#123; if err := pm.handleMsg(p); err != nil &#123; p.Log().Debug("Ethereum message handling failed", "err", err) return err &#125; &#125;&#125; Handshake首先检测是否超过最大peer数量或者不是信任节点，检测通过的话进行Ethereum握手。1234567891011121314151617181920212223242526272829303132// go-ethereum\eth\peer.gofunc (p *peer) Handshake(network uint64, td *big.Int, head common.Hash, genesis common.Hash) error &#123; errc := make(chan error, 2) var status statusData go func() &#123; errc &lt;- p2p.Send(p.rw, StatusMsg, &amp;statusData&#123; ProtocolVersion: uint32(p.version), NetworkId: network, TD: td, CurrentBlock: head, GenesisBlock: genesis, &#125;) &#125;() go func() &#123; errc &lt;- p.readStatus(network, &amp;status, genesis) &#125;() timeout := time.NewTimer(handshakeTimeout) defer timeout.Stop() for i := 0; i &lt; 2; i++ &#123; select &#123; case err := &lt;-errc: if err != nil &#123; return err &#125; case &lt;-timeout.C: return p2p.DiscReadTimeout &#125; &#125; p.td, p.head = status.TD, status.CurrentBlock return nil&#125; 首先启动一个goroutine利用Send发送一条初始消息，这里的Send是p2p包中message.go的方法，但是send方法中又调用了参数中的MsgWriter，这里的MsgWriter是在p2p包内peer.go在启动协议时传入的，实际上是protoRW的WriteMsg，但最终实际执行者是rlpx。这里还有一点需要注意的是，在发送时将原来的code加了一个offset，因为eth的协议code是从0开始，如果不加offset，会在读取时被当做基本协议过滤掉（详见p2p的peer源码分析），这个offset最后会在读取时减去恢复出原始的code。 发送的msg的code是StatusMsg，即0。发送的消息有协议版本，网络ID，总难度当前区块和创世区块。之后又启动一个goroutine去读取消息：1234567891011121314151617181920212223242526func (p *peer) readStatus(network uint64, status *statusData, genesis common.Hash) (err error) &#123; msg, err := p.rw.ReadMsg() if err != nil &#123; return err &#125; if msg.Code != StatusMsg &#123; return errResp(ErrNoStatusMsg, "first msg has code %x (!= %x)", msg.Code, StatusMsg) &#125; if msg.Size &gt; ProtocolMaxMsgSize &#123; return errResp(ErrMsgTooLarge, "%v &gt; %v", msg.Size, ProtocolMaxMsgSize) &#125; // Decode the handshake and make sure everything matches if err := msg.Decode(&amp;status); err != nil &#123; return errResp(ErrDecode, "msg %v: %v", msg, err) &#125; if status.GenesisBlock != genesis &#123; return errResp(ErrGenesisBlockMismatch, "%x (!= %x)", status.GenesisBlock[:8], genesis[:8]) &#125; if status.NetworkId != network &#123; return errResp(ErrNetworkIdMismatch, "%d (!= %d)", status.NetworkId, network) &#125; if int(status.ProtocolVersion) != p.version &#123; return errResp(ErrProtocolVersionMismatch, "%d (!= %d)", status.ProtocolVersion, p.version) &#125; return nil&#125; 首先调用ReadMsg，这个ReadMsg是p2p包内peer.go中protoRW的方法，回顾peer源码分析，对于一个peer当收到一条消息时，如果消息不是基本消息，会给protoRW的in字段赋值，而在ReadMsg会阻塞的从in字段读取msg并返回。回到readStatus中，首先判断code是否是StatusMsg，在判断size大小是否合格。之后调用msg的Decode方法解码，就是rlp解码，最后将数据写入statusData，之后对双方的创世区块、网络ID一届协议版本进行对比，判断是否匹配，不匹配的话返回具体错误。 回到Handshake中，在启动收发数据的goroutine的同时，启动了一个定时器，时间是5s，来判断是否握手超时，在判断超时时也判断了收发是否报错。握手成功后记录对方的总难度和当前区块。有一点需要注意的是，Handshake的这两个收发goroutine是没有先后关系的，因为我们p2p的peer是在主动发送或收到一个请求后经过握手建立的，建立成功后双方各自实例化一个peer对象，然后启动协议，并执行协议的Run方法，这些步骤在双方是独立进行的。 Register &amp; broadcast再回到handle中，经过刚才的握手后，如果双方的区块链信息也匹配，则将这个peer注册到ProtocolManager的peers中，这个注册会在结束时被移除。注册方法如下：123456789101112131415func (ps *peerSet) Register(p *peer) error &#123; ps.lock.Lock() defer ps.lock.Unlock() if ps.closed &#123; return errClosed &#125; if _, ok := ps.peers[p.id]; ok &#123; return errAlreadyRegistered &#125; ps.peers[p.id] = p go p.broadcast() return nil&#125; 主要实现就是将peer添加到pm的peers字段中用来集中管理，并启动了一个goroutine去调用broadcast：1234567891011121314151617181920212223242526func (p *peer) broadcast() &#123; for &#123; select &#123; case txs := &lt;-p.queuedTxs: if err := p.SendTransactions(txs); err != nil &#123; return &#125; p.Log().Trace("Broadcast transactions", "count", len(txs)) case prop := &lt;-p.queuedProps: if err := p.SendNewBlock(prop.block, prop.td); err != nil &#123; return &#125; p.Log().Trace("Propagated block", "number", prop.block.Number(), "hash", prop.block.Hash(), "td", prop.td) case block := &lt;-p.queuedAnns: if err := p.SendNewBlockHashes([]common.Hash&#123;block.Hash()&#125;, []uint64&#123;block.NumberU64()&#125;); err != nil &#123; return &#125; p.Log().Trace("Announced block", "number", block.Number(), "hash", block.Hash()) case &lt;-p.term: return &#125; &#125;&#125; 这也是一个无限循环，用于事件处理，具体逻辑稍后介绍。 之后开始同步交易，将自己交易池中等待的交易发送给对方。然后又验证了DAO硬分叉，另外如果有白名单则也去请求，和前面验证DAO一样，都是通过编号去请求头。 handleMsg最后来到主循环，调用handleMsg去处理消息：12345678910111213141516171819func (pm *ProtocolManager) handleMsg(p *peer) error &#123; // Read the next message from the remote peer, and ensure it's fully consumed msg, err := p.rw.ReadMsg() if err != nil &#123; return err &#125; if msg.Size &gt; ProtocolMaxMsgSize &#123; return errResp(ErrMsgTooLarge, "%v &gt; %v", msg.Size, ProtocolMaxMsgSize) &#125; defer msg.Discard() // Handle the message depending on its contents switch &#123; case msg.Code == StatusMsg: return errResp(ErrExtraStatusMsg, "uncontrolled status message") ... &#125; return nil&#125; GetBlockHeadersMsg这一部分代码非常多，由于是p2p通信的上层部分，所以要考虑的情况十分多。我们简单看几个，以刚才验证DAO分叉和请求白名单所用的RequestHeadersByNumber方法为例（其余的会在介绍后续流程时涉及到），首先发送如下请求：1234func (p *peer) RequestHeadersByNumber(origin uint64, amount int, skip int, reverse bool) error &#123; p.Log().Debug("Fetching batch of headers", "count", amount, "fromnum", origin, "skip", skip, "reverse", reverse) return p2p.Send(p.rw, GetBlockHeadersMsg, &amp;getBlockHeadersData&#123;Origin: hashOrNumber&#123;Number: origin&#125;, Amount: uint64(amount), Skip: uint64(skip), Reverse: reverse&#125;)&#125; 同样是发送一个msg，其code是GetBlockHeadersMsg，在handleMsg中对于逻辑如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778case msg.Code == GetBlockHeadersMsg: var query getBlockHeadersData if err := msg.Decode(&amp;query); err != nil &#123; return errResp(ErrDecode, "%v: %v", msg, err) &#125; hashMode := query.Origin.Hash != (common.Hash&#123;&#125;) first := true maxNonCanonical := uint64(100) var ( bytes common.StorageSize headers []*types.Header unknown bool ) for !unknown &amp;&amp; len(headers) &lt; int(query.Amount) &amp;&amp; bytes &lt; softResponseLimit &amp;&amp; len(headers) &lt; downloader.MaxHeaderFetch &#123; var origin *types.Header if hashMode &#123; if first &#123; first = false origin = pm.blockchain.GetHeaderByHash(query.Origin.Hash) if origin != nil &#123; query.Origin.Number = origin.Number.Uint64() &#125; &#125; else &#123; origin = pm.blockchain.GetHeader(query.Origin.Hash, query.Origin.Number) &#125; &#125; else &#123; origin = pm.blockchain.GetHeaderByNumber(query.Origin.Number) &#125; if origin == nil &#123; break &#125; headers = append(headers, origin) bytes += estHeaderRlpSize switch &#123; case hashMode &amp;&amp; query.Reverse: ancestor := query.Skip + 1 if ancestor == 0 &#123; unknown = true &#125; else &#123; query.Origin.Hash, query.Origin.Number = pm.blockchain.GetAncestor(query.Origin.Hash, query.Origin.Number, ancestor, &amp;maxNonCanonical) unknown = (query.Origin.Hash == common.Hash&#123;&#125;) &#125; case hashMode &amp;&amp; !query.Reverse: var ( current = origin.Number.Uint64() next = current + query.Skip + 1 ) if next &lt;= current &#123; infos, _ := json.MarshalIndent(p.Peer.Info(), "", " ") p.Log().Warn("GetBlockHeaders skip overflow attack", "current", current, "skip", query.Skip, "next", next, "attacker", infos) unknown = true &#125; else &#123; if header := pm.blockchain.GetHeaderByNumber(next); header != nil &#123; nextHash := header.Hash() expOldHash, _ := pm.blockchain.GetAncestor(nextHash, next, query.Skip+1, &amp;maxNonCanonical) if expOldHash == query.Origin.Hash &#123; query.Origin.Hash, query.Origin.Number = nextHash, next &#125; else &#123; unknown = true &#125; &#125; else &#123; unknown = true &#125; &#125; case query.Reverse: if query.Origin.Number &gt;= query.Skip+1 &#123; query.Origin.Number -= query.Skip + 1 &#125; else &#123; unknown = true &#125; case !query.Reverse: query.Origin.Number += query.Skip + 1 &#125; &#125; return p.SendBlockHeaders(headers) 第一步就是解码，得到请求消息getBlockHeadersData，其中包含要查询的某一个区块的编号或hash，查询数量，跳过的数量，是否反向查询等。然后判断查询用的是编号还是hash，之后再一个循环内，根据请求获取头数据，然后放到heads中，最后通过SendBlockHeaders发送数据：123func (p *peer) SendBlockHeaders(headers []*types.Header) error &#123; return p2p.Send(p.rw, BlockHeadersMsg, headers)&#125; BlockHeadersMsg可见code是BlockHeadersMsg，回到请求方，对应的逻辑如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152case msg.Code == BlockHeadersMsg: var headers []*types.Header if err := msg.Decode(&amp;headers); err != nil &#123; return errResp(ErrDecode, "msg %v: %v", msg, err) &#125; if len(headers) == 0 &amp;&amp; p.forkDrop != nil &#123; // Possibly an empty reply to the fork header checks, sanity check TDs verifyDAO := true if daoHeader := pm.blockchain.GetHeaderByNumber(pm.chainconfig.DAOForkBlock.Uint64()); daoHeader != nil &#123; if _, td := p.Head(); td.Cmp(pm.blockchain.GetTd(daoHeader.Hash(), daoHeader.Number.Uint64())) &gt;= 0 &#123; verifyDAO = false &#125; &#125; if verifyDAO &#123; p.Log().Debug("Seems to be on the same side of the DAO fork") p.forkDrop.Stop() p.forkDrop = nil return nil &#125; &#125; filter := len(headers) == 1 if filter &#123; if p.forkDrop != nil &amp;&amp; pm.chainconfig.DAOForkBlock.Cmp(headers[0].Number) == 0 &#123; p.forkDrop.Stop() p.forkDrop = nil if err := misc.VerifyDAOHeaderExtraData(pm.chainconfig, headers[0]); err != nil &#123; p.Log().Debug("Verified to be on the other side of the DAO fork, dropping") return err &#125; p.Log().Debug("Verified to be on the same side of the DAO fork") return nil &#125; if want, ok := pm.whitelist[headers[0].Number.Uint64()]; ok &#123; if hash := headers[0].Hash(); want != hash &#123; p.Log().Info("Whitelist mismatch, dropping peer", "number", headers[0].Number.Uint64(), "hash", hash, "want", want) return errors.New("whitelist block mismatch") &#125; p.Log().Debug("Whitelist block verified", "number", headers[0].Number.Uint64(), "hash", want) &#125; headers = pm.fetcher.FilterHeaders(p.id, headers, time.Now()) &#125; if len(headers) &gt; 0 || !filter &#123; err := pm.downloader.DeliverHeaders(p.id, headers) if err != nil &#123; log.Debug("Failed to deliver headers", "err", err) &#125; &#125; 到这里也是首先解析返回的数据，首先对于DAO分叉验证，如果收到的heads内容为空，则验证通过，最后如果验证通过则取消刚才请求时的定时器，否则那个定时器到期后会中断连接。接着当heads长度为1是，还是先验证DAO分叉，如果不必验证则是刚才请求的白名单区块，进行验证，主要是进行hash匹配。最后如果heads长度大于1则执行downloader的DeliverHeaders方法。 到这里handle基本分析完了，回到NewProtocolManager中，刚才主要看了定义协议时的Run方法，除了定义Run还定义了NodeInfo和PeerInfo，这两个方法也是共p2p调用的。在添加完要管理的协议后，检查总共协议的数量，如果为0则退出。否则调用downloader.New创建一个Downloader。接着配置了validator方法用来验证头部；heighter方法用来获取区块链高度；inserter 方法用于插入区块，但是如果开启fastSync，则不会使用，最后生成一个fetcher，这是用来汇集各个peer的区块通知。 Start这样一个ProtocolManager就创建并初始化完毕，随后随着Ethereum的启动，也会调用ProtocolManager的start方法12345678910111213func (pm *ProtocolManager) Start(maxPeers int) &#123; pm.maxPeers = maxPeers pm.txsCh = make(chan core.NewTxsEvent, txChanSize) pm.txsSub = pm.txpool.SubscribeNewTxsEvent(pm.txsCh) go pm.txBroadcastLoop() pm.minedBlockSub = pm.eventMux.Subscribe(core.NewMinedBlockEvent&#123;&#125;) go pm.minedBroadcastLoop() go pm.syncer() go pm.txsyncLoop()&#125; txBroadcastLoop主要是启动了几个goroutine，分别进行交易的广播，挖矿广播，网络同步和交易同步等。对于交易广播：12345678910111213141516171819202122232425262728293031323334353637383940func (pm *ProtocolManager) txBroadcastLoop() &#123; for &#123; select &#123; case event := &lt;-pm.txsCh: pm.BroadcastTxs(event.Txs) case &lt;-pm.txsSub.Err(): return &#125; &#125;&#125;func (pm *ProtocolManager) BroadcastTxs(txs types.Transactions) &#123; var txset = make(map[*peer]types.Transactions) for _, tx := range txs &#123; peers := pm.peers.PeersWithoutTx(tx.Hash()) for _, peer := range peers &#123; txset[peer] = append(txset[peer], tx) &#125; log.Trace("Broadcast transaction", "hash", tx.Hash(), "recipients", len(peers)) &#125; for peer, txs := range txset &#123; peer.AsyncSendTransactions(txs) &#125;&#125;func (ps *peerSet) PeersWithoutTx(hash common.Hash) []*peer &#123; ps.lock.RLock() defer ps.lock.RUnlock() list := make([]*peer, 0, len(ps.peers)) for _, p := range ps.peers &#123; if !p.knownTxs.Contains(hash) &#123; list = append(list, p) &#125; &#125; return list&#125; 当收到合法的交易时，变调用BroadcastTxs方法，在BroadcastTxs中，先查询每个peer是否有这个交易（通过判断knownTxs字段，knownTxs的内容实在pm中收到TxMsg消息时添加的，所以存储着对于peer所有的tx信息），找出没有的peer放入txset中，然后调用AsyncSendTransactions发送12345678910func (p *peer) AsyncSendTransactions(txs []*types.Transaction) &#123; select &#123; case p.queuedTxs &lt;- txs: for _, tx := range txs &#123; p.knownTxs.Add(tx.Hash()) &#125; default: p.Log().Debug("Dropping transaction propagation", "count", len(txs)) &#125;&#125; 这是一个异步发送方法，首先标记这个peer已有这些tx信息，由于是传值给queuedTxs，所以触发broadcast方法中对于的逻辑，123456789101112case txs := &lt;-p.queuedTxs: if err := p.SendTransactions(txs); err != nil &#123; return &#125; p.Log().Trace("Broadcast transactions", "count", len(txs))func (p *peer) SendTransactions(txs types.Transactions) error &#123; for _, tx := range txs &#123; p.knownTxs.Add(tx.Hash()) &#125; return p2p.Send(p.rw, TxMsg, txs)&#125; 最后利用SendTransactions中的Send方法发送，发送的包是TxMsg，顺便看一下接受到该包时的逻辑，还是在handleMsg中：12345678910111213141516case msg.Code == TxMsg: if atomic.LoadUint32(&amp;pm.acceptTxs) == 0 &#123; break &#125; var txs []*types.Transaction if err := msg.Decode(&amp;txs); err != nil &#123; return errResp(ErrDecode, "msg %v: %v", msg, err) &#125; for i, tx := range txs &#123; if tx == nil &#123; return errResp(ErrDecode, "transaction %d is nil", i) &#125; p.MarkTransaction(tx.Hash()) &#125; pm.txpool.AddRemotes(txs) 由于是pm主要是事件分发，所以主要就是先进行解码，然后标记对应的peer有相关tx，最后交给txpool处理。 minedBroadcastLoopstart中调用的另外一个方法是minedBroadcastLoop12345678func (pm *ProtocolManager) minedBroadcastLoop() &#123; for obj := range pm.minedBlockSub.Chan() &#123; if ev, ok := obj.Data.(core.NewMinedBlockEvent); ok &#123; pm.BroadcastBlock(ev.Block, true) // First propagate block to peers pm.BroadcastBlock(ev.Block, false) // Only then announce to the rest &#125; &#125;&#125; 这里当收到订阅事件时，调用BroadcastBlock用来广播区块：12345678910111213141516171819202122232425262728293031323334func (pm *ProtocolManager) BroadcastBlock(block *types.Block, propagate bool) &#123; hash := block.Hash() peers := pm.peers.PeersWithoutBlock(hash) if propagate &#123; var td *big.Int if parent := pm.blockchain.GetBlock(block.ParentHash(), block.NumberU64()-1); parent != nil &#123; td = new(big.Int).Add(block.Difficulty(), pm.blockchain.GetTd(block.ParentHash(), block.NumberU64()-1)) &#125; else &#123; log.Error("Propagating dangling block", "number", block.Number(), "hash", hash) return &#125; transferLen := int(math.Sqrt(float64(len(peers)))) if transferLen &lt; minBroadcastPeers &#123; transferLen = minBroadcastPeers &#125; if transferLen &gt; len(peers) &#123; transferLen = len(peers) &#125; transfer := peers[:transferLen] for _, peer := range transfer &#123; peer.AsyncSendNewBlock(block, td) &#125; log.Trace("Propagated block", "hash", hash, "recipients", len(transfer), "duration", common.PrettyDuration(time.Since(block.ReceivedAt))) return &#125; if pm.blockchain.HasBlock(hash, block.NumberU64()) &#123; for _, peer := range peers &#123; peer.AsyncSendNewBlockHash(block) &#125; log.Trace("Announced block", "hash", hash, "recipients", len(peers), "duration", common.PrettyDuration(time.Since(block.ReceivedAt))) &#125;&#125; 这个方法根据其第二个参数的不同，有两种不同的执行逻辑。首先寻找没有改区块的peer，然后当propagate为true时，先计算含该区块的总难度，然后对部分peer发送区块信息及总难度，如果是false则，在自己拥有该区块的前提下给peers发送区块的hash，二者分别调用了AsyncSendNewBlock和peer.AsyncSendNewBlockHash(block)1234567891011121314151617func (p *peer) AsyncSendNewBlock(block *types.Block, td *big.Int) &#123; select &#123; case p.queuedProps &lt;- &amp;propEvent&#123;block: block, td: td&#125;: p.knownBlocks.Add(block.Hash()) default: p.Log().Debug("Dropping block propagation", "number", block.NumberU64(), "hash", block.Hash()) &#125;&#125;func (p *peer) AsyncSendNewBlockHash(block *types.Block) &#123; select &#123; case p.queuedAnns &lt;- block: p.knownBlocks.Add(block.Hash()) default: p.Log().Debug("Dropping block announcement", "number", block.NumberU64(), "hash", block.Hash()) &#125;&#125; AsyncSendNewBlock方法中给queuedProps赋值，然后标记该peer拥有该区块。赋值后触发broadcast中的逻辑：12345678910case prop := &lt;-p.queuedProps: if err := p.SendNewBlock(prop.block, prop.td); err != nil &#123; return &#125; p.Log().Trace("Propagated block", "number", prop.block.Number(), "hash", prop.block.Hash(), "td", prop.td)func (p *peer) SendNewBlock(block *types.Block, td *big.Int) error &#123; p.knownBlocks.Add(block.Hash()) return p2p.Send(p.rw, NewBlockMsg, []interface&#123;&#125;&#123;block, td&#125;)&#125; 最后调用SendNewBlock利用p2p发送区块信息和总难度，所发的msg是NewBlockMsg。 对于AsyncSendNewBlockHash方法，先给queuedAnns赋值，然后标记该peer知道该区块，之后触发broadcast中的逻辑：1234567891011121314151617case block := &lt;-p.queuedAnns: if err := p.SendNewBlockHashes([]common.Hash&#123;block.Hash()&#125;, []uint64&#123;block.NumberU64()&#125;); err != nil &#123; return &#125; p.Log().Trace("Announced block", "number", block.Number(), "hash", block.Hash())func (p *peer) SendNewBlockHashes(hashes []common.Hash, numbers []uint64) error &#123; for _, hash := range hashes &#123; p.knownBlocks.Add(hash) &#125; request := make(newBlockHashesData, len(hashes)) for i := 0; i &lt; len(hashes); i++ &#123; request[i].Hash = hashes[i] request[i].Number = numbers[i] &#125; return p2p.Send(p.rw, NewBlockHashesMsg, request)&#125; 这里调用SendNewBlockHashes发送区块hash和编号，发送的msg是NewBlockHashesMsg。 顺便也看一下接受的逻辑，对于NewBlockMsg，还HandleMsg中123456789101112131415161718192021222324case msg.Code == NewBlockMsg: var request newBlockData if err := msg.Decode(&amp;request); err != nil &#123; return errResp(ErrDecode, "%v: %v", msg, err) &#125; request.Block.ReceivedAt = msg.ReceivedAt request.Block.ReceivedFrom = p p.MarkBlock(request.Block.Hash()) pm.fetcher.Enqueue(p.id, request.Block) var ( trueHead = request.Block.ParentHash() trueTD = new(big.Int).Sub(request.TD, request.Block.Difficulty()) ) if _, td := p.Head(); trueTD.Cmp(td) &gt; 0 &#123; p.SetHead(trueHead, trueTD) currentBlock := pm.blockchain.CurrentBlock() if trueTD.Cmp(pm.blockchain.GetTd(currentBlock.Hash(), currentBlock.NumberU64())) &gt; 0 &#123; go pm.synchronise(p) &#125; &#125; 首先进行解码，然后取出收到的时间和发送对象，之后标记对应的peer拥有该区块，然后交给fetcher处理。接着计算出对方的总难度减去区块的难度是否大于0，然后更新对应peer的区块链头和总难度，接着计算双方总难度之差，如果对方大于自己，则去同步。 对于另外一个消息NewBlockHashesMsg，逻辑如下：1234567891011121314151617case msg.Code == NewBlockHashesMsg: var announces newBlockHashesData if err := msg.Decode(&amp;announces); err != nil &#123; return errResp(ErrDecode, "%v: %v", msg, err) &#125; for _, block := range announces &#123; p.MarkBlock(block.Hash) &#125; unknown := make(newBlockHashesData, 0, len(announces)) for _, block := range announces &#123; if !pm.blockchain.HasBlock(block.Hash, block.Number) &#123; unknown = append(unknown, block) &#125; &#125; for _, block := range unknown &#123; pm.fetcher.Notify(p.id, block.Hash, block.Number, time.Now(), p.RequestOneHeader, p.RequestBodies) &#125; 这里也是先解码，然后标记对应的peer有响应的区块，然后统计自由不知道的区块最后交给fetcher处理。 syncerstart还启动了syncer方法：123456789101112131415161718192021222324func (pm *ProtocolManager) syncer() &#123; pm.fetcher.Start() defer pm.fetcher.Stop() defer pm.downloader.Terminate() forceSync := time.NewTicker(forceSyncCycle) defer forceSync.Stop() for &#123; select &#123; case &lt;-pm.newPeerCh: if pm.peers.Len() &lt; minDesiredPeerCount &#123; break &#125; go pm.synchronise(pm.peers.BestPeer()) case &lt;-forceSync.C: go pm.synchronise(pm.peers.BestPeer()) case &lt;-pm.noMorePeers: return &#125; &#125;&#125; 这里首先启动了fetcher，关于fetcher稍后介绍，然后启动了一个定时器每5秒执行一次逻辑。下面是一个阻塞型的事件触发逻辑，其中关于定时器的就是调用synchronise去同步。 txsyncLoopstart中最后还有一个txsyncLoop：123456789101112131415161718192021222324func (pm *ProtocolManager) txsyncLoop() &#123; .... for &#123; select &#123; case s := &lt;-pm.txsyncCh: pending[s.p.ID()] = s if !sending &#123; send(s) &#125; case err := &lt;-done: sending = false if err != nil &#123; pack.p.Log().Debug("Transaction send failed", "err", err) delete(pending, pack.p.ID()) &#125; if s := pick(); s != nil &#123; send(s) &#125; case &lt;-pm.quitSync: return &#125; &#125;&#125; 这里主要是先定义了两个方法，然后启动了一个循环取处理事件，第一个事件在syncTransactions中发出，它在ProtocolManager的handle中调用，handle在会在每个peer建立后得到调用，所以也就是对新来的连接会执行syncTransactions方法：1234567891011121314func (pm *ProtocolManager) syncTransactions(p *peer) &#123; var txs types.Transactions pending, _ := pm.txpool.Pending() for _, batch := range pending &#123; txs = append(txs, batch...) &#125; if len(txs) == 0 &#123; return &#125; select &#123; case pm.txsyncCh &lt;- &amp;txsync&#123;p, txs&#125;: case &lt;-pm.quitSync: &#125;&#125; 在syncTransactions中，首先获取所有等待中的交易，然后打包传给txsyncCh触发txsyncLoop中的逻辑。主要是调用send方法，就是开始定义的：12345678910111213141516send := func(s *txsync) &#123; size := common.StorageSize(0) pack.p = s.p pack.txs = pack.txs[:0] for i := 0; i &lt; len(s.txs) &amp;&amp; size &lt; txsyncPackSize; i++ &#123; pack.txs = append(pack.txs, s.txs[i]) size += s.txs[i].Size() &#125; s.txs = s.txs[:copy(s.txs, s.txs[len(pack.txs):])] if len(s.txs) == 0 &#123; delete(pending, s.p.ID()) &#125; s.p.Log().Trace("Sending batch of transactions", "count", len(pack.txs), "bytes", size) sending = true go func() &#123; done &lt;- pack.p.SendTransactions(pack.txs) &#125;()&#125; 这里一次只发送一部分交易信息，要求发送的消息总大小不超过txsyncPackSize。之后如果全都发送的话，把该peer从pending中移除，表示没有消息要发送，然后更新剩余信息。之后启动一个goroutine发送信息，使用的是SendTransactions方法，前文介绍过，并将发送结果传给done，触发txsyncLoop中select另外一个逻辑，这里如果发送无错则先调用pick方法：123456789101112pick := func() *txsync &#123; if len(pending) == 0 &#123; return nil &#125; n := rand.Intn(len(pending)) + 1 for _, s := range pending &#123; if n--; n == 0 &#123; return s &#125; &#125; return nil&#125; 这是从pending中随机选一个等待发送的peer（表示为一个txsync对象，里面含有一个peer和对应的tx），然后调用send方法。直到所有等待的都发送完了（先前一次没有发完的txsync也会在后续被随机选到再次发送），send–pick逻辑结束。 题图来自unsplash：https://unsplash.com/photos/fR9U2S31Exs]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中p2p源码学习]]></title>
    <url>%2F2019%2F04%2F23%2Fgo-ethereum%E4%B8%ADp2p%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前一篇笔记学习了以太坊p2p网络的发现和维护机制，这篇笔记就来了解一下p2p服务 server.go这是P2P服务的主逻辑代码所在处 Start服务的启动代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354func (srv *Server) Start() (err error) &#123; srv.lock.Lock() defer srv.lock.Unlock() if srv.running &#123; //判断是否启动，避免重复启动 return errors.New("server already running") &#125; srv.running = true srv.log = srv.Config.Logger if srv.log == nil &#123; srv.log = log.New() &#125; if srv.NoDial &amp;&amp; srv.ListenAddr == "" &#123; //判断节点是否主动连接其他节点或者监听提起节点 srv.log.Warn("P2P server will be useless, neither dialing nor listening") &#125; // static fields if srv.PrivateKey == nil &#123; return errors.New("Server.PrivateKey must be set to a non-nil key") &#125; if srv.newTransport == nil &#123; srv.newTransport = newRLPX &#125; if srv.Dialer == nil &#123; srv.Dialer = TCPDialer&#123;&amp;net.Dialer&#123;Timeout: defaultDialTimeout&#125;&#125; &#125; srv.quit = make(chan struct&#123;&#125;) srv.addpeer = make(chan *conn) srv.delpeer = make(chan peerDrop) srv.posthandshake = make(chan *conn) srv.addstatic = make(chan *enode.Node) srv.removestatic = make(chan *enode.Node) srv.addtrusted = make(chan *enode.Node) srv.removetrusted = make(chan *enode.Node) srv.peerOp = make(chan peerOpFunc) srv.peerOpDone = make(chan struct&#123;&#125;) if err := srv.setupLocalNode(); err != nil &#123; return err &#125; if srv.ListenAddr != "" &#123; if err := srv.setupListening(); err != nil &#123; return err &#125; &#125; if err := srv.setupDiscovery(); err != nil &#123; return err &#125; dynPeers := srv.maxDialedConns() dialer := newDialState(srv.localnode.ID(), srv.StaticNodes, srv.BootstrapNodes, srv.ntab, dynPeers, srv.NetRestrict) srv.loopWG.Add(1) go srv.run(dialer) return nil&#125; 首先判断是否启动，避免多起启动实例，然后将服务已运行的标志位置true。然后初始化log实例，检查是否要主动连接其他节点，检查私钥是否为空。之后配置rlpx与dial类，稍后再介绍这两个东西。再往下初始化了一系列的channel留作同步用。接着调用了setupLocalNode实现如下 setupLocalNode12345678910111213141516171819202122232425262728293031323334353637func (srv *Server) setupLocalNode() error &#123; pubkey := crypto.FromECDSAPub(&amp;srv.PrivateKey.PublicKey) srv.ourHandshake = &amp;protoHandshake&#123;Version: baseProtocolVersion, Name: srv.Name, ID: pubkey[1:]&#125; for _, p := range srv.Protocols &#123; srv.ourHandshake.Caps = append(srv.ourHandshake.Caps, p.cap()) &#125; sort.Sort(capsByNameAndVersion(srv.ourHandshake.Caps)) db, err := enode.OpenDB(srv.Config.NodeDatabase) if err != nil &#123; return err &#125; srv.nodedb = db srv.localnode = enode.NewLocalNode(db, srv.PrivateKey) srv.localnode.SetFallbackIP(net.IP&#123;127, 0, 0, 1&#125;) srv.localnode.Set(capsByNameAndVersion(srv.ourHandshake.Caps)) for _, p := range srv.Protocols &#123; for _, e := range p.Attributes &#123; srv.localnode.Set(e) &#125; &#125; switch srv.NAT.(type) &#123; case nil: case nat.ExtIP: ip, _ := srv.NAT.ExternalIP() srv.localnode.SetStaticIP(ip) default: srv.loopWG.Add(1) go func() &#123; defer srv.loopWG.Done() if ip, err := srv.NAT.ExternalIP(); err == nil &#123; srv.localnode.SetStaticIP(ip) &#125; &#125;() &#125; return nil&#125; 首先FromECDSAPub是将公钥以字节数组的形式表示（根据椭圆加密算法，我们知道公钥实际上是一对点坐标，这里我们将这对点用字节数组表示出来），之后构造了握手协议的实例，主要记录了版本号（5）；服务名以及ID（就是公钥）。之后遍历了服务的所有协议，将每个协议的cap添加到握手协议的caps中（cap实际上记录了该协议的版本号及名字）。下面先创建了数据库，并配置给服务。接着调用NewLocalNode创建本地节点，实际上就是实例化了一个LocalNode对象，存储了公钥私钥数据库对象等信息。接下来设置了fallbackIP，Set方法实际上是将对象存储在localnode的entries中，capsByNameAndVersion实现了Entry接口。然后遍历服务中所有协议的所有Attributes（实际上也是一个个Entry数组）存储起来。 setupListening配置完localnode后接着调用了setupListening12345678910111213141516171819202122func (srv *Server) setupListening() error &#123; listener, err := net.Listen("tcp", srv.ListenAddr) if err != nil &#123; return err &#125; laddr := listener.Addr().(*net.TCPAddr) srv.ListenAddr = laddr.String() srv.listener = listener srv.localnode.Set(enr.TCP(laddr.Port)) srv.loopWG.Add(1) go srv.listenLoop() if !laddr.IP.IsLoopback() &amp;&amp; srv.NAT != nil &#123; srv.loopWG.Add(1) go func() &#123; nat.Map(srv.NAT, srv.quit, "tcp", laddr.Port, laddr.Port, "ethereum p2p") srv.loopWG.Done() &#125;() &#125; return nil&#125; 这里主要是监听某个tcp端口地址，启动了listenLoop1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253func (srv *Server) listenLoop() &#123; defer srv.loopWG.Done() srv.log.Debug("TCP listener up", "addr", srv.listener.Addr()) tokens := defaultMaxPendingPeers if srv.MaxPendingPeers &gt; 0 &#123; tokens = srv.MaxPendingPeers &#125; slots := make(chan struct&#123;&#125;, tokens) for i := 0; i &lt; tokens; i++ &#123; slots &lt;- struct&#123;&#125;&#123;&#125; &#125; for &#123; &lt;-slots var ( fd net.Conn err error ) for &#123; fd, err = srv.listener.Accept() if netutil.IsTemporaryError(err) &#123; srv.log.Debug("Temporary read error", "err", err) continue &#125; else if err != nil &#123; srv.log.Debug("Read error", "err", err) return &#125; break &#125; if srv.NetRestrict != nil &#123; if tcp, ok := fd.RemoteAddr().(*net.TCPAddr); ok &amp;&amp; !srv.NetRestrict.Contains(tcp.IP) &#123; srv.log.Debug("Rejected conn (not whitelisted in NetRestrict)", "addr", fd.RemoteAddr()) fd.Close() slots &lt;- struct&#123;&#125;&#123;&#125; continue &#125; &#125; var ip net.IP if tcp, ok := fd.RemoteAddr().(*net.TCPAddr); ok &#123; ip = tcp.IP &#125; fd = newMeteredConn(fd, true, ip) srv.log.Trace("Accepted connection", "addr", fd.RemoteAddr()) go func() &#123; srv.SetupConn(fd, inboundConn, nil) slots &lt;- struct&#123;&#125;&#123;&#125; &#125;() &#125;&#125; 首先规定了最大的等待连接数量tokens，然后创建了一个容量与之一样大的channel，在于一个无限循环中中，利用channel机制，启动了tokens个无限循环。每个循环会接收一个连接请求，实际上虽然是无限循环，在获得一个请求后循环便结束了（之所以要用无限循环是要跳过其中的临时性错误）。然后检查白名单，不在名单内的IP都拒绝服务。对于可以服务的连接，单独启动一个goroutine去处理，然后主循环继续，如果连接数未达到最大，则继续等待连接到来。处理连接的方法是SetupConn：123456789func (srv *Server) SetupConn(fd net.Conn, flags connFlag, dialDest *enode.Node) error &#123; c := &amp;conn&#123;fd: fd, transport: srv.newTransport(fd), flags: flags, cont: make(chan error)&#125; err := srv.setupConn(c, flags, dialDest) if err != nil &#123; c.close(err) srv.log.Trace("Setting up connection failed", "addr", fd.RemoteAddr(), "err", err) &#125; return err&#125; SetupConn是执行一个握手协议，并尝试把连接创建成一个peer对象。可以看到只是先创建了conn对象，然后调用了setupConn：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func (srv *Server) setupConn(c *conn, flags connFlag, dialDest *enode.Node) error &#123; srv.lock.Lock() running := srv.running srv.lock.Unlock() if !running &#123; return errServerStopped &#125; var dialPubkey *ecdsa.PublicKey if dialDest != nil &#123; dialPubkey = new(ecdsa.PublicKey) if err := dialDest.Load((*enode.Secp256k1)(dialPubkey)); err != nil &#123; return errors.New("dial destination doesn't have a secp256k1 public key") &#125; &#125; remotePubkey, err := c.doEncHandshake(srv.PrivateKey, dialPubkey) if err != nil &#123; srv.log.Trace("Failed RLPx handshake", "addr", c.fd.RemoteAddr(), "conn", c.flags, "err", err) return err &#125; if dialDest != nil &#123; // For dialed connections, check that the remote public key matches. if dialPubkey.X.Cmp(remotePubkey.X) != 0 || dialPubkey.Y.Cmp(remotePubkey.Y) != 0 &#123; return DiscUnexpectedIdentity &#125; c.node = dialDest &#125; else &#123; c.node = nodeFromConn(remotePubkey, c.fd) &#125; if conn, ok := c.fd.(*meteredConn); ok &#123; conn.handshakeDone(c.node.ID()) &#125; clog := srv.log.New("id", c.node.ID(), "addr", c.fd.RemoteAddr(), "conn", c.flags) err = srv.checkpoint(c, srv.posthandshake) if err != nil &#123; clog.Trace("Rejected peer before protocol handshake", "err", err) return err &#125; phs, err := c.doProtoHandshake(srv.ourHandshake) if err != nil &#123; clog.Trace("Failed proto handshake", "err", err) return err &#125; if id := c.node.ID(); !bytes.Equal(crypto.Keccak256(phs.ID), id[:]) &#123; clog.Trace("Wrong devp2p handshake identity", "phsid", hex.EncodeToString(phs.ID)) return DiscUnexpectedIdentity &#125; c.caps, c.name = phs.Caps, phs.Name err = srv.checkpoint(c, srv.addpeer) if err != nil &#123; clog.Trace("Rejected peer", "err", err) return err &#125; clog.Trace("connection set up", "inbound", dialDest == nil) return nil&#125; 首先确保服务正在运行，然后判断远端节点是否为nil（为nil其实是被动连接，不为nil其实是在dial中主动连接），来计算其公钥。当收到一个连接时，这里为nil不执行。然后调用doEncHandshake开始加密握手，这里实际上是调用的rlpx中的方法，稍后再讲。这里最后得到远端的公钥。对于收到一个连接，远端node开始为空，这里调用nodeFromConn创建一个，主要是记录公钥、ip地址及端口号。接着执行checkpoint方法：12345678910111213func (srv *Server) checkpoint(c *conn, stage chan&lt;- *conn) error &#123; select &#123; case stage &lt;- c: case &lt;-srv.quit: return errServerStopped &#125; select &#123; case err := &lt;-c.cont: return err case &lt;-srv.quit: return errServerStopped &#125;&#125; 实际上就是给posthandshake赋值，然后触发后续逻辑，我们稍后再讲。紧接着又执行了协议握手，调用了doProtoHandshake方法，也是rlpx中方法，传入的参数是ourHandshake，也就是在配置localnode是初始化的，记录了版本号、服务名和自己公钥以及服务中所有协议的摘要。这个方法返回远端的协议信息，之后在conn对象中记录下来远端的服务名和服务中所有协议摘要。同样也通过checkpoint传递给addpeer用来触发后续逻辑。完成后就和远端建立的连接。 setupDiscovery刚才我们在分析配置网络监听的代码时顺便看了收到连接时的逻辑。再回到Start中，下面又调用了setupDiscovery;12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (srv *Server) setupDiscovery() error &#123; if srv.NoDiscovery &amp;&amp; !srv.DiscoveryV5 &#123; return nil &#125; addr, err := net.ResolveUDPAddr("udp", srv.ListenAddr) if err != nil &#123; return err &#125; conn, err := net.ListenUDP("udp", addr) if err != nil &#123; return err &#125; realaddr := conn.LocalAddr().(*net.UDPAddr) srv.log.Debug("UDP listener up", "addr", realaddr) if srv.NAT != nil &#123; if !realaddr.IP.IsLoopback() &#123; go nat.Map(srv.NAT, srv.quit, "udp", realaddr.Port, realaddr.Port, "ethereum discovery") &#125; &#125; srv.localnode.SetFallbackUDP(realaddr.Port) var unhandled chan discover.ReadPacket var sconn *sharedUDPConn if !srv.NoDiscovery &#123; if srv.DiscoveryV5 &#123; unhandled = make(chan discover.ReadPacket, 100) sconn = &amp;sharedUDPConn&#123;conn, unhandled&#125; &#125; cfg := discover.Config&#123; PrivateKey: srv.PrivateKey, NetRestrict: srv.NetRestrict, Bootnodes: srv.BootstrapNodes, Unhandled: unhandled, &#125; ntab, err := discover.ListenUDP(conn, srv.localnode, cfg) if err != nil &#123; return err &#125; srv.ntab = ntab &#125; if srv.DiscoveryV5 &#123; var ntab *discv5.Network var err error if sconn != nil &#123; ntab, err = discv5.ListenUDP(srv.PrivateKey, sconn, "", srv.NetRestrict) &#125; else &#123; ntab, err = discv5.ListenUDP(srv.PrivateKey, conn, "", srv.NetRestrict) &#125; if err != nil &#123; return err &#125; if err := ntab.SetFallbackNodes(srv.BootstrapNodesV5); err != nil &#123; return err &#125; srv.DiscV5 = ntab &#125; return nil&#125; 这里主要就是监听udp连接，配置私钥、白名单、bootstrap节点等，然后调用discover的ListenUDP开始节点发现，后续逻辑详见这里。 run稍微总结一下，start的逻辑主要是配置：配置localnode，处理tcp连接用于节点通信，处理udp连接用于节点发现。配置完毕后，调用newDialState创建了一个dialstate对象，然后运行run方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455func (srv *Server) run(dialstate dialer) &#123; srv.log.Info("Started P2P networking", "self", srv.localnode.Node()) defer srv.loopWG.Done() defer srv.nodedb.Close() var ( peers = make(map[enode.ID]*Peer) inboundCount = 0 trusted = make(map[enode.ID]bool, len(srv.TrustedNodes)) taskdone = make(chan task, maxActiveDialTasks) runningTasks []task queuedTasks []task // tasks that can't run yet ) for _, n := range srv.TrustedNodes &#123; trusted[n.ID()] = true &#125; delTask := func(t task) &#123; for i := range runningTasks &#123; if runningTasks[i] == t &#123; runningTasks = append(runningTasks[:i], runningTasks[i+1:]...) break &#125; &#125; &#125; startTasks := func(ts []task) (rest []task) &#123; i := 0 for ; len(runningTasks) &lt; maxActiveDialTasks &amp;&amp; i &lt; len(ts); i++ &#123; t := ts[i] srv.log.Trace("New dial task", "task", t) go func() &#123; t.Do(srv); taskdone &lt;- t &#125;() runningTasks = append(runningTasks, t) &#125; return ts[i:] &#125; scheduleTasks := func() &#123; queuedTasks = append(queuedTasks[:0], startTasks(queuedTasks)...) if len(runningTasks) &lt; maxActiveDialTasks &#123; nt := dialstate.newTasks(len(runningTasks)+len(queuedTasks), peers, time.Now()) queuedTasks = append(queuedTasks, startTasks(nt)...) &#125; &#125;running: for &#123; scheduleTasks() select&#123; ... &#125; &#125;&#125; run方法主要是处理一些连接的逻辑，首先定义了两个队列runningTasks与queuedTasks，保存正在运行和等待运行的任务。然后定义了三个处理任务的方法。delTask就是删除任务。startTasks就是将任务添加到runningTasks并执行do方法，对于暂时无法运行的任务则返回。scheduleTasks是用来启动任务，他会先尝试启动等待中的任务，然后用newTasks新建一个任务，添加到queuedTasks中。 在接下来的一个无限循环开始，首先启动scheduleTasks，触发一些连接的建立和任务的启动，之后进入select开始阻塞，等待特定的逻辑被触发。 run:running回顾刚才的代码流程，在执行完加密握手后，调用了checkpoint，将一个conn对象传给了srv.posthandshake，出发了run中如下逻辑：123456789case c := &lt;-srv.posthandshake: if trusted[c.node.ID()] &#123; c.flags |= trustedConn &#125; select &#123; case c.cont &lt;- srv.encHandshakeChecks(peers, inboundCount, c): case &lt;-srv.quit: break running &#125; 首先检测是否是可信节点，是的话修改flags的值。然后执行encHandshakeChecks方法：1234567891011121314func (srv *Server) encHandshakeChecks(peers map[enode.ID]*Peer, inboundCount int, c *conn) error &#123; switch &#123; case !c.is(trustedConn|staticDialedConn) &amp;&amp; len(peers) &gt;= srv.MaxPeers: return DiscTooManyPeers case !c.is(trustedConn) &amp;&amp; c.is(inboundConn) &amp;&amp; inboundCount &gt;= srv.maxInboundConns(): return DiscTooManyPeers case peers[c.node.ID()] != nil: return DiscAlreadyConnected case c.node.ID() == srv.localnode.ID(): return DiscSelf default: return nil &#125;&#125; 前两个case主要是通过检查conn的flags判断是节点的性质以及连接数，后两个检查是否是自己或者已连接。检查结果赋值给c.cont，这时回到checkpoint中，如果刚才检查无误setupConn流程继续，否则则抛出异常拒绝服务。 再往下，在setupConn中执行完协议握手后，同样调用了checkpoint方法，这次是给srv.addpeer赋值来触发逻辑：1234567891011121314151617181920case c := &lt;-srv.addpeer: err := srv.protoHandshakeChecks(peers, inboundCount, c) if err == nil &#123; p := newPeer(c, srv.Protocols) if srv.EnableMsgEvents &#123; p.events = &amp;srv.peerFeed &#125; name := truncateName(c.name) srv.log.Debug("Adding p2p peer", "name", name, "addr", c.fd.RemoteAddr(), "peers", len(peers)+1) go srv.runPeer(p) peers[c.node.ID()] = p if p.Inbound() &#123; inboundCount++ &#125; &#125; select &#123; case c.cont &lt;- err: case &lt;-srv.quit: break running &#125; 同样先检查节点，这次调用的是protoHandshakeChecks：123456func (srv *Server) protoHandshakeChecks(peers map[enode.ID]*Peer, inboundCount int, c *conn) error &#123; if len(srv.Protocols) &gt; 0 &amp;&amp; countMatchingProtocols(srv.Protocols, c.caps) == 0 &#123; return DiscUselessPeer &#125; return srv.encHandshakeChecks(peers, inboundCount, c)&#125; 由于握手后，我们知道了对方能提供的协议详情，这里进行了匹配检查，如果双方没有能匹配到的协议，则返回DiscUselessPeer，之后和刚才加密握手一样调用encHandshakeChecks进行节点检查。最后如果都没有问题，调用newPeer创建一个新的Peer。这里表示握手通过，连接正式建立。之后进行了后续操作，如将刚才生成的peer记录下来，另外如果是一个接入的连接，则inboundCount自增。同时调用了runPeer方法1234567891011121314151617181920func (srv *Server) runPeer(p *Peer) &#123; if srv.newPeerHook != nil &#123; srv.newPeerHook(p) &#125; srv.peerFeed.Send(&amp;PeerEvent&#123; Type: PeerEventTypeAdd, Peer: p.ID(), &#125;) remoteRequested, err := p.run() srv.peerFeed.Send(&amp;PeerEvent&#123; Type: PeerEventTypeDrop, Peer: p.ID(), Error: err.Error(), &#125;) srv.delpeer &lt;- peerDrop&#123;p, err, remoteRequested&#125;&#125; 这里主要是先广播了peer的建立，然后调用peer的run方法，这里稍后再讲，知道peer连接断开，然后给delpeer赋值触发相应逻辑。由于runPeer是运行在一个单独goroutine中，所以不会阻塞server的run运行，我们回到run中，srv.addpeer对应的逻辑最后有个阻塞，会给c.cont赋值，这时回到setupConn，如果赋值为空表示没有错误，连接正常，则继续setupConn的逻辑。这样一次握手完成。再看peer断开时，srv.delpeer被赋值，触发如下逻辑：12345678case pd := &lt;-srv.delpeer: d := common.PrettyDuration(mclock.Now() - pd.created) pd.log.Debug("Removing p2p peer", "duration", d, "peers", len(peers)-1, "req", pd.requested, "err", pd.err) delete(peers, pd.ID()) if pd.Inbound() &#123; inboundCount-- &#125;&#125; 主要的逻辑就是从peers删除对应的peer，然后如果是接入型peer，inboundCount再自减1。 到这里server的主逻辑分析完毕，除了这些，服务还提供了一些方法供外部使用，首先看AddPeer：123456func (srv *Server) AddPeer(node *enode.Node) &#123; select &#123; case srv.addstatic &lt;- node: case &lt;-srv.quit: &#125;&#125; 也是利用channel模式触发run中的逻辑123case n := &lt;-srv.addstatic: srv.log.Trace("Adding static node", "node", n) dialstate.addStatic(n) 很简单就是将要添加的节点dialstate的static这个map中，key就是节点的ID，值就是一个dialTask。 除此之外还有RemovePeer、AddTrustedPeer、RemoveTrustedPeer等方法，都是利用向一个channel中赋值，来触发run中的逻辑这里不再详细叙述。 rlpx.go这是一个较独立的模块，所以拿出来分析了，详见此文：go-ethereum中p2p-rlpx源码学习 dial.godial在p2p中也负责链接的建立，在p2pserver中第一次出现是在start方法内构造了一个TCPDialer对象赋值给Dialer：123456789101112 if srv.Dialer == nil &#123; srv.Dialer = TCPDialer&#123;&amp;net.Dialer&#123;Timeout: defaultDialTimeout&#125;&#125; &#125; type TCPDialer struct &#123; *net.Dialer&#125; func (t TCPDialer) Dial(dest *enode.Node) (net.Conn, error) &#123; addr := &amp;net.TCPAddr&#123;IP: dest.IP(), Port: dest.TCP()&#125; return t.Dialer.Dial("tcp", addr.String())&#125; TCPDialer实际上对Dialer进行了封装，然后提供了Dial用于和指定Node建立tcp链接。除此之外还有一个重要的结构体dialstate，它在p2pserver中的start方法最后进行了实例化，并作为参数传递给了run方法，初始化方法如下：123456789101112131415161718func newDialState(self enode.ID, static []*enode.Node, bootnodes []*enode.Node, ntab discoverTable, maxdyn int, netrestrict *netutil.Netlist) *dialstate &#123; s := &amp;dialstate&#123; maxDynDials: maxdyn, ntab: ntab, self: self, netrestrict: netrestrict, static: make(map[enode.ID]*dialTask), dialing: make(map[enode.ID]connFlag), bootnodes: make([]*enode.Node, len(bootnodes)), randomNodes: make([]*enode.Node, maxdyn/2), hist: new(dialHistory), &#125; copy(s.bootnodes, bootnodes) for _, n := range static &#123; s.addStatic(n) &#125; return s&#125; maxDynDials就是server的maxDialedConns，计算如下：12345678910func (srv *Server) maxDialedConns() int &#123; if srv.NoDiscovery || srv.NoDial &#123; return 0 &#125; r := srv.DialRatio if r == 0 &#123; r = defaultDialRatio &#125; return srv.MaxPeers / r&#125; 他在节点从不进行发现或进行连接时等于0，否则根据MaxPeers和DialRatio计算。ntab就是discover的table，代表节点发现协议。其他的赋值了信赖节点和boot节点。实例化之后，在run方法中调用了它的下面几个方法： newTasks这是在定义scheduleTasks时调用的1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func (s *dialstate) newTasks(nRunning int, peers map[enode.ID]*Peer, now time.Time) []task &#123; if s.start.IsZero() &#123; s.start = now &#125; var newtasks []task addDial := func(flag connFlag, n *enode.Node) bool &#123; if err := s.checkDial(n, peers); err != nil &#123; log.Trace("Skipping dial candidate", "id", n.ID(), "addr", &amp;net.TCPAddr&#123;IP: n.IP(), Port: n.TCP()&#125;, "err", err) return false &#125; s.dialing[n.ID()] = flag newtasks = append(newtasks, &amp;dialTask&#123;flags: flag, dest: n&#125;) return true &#125; needDynDials := s.maxDynDials for _, p := range peers &#123; if p.rw.is(dynDialedConn) &#123; needDynDials-- &#125; &#125; for _, flag := range s.dialing &#123; if flag&amp;dynDialedConn != 0 &#123; needDynDials-- &#125; &#125; s.hist.expire(now) for id, t := range s.static &#123; err := s.checkDial(t.dest, peers) switch err &#123; case errNotWhitelisted, errSelf: log.Warn("Removing static dial candidate", "id", t.dest.ID, "addr", &amp;net.TCPAddr&#123;IP: t.dest.IP(), Port: t.dest.TCP()&#125;, "err", err) delete(s.static, t.dest.ID()) case nil: s.dialing[id] = t.flags newtasks = append(newtasks, t) &#125; &#125; if len(peers) == 0 &amp;&amp; len(s.bootnodes) &gt; 0 &amp;&amp; needDynDials &gt; 0 &amp;&amp; now.Sub(s.start) &gt; fallbackInterval &#123; bootnode := s.bootnodes[0] s.bootnodes = append(s.bootnodes[:0], s.bootnodes[1:]...) s.bootnodes = append(s.bootnodes, bootnode) if addDial(dynDialedConn, bootnode) &#123; needDynDials-- &#125; &#125; randomCandidates := needDynDials / 2 if randomCandidates &gt; 0 &#123; n := s.ntab.ReadRandomNodes(s.randomNodes) for i := 0; i &lt; randomCandidates &amp;&amp; i &lt; n; i++ &#123; if addDial(dynDialedConn, s.randomNodes[i]) &#123; needDynDials-- &#125; &#125; &#125; i := 0 for ; i &lt; len(s.lookupBuf) &amp;&amp; needDynDials &gt; 0; i++ &#123; if addDial(dynDialedConn, s.lookupBuf[i]) &#123; needDynDials-- &#125; &#125; s.lookupBuf = s.lookupBuf[:copy(s.lookupBuf, s.lookupBuf[i:])] if len(s.lookupBuf) &lt; needDynDials &amp;&amp; !s.lookupRunning &#123; s.lookupRunning = true newtasks = append(newtasks, &amp;discoverTask&#123;&#125;) &#125; if nRunning == 0 &amp;&amp; len(newtasks) == 0 &amp;&amp; s.hist.Len() &gt; 0 &#123; t := &amp;waitExpireTask&#123;s.hist.min().exp.Sub(now)&#125; newtasks = append(newtasks, t) &#125; return newtasks&#125; 他所返回的是一组task对象，task有一个Do方法。开头第一个检查时间的是为了初始化开始时间。然后定义了addDial方法，主要将节点包装成dialTask添加到newtasks中。不过首先对节点进行了检查，主要是检查是否已连接或者正在连接或者非信任节点等。之后计算了需要建立动态连接的数量。 然后遍历所有静态节点，检查每个节点，没有问题的将其暂存到newtasks中。接下来如果已连接数为0，并且已经过了fallbackInterval时间，则寻找一个bootnode进行连接。接下来在randomNodes中添加需要建立动态连接的数量的一半的节点。后面如果还未达到需要建立动态连接的数量要求，则从lookupBuf中挑选。如果数量还不够创建discoverTask添加进去，用于节点发现。最后当什么都不做创建waitExpireTask返回。 这个方法就是添加一系列要执行的任务。 Do之后回到p2pserver的run方法中，在startTasks方法内，会启动这一系列任务，通过Do方法，不同的任务有同的Do方法： dialTask1234567891011121314151617func (t *dialTask) Do(srv *Server) &#123; if t.dest.Incomplete() &#123; if !t.resolve(srv) &#123; return &#125; &#125; err := t.dial(srv, t.dest) if err != nil &#123; log.Trace("Dial error", "task", t, "err", err) // Try resolving the ID of static nodes if dialing failed. if _, ok := err.(*dialError); ok &amp;&amp; t.flags&amp;staticDialedConn != 0 &#123; if t.resolve(srv) &#123; t.dial(srv, t.dest) &#125; &#125; &#125;&#125; Incomplete方法是检查节点是否有IP地址，如果没有则调用resolve方法：123456789101112131415161718192021222324252627func (t *dialTask) resolve(srv *Server) bool &#123; if srv.ntab == nil &#123; log.Debug("Can't resolve node", "id", t.dest.ID, "err", "discovery is disabled") return false &#125; if t.resolveDelay == 0 &#123; t.resolveDelay = initialResolveDelay &#125; if time.Since(t.lastResolved) &lt; t.resolveDelay &#123; return false &#125; resolved := srv.ntab.Resolve(t.dest) t.lastResolved = time.Now() if resolved == nil &#123; t.resolveDelay *= 2 if t.resolveDelay &gt; maxResolveDelay &#123; t.resolveDelay = maxResolveDelay &#125; log.Debug("Resolving node failed", "id", t.dest.ID, "newdelay", t.resolveDelay) return false &#125; t.resolveDelay = initialResolveDelay t.dest = resolved log.Debug("Resolved node", "id", t.dest.ID, "addr", &amp;net.TCPAddr&#123;IP: t.dest.IP(), Port: t.dest.TCP()&#125;) return true&#125; 这个方法是进程查询的，规定最小查询间隔是60秒。调用的是table中的Resolve，具体代码就不贴了，实际上就是先查找k桶，找到目标节点返回或摘到离他较近的节点调用lookup进行查找，所以就是节点查找的过程。如果查不到节点，则将最小查询间隔翻倍。如果查到的话，则更新节点。回到Do中，如果IP地址被补全，则调用dial进行连接，12345678func (t *dialTask) dial(srv *Server, dest *enode.Node) error &#123; fd, err := srv.Dialer.Dial(dest) if err != nil &#123; return &amp;dialError&#123;err&#125; &#125; mfd := newMeteredConn(fd, false, dest.IP()) return srv.SetupConn(mfd, t.flags, dest)&#125; Dialer实际上就是前文的TCPDialer，建立tcp连接后，调用了SetupConn，之后的逻辑前文以及分析过了。 discoverTask12345678func (t *discoverTask) Do(srv *Server) &#123; next := srv.lastLookup.Add(lookupInterval) if now := time.Now(); now.Before(next) &#123; time.Sleep(next.Sub(now)) &#125; srv.lastLookup = time.Now() t.results = srv.ntab.LookupRandom()&#125; 首先也是判断是否在最小间隔内，若是则等待，否则执行disocer的LookupRandom方法进行随机查找 waitExpireTask123func (t waitExpireTask) Do(*Server) &#123; time.Sleep(t.Duration)&#125; 就是一个定时方法 addStatic removeStatic这两个方法是提供给p2pserver的run方法中使用的，就是添加或移除节点。 dial总结结合p2pserver分析，可知首先封装了一个TCP连接对象给server。然后初始化dialstate进行连接的建立。首先在run的大循环中第一次调用scheduleTasks，此时queuedTasks和queuedTasks都为空，此时添加的任务就是那些静态节点或桶中节点包装的dialTask，以及还有可能的discoverTask和最后的waitExpireTask。然后启动这些任务。对于dialTask，主动和相关节点建立联系；对于discoverTask，执行节点发现逻辑；对于waitExpireTask进行定时方法。 peer.gonewPeer前面介绍了链路建立的准备工作，到这里peer代表一个已经建立好的连接。在p2p服务中，最早出现peer的地方是在节点主动发出或收到一个连接请求，并进行协议握手后，双方检查协议匹配性，检查通过后利用newPeer方法建立了一个peer对象，表示一条稳定的连接：12345678910111213func newPeer(conn *conn, protocols []Protocol) *Peer &#123; protomap := matchProtocols(protocols, conn.caps, conn) p := &amp;Peer&#123; rw: conn, running: protomap, created: mclock.Now(), disc: make(chan DiscReason), protoErr: make(chan error, len(protomap)+1), // protocols + pingLoop closed: make(chan struct&#123;&#125;), log: log.New("id", conn.node.ID(), "conn", conn.flags), &#125; return p&#125; matchProtocols表示双方都能提供的协议，参数中protocols表示自己能提供的协议，conn.caps表示对方能提供的协议，来看具体实现：1234567891011121314151617181920212223func matchProtocols(protocols []Protocol, caps []Cap, rw MsgReadWriter) map[string]*protoRW &#123; sort.Sort(capsByNameAndVersion(caps)) offset := baseProtocolLength result := make(map[string]*protoRW)outer: for _, cap := range caps &#123; for _, proto := range protocols &#123; if proto.Name == cap.Name &amp;&amp; proto.Version == cap.Version &#123; // If an old protocol version matched, revert it if old := result[cap.Name]; old != nil &#123; offset -= old.Length &#125; // Assign the new match result[cap.Name] = &amp;protoRW&#123;Protocol: proto, offset: offset, in: make(chan Msg), w: rw&#125; offset += proto.Length continue outer &#125; &#125; &#125; return result&#125; 基本就是遍历自己和对方的协议集合，将所有名字和版本号一样的协议封装成protoRW对象并按名字存入result中，最后返回二者都能提供的协议集合。 run回到newPeer中，构建了一个Peer对象并返回。紧接着启动了一个goroutine去调用runPeer，在runPeer中执行了peer的run方法：123456789101112131415161718192021222324252627282930313233343536373839404142434445func (p *Peer) run() (remoteRequested bool, err error) &#123; var ( writeStart = make(chan struct&#123;&#125;, 1) writeErr = make(chan error, 1) readErr = make(chan error, 1) reason DiscReason // sent to the peer ) p.wg.Add(2) go p.readLoop(readErr) go p.pingLoop() writeStart &lt;- struct&#123;&#125;&#123;&#125; p.startProtocols(writeStart, writeErr)loop: for &#123; select &#123; case err = &lt;-writeErr: if err != nil &#123; reason = DiscNetworkError break loop &#125; writeStart &lt;- struct&#123;&#125;&#123;&#125; case err = &lt;-readErr: if r, ok := err.(DiscReason); ok &#123; remoteRequested = true reason = r &#125; else &#123; reason = DiscNetworkError &#125; break loop case err = &lt;-p.protoErr: reason = discReasonForError(err) break loop case err = &lt;-p.disc: reason = discReasonForError(err) break loop &#125; &#125; close(p.closed) p.rw.close(reason) p.wg.Wait() return remoteRequested, err&#125; readLoop在run方法中，首先在一个独立goroutine中启动了readLoop方法：123456789101112131415func (p *Peer) readLoop(errc chan&lt;- error) &#123; defer p.wg.Done() for &#123; msg, err := p.rw.ReadMsg() if err != nil &#123; errc &lt;- err return &#125; msg.ReceivedAt = time.Now() if err = p.handle(msg); err != nil &#123; errc &lt;- err return &#125; &#125;&#125; 这就是一个阻塞型的从流中读取信息的方法。rw是conn类型，conn是在开启一个tcp连接后，在SetupConn中将net.Conn包装后的对象。它的ReadMsg实际上就是rlpx的ReadMsg方法，前文已经分析过，返回的是一个Msg对象。之后在readLoop中给mag打上接受的时间戳，然后调用handle处理这个msg12345678910111213141516171819202122232425func (p *Peer) handle(msg Msg) error &#123; switch &#123; case msg.Code == pingMsg: msg.Discard() go SendItems(p.rw, pongMsg) case msg.Code == discMsg: var reason [1]DiscReason rlp.Decode(msg.Payload, &amp;reason) return reason[0] case msg.Code &lt; baseProtocolLength: return msg.Discard() default: proto, err := p.getProto(msg.Code) if err != nil &#123; return fmt.Errorf("msg code out of range: %v", msg.Code) &#125; select &#123; case proto.in &lt;- msg: return nil case &lt;-p.closed: return io.EOF &#125; &#125; return nil&#125; 这里主要是根据msg.Code决定执行的逻辑。主要是判断是否是ping消息或的断开连接的消息。都不是的话判断code是否满足规范，满足的话根据code取具体的协议getProto：12345678func (p *Peer) getProto(code uint64) (*protoRW, error) &#123; for _, proto := range p.running &#123; if code &gt;= proto.offset &amp;&amp; code &lt; proto.offset+proto.Length &#123; return proto, nil &#125; &#125; return nil, newPeerError(errInvalidMsgCode, "%d", code)&#125; 这里根据code查找具体协议，匹配的方式是根据协议的offset和length，看是否在[offset,offset+length)区间内，然后返回具体协议。找到后将msg赋值给proto.in触发相应逻辑。到这里handle执行完毕，readLoop的一个循环结束，开始下一个循环等待数据到来，这样一次完整的数据读取完成。还有一点需要注意的是handle多次出现了Discard方法：123456func (msg Msg) Discard() error &#123; _, err := io.Copy(ioutil.Discard, msg.Payload) return err&#125;var Discard io.Writer = devNull(0) 由于msg的payload携带的是一个Reader对象，当消息抛弃是也要把read的内容读完，所以这里使用Discard这个虚拟的写对象，这个不执行什么实际操作，但是不会报错，可以安全的丢弃数据。 pingLoop再回到run方法中，和readLoop同时启动的还有pingLoop1234567891011121314151617func (p *Peer) pingLoop() &#123; ping := time.NewTimer(pingInterval) defer p.wg.Done() defer ping.Stop() for &#123; select &#123; case &lt;-ping.C: if err := SendItems(p.rw, pingMsg); err != nil &#123; p.protoErr &lt;- err return &#125; ping.Reset(pingInterval) case &lt;-p.closed: return &#125; &#125;&#125; 这相当于是一个心跳包，即使双方没有数据传输，也要每隔一段时间内发送一个ping包看对方是否在线，这里时间间隔是15秒。15秒后执行SendItems方法1234567891011func SendItems(w MsgWriter, msgcode uint64, elems ...interface&#123;&#125;) error &#123; return Send(w, msgcode, elems)&#125;func Send(w MsgWriter, msgcode uint64, data interface&#123;&#125;) error &#123; size, r, err := rlp.EncodeToReader(data) if err != nil &#123; return err &#125; return w.WriteMsg(Msg&#123;Code: msgcode, Size: uint32(size), Payload: r&#125;)&#125; 这里的ping包是一个空包，只有一个pingMsg，最后还用rlpx的WriteMsg发送一个封装好的msg对象。发送后对方接受的逻辑就在上文分析的handle方法，123case msg.Code == pingMsg: msg.Discard() go SendItems(p.rw, pongMsg) 可见显示抛弃消息，然后为了避免阻塞发送了pong包，和发送ping包一样。当我们接受到pong包时，由于pongMsg小于baseProtocolLength，所以直接被抛弃。 startProtocols再回到run中，由于readLoop和pingLoop都是异步进行了，我们看主线程的逻辑，首先调用了startProtocols12345678910111213141516171819202122232425func (p *Peer) startProtocols(writeStart &lt;-chan struct&#123;&#125;, writeErr chan&lt;- error) &#123; p.wg.Add(len(p.running)) for _, proto := range p.running &#123; proto := proto proto.closed = p.closed proto.wstart = writeStart proto.werr = writeErr var rw MsgReadWriter = proto if p.events != nil &#123; rw = newMsgEventer(rw, p.events, p.ID(), proto.Name) &#125; p.log.Trace(fmt.Sprintf("Starting protocol %s/%d", proto.Name, proto.Version)) go func() &#123; err := proto.Run(p, rw) if err == nil &#123; p.log.Trace(fmt.Sprintf("Protocol %s/%d returned", proto.Name, proto.Version)) err = errProtocolReturned &#125; else if err != io.EOF &#123; p.log.Trace(fmt.Sprintf("Protocol %s/%d failed", proto.Name, proto.Version), "err", err) &#125; p.protoErr &lt;- err p.wg.Done() &#125;() &#125;&#125; running就是在newPeer中挑选的匹配上的协议，这里遍历这些协议进行启动操作。由于这里遍历的是Protocol的封装类protoRW，所以先对其几个channel赋值，然后启动一个匿名方法，执行协议的Run方法。 run:loop在启动完所有协议后，开启了一个loop，也是一个无限循环，这个主要是处理各种错误的，如读写错误等，对于所有读写错误处理都是直接结束循环，后续触发peer的结束。 题图来自unsplash：https://unsplash.com/photos/gooBgyq17i0]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中p2p-rlpx源码学习]]></title>
    <url>%2F2019%2F04%2F21%2Fgo-ethereum%E4%B8%ADp2p-rlpx%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[rlpx是一种传输协议，它是基于tcp的，用于节点之间的信息，rlpx并不是什么的缩写，而是基于rlp序列化命名的。代码主要集中在p2p包的rlpx.go中，以太坊主要借助这个协议进行节点间数据传输，所传输的数据也是加密的 ECIES加密ECIES全称Elliptic Curve Integrated Encryption Scheme，即椭圆曲线集成加密方案，是一种混合加密方法。 假设Alice要发发送一条加密消息给Bob，Alice知晓Bob的公钥KB（后文中||符号表示简单的拼接,如a||b=ab）。为了加密消息m，Alice进行如下流程： 首先生成一个随机数r，然后生成公钥R=r*G。 计算出共享秘密S = Px。其中（Px，Py）= r*KB。 得到S后，计算kE || kM = KDF(S,32)（KDF是密钥生成函数，见文档5.8节）。 随机生成一个初始化向量iv。 最后发送给Bob的消息为：R || iv || c || d，其中c为以kE为密钥，以iv为初始化向量对m进行AES的CTR模式加密（CTR模式,AES加密）；d为以kM为密钥，使用SHA-256作为摘要函数，对iv||c计算HMAC（HMAC） Bob在收到消息后，进行如下步骤： 计算共享秘密S，S=Px，其中（Px，Py） = kB*R（注意kB是Bob私钥，KB是Bob公钥，利用的椭圆曲线加密原理，简单证明如下：kB*R = kB*r*G=r*KB =（Px，Py）） 根据共享秘密S计算出密钥：kE || kM = KDF(S,32) 先验证d，即对iv || c使用kM作为密钥计算HMAC 再利用kE作为密钥，以iv为初始化向量，使用AES算法的CTR模式进行解密得到明文m 上述步骤的大致思想就是利用非对称加密算法安全的交换密钥，在使用对称加密算法加密消息，弥补非对称算法的性能缺陷。 握手协议 发起者尝试连接接受者，并发送auth消息 接受者验证auth消息 接受者构造应答auth-ack消息 接受者计算共享秘密，发送第一个加密消息：hello 发起者收到auth-ack消息并计算共享秘密 发起者发送它的第一个加密消息：hello 双方验证各自收到的对方第一个加密消息 若有效，则加密握手完成 auth消息如下：123456auth = auth-size || enc-auth-bodyauth-size：enc-auth-body的长度enc-auth-body = ecies.encrypt(recipient-pubk, auth-body || auth-padding, auth-size) #auth-size不会被写入密文但是会写入HMACauth-padding ：任意填充数据auth-body = [sig, initiator-pubk, initiator-nonce, auth-vsn, ...]auth-vsn = 4 auth-ack消息如下：123456ack = ack-size || enc-ack-bodyack-size = enc-ack-body的长度enc-ack-body = ecies.encrypt(initiator-pubk, ack-body || ack-padding, ack-size)ack-padding ：任意填充数据ack-body = [recipient-ephemeral-pubk, recipient-nonce, ack-vsn, ...]ack-vsn = 4 几个秘密生成算法： 静态共享秘密：static-shared-secret = ecdh.agree(privkey, remote-pubk)。ecdh是一种基于ecc的密钥协商算法 临时密钥: ephemeral-key = ecdh.agree(ephemeral-privkey, remote-ephemeral-pubk) 共享秘密：shared-secret = keccak256(ephemeral-key || keccak256(nonce || initiator-nonce)) aes密钥：aes-secret = keccak256(ephemeral-key || shared-secret) mac密钥：mac-secret = keccak256(ephemeral-key || aes-secret) 帧握手成功之后所有消息都是以帧的形式传播。帧的目的是在一个连接上复用多个功能。其次，由于框架型的消息为消息身份验证提供了合理的分界点，因此加密和身份验证流变得非常简单。帧通过在握手过程中生成的密钥进行加密和身份验证。 帧格式如下：123456789frame = header-ciphertext || header-mac || frame-ciphertext || frame-macheader-ciphertext = aes(aes-secret, header)header = frame-size || header-data || header-paddingheader-data = [capability-id, context-id]capability-id = integer, always zerocontext-id = integer, always zeroheader-padding = zero-fill header to 16-byte boundaryframe-ciphertext = aes(aes-secret, frame-data || frame-padding)frame-padding = zero-fill frame-data to 16-byte boundary MAC就是所谓的消息认证码，rlpx中使用keccak256作为hash函数，并且使用了两个不同的mac用作不同方向的通信，分别是egress-mac和ingress-mac。这两个mac会在通信中不断更新，其构造如下 发送方初始状态：12egress-mac = keccak256.init((mac-secret ^ recipient-nonce) || auth)ingress-mac = keccak256.init((mac-secret ^ initiator-nonce) || ack) 接收方初始状态：12egress-mac = keccak256.init((mac-secret ^ initiator-nonce) || ack)ingress-mac = keccak256.init((mac-secret ^ recipient-nonce) || auth) 当帧发送时，要根据发送的数据更新egress-mac：123header-mac-seed = aes(mac-secret, keccak256.digest(egress-mac)[:16] ^ header-ciphertext)egress-mac = keccak256.update(egress-mac, header-mac-seed)header-mac = keccak256.digest(egress-mac)[:16] 帧mac的计算如下：1234egress-mac = keccak256.update(egress-mac, frame-ciphertext)frame-mac-seed = aes(mac-secret, keccak256.digest(egress-mac)[:16]) ^ keccak256.digest(egress-mac)[:16]egress-mac = keccak256.update(egress-mac, frame-mac-seed)frame-mac = keccak256.digest(egress-mac)[:16] 接收方收到后，以同样方式更新ingress-mac，通过对比来判断通信完整性。 源码首先回顾一下rlpx的服务中的创建：123456789101112131415newTransport func(net.Conn) transportsrv.newTransport = newRLPXfunc newRLPX(fd net.Conn) transport &#123; fd.SetDeadline(time.Now().Add(handshakeTimeout)) return &amp;rlpx&#123;fd: fd&#125;&#125;type rlpx struct &#123; fd net.Conn rmu, wmu sync.Mutex rw *rlpxFrameRW&#125; rlpx之所以能被赋值给newTransport是因为他实现了transport接口：123456789101112131415161718192021type transport interface &#123; doEncHandshake(prv *ecdsa.PrivateKey, dialDest *ecdsa.PublicKey) (*ecdsa.PublicKey, error) doProtoHandshake(our *protoHandshake) (*protoHandshake, error) MsgReadWriter close(err error)&#125;type MsgReadWriter interface &#123; MsgReader MsgWriter&#125;type MsgReader interface &#123; ReadMsg() (Msg, error)&#125;type MsgWriter interface &#123; WriteMsg(Msg) error&#125; doEncHandshake在服务的启动中配置tcp连接时，每接到一个tcp连接，在setupConn中调用了doEncHandshake执行加密握手：123456789101112131415161718func (t *rlpx) doEncHandshake(prv *ecdsa.PrivateKey, dial *ecdsa.PublicKey) (*ecdsa.PublicKey, error) &#123; var ( sec secrets err error ) if dial == nil &#123; sec, err = receiverEncHandshake(t.fd, prv) &#125; else &#123; sec, err = initiatorEncHandshake(t.fd, prv, dial) &#125; if err != nil &#123; return nil, err &#125; t.wmu.Lock() t.rw = newRLPXFrameRW(t.fd, sec) t.wmu.Unlock() return sec.Remote.ExportECDSA(), nil&#125; 当收到一个连接时，dial为null，调用receiverEncHandshake，当发起一个连接时调用initiatorEncHandshake。先看发起一个连接：123456789101112131415161718192021222324func initiatorEncHandshake(conn io.ReadWriter, prv *ecdsa.PrivateKey, remote *ecdsa.PublicKey) (s secrets, err error) &#123; h := &amp;encHandshake&#123;initiator: true, remote: ecies.ImportECDSAPublic(remote)&#125; authMsg, err := h.makeAuthMsg(prv) if err != nil &#123; return s, err &#125; authPacket, err := sealEIP8(authMsg, h) if err != nil &#123; return s, err &#125; if _, err = conn.Write(authPacket); err != nil &#123; return s, err &#125; authRespMsg := new(authRespV4) authRespPacket, err := readHandshakeMsg(authRespMsg, encAuthRespLen, prv, conn) if err != nil &#123; return s, err &#125; if err := h.handleAuthResp(authRespMsg); err != nil &#123; return s, err &#125; return h.secrets(authPacket, authRespPacket)&#125; 首先初始化encHandshake，并用其构造一个auth消息：12345678910111213141516171819202122232425262728293031func (h *encHandshake) makeAuthMsg(prv *ecdsa.PrivateKey) (*authMsgV4, error) &#123; h.initNonce = make([]byte, shaLen) _, err := rand.Read(h.initNonce) if err != nil &#123; return nil, err &#125; h.randomPrivKey, err = ecies.GenerateKey(rand.Reader, crypto.S256(), nil) if err != nil &#123; return nil, err &#125; token, err := h.staticSharedSecret(prv) if err != nil &#123; return nil, err &#125; signed := xor(token, h.initNonce) signature, err := crypto.Sign(signed, h.randomPrivKey.ExportECDSA()) if err != nil &#123; return nil, err &#125; msg := new(authMsgV4) copy(msg.Signature[:], signature) copy(msg.InitiatorPubkey[:], crypto.FromECDSAPub(&amp;prv.PublicKey)[1:]) copy(msg.Nonce[:], h.initNonce) msg.Version = 4 return msg, nil&#125; 首先随机一个随机数，长度32字节。然后构造一对秘钥用于ECDH，然后计算静态共享秘钥（使用自己私钥和对方公钥，按照ECDH算法）。接着将共享秘钥和自己的随机数异或，并将结果用ecc算法签名。字后构造出auth消息，包含签名值，自己的公钥，自己的随机数，以及版本号。 生成auth消息后，按EIP8协议进行封装1234567891011121314func sealEIP8(msg interface&#123;&#125;, h *encHandshake) ([]byte, error) &#123; buf := new(bytes.Buffer) if err := rlp.Encode(buf, msg); err != nil &#123; return nil, err &#125; pad := padSpace[:mrand.Intn(len(padSpace)-100)+100] buf.Write(pad) prefix := make([]byte, 2) binary.BigEndian.PutUint16(prefix, uint16(buf.Len()+eciesOverhead)) enc, err := ecies.Encrypt(rand.Reader, h.remote, buf.Bytes(), nil, prefix) return append(prefix, enc...), err&#125; 可见先进行rlp编码，然后进行填充随机长度的内容（最少100字节），然后计算长度前缀，前缀表示长度，包含填充后内容长度以及加上公钥初始化向量及MAC消息后的总长度。最后对内容进行加密（加密流程见前文ECIES加密），最后在头部补上前缀得到最后封装数据。 继续回到initiatorEncHandshake一切消息准备完毕后，通过连接发送握手包，下面我们分析收到一个握手请求时的逻辑。 同样还是doEncHandshake，收到一个连接请求时，也就是加密握手包，此时dial为空，执行receiverEncHandshake：1234567891011121314151617181920212223242526272829func receiverEncHandshake(conn io.ReadWriter, prv *ecdsa.PrivateKey) (s secrets, err error) &#123; authMsg := new(authMsgV4) authPacket, err := readHandshakeMsg(authMsg, encAuthMsgLen, prv, conn) if err != nil &#123; return s, err &#125; h := new(encHandshake) if err := h.handleAuthMsg(authMsg, prv); err != nil &#123; return s, err &#125; authRespMsg, err := h.makeAuthResp() if err != nil &#123; return s, err &#125; var authRespPacket []byte if authMsg.gotPlain &#123; authRespPacket, err = authRespMsg.sealPlain(h) &#125; else &#123; authRespPacket, err = sealEIP8(authRespMsg, h) &#125; if err != nil &#123; return s, err &#125; if _, err = conn.Write(authRespPacket); err != nil &#123; return s, err &#125; return h.secrets(authPacket, authRespPacket)&#125; 这个方法表示接受到一个加密握手，首先调用readHandshakeMsg读取信息：这里会尝试用两种标准进行解码，一种是我们前面讲的对握手包进行了加密，这里直接尝试解密，否则进行其他尝试，具体就不细讲了，最后返回所读到的信息，同时解码authMsg。 然后创建了一个encHandshake对象，执行handleAuthMsg方法：123456789101112131415161718192021222324252627func (h *encHandshake) handleAuthMsg(msg *authMsgV4, prv *ecdsa.PrivateKey) error &#123; rpub, err := importPublicKey(msg.InitiatorPubkey[:]) if err != nil &#123; return err &#125; h.initNonce = msg.Nonce[:] h.remote = rpub if h.randomPrivKey == nil &#123; h.randomPrivKey, err = ecies.GenerateKey(rand.Reader, crypto.S256(), nil) if err != nil &#123; return err &#125; &#125; token, err := h.staticSharedSecret(prv) if err != nil &#123; return err &#125; signedMsg := xor(token, h.initNonce) remoteRandomPub, err := secp256k1.RecoverPubkey(signedMsg, msg.Signature[:]) if err != nil &#123; return err &#125; h.remoteRandomPub, _ = importPublicKey(remoteRandomPub) return nil&#125; 这个方法是用来处理发起方发送的auth消息。获取读取了发起方的公钥、随机数，同时自己也生成了随机的密钥对用于ECDH，之后利用自己密钥和远端公钥生成静态共享秘密，并利用该结果与对方的随机数异或，然后验证签名并得到远端随机公钥 处理完远端的消息收，开始构造响应：123456789101112func (h *encHandshake) makeAuthResp() (msg *authRespV4, err error) &#123; h.respNonce = make([]byte, shaLen) if _, err = rand.Read(h.respNonce); err != nil &#123; return nil, err &#125; msg = new(authRespV4) copy(msg.Nonce[:], h.respNonce) copy(msg.RandomPubkey[:], exportPubkey(&amp;h.randomPrivKey.PublicKey)) msg.Version = 4 return msg, nil&#125; 响应主要包含自己的随机数，自己的随机公钥和版本号。然后对消息进行封装，根据最新版本调用的是sealEIP8方法，前文已进行过分析。封装后发送给发起人。此时对于接收方握手已经完成，可以构造秘密：12345678910111213141516171819202122232425262728func (h *encHandshake) secrets(auth, authResp []byte) (secrets, error) &#123; ecdheSecret, err := h.randomPrivKey.GenerateShared(h.remoteRandomPub, sskLen, sskLen) if err != nil &#123; return secrets&#123;&#125;, err &#125; sharedSecret := crypto.Keccak256(ecdheSecret, crypto.Keccak256(h.respNonce, h.initNonce)) aesSecret := crypto.Keccak256(ecdheSecret, sharedSecret) s := secrets&#123; Remote: h.remote, AES: aesSecret, MAC: crypto.Keccak256(ecdheSecret, aesSecret), &#125; mac1 := sha3.NewLegacyKeccak256() mac1.Write(xor(s.MAC, h.respNonce)) mac1.Write(auth) mac2 := sha3.NewLegacyKeccak256() mac2.Write(xor(s.MAC, h.initNonce)) mac2.Write(authResp) if h.initiator &#123; s.EgressMAC, s.IngressMAC = mac1, mac2 &#125; else &#123; s.EgressMAC, s.IngressMAC = mac2, mac1 &#125; return s, nil&#125; 首先利用自己的随机私钥和远端的随机公钥生成共享秘密。然后利用该秘密和双方的随机数生成最终共享秘密。利用共享秘密和最终共享秘密生成aes秘密，再利用aes秘密个共享秘密生成mac秘密，最后远端公钥和aes、mac秘密构成一个主秘密。最后如前文介绍额方法配置EgressMAC和IngressMAC 在接收方发送完响应后，再回到发起人的角度，在initiatorEncHandshake方法中readHandshakeMsg方法读到一个响应，这个逻辑不在重复，之后处理这个响应：12345func (h *encHandshake) handleAuthResp(msg *authRespV4) (err error) &#123; h.respNonce = msg.Nonce[:] h.remoteRandomPub, err = importPublicKey(msg.RandomPubkey[:]) return err&#125; 很简单就是获取对方的随机数和随机公钥，到这里加密握手，实际上是密钥交换的所有信息都交换完毕，双方知晓对方的随机数和随机公钥，可以独立的构建主秘密，所以在initiatorEncHandshake最后发起人也调用secrets构建了主秘密。 最后回到doEncHandshake，在生成主秘密后，构建了rlpx帧的读写器，主要是构造了用于aes和hamc的加密器（都是ctr模式，初始化向量全为0），最后构造了rlpxFrameRW对象。最后将远端公钥返回。 前面握手协议已经完成，中间涉及了许多秘密和密钥，我们这里来梳理一下： 静态共享秘密：利用的是自己的私钥和对方的公钥生成，二者按照ECDH算法计算后结果一致，由于用的是自己固定的密钥对，无论在何时这个秘密都是固定的，所以称为静态共享秘密，它的作用是与随机数进行异或后进行签名，进行身份认证，因为只有是公钥对应的私钥的持有人才能计算出和发起方一致的秘密。 随机密钥：在握手时双方都会生成一对随机密钥，用于后续通信的加密。 共享秘密：和静态共享秘密类似，只不过是用双方随机生成的密钥对按照ECDH算法生成，这样保证了即使密钥泄漏，也只影响本次通信。 最终共享秘密：为了保证密钥的随机性，现将二者随机数拼接后进行摘要，然后将结果与共享秘密拼接后再进行摘要得到最终秘密。 在发起人对消息加密时，按照的就是前文ecies的流程，通过对方公钥与自己一个随机数生成秘密S，再利用KDF函数生成AES和HMAC要用的密钥。当然为了保护自己的随机数，发起方随机生成了一对密钥，并将公钥发送，用于对方计算S 总结一下加密握手，实际上就是密钥交换，为了构建通信时的密钥，需要知道对方的随机公钥和随机数。最开始发起人只知道接受者的公钥，所以根据ECIES算法传递了自己的随机公钥和随机数，接收方收到之后自己也生成了随机公钥的随机数，测试接收方以及能构建主秘密，发起人收到响应后，根据接收方的随机公钥的随机数同样也能构建一样的主秘密。 doProtoHandshake在p2p服务的start逻辑中，紧随加密握手之后进行了协议握手123456789101112131415func (t *rlpx) doProtoHandshake(our *protoHandshake) (their *protoHandshake, err error) &#123; werr := make(chan error, 1) go func() &#123; werr &lt;- Send(t.rw, handshakeMsg, our) &#125;() if their, err = readProtocolHandshake(t.rw, our); err != nil &#123; &lt;-werr // make sure the write terminates too return nil, err &#125; if err := &lt;-werr; err != nil &#123; return nil, fmt.Errorf("write error: %v", err) &#125; t.rw.snappy = their.Version &gt;= snappyProtocolVersion return their, nil&#125; 传入的对象是protoHandshake，在sserver的etupLocalNode方法中构建了该对象，存储了自己的协议版本，服务名，ID和自己所有协议信息。在doProtoHandshake中首先调用了Send方法进行发送1234567func Send(w MsgWriter, msgcode uint64, data interface&#123;&#125;) error &#123; size, r, err := rlp.EncodeToReader(data) if err != nil &#123; return err &#125; return w.WriteMsg(Msg&#123;Code: msgcode, Size: uint32(size), Payload: r&#125;)&#125; 首先用rlp进行编码，然后将消息码（握手消息代码为0），消息长度和消息内容封装，并用MsgWriter的WriteMsg进行发送。MsgWriter是一个接口，在doProtoHandshake实际的执行者是rlpxFrameRW，即在加密握手最后构造的对象，它的WriteMsg实现如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546func (rw *rlpxFrameRW) WriteMsg(msg Msg) error &#123; ptype, _ := rlp.EncodeToBytes(msg.Code) if rw.snappy &#123; if msg.Size &gt; maxUint24 &#123; return errPlainMessageTooLarge &#125; payload, _ := ioutil.ReadAll(msg.Payload) payload = snappy.Encode(nil, payload) msg.Payload = bytes.NewReader(payload) msg.Size = uint32(len(payload)) &#125; headbuf := make([]byte, 32) fsize := uint32(len(ptype)) + msg.Size if fsize &gt; maxUint24 &#123; return errors.New("message size overflows uint24") &#125; putInt24(fsize, headbuf) // TODO: check overflow copy(headbuf[3:], zeroHeader) rw.enc.XORKeyStream(headbuf[:16], headbuf[:16]) // first half is now encrypted copy(headbuf[16:], updateMAC(rw.egressMAC, rw.macCipher, headbuf[:16])) if _, err := rw.conn.Write(headbuf); err != nil &#123; return err &#125; tee := cipher.StreamWriter&#123;S: rw.enc, W: io.MultiWriter(rw.conn, rw.egressMAC)&#125; if _, err := tee.Write(ptype); err != nil &#123; return err &#125; if _, err := io.Copy(tee, msg.Payload); err != nil &#123; return err &#125; if padding := fsize % 16; padding &gt; 0 &#123; if _, err := tee.Write(zero16[:16-padding]); err != nil &#123; return err &#125; &#125; fmacseed := rw.egressMAC.Sum(nil) mac := updateMAC(rw.egressMAC, rw.macCipher, fmacseed) _, err := rw.conn.Write(mac) return err&#125; 第一步是对msg的code字段进行rlp编码，之后如果压缩可用的话对消息进行压缩，然后更新message的内容和大小。 接下来是头部的构造。首先计算帧大小，包括刚才编码的code字段长度和msg的大小，不过最大长度不能大于^uint32(0) &gt;&gt; 8 (即2^24 - 1)。接下来用3个字节存储长度(大端模式)，之后填充{0xC2, 0x80, 0x80}这3个字节。之后对前16个字节进行加密（注意XORKeyStream就是aes的ctr模式加密算法） 再往下是写入头的消息认证码，调用updateMAC方法123456789func updateMAC(mac hash.Hash, block cipher.Block, seed []byte) []byte &#123; aesbuf := make([]byte, aes.BlockSize) block.Encrypt(aesbuf, mac.Sum(nil)) for i := range aesbuf &#123; aesbuf[i] ^= seed[i] &#125; mac.Write(aesbuf) return mac.Sum(nil)[:16]&#125; updateMAC就和前文mac那一节中介绍的一样。会多次用到，这里需要三个参数，第一个是要更新的hash，第二个是加密方法，第三个是种子。首先对hash中当前数据计算hash值然后进行加密，接下来把加密值与种子逐字节的异或，并将结果写入hash，更新完毕，同时计算并返回更新后的hash值。这这段代码中，要更新的是egressMAC，种子是刚才加密过的头数据。 回到WriteMsg中，将返回的hash值从headbuf的第16字节开始写入。到这里头部构造完成，是根据前文帧的定义包含了头部数据密文及头部数据hash。然后通过conn的write发送出去。conn就是最初构造rlpx传入的网络连接。 接下来开始处理帧主体内容，先是构造了StreamWriter，所有传入的数据都会被加密处理，它的writer是一个MultiWriter，包含了conn和egressMAC两个写对象，表示同一份数据会被两个对象同时写。接下来首先写入ptype也就是经rlp编码过msg.Code，之后写入msg的Payload就是帧内容。最后写入填充内容，保证数据是16的整数倍，填充的内容全为0。之后又进行了一次mac更新，依旧是更新egressMAC。种子是刚才持续写入数据后计算出的hash值。最后利用刚才网络通道将mac值发送出去。 上面几步就完成了前文帧定义中的几部分数据的构造与发送。再回到doProtoHandshake中，由于发送时异步进行的，在发送同时进行了readProtocolHandshake操作12345678910111213141516171819202122232425func readProtocolHandshake(rw MsgReader, our *protoHandshake) (*protoHandshake, error) &#123; msg, err := rw.ReadMsg() if err != nil &#123; return nil, err &#125; if msg.Size &gt; baseProtocolMaxMsgSize &#123; return nil, fmt.Errorf("message too big") &#125; if msg.Code == discMsg &#123; var reason [1]DiscReason rlp.Decode(msg.Payload, &amp;reason) return nil, reason[0] &#125; if msg.Code != handshakeMsg &#123; return nil, fmt.Errorf("expected handshake, got %x", msg.Code) &#125; var hs protoHandshake if err := msg.Decode(&amp;hs); err != nil &#123; return nil, err &#125; if len(hs.ID) != 64 || !bitutil.TestBytes(hs.ID) &#123; return nil, DiscInvalidIdentity &#125; return &amp;hs, nil&#125; 这是读取对方的握手包。首先调用ReadMsg读取信息，依旧用的是rlpxFrameRW的ReadMsg方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func (rw *rlpxFrameRW) ReadMsg() (msg Msg, err error) &#123; headbuf := make([]byte, 32) if _, err := io.ReadFull(rw.conn, headbuf); err != nil &#123; return msg, err &#125; shouldMAC := updateMAC(rw.ingressMAC, rw.macCipher, headbuf[:16]) if !hmac.Equal(shouldMAC, headbuf[16:]) &#123; return msg, errors.New("bad header MAC") &#125; rw.dec.XORKeyStream(headbuf[:16], headbuf[:16]) // first half is now decrypted fsize := readInt24(headbuf) var rsize = fsize if padding := fsize % 16; padding &gt; 0 &#123; rsize += 16 - padding &#125; framebuf := make([]byte, rsize) if _, err := io.ReadFull(rw.conn, framebuf); err != nil &#123; return msg, err &#125; rw.ingressMAC.Write(framebuf) fmacseed := rw.ingressMAC.Sum(nil) if _, err := io.ReadFull(rw.conn, headbuf[:16]); err != nil &#123; return msg, err &#125; shouldMAC = updateMAC(rw.ingressMAC, rw.macCipher, fmacseed) if !hmac.Equal(shouldMAC, headbuf[:16]) &#123; return msg, errors.New("bad frame MAC") &#125; rw.dec.XORKeyStream(framebuf, framebuf) content := bytes.NewReader(framebuf[:fsize]) if err := rlp.Decode(content, &amp;msg.Code); err != nil &#123; return msg, err &#125; msg.Size = uint32(content.Len()) msg.Payload = content if rw.snappy &#123; payload, err := ioutil.ReadAll(msg.Payload) if err != nil &#123; return msg, err &#125; size, err := snappy.DecodedLen(payload) if err != nil &#123; return msg, err &#125; if size &gt; int(maxUint24) &#123; return msg, errPlainMessageTooLarge &#125; payload, err = snappy.Decode(nil, payload) if err != nil &#123; return msg, err &#125; msg.Size, msg.Payload = uint32(size), bytes.NewReader(payload) &#125; return msg, nil&#125; 第一步先从流中读取32字节，就是头部数据，根据刚才发送数据的分析，包括16字节的加密信息和16字节的mac。读取后根据以前16字节信息为种子更新ingressMAC验证数据时候有误，无误的话对前16字节解密，同时读取前3字节信息，还原出长度信息。由于填充的存在还要计算出发送方填充了多少数据，计算出实际长度。下面就从流中读取帧主体信息。同样也将信息写入ingressMAC，并计算出hash值后作为种子更新一次ingressMAC，与数据流的最后16字节也就是帧mac进行对比看数据是否被篡改。确认无误后解密数据。在去除填充数据后，先解码出code信息，然后填充msg其他字段，另外如果压缩可用的话，还要进行解压操作。最后返回message对象。 读取出正确的msg后，回到readProtocolHandshake中，下面就是根据不同的code执行不同的逻辑。这里进区分了为discMsg，不为handshakeMsg以及其他（就是code是handshakeMsg）的情况。我们先看是handshakeMsg的情况，就是刚才我们分析的发送代码发送的code。第一步当然是解码消息，获得protoHandshake对象，进行简单的检查后返回。这一步是获得了对象p2p所有协议的信息。 在回到doProtoHandshake中，读取到信息后，如果没有错误，则等待Send的完成，如果发送也没有错误，则配置一下snappy，条件就是对方的版本大于5，如果成立以后的信息都会进行压缩。最后返回对方的握手信息，逻辑又回到p2p的server中。这样协议握手也完成了。 在rlpx中也提供了ReadMsg和WriteMsg方法，不过具体实现也是直接调用rlpxFrameRW的读写，前面已经分析过了这里不再重复。 题图来自unsplash：https://unsplash.com/photos/ZIlG-_lwXbg]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中p2p-discover源码学习]]></title>
    <url>%2F2019%2F04%2F15%2Fgo-ethereum%E4%B8%ADp2p-discover%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[区块链系统就是一个基于P2P网络的系统，这里先来学习一下以太坊的P2P网络实现。P2P网络运作的第一个要求就是节点之间能互相发现，这里以太坊用到了一个名为Kademlia的协议算法，这里来梳理一下ethereum P2P的discover实现 Kademlia协议这个协议是2002年美国纽约大学Petar Maymounkov和David Mazières发表的一篇论文中所介绍的，该论文的核心部分翻译见这里,下面我们就来详细介绍一下这个协议 概述Kademlia规定了网络的结构，也规定了通过节点查询进行信息交换的方式。Kademlia网络节点之间使用UDP进行通讯。参与通讯的所有节点形成一张虚拟网（或者叫做覆盖网）。这些节点通过一组数字（或称为节点ID）来进行身份标识。节点ID不仅可以用来做身份标识，还可以用来进行值定位（标识这哪些节点存储哪些资源）。 当进行节点搜索时，Kademlia算法需要知道与这些值相关的键，然后分步在网络中开始搜索，每一步都会找到一些节点，这些节点的ID与键更为接近，如果有节点直接返回搜索的值或者再也无法找到与键更为接近的节点ID的时候搜索便会停止。这种搜索值的方法是非常高效的：与其他的分布式散列表的实现类似，在一个包含n个节点的系统的值的搜索中，Kademlia仅访问O(log(n))个节点。 节点Kademlia定义每个节点都以一个随机的ID，文中定义有160位，不必确保两个节点ID有什么联系，唯一需要做的足够随机。 距离度量Kademlia定义两个节点的距离为两个节点ID异或的结果。如节点A为010101，节点B为110001，二者异或的100100，转换为十进制就是36，则二者之间的距离就是36。关于选择异或作为距离的度量，作者表示有一些几个特点： 一个节点到自己的距离为0，即d(x,x) = 0 从A到B与从B到A的距离相等，即d(x,y) = d(y,x) 满足三角不等式：d(x,z) = d(x,y) XOR d(y,z),而a+b&gt;a XOR b 有了这三点，就足以证明异或算法也可以作为距离度量的标准，更重要的是异或计算非常高效。实际上用异或计算距离，更重要的是给出了一个节点分类的标准，类似于显示生活根据距离分类一样，便于通过一个ID搜索一个节点，也就是节点发现 K桶文章提出了一个K桶的概念，实际上就是一个列表，如果ID有160位，那么一个节点就有160个所谓K桶，第i个桶保存着距离自己[2^i,2^i+1)范围内的节点，当寻找一个节点时，就从相应范围内的列表去搜索，k是一个列表的最大长度，如20。可知i越大，区间范围越大，里面的节点数可能越多。离自己越近的k桶内所记录的节点数虽然越少，但命中率越高。所以进行节点搜索是去寻找目标节点距离附近的节点，在进一步迭代，就能很快找到所需节点。 K桶使用一种类似于最近最久未使用的淘汰算法，当新节点被探知时，如果所在k桶未满，则直接在队尾插入，如果已满，则ping队头节点，如果节点不在线，则移除，把新节点插到队尾，如果队头节点在线，则从队头移到队尾，新节点被抛弃 RPC消息Kademlia是利用一系列RPC消息来维护网络的 PING主要作用是探测一个节点是否仍在线 STORE通知一个节点存储一个键值对 FIND_NODE节点定位。计算距离，寻找对应区间的k桶，选择一些节点发送消息，返回这些节点所知的距离目标节点更近的节点，然后对这些节点再次发送消息，多次迭代，最后定位到节点。 FIND_VALUE定位资源。类似于FIND_NODE，返回的是节点的信息，如IP地址，udp端口即节点ID。 加入网络要加入一个P2P首先必须要与一个网络内的节点建立通信，之后新节点进行自我定位，通过这种方法其他节点可以更新自己的k桶，新节点也可以获得网络信息。 其他还有一些详细的协议规范请参考论文。 源码分析go-ethereum的p2p实现源码主要集中在p2p目录下，该目录下的discover主要实现了节点方法算法，本文主要来梳理这一部分源码 table.go在源码中table就是Kademlia的主要实现地方，先看常量和结构体123456789101112131415161718192021222324252627282930313233343536373839404142const ( alpha = 3 // Kademlia concurrency factor bucketSize = 16 // Kademlia bucket size maxReplacements = 10 // Size of per-bucket replacement list // We keep buckets for the upper 1/15 of distances because // it's very unlikely we'll ever encounter a node that's closer. hashBits = len(common.Hash&#123;&#125;) * 8 nBuckets = hashBits / 15 // Number of buckets bucketMinDistance = hashBits - nBuckets // Log distance of closest bucket // IP address limits. bucketIPLimit, bucketSubnet = 2, 24 // at most 2 addresses from the same /24 tableIPLimit, tableSubnet = 10, 24 maxFindnodeFailures = 5 // Nodes exceeding this limit are dropped refreshInterval = 30 * time.Minute revalidateInterval = 10 * time.Second copyNodesInterval = 30 * time.Second seedMinTableTime = 5 * time.Minute seedCount = 30 seedMaxAge = 5 * 24 * time.Hour)type Table struct &#123; mutex sync.Mutex // protects buckets, bucket content, nursery, rand buckets [nBuckets]*bucket // index of known nodes by distance nursery []*node // bootstrap nodes rand *mrand.Rand // source of randomness, periodically reseeded ips netutil.DistinctNetSet db *enode.DB // database of known nodes net transport refreshReq chan chan struct&#123;&#125; initDone chan struct&#123;&#125; closeOnce sync.Once closeReq chan struct&#123;&#125; closed chan struct&#123;&#125; nodeAddedHook func(*node) // for testing&#125; 首先常量中定义了一些Kademlia协议中的一些值，如k桶容量也就是k等于16，每次查找的节点为3，k桶置换表大小为10。有一点和协议不同的是，这里定义k桶的数量为hash长度的15分之一，没有像协议中定义有hash有多长就有多少个k桶。另外还有超时重试次数，刷新间隔等定义。 table中维护了一组k桶实例，一组bootstrap节点，还有数据库等辅助参数。我们看k桶的定义12345type bucket struct &#123; entries []*node replacements []*node ips netutil.DistinctNetSet&#125; 和协议中定义的类似，一组节点和一组置换节点。下面看初始化代码1234567891011121314151617181920212223242526272829303132333435func newTable(t transport, db *enode.DB, bootnodes []*enode.Node) (*Table, error) &#123; tab := &amp;Table&#123; net: t, db: db, refreshReq: make(chan chan struct&#123;&#125;), initDone: make(chan struct&#123;&#125;), closeReq: make(chan struct&#123;&#125;), closed: make(chan struct&#123;&#125;), rand: mrand.New(mrand.NewSource(0)), ips: netutil.DistinctNetSet&#123;Subnet: tableSubnet, Limit: tableIPLimit&#125;, &#125; if err := tab.setFallbackNodes(bootnodes); err != nil &#123; return nil, err &#125; for i := range tab.buckets &#123; tab.buckets[i] = &amp;bucket&#123; ips: netutil.DistinctNetSet&#123;Subnet: bucketSubnet, Limit: bucketIPLimit&#125;, &#125; &#125; tab.seedRand() tab.loadSeedNodes() go tab.loop() return tab, nil&#125;func (tab *Table) setFallbackNodes(nodes []*enode.Node) error &#123; for _, n := range nodes &#123; if err := n.ValidateComplete(); err != nil &#123; return fmt.Errorf("bad bootstrap node %q: %v", n, err) &#125; &#125; tab.nursery = wrapNodes(nodes) return nil&#125; 首先初始化一个table实例，然后调用setFallbackNodes初始化连接节点。在setFallbackNodes中先检查所有节点是否有效，接下来的wrapNodes方法主要是将enode.Node类型对象包装为discover包内的node对象。 在setFallbackNodes方法中table的bootstrap被设置完成之后，接下来的一个遍历是用来初始化所有k桶。 再往下，tab.seedRand()方法先用crypto/rand中的Read随机生成一个长度为8的byte数组，并用该数组生成一个64位int类型数去作为rand的种子。接下来loadSeedNodes实现如下12345678910func (tab *Table) loadSeedNodes() &#123; seeds := wrapNodes(tab.db.QuerySeeds(seedCount, seedMaxAge)) seeds = append(seeds, tab.nursery...) for i := range seeds &#123; seed := seeds[i] age := log.Lazy&#123;Fn: func() interface&#123;&#125; &#123; return time.Since(tab.db.LastPongReceived(seed.ID(), seed.IP())) &#125;&#125; log.Trace("Found seed node in database", "id", seed.ID(), "addr", seed.addr(), "age", age) tab.addSeenNode(seed) &#125;&#125; 还是先用wrapNodes进行了一次包装，这次包装的对象来自于数据库，tab.db保存的是已知的节点，我们要查找的种子节点数量为30，种子节点最长寿命为5天（根据前面常量定义），QuerySeeds的逻辑也很简单，就是从数据库中随机查找，但是要过滤掉那些太老的节点，而且最后返回的节点数不超过30。接下来将数据库中返回的节点和前面的种子节点进行合并，开始遍历，遍历的目的是利用addSeenNode将节点添加到合适的桶中，既然要添加的合适的桶中，就要计算距离，我们来看看距离的计算1234567891011121314// go-ethereum\p2p\enode\node.gofunc LogDist(a, b ID) int &#123; lz := 0 //记录前导0数量 for i := range a &#123; x := a[i] ^ b[i] if x == 0 &#123; //结果为8表示全为零，就是8个前导零 lz += 8 &#125; else &#123; lz += bits.LeadingZeros(x) break &#125; &#125; return len(a)*8 - lz&#125; 其实严格来说，这里已经不叫距离计算，由于前面k桶数量并不是根据原始Kademlia协议中写的那样定义而是ID的比特数除以15，所以对应的距离计算也要改变，通过阅读代码，我们发现距离定义变为比特数减去两个ID对应字节异或后前导零的数量之和的差。根据距离选桶的实现如下1234567func (tab *Table) bucket(id enode.ID) *bucket &#123; d := enode.LogDist(tab.self().ID(), id) if d &lt;= bucketMinDistance &#123; return tab.buckets[0] &#125; return tab.buckets[d-bucketMinDistance-1]&#125; 其中最短距离bucketMinDistance = hashBits - nBuckets。为的是确保能找到一个合适的桶，避免差值过大。在回到addSeenNode，找的合适的桶时，先判断是否满了或已包含，来决定否添加，或是否添加到缓存表中。加载完种子节点之后，启动了一个goroutine运行loop，实现如下。12345678910111213141516171819func (tab *Table) loop() &#123; var ( revalidate = time.NewTimer(tab.nextRevalidateTime()) refresh = time.NewTicker(refreshInterval) copyNodes = time.NewTicker(copyNodesInterval) refreshDone = make(chan struct&#123;&#125;) // where doRefresh reports completion revalidateDone chan struct&#123;&#125; // where doRevalidate reports completion waiting = []chan struct&#123;&#125;&#123;tab.initDone&#125; // holds waiting callers while doRefresh runs ) defer refresh.Stop() defer revalidate.Stop() defer copyNodes.Stop() // Start initial refresh. go tab.doRefresh(refreshDone)loop: .....&#125; 首先初始化了几个定时器和几个channel。之后启动了一个goroutine执行初始化刷新。12345678910111213141516func (tab *Table) doRefresh(done chan struct&#123;&#125;) &#123; defer close(done) tab.loadSeedNodes() var key ecdsa.PublicKey if err := tab.self().Load((*enode.Secp256k1)(&amp;key)); err == nil &#123; tab.lookup(encodePubkey(&amp;key), false) &#125; for i := 0; i &lt; 3; i++ &#123; var target encPubkey crand.Read(target[:]) tab.lookup(target, false) &#125;&#125; 刷新操作中先加载了种子节点。之后执行了自我查找，就是查找自己，用的就是lookup，我们来看一下实现：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849func (tab *Table) lookup(targetKey encPubkey, refreshIfEmpty bool) []*node &#123; var ( target = enode.ID(crypto.Keccak256Hash(targetKey[:])) asked = make(map[enode.ID]bool) seen = make(map[enode.ID]bool) reply = make(chan []*node, alpha) pendingQueries = 0 result *nodesByDistance ) asked[tab.self().ID()] = true for &#123; tab.mutex.Lock() result = tab.closest(target, bucketSize) tab.mutex.Unlock() if len(result.entries) &gt; 0 || !refreshIfEmpty &#123; break &#125; &lt;-tab.refresh() refreshIfEmpty = false &#125; for &#123; for i := 0; i &lt; len(result.entries) &amp;&amp; pendingQueries &lt; alpha; i++ &#123; n := result.entries[i] if !asked[n.ID()] &#123; asked[n.ID()] = true pendingQueries++ go tab.findnode(n, targetKey, reply) &#125; &#125; if pendingQueries == 0 &#123; break &#125; select &#123; case nodes := &lt;-reply: for _, n := range nodes &#123; if n != nil &amp;&amp; !seen[n.ID()] &#123; seen[n.ID()] = true result.push(n, bucketSize) &#125; &#125; case &lt;-tab.closeReq: return nil &#125; pendingQueries-- &#125; return result.entries&#125; 首先定义了一系列变量，然后从k桶中取得离目标最近的几个节点，实现如下12345678910111213141516func (tab *Table) closest(target enode.ID, nresults int) *nodesByDistance &#123; close := &amp;nodesByDistance&#123;target: target&#125; for _, b := range &amp;tab.buckets &#123; for _, n := range b.entries &#123; if n.livenessChecks &gt; 0 &#123; close.push(n, nresults) &#125; &#125; &#125; return close&#125;type nodesByDistance struct &#123; entries []*node target enode.ID&#125; nodesByDistance类型存储着目标ID和一组距离目标较近的节点。实际上closest逻辑很简单，就是遍历所有桶内的节点，看是比已有的更近，判断是否添加的逻辑在push中：12345678910111213func (h *nodesByDistance) push(n *node, maxElems int) &#123; ix := sort.Search(len(h.entries), func(i int) bool &#123; return enode.DistCmp(h.target, h.entries[i].ID(), n.ID()) &gt; 0 &#125;) if len(h.entries) &lt; maxElems &#123; h.entries = append(h.entries, n) &#125; if ix == len(h.entries) &#123; &#125; else &#123; copy(h.entries[ix+1:], h.entries[ix:]) h.entries[ix] = n &#125;&#125; DistCmp是给a，b判断二者谁离目标更近， sort.Search则是得出给定的ID在entries的位置，如果最后ix排到末尾而且entries已满，说明这个点不比已有的点目标更近。继续回到lookup，找到一组离目标较近的节点后，在第二个循环体内，开始遍历这一组节点，对每个节点都执行findnode操作，但是最多每次并发执行alpha个，也就是3个。由于entries是有序的，所以前面的都是例目标最近的。下面看findnode操作：1234567891011121314151617181920212223func (tab *Table) findnode(n *node, targetKey encPubkey, reply chan&lt;- []*node) &#123; fails := tab.db.FindFails(n.ID(), n.IP()) r, err := tab.net.findnode(n.ID(), n.addr(), targetKey) if err == errClosed &#123; reply &lt;- nil return &#125; else if err != nil || len(r) == 0 &#123; fails++ tab.db.UpdateFindFails(n.ID(), n.IP(), fails) log.Trace("Findnode failed", "id", n.ID(), "failcount", fails, "err", err) if fails &gt;= maxFindnodeFailures &#123; log.Trace("Too many findnode failures, dropping", "id", n.ID(), "failcount", fails) tab.delete(n) &#125; &#125; else if fails &gt; 0 &#123; tab.db.UpdateFindFails(n.ID(), n.IP(), fails-1) &#125; for _, n := range r &#123; tab.addSeenNode(n) &#125; reply &lt;- r&#125; 实际上findnode的逻辑并不在这里，这里先不管后面再说，先知道findnode会返回一组离目标更近的node，否则返回一个错误。对于某个node当错误次数大于5次时就把它删除。而对于之前出错但这次成功的话，就将其累积出错次数减一。最后遍历返回的一组node，调用addSeenNode，这个方法在之前加载种子节点时出现，就是将节点添加到合适桶中。方法最后向reply中写入r。这样就回到lookup中，有一个select，当reply可以取值时，执行下面逻辑1234567case nodes := &lt;-reply: for _, n := range nodes &#123; if n != nil &amp;&amp; !seen[n.ID()] &#123; seen[n.ID()] = true result.push(n, bucketSize) &#125; &#125; 这里继续将新得到的node添加到有序的entries中，继续启动新一轮循环按照前面的逻辑继续查找。至于什么时候停止呢？在遍历entries时，对于每个node会判断是否访问过，对于访问过就不在进行findnode，当所有entries都被访问就意味着已经找不到离目标更近的节点了，这是for循环结束，pendingQueries为0，根据代码执行break退出外层循环，返回entries。这样lookup就执行完毕。代码返回到doRefresh中，在执行完初始的自我查找之后，开始了一个小循环，进行随机查找，只查找3个，每次产生一个随机的ID调用lookup进行查找，目的都是尽可能的完善桶。doRefresh结束后后回到loop中，由于doRefresh是一个单独的goroutine，loop主要循环在loop标签的代码中：1234567891011121314151617181920212223242526272829303132loop: for &#123; select &#123; case &lt;-refresh.C: tab.seedRand() if refreshDone == nil &#123; refreshDone = make(chan struct&#123;&#125;) go tab.doRefresh(refreshDone) &#125; case req := &lt;-tab.refreshReq: waiting = append(waiting, req) if refreshDone == nil &#123; refreshDone = make(chan struct&#123;&#125;) go tab.doRefresh(refreshDone) &#125; case &lt;-refreshDone: for _, ch := range waiting &#123; close(ch) &#125; waiting, refreshDone = nil, nil case &lt;-revalidate.C: revalidateDone = make(chan struct&#123;&#125;) go tab.doRevalidate(revalidateDone) case &lt;-revalidateDone: revalidate.Reset(tab.nextRevalidateTime()) revalidateDone = nil case &lt;-copyNodes.C: go tab.copyLiveNodes() case &lt;-tab.closeReq: break loop &#125; &#125; 可见还是一个同步代码。外层是一个无限循环，内存是一个select阻塞，根据不同的操作触发不同代码。首先是一个refresh定时器，每30分钟触发一次，调用doRefresh执行刷新。除了定时刷新还有主动刷新，使用的是refreshReq这个channel。另外还有一个revalidate定时器，它的时间不固定，随机从0到10秒内选一个时间，到时间后触发doRevalidate，逻辑如下：12345678910111213141516171819202122232425func (tab *Table) doRevalidate(done chan&lt;- struct&#123;&#125;) &#123; defer func() &#123; done &lt;- struct&#123;&#125;&#123;&#125; &#125;() last, bi := tab.nodeToRevalidate() if last == nil &#123; return &#125; err := tab.net.ping(last.ID(), last.addr()) tab.mutex.Lock() defer tab.mutex.Unlock() b := tab.buckets[bi] if err == nil &#123; last.livenessChecks++ log.Debug("Revalidated node", "b", bi, "id", last.ID(), "checks", last.livenessChecks) tab.bumpInBucket(b, last) return &#125; if r := tab.replace(b, last); r != nil &#123; log.Debug("Replaced dead node", "b", bi, "id", last.ID(), "ip", last.IP(), "checks", last.livenessChecks, "r", r.ID(), "rip", r.IP()) &#125; else &#123; log.Debug("Removed dead node", "b", bi, "id", last.ID(), "ip", last.IP(), "checks", last.livenessChecks) &#125;&#125; 这段代码主要逻辑是随机找一个非空的桶，取得其最后一个节点，然后去ping这个节点，看是否在线，如果在线将其移到桶的前部，否则从缓存节点找一个去替代这个节点。当操作结束后，重新设置revalidate时间，准备下一次随机验证。最后还有一个定时器copyNodesInterval，每30分钟触发一次，执行copyLiveNodes逻辑12345678910111213func (tab *Table) copyLiveNodes() &#123; tab.mutex.Lock() defer tab.mutex.Unlock() now := time.Now() for _, b := range &amp;tab.buckets &#123; for _, n := range b.entries &#123; if n.livenessChecks &gt; 0 &amp;&amp; now.Sub(n.addedAt) &gt;= seedMinTableTime &#123; tab.db.UpdateNode(unwrapNode(n)) &#125; &#125; &#125;&#125; 主要逻辑是，遍历所有节点，对存活检查过的，且添加时间大于5分钟的节点存入数据库，存储的内容是经过rlp编码的数据。再回到loop中，只剩下一个关闭请求的channel，用于退出loop。退出loop的逻辑也很简单，如下12345678910if refreshDone != nil &#123; &lt;-refreshDone&#125;for _, ch := range waiting &#123; close(ch)&#125;if revalidateDone != nil &#123; &lt;-revalidateDone&#125;close(tab.closed) 先等待刷新结束，然后关闭那些等待中的操作，再等待验证结束，最后关闭closed用于正常退出close方法。closeReq是在close方法中发出的：123456789func (tab *Table) Close() &#123; tab.closeOnce.Do(func() &#123; if tab.net != nil &#123; tab.net.close() &#125; close(tab.closeReq) &lt;-tab.closed &#125;)&#125; 到这里p2p节点的发现以及维护逻辑源码梳理完毕。总体还是很清晰的，基本都是按照Kademlia协议要求的进行的，主要流程是先加载种子节点，这些种子节点来源于用户指定或者之前数据库的值，然后利用自我查找进一步的填充k桶，最后通过各种定时器维护k桶。 udp.go前面table.go实现了Kademlia协议，udp则是进行网络通信的，先看常量的定义123456const ( pingPacket = iota + 1 // zero is 'reserved' pongPacket findnodePacket neighborsPacket) 定义了4种数据包，pingPacket就是询问节点是否在线，pongPacket是对ping的回应。findnodePacket是请求节点，neighborsPacket是对findnode的响应。详细的结构体如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253type ( ping struct &#123; senderKey *ecdsa.PublicKey // filled in by preverify Version uint From, To rpcEndpoint Expiration uint64 // Ignore additional fields (for forward compatibility). Rest []rlp.RawValue `rlp:"tail"` &#125; // pong is the reply to ping. pong struct &#123; // This field should mirror the UDP envelope address // of the ping packet, which provides a way to discover the // the external address (after NAT). To rpcEndpoint ReplyTok []byte // This contains the hash of the ping packet. Expiration uint64 // Absolute timestamp at which the packet becomes invalid. // Ignore additional fields (for forward compatibility). Rest []rlp.RawValue `rlp:"tail"` &#125; // findnode is a query for nodes close to the given target. findnode struct &#123; Target encPubkey Expiration uint64 // Ignore additional fields (for forward compatibility). Rest []rlp.RawValue `rlp:"tail"` &#125; // reply to findnode neighbors struct &#123; Nodes []rpcNode Expiration uint64 // Ignore additional fields (for forward compatibility). Rest []rlp.RawValue `rlp:"tail"` &#125; rpcNode struct &#123; IP net.IP // len 4 for IPv4 or 16 for IPv6 UDP uint16 // for discovery protocol TCP uint16 // for RLPx protocol ID encPubkey &#125; rpcEndpoint struct &#123; IP net.IP // len 4 for IPv4 or 16 for IPv6 UDP uint16 // for discovery protocol TCP uint16 // for RLPx protocol &#125;) 还有两个接口，分别定义数据包和upd连接。123456789101112131415type packet interface &#123; // preverify checks whether the packet is valid and should be handled at all. preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error // handle handles the packet. handle(t *udp, from *net.UDPAddr, fromID enode.ID, mac []byte) // name returns the name of the packet for logging purposes. name() string&#125;type conn interface &#123; ReadFromUDP(b []byte) (n int, addr *net.UDPAddr, err error) WriteToUDP(b []byte, addr *net.UDPAddr) (n int, err error) Close() error LocalAddr() net.Addr&#125; udp的结构如下12345678910111213type udp struct &#123; conn conn netrestrict *netutil.Netlist priv *ecdsa.PrivateKey localNode *enode.LocalNode db *enode.DB tab *Table wg sync.WaitGroup addReplyMatcher chan *replyMatcher gotreply chan reply closing chan struct&#123;&#125;&#125; 接下来看udp的创建123456789101112131415161718192021222324252627282930func ListenUDP(c conn, ln *enode.LocalNode, cfg Config) (*Table, error) &#123; tab, _, err := newUDP(c, ln, cfg) if err != nil &#123; return nil, err &#125; return tab, nil&#125;func newUDP(c conn, ln *enode.LocalNode, cfg Config) (*Table, *udp, error) &#123; udp := &amp;udp&#123; conn: c, priv: cfg.PrivateKey, netrestrict: cfg.NetRestrict, localNode: ln, db: ln.Database(), closing: make(chan struct&#123;&#125;), gotreply: make(chan reply), addReplyMatcher: make(chan *replyMatcher), &#125; tab, err := newTable(udp, ln.Database(), cfg.Bootnodes) if err != nil &#123; return nil, nil, err &#125; udp.tab = tab udp.wg.Add(2) go udp.loop() go udp.readLoop(cfg.Unhandled) return udp.tab, udp, nil&#125; 外部调用的是ListenUDP，传入一个连接，然后调用newUDP创建，由于UDP是为table服务的，所以也创建了table。接下来启动了两个goroutine，后面再讲，我们下面主要看看那几个PRC是如何实现的 ping在table中的doRevalidate也就是检查节点活性的时候调用udp的ping方法12345678910111213141516171819202122232425262728func (t *udp) ping(toid enode.ID, toaddr *net.UDPAddr) error &#123; return &lt;-t.sendPing(toid, toaddr, nil)&#125;func (t *udp) sendPing(toid enode.ID, toaddr *net.UDPAddr, callback func()) &lt;-chan error &#123; req := &amp;ping&#123; Version: 4, From: t.ourEndpoint(), To: makeEndpoint(toaddr, 0), Expiration: uint64(time.Now().Add(expiration).Unix()), &#125; packet, hash, err := encodePacket(t.priv, pingPacket, req) if err != nil &#123; errc := make(chan error, 1) errc &lt;- err return errc &#125; errc := t.pending(toid, toaddr.IP, pongPacket, func(p interface&#123;&#125;) (matched bool, requestDone bool) &#123; matched = bytes.Equal(p.(*pong).ReplyTok, hash) if matched &amp;&amp; callback != nil &#123; callback() &#125; return matched, matched &#125;) t.localNode.UDPContact(toaddr) t.write(toaddr, toid, req.name(), packet) return errc&#125; 主要执行的地方在sendPing，首先构造一个ping对象，这里面指明了发送方和接收方，超时时间为20s。接收方和发送方都是以rpcEndpoint表示的，内含IP地址，udp和tcp端口。紧接着调用encodePacket打包数据。12345678910111213141516171819func encodePacket(priv *ecdsa.PrivateKey, ptype byte, req interface&#123;&#125;) (packet, hash []byte, err error) &#123; b := new(bytes.Buffer) b.Write(headSpace) b.WriteByte(ptype) if err := rlp.Encode(b, req); err != nil &#123; log.Error("Can't encode discv4 packet", "err", err) return nil, nil, err &#125; packet = b.Bytes() sig, err := crypto.Sign(crypto.Keccak256(packet[headSize:]), priv) if err != nil &#123; log.Error("Can't sign discv4 packet", "err", err) return nil, nil, err &#125; copy(packet[macSize:], sig) hash = crypto.Keccak256(packet[macSize:]) copy(packet, hash) return packet, hash, nil&#125; 数据包中首先有一个长度为97的空字节数组，然后写入包的类型即pingPacket，最后再将刚才的ping对象编码为rlp格式写入。然后对数据进行签名，签名前先对除开头空字节部分以外的数据进行摘要。然后将签名结果写入开头预留的地方，然后在对签名数据和数据进行摘要，填充到开头，这样就完成了对数据打包，这也是常见的消息认证的步骤。回到sendPing中，有了要发送的数据，接下来调用pending12345678910111213func (t *udp) pending(id enode.ID, ip net.IP, ptype byte, callback replyMatchFunc) &lt;-chan error &#123; ch := make(chan error, 1) p := &amp;replyMatcher&#123;from: id, ip: ip, ptype: ptype, callback: callback, errc: ch&#125; select &#123; case t.addReplyMatcher &lt;- p: // loop will handle it case &lt;-t.closing: ch &lt;- errClosed &#125; return ch&#125;type replyMatchFunc func(interface&#123;&#125;) (matched bool, requestDone bool) pending主要是添加一个响应的匹配者用于匹配响应，匹配主要是通过对hash进行对比，这里的hash是前面数据包中的签名数据和数据摘要后的结果。最后发送数据。其实到这里还没有结束，sendPing返回一个channel对象err，而在ping中一直阻塞，知道可以从err中取值。err是由pending返回的，在pending中被replyMatcher持有并赋值给addReplyMatcher，这是触发loop方法（在newUDP中启动的一个goroutine）中的select结构中的一个条件123case p := &lt;-t.addReplyMatcher: p.deadline = time.Now().Add(respTimeout) plist.PushBack(p) 这里将pending中构造的replyMatcher存到plist中。 findnode在table中的lookup中使用了findnode功能，为的是进行节点查找，而实际执行的地方在udp的findnode中123456789101112131415161718192021222324252627func (t *udp) findnode(toid enode.ID, toaddr *net.UDPAddr, target encPubkey) ([]*node, error) &#123; if time.Since(t.db.LastPingReceived(toid, toaddr.IP)) &gt; bondExpiration &#123; t.ping(toid, toaddr) time.Sleep(respTimeout) &#125; nodes := make([]*node, 0, bucketSize) nreceived := 0 errc := t.pending(toid, toaddr.IP, neighborsPacket, func(r interface&#123;&#125;) (matched bool, requestDone bool) &#123; reply := r.(*neighbors) for _, rn := range reply.Nodes &#123; nreceived++ n, err := t.nodeFromRPC(toaddr, rn) if err != nil &#123; log.Trace("Invalid neighbor node received", "ip", rn.IP, "addr", toaddr, "err", err) continue &#125; nodes = append(nodes, n) &#125; return true, nreceived &gt;= bucketSize &#125;) t.send(toaddr, toid, findnodePacket, &amp;findnode&#123; Target: target, Expiration: uint64(time.Now().Add(expiration).Unix()), &#125;) return nodes, &lt;-errc&#125; 首先对于那些超过24小时没有ping过的节点先ping一次看是否存活。之后也是利用pending添加了一个响应的匹配。最后调用send发送数据，和ping一样，也是先进行打包，在发送数据。 响应对于响应，这里要看在新建udp时启动的第二个goroutine–readLoop。在readLoop中先分析了udp包的长度和发送者，然后处理这个包12345678910111213141516func (t *udp) handlePacket(from *net.UDPAddr, buf []byte) error &#123; packet, fromKey, hash, err := decodePacket(buf) if err != nil &#123; log.Debug("Bad discv4 packet", "addr", from, "err", err) return err &#125; fromID := fromKey.id() if err == nil &#123; err = packet.preverify(t, from, fromID, fromKey) &#125; log.Trace("&lt;&lt; "+packet.name(), "id", fromID, "addr", from, "err", err) if err == nil &#123; packet.handle(t, from, fromID, hash) &#125; return err&#125; 第一步先解包12345678910111213141516171819202122232425262728293031func decodePacket(buf []byte) (packet, encPubkey, []byte, error) &#123; if len(buf) &lt; headSize+1 &#123; return nil, encPubkey&#123;&#125;, nil, errPacketTooSmall &#125; hash, sig, sigdata := buf[:macSize], buf[macSize:headSize], buf[headSize:] shouldhash := crypto.Keccak256(buf[macSize:]) if !bytes.Equal(hash, shouldhash) &#123; return nil, encPubkey&#123;&#125;, nil, errBadHash &#125; fromKey, err := recoverNodeKey(crypto.Keccak256(buf[headSize:]), sig) if err != nil &#123; return nil, fromKey, hash, err &#125; var req packet switch ptype := sigdata[0]; ptype &#123; case pingPacket: req = new(ping) case pongPacket: req = new(pong) case findnodePacket: req = new(findnode) case neighborsPacket: req = new(neighbors) default: return nil, fromKey, hash, fmt.Errorf("unknown type: %d", ptype) &#125; s := rlp.NewStream(bytes.NewReader(sigdata[1:]), 0) err = s.Decode(req) return req, fromKey, hash, err&#125; 解包就是打包的逆过程。我们先回顾一下打包的内容：Hash(签名加数据)，签名(对数据摘要后签名)，数据(类型，请求体)。再看解包过程，先判断长度是否争取，然后分理出hash，签名和数据。然后验证hash是否正确。再根据签名以及被签名的内容计算出公钥。之后根据类型（数据部分的第一个字节）构造出请求对象。然后解码原始数据。通过解包我们得到了请求数据，发送节点公钥，以及hash值。之后回到handlePacket中，先计算发送者ID（就是对公钥的摘要），接着根据不同的请求执行不同的逻辑。 ping的接受与响应以ping为例，执行ping的preverify和handle方法1234567891011func (req *ping) preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error &#123; if expired(req.Expiration) &#123; return errExpired &#125; key, err := decodePubkey(fromKey) if err != nil &#123; return errors.New("invalid public key") &#125; req.senderKey = key return nil&#125; preverify主要是判断是否超时然后解码出公钥。主要处理逻辑在handle中12345678910111213141516171819func (req *ping) handle(t *udp, from *net.UDPAddr, fromID enode.ID, mac []byte) &#123; t.send(from, fromID, pongPacket, &amp;pong&#123; To: makeEndpoint(from, req.From.TCP), ReplyTok: mac, Expiration: uint64(time.Now().Add(expiration).Unix()), &#125;) n := wrapNode(enode.NewV4(req.senderKey, from.IP, int(req.From.TCP), from.Port)) if time.Since(t.db.LastPongReceived(n.ID(), from.IP)) &gt; bondExpiration &#123; t.sendPing(fromID, from, func() &#123; t.tab.addVerifiedNode(n) &#125;) &#125; else &#123; t.tab.addVerifiedNode(n) &#125; t.db.UpdateLastPingReceived(n.ID(), from.IP, time.Now()) t.localNode.UDPEndpointStatement(from, &amp;net.UDPAddr&#123;IP: req.To.IP, Port: int(req.To.UDP)&#125;)&#125; 直接是调用send发送数据，由于是相应ping，所以这里类型为pongPacket，相应体也是一个pong对象，同用叶经理了打包和发送的过程。发送完之后还有一些事情要处理。首先判断这个节点上一次pong相应是否超过24小时，若是超过则进行ping，否则更新节点，随后也要更新数据库。 pong的接收到这一步我们梳理了节点A发送ping到节点B，B返回一个pong相应到节点A，我们再看节点A收到pong相应的动作。直接看pong的preverify和handle。1234567891011121314151617181920func (req *pong) preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error &#123; if expired(req.Expiration) &#123; return errExpired &#125; if !t.handleReply(fromID, from.IP, pongPacket, req) &#123; return errUnsolicitedReply &#125; return nil&#125;func (t *udp) handleReply(from enode.ID, fromIP net.IP, ptype byte, req packet) bool &#123; matched := make(chan bool, 1) select &#123; case t.gotreply &lt;- reply&#123;from, fromIP, ptype, req, matched&#125;: // loop will handle it return &lt;-matched case &lt;-t.closing: return false &#125;&#125; preverify第一步也是验证是否超时，接着调用handleReply分发相应。首先是t.gotreply获得赋值，触发loop中的select逻辑，123456789101112131415case r := &lt;-t.gotreply: var matched bool // whether any replyMatcher considered the reply acceptable. for el := plist.Front(); el != nil; el = el.Next() &#123; p := el.Value.(*replyMatcher) if p.from == r.from &amp;&amp; p.ptype == r.ptype &amp;&amp; p.ip.Equal(r.ip) &#123; ok, requestDone := p.callback(r.data) matched = matched || ok if requestDone &#123; p.errc &lt;- nil plist.Remove(el) &#125; contTimeouts = 0 &#125; &#125; r.matched &lt;- matched 这里首先遍历plist，plist存储着我们发送请求时的响应匹配者，也就是回调。我们通过发送者，请求类型和ip三个条件判断是否匹配。如果匹配上的话执行callback方法，对于ping的callback并没有实质的内容，只是通过比较两个hash值是否相等来判断是否匹配。两个hash值分别是发送ping请求时对签名和数据的摘要以及pong响应的ReplyTok，而ReplyTok来自于对请求包解包后得到hash，实际上也就是请求所携带的hash，只不过在响应是写到了pong的ReplyTok字段中。只有二者相等，才能证明是从正确节点得到了响应。接下来如果请求结束，则给p.errc赋值为nil并移除这个回调，对于p.err这个channel，他在发送请求后一直阻塞，知道这里阻塞得到解除，ping流程结束。回到loop的select中，接着给matched赋值，这时handleReply的阻塞得到解决，preverify方法调用结束，接着调用handle方法，这里主要就是更新节点信息。刚才是成功响应时的流程，对于超时的情况，在loop的select有一个timeout触发的case，他会检测plist中各个回调是否超时，对于超时的给p.errc赋值超时错误，然后移除该回调。同时统计超时次数，对于超时次数过多的话检查时间是否准确。这个我们稍后再讲。 findnode的接收与响应我们再梳理一下findnode的接收与响应。前面的逻辑都是一样的，直接从handlePacket中开始，实际上是看preverify和handle。123456789func (req *findnode) preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error &#123; if expired(req.Expiration) &#123; return errExpired &#125; if time.Since(t.db.LastPongReceived(fromID, from.IP)) &gt; bondExpiration &#123; return errUnknownNode &#125; return nil&#125; 首先判断是否超时，再看这个节点是否过长时间没有响应。主要看handle12345678910111213141516171819202122func (req *findnode) handle(t *udp, from *net.UDPAddr, fromID enode.ID, mac []byte) &#123; target := enode.ID(crypto.Keccak256Hash(req.Target[:])) t.tab.mutex.Lock() closest := t.tab.closest(target, bucketSize).entries t.tab.mutex.Unlock() p := neighbors&#123;Expiration: uint64(time.Now().Add(expiration).Unix())&#125; var sent bool for _, n := range closest &#123; if netutil.CheckRelayIP(from.IP, n.IP()) == nil &#123; p.Nodes = append(p.Nodes, nodeToRPC(n)) &#125; if len(p.Nodes) == maxNeighbors &#123; t.send(from, fromID, neighborsPacket, &amp;p) p.Nodes = p.Nodes[:0] sent = true &#125; &#125; if len(p.Nodes) &gt; 0 || !sent &#123; t.send(from, fromID, neighborsPacket, &amp;p) &#125;&#125; 首先得到目标的ID，然后调用table的closest得出距目标较近的一组节点，然后构造响应体，主要有超时时间和要返回的节点，最后通过send方法发送响应。到这里我们梳理了节点A发送findnode请求到B，B找到一组节点发回A，再看A接到neighborsPacket响应时的动作，主要还是看preverify和handle。123456789func (req *neighbors) preverify(t *udp, from *net.UDPAddr, fromID enode.ID, fromKey encPubkey) error &#123; if expired(req.Expiration) &#123; return errExpired &#125; if !t.handleReply(fromID, from.IP, neighborsPacket, req) &#123; return errUnsolicitedReply &#125; return nil&#125; 先检查超时，在调用handleReply，还是回到loop中执行之前findnode时预留的回调。回调如下：12345678910111213func(r interface&#123;&#125;) (matched bool, requestDone bool) &#123; reply := r.(*neighbors) for _, rn := range reply.Nodes &#123; nreceived++ n, err := t.nodeFromRPC(toaddr, rn) if err != nil &#123; log.Trace("Invalid neighbor node received", "ip", rn.IP, "addr", toaddr, "err", err) continue &#125; nodes = append(nodes, n) &#125; return true, nreceived &gt;= bucketSize &#125; 在这里将接受到的节点存储到nodes中，在findnode最后errc阻塞得到接触，findnode顺利返回nodes供table使用。 ndoe.go这是discover包内的节点类，它包装了enode，同时又附加了节点添加时间和活性检查时间两个成员12345type node struct &#123; enode.Node addedAt time.Time livenessChecks uint &#125; 这个类提供了一组对公钥操作的方法：encodePubkey是将公钥记为64字节类型，decodePubkey则是从字节数组还原公钥，recoverNodeKey从签名数据和原始数据中还原出公钥。还规定了节点的ID就是对公钥的字节数组形式摘要的结果。最后提供了一组包装与解包装enode的方法. ntp.go这是一个时间校准的工具类，在udp中如果多次超时的话就要考虑是否是本地时间出错。调用了checkClockDrift方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758func checkClockDrift() &#123; drift, err := sntpDrift(ntpChecks) if err != nil &#123; return &#125; if drift &lt; -driftThreshold || drift &gt; driftThreshold &#123; log.Warn(fmt.Sprintf("System clock seems off by %v, which can prevent network connectivity", drift)) log.Warn("Please enable network time synchronisation in system settings.") &#125; else &#123; log.Debug("NTP sanity check done", "drift", drift) &#125;&#125;func sntpDrift(measurements int) (time.Duration, error) &#123; addr, err := net.ResolveUDPAddr("udp", ntpPool+":123") if err != nil &#123; return 0, err &#125; request := make([]byte, 48) request[0] = 3&lt;&lt;3 | 3 drifts := []time.Duration&#123;&#125; for i := 0; i &lt; measurements+2; i++ &#123; conn, err := net.DialUDP("udp", nil, addr) if err != nil &#123; return 0, err &#125; defer conn.Close() sent := time.Now() if _, err = conn.Write(request); err != nil &#123; return 0, err &#125; conn.SetDeadline(time.Now().Add(5 * time.Second)) reply := make([]byte, 48) if _, err = conn.Read(reply); err != nil &#123; return 0, err &#125; elapsed := time.Since(sent) sec := uint64(reply[43]) | uint64(reply[42])&lt;&lt;8 | uint64(reply[41])&lt;&lt;16 | uint64(reply[40])&lt;&lt;24 frac := uint64(reply[47]) | uint64(reply[46])&lt;&lt;8 | uint64(reply[45])&lt;&lt;16 | uint64(reply[44])&lt;&lt;24 nanosec := sec*1e9 + (frac*1e9)&gt;&gt;32 t := time.Date(1900, 1, 1, 0, 0, 0, 0, time.UTC).Add(time.Duration(nanosec)).Local() drifts = append(drifts, sent.Sub(t)+elapsed/2) &#125; sort.Sort(durationSlice(drifts)) drift := time.Duration(0) for i := 1; i &lt; len(drifts)-1; i++ &#123; drift += drifts[i] &#125; return drift / time.Duration(measurements), nil&#125; 首先可以看出来是以udp方法通信的，目标地址是pool.ntp.org:123。首先构造了请求体，就是一个长度为48的字节数组，第一个字节是00011011（从左到右第3-5位表示协议版本号，也就是3，第6-8位表示操作模式，客户端为3）。接下来启动一个循环，一共5次。每次都通过udp与目标地址通信。读取到的响应长度也是48字节。分两部分，最后4字节表示秒的小数部分，再向前数4个字节表示秒。之后我们计算出服务给我们的时间的纳秒表示，之后计算出我们与服务器的时间差。详细的SNTP协议见官方文档 题图来自unsplash：https://unsplash.com/photos/-CZERTBlepA]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSL协议学习]]></title>
    <url>%2F2019%2F04%2F15%2FSSL%2F</url>
    <content type="text"><![CDATA[简介SSL全称Secure Sockets Layer，即安全套接层。简而言之，它是一项标准技术，可确保互联网连接安全，保护两个系统之间发送的任何敏感数据，防止网络犯罪分子读取和修改任何传输信息，包括个人资料。两个系统可能是指服务器和客户端或两个服务器之间。 SSL与TSLSSL最初由Netscape公司在1994年推出，此后，成为最为著名的Web安全机制，所有主要web浏览器都支持SSL。1996年发布的3.0版本是使用最广的版本（官方文档），但是2014年10月，Google发布在SSL 3.0中发现设计缺陷，建议禁用此一协议。Google在自己公司相关产品中陆续禁止回溯兼容，强制使用TLS协议。Mozilla也在11月25日发布的Firefox 34中彻底禁用了SSL 3.0。 TLS全称Transport Layer Security，即传输层安全性协议。是更为安全的升级版 SSL。TSL1.0（官方文档）是IETF将SSL标准化的结果，从技术上讲，TLS 1.0与SSL 3.0的差异非常微小。TLS随后又发布了1.1、1.2与1.3版本。其中1.3版本2018年才发布，支持的浏览器较少。所有TLS版本在2011年3月发布的RFC 6176中删除了对SSL的兼容，这样TLS会话将永远无法协商使用的SSL 2.0以避免安全问题。本文主要讲述SSL3.0内容 工作原理SSL可以看做TCP/IP协议中的一层，位于应用层和传输层之间，属于一种附加层，没有改层也可以正常通信，但是缺少安全性。 SSL有3个子协议：握手协议、记录协议和警报协议 握手协议这是客户端与服务端进行SSL通信时的第一个子协议，该协议会在客户端与服务端传输一系列信息，信息有如下三个字段： Type：类型字段，一共有10种类型，占1字节 Length：表示消息长度，占3字节 Content：消息参数，长度不固定 对于握手协议，一般分4个阶段 建立安全能力握手的第一阶段包含两个消息：“client hello”和“server hello”。 首先客户端向服务器发送“client hello”消息，包含以下字段： Version：客户端支持的最高SSL协议版本 Random：随机数，包含两个字段：32位日期时间和28位随机数 Session ID：会话号，若为非0值，表示连接已建立，但是客户端要更新参数；为0表示要建立新连接 Cipher suite：客户端支持的加密算法清单 Compression method：客户端支持的压缩算法 可见“client hello”是将客户端的一些情况发送给服务端，以便连接的建立 服务端收到客户端消息后，返回“server hello”消息，字段和“client hello”相同，但用途不同： Version：表示客户端和服务端共同支持的最高SSL版本的最低版本，如一方支持3.0一方支持3.1，则选择3.0版本 Random：同样包含32位日期时间和28位随机数 Session ID：若客户端发送的位非0值，则使用客户端发送的值，否则服务端生成一个新的ID Cipher suite：服务器选择的加密算法 Compression method：服务器选择的压缩算法 到此客户端与服务端在一些基本问题上达成共识，在这些共识的基础上进行后续步骤 服务器认证与秘钥交换握手的第二阶段，该阶段只有服务器发送消息，客户端只接受消息。一般有以下几步： 服务端将自己的数字证书和到根CA的证书链发送给客户端，供客户端进行认证 在第一步没有发送证书时，这一步才会发送服务器的公钥到客户端（数字证书中包含公钥，所以有数字证书就不用这一步） 服务器请求客户端证书，这一步是可选的，不要求全部链接都进行客户端认证 该阶段结束，发送“ServerHelloDone”信息，不包含任何参数，等待客户端响应。 客户端认证与秘钥交换握手的第三阶段，该阶段只有客户端发送消息，服务器只接受消息。一般有以下几步： 这一步是可选的，只有在服务端请求客户端证书时，客户端才发送自己的证书。对于服务器要求但客户端没有证书的情况，客户端发送“No certificate”消息，后续由服务端决定通信是否继续 秘钥交换，客户端生成48字节的预备秘密，用服务器公钥加密发送给服务器 证书验证，也只在服务器请求客户端证书时才执行。这一步客户端要证明自己是证书的所有者，一般将前面握手第一阶段中发送的随机数进行摘要并用自己私钥加密发送给服务端 完成阶段这一阶段由客户端启动。一共有四个消息，首先客户端发送改变加密规范消息和完成消息，服务端也随后也发送这两个消息。 这阶段需要一个主秘密，它是由前一步中的预备秘密和第一阶段中客户端与服务端的随机数进行拼接后进行摘要后生产的。主秘密产生后再和第一阶段中客户端与服务端的随机数进行拼接然后再次进行摘要得到会话的对称秘钥。 根据之前的握手信息，如果客户端和服务端都能对Finish信息进行正常加解密且消息正确的被验证，则说明握手通道已经建立成功，接下来，双方可以使用上面产生的Session Secret对数据进行加密传输了。 记录协议完成握手后，进入SSL记录协议，一般提供两个服务：保密性和完整性 SSL记录协议以要传输的信息位输入，首先进行分块，对每块可选的进行压缩，然后增加MAC信息，之后进行加密，在添加头信息，之后交由TCP协议的下一层处理，具体步骤如下： 分块：每块16KB 压缩：可选，但必须是无损压缩 加MAC：对前一步的输出计算MAC（消息认证码），类似于HMAC，秘钥使用的即使握手阶段协商的秘钥。 加密：用握手阶段协商的秘钥对上一步输出进行加密 添加头部：包含以下几个字段：内容类型（8位）：指上一层处理记录所用的协议；主版本（8位）：如SSL3.1，主版本位3；次版本（8位）：如SSL3.1，次版本是1；压缩长度（16位）：指原始信息或压缩过的信息的长度 可见记录协议就是实际通信所用的协议 警报协议通信双方任何一方发现错误时，向对方发送警报信息。若错误是致命的则立即关闭连接，终止传输，同时删除回话号、秘密和秘钥。如果错误不严重，则处理错误并继续通信。 每个警报消息有两字节，第一个字节指出错误类型，1代表一般错误，2代表致命错误；第二个字节指出详细错误 致命错误如下： 警报 描述 无关消息(unexpected_message) 收到不适当消息 坏记录(bad_record_mac) 收到的消息没有正确的MAC 解压失败(decompression_failure) 解压缩功能收到错误输入 握手失败(handshake_failure) 发送方无法从收到的选项中得到可接受的参数 非法参数(illegal_parameter) 握手消息中字段越界或其他字段不一致 非致命错误： 警报 描述 无证书(no_certificate) 没有适当证书 坏证书(bad_certificate) 证书验证失败 不支持的证书(unsupported_certificate) 不支持的证书类型 证书吊销(certificate_revoked) 证书已被吊销 证书过期(certificate_expired) 证书已过期 证书未知(certificate_unknown) 处理证书时出现未知错误 关闭通知(close_notify) 表示发送方在本次连接中不再发送任何信息，双方都要发送这个消息后才关闭连接 关闭与恢复连接对于关闭连接双方都要发送close_notify消息，这样才能优雅的借书连接。若有一方没有发送该信息，则连接无法恢复 从整个流程看，握手协议比较复杂与费时，所以复用或恢复连接是一个较好的选择，算法可以协商复用，若一方不同意则不能复用，另外，对于任何连接，在24小时后不得复用 题图来自unsplash：https://unsplash.com/photos/UZ3V6AV5y4o]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字证书]]></title>
    <url>%2F2019%2F04%2F15%2F%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[背景数字证书又称公开密钥证书、公钥证书等。是用于公开密钥基础建设的电子文件，用来证明公开密钥拥有者的身份。此文件包含了公钥信息、拥有者身份信息（主体）、以及数字证书认证机构（发行者）对这份文件的数字签名，以保证这个文件的整体内容正确无误。拥有者凭着此文件，可向计算机系统或其他用户表明身份。如果你信任签发的机构，就可以信任证书上的密钥，凭公钥加密与拥有者进行可靠的通信。 数字证书技术细节X.509 是密码学里公钥证书的格式标准。X.509 证书己应用在包括TLS/SSL在内的众多 Intenet协议里.同时它也用在很多非在线应用场景里。X.509最早与X.500一起发布于1988年7月3日。后来又做了两次修订，最新标准是X.509v3。 证书结构一般有以下几部分组成： 版本号 序列号 签名算法 颁发者 有效期（在有效期前后都是无效的） 主体名（即证书所指的用户或组织） 主体公钥信息（公钥算法，主题公钥） 颁发者唯一身份信息（可选） 主体唯一身份信息（可选） 扩展信息（可选） 证书签名算法 数字签名 证书的生成与使用证书生成 申请者生成一对足够强的秘钥，并对私钥进行保密 申请者将公钥连同其他信息组成证书请求发送给注册机构 注册机构验证申请者是公钥的持有人，验证方法有很多，如要求申请人用私钥对请求进行数字签名，注册机构用公钥验证。 验证成功后，注册机构将申请人的公钥、主体信息及有效期等一些信息组成证书基本数据 注册机构用自己的私钥对证书进行签名 将签名好的证书颁发给申请人 证书使用 证书所有者将自己的证书对外公开 第三方用注册机构的公钥验证证书签名，确保证书是可信的机构颁发的 验证成功后可以利用公钥对消息进行加密然后与证书所有者进行通信 证书的验证证书层次证书机构(CA)在实际中是分层的，假设A和B分属不同的子CA，如A属于CA20，B属于CA242，二者互相不知道对方CA的公钥。所以要获得这两个CA的证书，他们的证书由其上一级CA签名，一直到根CA。对于根CA的证书一般都固定到软件中，有了根CA的公钥就可以层层验证下面子CA的证书，这样就可以确保子CA的可信。 交叉证书若A与B位于不同国家，可能各个国家有自己的根CA，而国家自己没有再高一级的CA。这是就无法确保获得的对应根CA的有效性。这是可以进行交叉证书。如A属于中国，B属于美国。这是中国的根CA获得一个由美国根CA颁发的证书，同样美国的根CA也获得一个由中国跟CA颁发的证书。这样，A本来就拥有中国根CA的证书，用其公钥验证美国的根CA是否值得信任，然后获得美国根CA的证书与公钥，与处在美国的B进行可信通信。 证书的吊销脱机证书吊销状态检查需要一个证书吊销表（CRL），这个表不包括过期的证书，只包含因故吊销的证书。这个表按照固定时间更新，用户定期下载这个表。之所以成为脱机，是因为在更新间隔内，用户只用检查本地的表即可。当用户收到一个证书后进行如下检查 有效期检查 有效性检查，即CA的签名是否正确 查询CRL检查是否被吊销 联机证书状态协议主要是CA提供一个服务器，可以实时查询证书状态，验证证书是否吊销 题图来自unsplash：https://unsplash.com/photos/9NUeLk0uqME]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HMAC算法]]></title>
    <url>%2F2019%2F04%2F05%2FHMAC%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景首先说一下什么是MAC，MAC全称Message authentication code，即消息认证码。是经过特定算法后产生的一小段信息，检查某段消息的完整性，以及作身份验证。 在网络传输中，由于一般的传输通道是透明的，所以对消息进行认证是十分必要的，认证消息是否被修改，无论是恶意攻击或意外改变。一般的操作是对消息产生认证码，然后连同消息和认证码一起发送，接收方用同样的方法计算认证码，看两个认证码是否一致。 HMAC全称Hash-based message authentication code，即散列消息认证码(官方文档)是一个比较完善的消息认证码机制。是一种通过特别计算方式之后产生的消息认证码（MAC），使用密码散列函数，同时结合一个加密密钥。它可以用来保证数据的完整性，同时可以用来作某个消息的身份验证。 详细流程调整秘钥长度秘钥是收发双发都知晓的一个对称加密的秘钥。算法第一步要调整秘钥长度，使其和消息块长度匹配。分一下三种情况 k&lt;b：秘钥长度小于消息块长，这是需要在秘钥左边填充一定的0，使其等于消息块长 k=b：不做任何处理 k&gt;b：对秘钥进行信息摘要，使其等于消息块长，摘要算法和HMAC中用到的散列算法一样 生成S1将K与ipad进行异或运算生成S1，ipad = (00110110) 重复 b/8次，也就是说ipad长度和消息块长相等 填充将消息M拼接到S1后面 消息摘要对上一步拼接后的信息进行摘要得到H 生成S2将K与opad进行异或运算生成S2，opad = (01011010) 重复 b/8次，也就是说opad长度和消息块长相等 填充将前面摘要得到的H拼接到S2后面 消息摘要对上一步拼接后的信息进行摘要得到HMAC。 整体流程还是很简单的，整体流程如下： 算法分析HMAC主要解决的发送方的认证和消息完整性认证。首先中间涉及的秘钥只有收发双发知道，所以攻击者即使篡改消息也无法生成相应的HMAC，同样且只有持有正确秘钥的发送方才能正确生成HMAC。其次，由于摘要算法，只要消息不完整，验证也不会通过。最后，由于摘要算法是单向函数，所以无法从消息和HMAC推测秘钥。 但是HMAC也存在下面几个问题： 秘钥交换问题是一个普遍存在的问题，对于中间人攻击，HMAC也无能为力 HMAC不适用与多个接收方情况，由于是对称加密，接收方并不能认证消息来自某个发送方，任何一个接收方都可以伪造消息 若是不同收发方使用不同的秘钥，则秘钥管理也比较困难 接收方也可能伪造消息，对于一个HMAC并不能判断具体是哪一方发出的。 题图来自unsplash：https://unsplash.com/photos/Anosw0HcGRk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SHA-2算法]]></title>
    <url>%2F2019%2F04%2F03%2FSHA-2%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景前面介绍了SHA-1的详细内容。因为SHA-1已经被认为是不安全的，所以又开发了SHA-2。SHA-2可分为6种不同标准：SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。其后数字表示摘要长度。 SHA-256和SHA-512是很新的散列函数，前者以定义一个word为32位，后者则定义一个word为64位。它们分别使用了不同的偏移量，或用不同的常量，然而，实际上二者结构是相同的，只在循环运行的次数上有所差异。SHA-224以及SHA-384则是前述二种散列函数的截短版，利用不同的初始值做计算。我们这里介绍SHA-512的内容，其余标准见标准文档 详细流程SHA-512的最大数据长度为2^128 - 1。它的摘要长度为512位，分块长度为1024位。SHA-512是按照SHA-1的模型而来的，而SHA-1又是仿照MD5而来的，所以他们之间有很多相似之处，对于相似地方我们只简要说明一下 填充填充为1024的倍数少128位，通用填充总是要进行的，即使已满足条件 添加长度将原始信息长度写成128位形式填充到最后 分块按1024一组进行分块 初始化链接变量一共有8个初始化变量，实际上多少个初始化变量是由最后摘要长度决定的。如MD5为128位，就是4个，SHA-1位160位，就是5个。而SHA-512是512位，就是8个，但每个是64位：12345678A = 6a09e667f3bcc908B = bb67ae8584caa73bC = 3c6ef372fe94f82bD = a54ff53a5f1d36f1E = 510e527fade682d1F = 9b05688c2b3e6c1fG = 1f83d9abfb41bd6bH = 5be0cd19137e2179 轮次操作 将初始化变量复制到abcdefgh中 将当前子块每64位一组，分16组 一共有80轮，每轮以当前块，abcdefgh和常量K[t]，常量总共有80个，这些常数的取值是前80个质数的立方根的小数部分的前64位。每轮操作如下：12345678910temp1 = h + ch(e,f,g) + sum1(e)+wt+kttemp2 = sum0(a) + maj(a,b,c)a = temp1 + temp2b = ac = bd = ce = d + temp1f = eg = fh = g 上面运算中t为轮次号，加法均是加完之后取2^64模，几个函数如下定义：1234ch(e,f,g) = (e and f) xor (not e and g)maj(a,b,c) = (a and b) xor (a and c) xor (b and c)sum1(e) = e&gt;&gt;14 xor e&gt;&gt;18 xor e&gt;&gt;41sum0(a) = a&gt;&gt;28 xor a&gt;&gt;34 xor a&gt;&gt;39 对于每轮中的w，前16轮就是分好的16组子块，后面的w如下计算1234wt = a1(w(t-2)) + w(t-7) + a0(w(t-15)) + w(t-16)a1(x) = x&gt;&gt;1 xor x&gt;&gt;8 xor x&gt;3a0(x) = x&gt;&gt;17 xor x&gt;&gt;19 xor x&gt;10 上面&gt;&gt;表示循环右移，&gt;表示右移，空出的补零 80轮之后计算出的abcdefgh分别加上原来的ABCDEFGH作为处理下一个块的输入 和MD5与SHA-1一样，处理完所有块之后，最后的ABCDEFGH拼接到一起就是摘要信息。 题图来自unsplash：https://unsplash.com/photos/OIYrmG5FNFg]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SHA-1算法]]></title>
    <url>%2F2019%2F04%2F02%2FSHA-1%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景SHA全称Secure Hash Algorithm，即安全散列算法。它是一个算法簇，包含多种算法。是FIPS所认证的安全散列算法。能计算出一个数字消息所对应到的，长度固定的字符串（又称消息摘要）的算法。且若输入的消息不同，它们对应到不同字符串的机率很高。 SHA-1于1995年发布，应用相当广泛，被认为是MD5的替代者，但是随着技术的进步SHA-1已经被认为是不安全的，特别是2017年荷兰密码学研究小组CWI和Google正式宣布攻破了SHA-1 SHA-2在2001年发布，包括SHA-224、SHA-256、SHA-384、SHA-512、SHA-512/224、SHA-512/256。虽然至今尚未出现对SHA-2有效的攻击，它的算法跟SHA-1基本上仍然相似，所以理论上也有漏洞 SHA-3在2015年正式发布，SHA-3并不是要取代SHA-2，因为SHA-2当前并没有出现明显的弱点。由于对MD5出现成功的破解，以及对SHA-0和SHA-1出现理论上破解的方法，NIST感觉需要一个与之前算法不同的，可替换的加密散列算法，也就是现在的SHA-3。 SHA家族几种算法比较如下： 这里我们先来梳理SHA-1的详细过程 详细流程SHA-1和MD5设计非常类似，标准文档链接，基本步骤如下 填充和MD5一样，填充总是增加的，也就是512的倍数少64 添加长度将原始长度的64位表示添加到末尾 分块每512位一块 初始化链接变量总共有5个，其中ABCD和MD5一样，D的值位C3D2E1F0。五个值如下12345A=67452301B=efcdab89C=98badcfeD=10325476E=c3d2e1f0 处理块 将A~E赋值到a~e 将每块分为16个子块，每个子块32位 SHA共4轮，每轮20步，输入为子块，abcde，常量。整体算法和MD5类似。与MD5不同，这里的常量仅有四个值，每轮用一个，分别是：5a827999,6ed9eba1,8f1bbcdc，ca62c1d6。 每一步的逻辑如下图所示 具体来说，一次操作的数学表达式如下：1abcde=(e + P + a&lt;&lt;5 + W[] + K[]),a,b&lt;&lt;30,c,d P依然还是一个非线性操作，&lt;&lt;表示循环左移，W[]表示计算某一子块，K[]表示该轮的常量 w是将16个子块扩展为80个，前16个就是原16个子块，后面的按照下面公式计算1w[t] = (w[t-16] xor w[t-14] xor w[t-8] xor w[t-3])&lt;&lt;1 P的具体运算如下轮次 | P—|—1 | (b AND c) OR ((NOT b) AND d)2 | b xor c xor d3 | (b AND c) or (b AND d) OR (c AND d)4 | b xor c xor d 就这样对每一块执行80次后，输出的abcde就是160位的散列值。相比于MD5无规则的运算，SHA-1基本可以用公式表示整个算法 题图来自unsplash：https://unsplash.com/photos/I2UR7wEftf4]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MD5算法与实现]]></title>
    <url>%2F2019%2F04%2F02%2FMD5%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景MD5全称Message-Digest Algorithm，就是信息摘要算法。是一种被广泛使用的密码散列函数，可以产生出一个128位的散列值，它是由美国密码学家Ron Rivest开发的，于1992年公开。最开始算法是MD，很快出现MD2，不过算法很脆弱，又改为研究MD3，不过最终研发失败。接下来又出现MD4，但仍不理想，最后研发出MD5，成为一个全世界广泛使用的算法。 如今，MD5被证实存在一系列弱点，可以被加以破解，同时也无法防止碰撞，所以已经不适合安全认证。但是，MD5算法因其普遍、稳定、快速的特点，仍广泛应用于普通数据的错误检查领域。 作为一个经典算法，这里就详细梳理一下整个流程。MD5标准文档见这里 详细步骤填充第一步是在初始消息中填充信息，使其达到一个要求的长度，即比512位的倍数少64位。如原始消息是1000位，512*3=1536,1536-64=1472，所以要填充472位。填充的内容是1个1和多个0 填充总是要进行的，即使消息长度已经比512的倍数少64位，仍要填充512位 添加长度计算源消息的长度，表示成64位填充到末尾。如果消息的长度大于2^64，则使用低64位填充，即len mod 2^64 添加完之后，整体长度为512的倍数 分块将输入以512位一组分块 初始化链接变量初始化4个32位数字，16进制表示如下1234A = 0x67452301B = 0xEFCDAB89C = 0x98BADCFED = 0x10325476 处理块前面都是初始化操作，这里开始才是算法开始 复制将4个初始化变量复制到4个变量abcd中，这四个变量组成一个128位寄存器，用于表示中间结果和最终结果 分解将每块512位分解为16个子块，每个子块32位 轮次迭代主循环有4轮，每轮有16次操作。每次操作对abcd的其中三个做一次非线性运算P，然后将所得结果加上第四个变量、一个子块和一个常数。再将所得结果向左循环移位,最后加上abcd的其中给一个，最后用该结果取代abcd其中之一。如下图所示 表示成数学表达式如下1a = b + ((a + P(b,c,d) + M[i] + t[k])&lt;&lt;&lt;s) P的每一轮操作如下： 轮次 P 1 (b AND c) OR ((NOT b) AND b) 2 (b AND d) OR (c AND (NOT d) 3 b XOR c XOR d 4 C XOR (b OR (NOTd) 轮次操作中常量t[i] = 4294967296*abs(sin(i))的整数部分。下面我们给出每一步详细操作：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081首先定义P的4种运算：F( X ,Y ,Z ) = ( X &amp; Y ) | ( (~X) &amp; Z )G( X ,Y ,Z ) = ( X &amp; Z ) | ( Y &amp; (~Z) )H( X ,Y ,Z ) =X ^ Y ^ ZI( X ,Y ,Z ) =Y ^ ( X | (~Z) )再定义4个函数：FF(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + F(b,c,d) + Mj + ti) &lt;&lt; s)GG(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + G(b,c,d) + Mj + ti) &lt;&lt; s)HH(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + H(b,c,d) + Mj + ti) &lt;&lt; s)II(a ,b ,c ,d ,Mj ,s ,ti ) ： a = b + ( (a + I(b,c,d) + Mj + ti) &lt;&lt; s)这4轮64步分别如下：第一轮：FF(a ,b ,c ,d ,M0 ,7 ,0xd76aa478 )FF(d ,a ,b ,c ,M1 ,12 ,0xe8c7b756 )FF(c ,d ,a ,b ,M2 ,17 ,0x242070db )FF(b ,c ,d ,a ,M3 ,22 ,0xc1bdceee )FF(a ,b ,c ,d ,M4 ,7 ,0xf57c0faf )FF(d ,a ,b ,c ,M5 ,12 ,0x4787c62a )FF(c ,d ,a ,b ,M6 ,17 ,0xa8304613 )FF(b ,c ,d ,a ,M7 ,22 ,0xfd469501)FF(a ,b ,c ,d ,M8 ,7 ,0x698098d8 )FF(d ,a ,b ,c ,M9 ,12 ,0x8b44f7af )FF(c ,d ,a ,b ,M10 ,17 ,0xffff5bb1 )FF(b ,c ,d ,a ,M11 ,22 ,0x895cd7be )FF(a ,b ,c ,d ,M12 ,7 ,0x6b901122 )FF(d ,a ,b ,c ,M13 ,12 ,0xfd987193 )FF(c ,d ,a ,b ,M14 ,17 ,0xa679438e )FF(b ,c ,d ,a ,M15 ,22 ,0x49b40821 )第二轮GG(a ,b ,c ,d ,M1 ,5 ,0xf61e2562 )GG(d ,a ,b ,c ,M6 ,9 ,0xc040b340 )GG(c ,d ,a ,b ,M11 ,14 ,0x265e5a51 )GG(b ,c ,d ,a ,M0 ,20 ,0xe9b6c7aa )GG(a ,b ,c ,d ,M5 ,5 ,0xd62f105d )GG(d ,a ,b ,c ,M10 ,9 ,0x02441453 )GG(c ,d ,a ,b ,M15 ,14 ,0xd8a1e681 )GG(b ,c ,d ,a ,M4 ,20 ,0xe7d3fbc8 )GG(a ,b ,c ,d ,M9 ,5 ,0x21e1cde6 )GG(d ,a ,b ,c ,M14 ,9 ,0xc33707d6 )GG(c ,d ,a ,b ,M3 ,14 ,0xf4d50d87 )GG(b ,c ,d ,a ,M8 ,20 ,0x455a14ed )GG(a ,b ,c ,d ,M13 ,5 ,0xa9e3e905 )GG(d ,a ,b ,c ,M2 ,9 ,0xfcefa3f8 )GG(c ,d ,a ,b ,M7 ,14 ,0x676f02d9 )GG(b ,c ,d ,a ,M12 ,20 ,0x8d2a4c8a )第三轮HH(a ,b ,c ,d ,M5 ,4 ,0xfffa3942 )HH(d ,a ,b ,c ,M8 ,11 ,0x8771f681 )HH(c ,d ,a ,b ,M11 ,16 ,0x6d9d6122 )HH(b ,c ,d ,a ,M14 ,23 ,0xfde5380c )HH(a ,b ,c ,d ,M1 ,4 ,0xa4beea44 )HH(d ,a ,b ,c ,M4 ,11 ,0x4bdecfa9 )HH(c ,d ,a ,b ,M7 ,16 ,0xf6bb4b60 )HH(b ,c ,d ,a ,M10 ,23 ,0xbebfbc70 )HH(a ,b ,c ,d ,M13 ,4 ,0x289b7ec6 )HH(d ,a ,b ,c ,M0 ,11 ,0xeaa127fa )HH(c ,d ,a ,b ,M3 ,16 ,0xd4ef3085 )HH(b ,c ,d ,a ,M6 ,23 ,0x04881d05 )HH(a ,b ,c ,d ,M9 ,4 ,0xd9d4d039 )HH(d ,a ,b ,c ,M12 ,11 ,0xe6db99e5 )HH(c ,d ,a ,b ,M15 ,16 ,0x1fa27cf8 )HH(b ,c ,d ,a ,M2 ,23 ,0xc4ac5665 )第四轮II(a ,b ,c ,d ,M0 ,6 ,0xf4292244 )II(d ,a ,b ,c ,M7 ,10 ,0x432aff97 )II(c ,d ,a ,b ,M14 ,15 ,0xab9423a7 )II(b ,c ,d ,a ,M5 ,21 ,0xfc93a039 )II(a ,b ,c ,d ,M12 ,6 ,0x655b59c3 )II(d ,a ,b ,c ,M3 ,10 ,0x8f0ccc92 )II(c ,d ,a ,b ,M10 ,15 ,0xffeff47d )II(b ,c ,d ,a ,M1 ,21 ,0x85845dd1 )II(a ,b ,c ,d ,M8 ,6 ,0x6fa87e4f )II(d ,a ,b ,c ,M15 ,10 ,0xfe2ce6e0 )II(c ,d ,a ,b ,M6 ,15 ,0xa3014314 )II(b ,c ,d ,a ,M13 ,21 ,0x4e0811a1 )II(a ,b ,c ,d ,M4 ,6 ,0xf7537e82 )II(d ,a ,b ,c ,M11 ,10 ,0xbd3af235 )II(c ,d ,a ,b ,M2 ,15 ,0x2ad7d2bb )II(b ,c ,d ,a ,M9 ,21 ,0xeb86d391 ) 上面是网上大多是文章给出的方法，就是生硬的给出64轮具体操作，但其实每一步都是可以推算的，下面来说一下简单的方法：123456789101112131415161718192021222324252627282930313233343536373839404142首先对于常数，可以通过公式计算，t[i] = 4294967296*abs(sin(i))的整数部分，其中4294967296就是1&lt;&lt;32，即2^32对于这个长度建议是直接写成常量，不然每次都计算也比较耗时：private static final int T[] = &#123; 0xd76aa478, 0xe8c7b756, 0x242070db, 0xc1bdceee, 0xf57c0faf, 0x4787c62a, 0xa8304613, 0xfd469501, 0x698098d8, 0x8b44f7af, 0xffff5bb1, 0x895cd7be, 0x6b901122, 0xfd987193, 0xa679438e, 0x49b40821, 0xf61e2562, 0xc040b340, 0x265e5a51, 0xe9b6c7aa, 0xd62f105d, 0x02441453, 0xd8a1e681, 0xe7d3fbc8, 0x21e1cde6, 0xc33707d6, 0xf4d50d87, 0x455a14ed, 0xa9e3e905, 0xfcefa3f8, 0x676f02d9, 0x8d2a4c8a, 0xfffa3942, 0x8771f681, 0x6d9d6122, 0xfde5380c, 0xa4beea44, 0x4bdecfa9, 0xf6bb4b60, 0xbebfbc70, 0x289b7ec6, 0xeaa127fa, 0xd4ef3085, 0x04881d05, 0xd9d4d039, 0xe6db99e5, 0x1fa27cf8, 0xc4ac5665, 0xf4292244, 0x432aff97, 0xab9423a7, 0xfc93a039, 0x655b59c3, 0x8f0ccc92, 0xffeff47d, 0x85845dd1, 0x6fa87e4f, 0xfe2ce6e0, 0xa3014314, 0x4e0811a1, 0xf7537e82, 0xbd3af235, 0x2ad7d2bb, 0xeb86d391 &#125;; 对于每次取哪一小组明文，是根据轮次定的，定义j是小轮次，0 &lt;= j &lt; 64：第一大轮就是按顺序取1~16小组 i = j第二大轮的计算规则为 i = (1+5*j)%16 即 (j*5+1)&amp;0x0f第三大轮的计算规则为 i = (5+3*j)%16 即 (j*3+5)&amp;0x0F第四大轮的计算规则为 i = (7*j)%16 即 (j*7)&amp;0x0F对于移位，也是根据轮次定的,定义j是小轮次，0 &lt;= j &lt; 64：第一大轮 从[7, 12, 17, 22]取，j%4第一大轮 从[5, 9, 14, 20]取，j%4第一大轮 从[4, 11, 16, 23]取，j%4第一大轮 从[6, 10, 15, 21]取，j%4若写到一个数组中：public static final int S[] = new int[]&#123; 7, 12, 17, 22, 5, 9, 14, 20, 4, 11, 16, 23, 6, 10, 15, 21 &#125;;可以通过如下公式取值：S[(pType &lt;&lt; 2) | (j &amp; 3)]) //pType指第几大轮，j指第几小轮对于每次运算abcd数输入顺序：可以明显观察到，每一小轮之后，下一轮的输入相当于把abcd做循环右移一位，而P运算的输入固定位bcd，所以做如下交换a = d;d = c;c = b;b = temp; 经过这64步之后，A=a，B=b，C=c，D=d，然后将ABCD作为处理下一明文块的输入 应用MD5已经广泛使用在为文件传输提供一定的可靠性方面。例如，服务器预先提供一个MD5校验和，用户下载完文件以后，用MD5算法计算下载文件的MD5校验和，然后通过检查这两个校验和是否一致，就能判断下载的文件是否出错。 实现下面来给出java版本的具体实现，关键步骤有注释，详细代码见这里12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public String md5(String msg)&#123; byte[] msgBytes = msg.getBytes(); int msgBytesLen = msgBytes.length;//原始信息长度，单位bit int numBlock = ((msgBytesLen + 8)&gt;&gt;&gt;6) + 1; //总块数=(原始长度+8bit)/64bit + 1 int totalLen = numBlock &lt;&lt; 6; //补全后的长度 = 块数 * 64bit byte[] padBytes = new byte[totalLen - msgBytesLen]; //需要补的bit数 padBytes[0] = (byte) 0x80; //补一个1和若干个0 long msgLen = (long)msgBytesLen &lt;&lt; 3; //计算出多少bit，长度*8 for(int i = 0;i&lt;8;i++)&#123; padBytes[padBytes.length - 8 + i] = (byte) msgLen;//从低位开始写入长度 msgLen &gt;&gt;&gt;= 8; &#125; int a = A,b =B,c = C,d = D; //赋值常量 int[] buffer = new int[16]; //每块512位，16个int类型 for (int i = 0;i&lt;numBlock;i++)&#123; int index = i &lt;&lt; 6; for (int j = 0;j&lt;64;j++,index++) //index是msg的游标，j是buffer的游标，一个int类型存4个byte类型 //从低位开始存 buffer[j &gt;&gt;&gt; 2] = ((int) ((index &lt; msgBytesLen) ? msgBytes[index] : padBytes[index - msgBytesLen]) &lt;&lt; 24) | (buffer[j &gt;&gt;&gt; 2] &gt;&gt;&gt; 8); int tempa = a; //记录abcd的临时变量 int tempb = b; int tempc = c; int tempd = d; for (int j = 0;j&lt;64;j++) &#123; //64小轮 int pType = j &gt;&gt;&gt; 4; //判断是第几大轮 int f = 0; //P运算的值 int bufferIndex = j; //buffer的游标 switch (pType)&#123; //定义不同大轮的具体P运算 case 0: f = (b &amp;c) | (~b &amp; d); break; case 1: f = (b &amp; d) | (c &amp; ~d); bufferIndex = (bufferIndex*5+1)&amp;0x0f; //明文子组和轮数的关系 break; case 2: f = b ^ c ^ d; bufferIndex = (bufferIndex * 3 + 5) &amp; 0x0F; break; case 3: f = c ^ (b | ~d); bufferIndex = (bufferIndex * 7) &amp; 0x0F; break; &#125; //运算 int temp = b + Integer.rotateLeft(a + f + buffer[bufferIndex] + T[j], S[(pType &lt;&lt; 2) | (j &amp; 3)]); //交换abcd a = d; d = c; c = b; b = temp; &#125; //分组处理完之后abcd各自累加 a += tempa; b += tempb; c += tempc; d += tempd; &#125; //abcd写到16个byte中 byte[] out = new byte[16]; int count = 0; for (int i = 0;i&lt;4;i++)&#123; int n = (i == 0) ? a : ((i == 1) ? b : ((i == 2) ? c : d)); for (int j = 0;j&lt;4;j++)&#123; out[count++] = (byte)n; n&gt;&gt;&gt;=8; &#125; &#125; //转为十六进制表示 StringBuffer sb = new StringBuffer(); for (byte bout : out)&#123; sb.append(HEX[(bout&gt;&gt;&gt;4)&amp;0xf]); sb.append(HEX[bout&amp;0xf]); &#125; return sb.toString();&#125; 简单测试后结果正确无误 题图来自unsplash：https://unsplash.com/photos/HsEz1XZ1TO8]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kademlia：一个基于异或度量的P2P信息系统]]></title>
    <url>%2F2019%2F04%2F01%2FKademlia%EF%BC%9A%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E%E5%BC%82%E6%88%96%E5%BA%A6%E9%87%8F%E7%9A%84P2P%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[论文原文：https://link.springer.com/chapter/10.1007%2F3-540-45748-8_5 原文除了摘要，总共有5部分，分别是：介绍、系统描述、证明、实现要点、总结。这里只翻译摘要和核心的系统描述以及实现要点部分 摘要我们描述了一个在易发生故障的环境中具有可证明的一致性和高性能的P2P系统。我们的系统使用一种新的基于异或度量拓扑来进行路由查询和结点定位，这种拓扑简化了算法并易于证明。该拓扑在信息交换时仅传递或增强有用的信息，系统利用这些信息进行并行或异步的信息查询，同时也能容忍节点故障，并且不会给用户带来超时延迟 系统描述我们的系统基本上采取了和其他DHT系统一样的方法。节点的 ID 是 160 位不透明的值，我们的算法也是逐步“逼近”所期望的 ID ，并以对数级的速度收敛到要查询的目标。 Kademlia把一个节点看这一颗二叉树的叶子，每个节点的位置由其ID的最短唯一前缀决定。图一展示了一个唯一前缀为0011节点在树中的位置。对于任意给定的一个节点，我们都把树划分为一系列不包含该节点的逐步降低的子树。最高层的子树有二叉树中不包含该节点的那一半组成，接下来的子树由剩余的不包含该节点的一半组成，以此类推。在示例中的0011节点，子树被圈出来，分别由前缀为0,01,000以及0010的节点构成 Kademlia协议确保每个节点都至少知晓这些子树中的一个节点。有了这个保证，任何一个节点都可以通过ID定位其他节点。1110的示例，其中节点 0011通过逐步查询它所知道的最佳节点来取得和越来越低层次子树的联系；最后查询收敛到目标节点。 接下来，我们会补充一些细节，并更具体的描述查询算法。首先，我们会给出 ID 接近这个概念的准确定义，这样就可以谈及“在距离 key 最近的k个节点上存储或者查询 键值对”这样的行为。然后，我们会介绍一个查询协议，该协议即使在任何节点都不和某个key具有相同的前缀或者和某个给定节点关联的子树中有一些为空的情况下，都可以正常工作。 异或度量每个Kademlia节点都有160位的ID，节点id构造像Chord一样，但是为了简化，我们假设机器在加入系统时选择一个随机的160位标识符。节点传输的每个消息都包含其ID，并且允许接收方在必要时记录发送方的存在。 key同样也是160位的标识符。为了发布和查找键值对，Kademlia依赖于两个标识符之间的距离。给定两个160位标识符x和y,Kademlia将它们之间的距离定义为它们的为异或（d(x,y)），并转化为整数。 我们首先注意到虽然异或不是欧几里得度量，但仍是有效的。很明显，d(x,x) = 0。如果x ≠ y则d(x,y)&gt;0。以及d(x,y)=d(y,x)。除此之外，异或还满足三角不等式，因为d(x,z) = d(x,y) xor d(y,z),而a+b &gt;= a xor b 和chord的顺时针圆周度量一样，异或也是单向的。给定任意一个点x和距离d&gt;0，都会存在一个点y，使得d(x,y) = d。单向性确保所有对相同键的查找都沿着相同的路径收敛，而不管初始节点是什么。因此，沿着查找路径缓存键值对可以缓解热点。就像Pastry一样，但不像Chord，异或拓扑是对称的，即(d(x,y) = d(y,x)) 节点状态Kademlia节点存储彼此之间的路由联系信息。对于每个i（0 &lt;= i &lt; 160），节点都会存储一个含有&lt;IP地址列表;UDP端口;节点ID&gt;列表，每个列表项表示距离自己2^i和2^i+1之间的节点。我们称这些列表为k桶。每个k桶都按照时间顺序进行排序，最后一次看到的节点位于头部，最近一次看到的节点位于尾部。对于较小的i值，为k桶通常是空的(因为没有合适的节点)。对于较大的i值，列表长度可以增长到k，其中k是一个系统范围的全局变量。选择k时，任何给定的k个节点都不太可能在一小时内发生故障(例如k = 20)。 当Kademlia节点接收到来自另一个节点的任何消息(请求或响应)时，它将更新发送方节点ID所在的k桶。如果发送节点已经存在于收件人的k桶中，则收件人将其移动到列表的末尾。如果节点还没有在适当的的k桶中，并且桶的条目数小于k，那么接收方只需在列表的末尾插入新的发送方。但是，如果应村的k桶已满，则接收方将PING k桶的最近最少出现的节点，以决定该做什么。如果最近最少出现的节点没有响应，则将其从k桶中删除，并在末尾插入新的发送者。否则，如果最近最少出现的节点有响应，则将其移动到列表的末尾，并丢弃新发送方的联系人。 k桶有效地实现了一个最近很少键的清除策略，除非活动节点从未从列表中删除。这种对旧的联系的处理是基于对Saroiu等人收集的Gnutella微量数据分析而得出的。图1显示了Gnutella节点继续在线一个小时的百分比，这是当前正常运行的时间函数。节点运行的时间越长，它继续运行一个小时的可能性就越大。通过保留旧的联系人，k桶最大化了它们所存的节点保持在线的可能性。 k桶的第二个好处是，可以抵抗特定的DoS攻击。无法通过向系统中注入新节点来刷新节点的路由状态。Kademlia节点只会在旧节点离开系统时将新节点插入到k桶中。 Kademlia协议Kademlia协议由四个rpc组成：PING, STORE, FIND NODE 和 FIND VALUE。PING探测一个节点，看看它是否在线。STORE指示节点存储键值对，以便以后检索。 FIND NODE以160位的ID作为参数。接收者返回&lt;IP地址;UDP端口;节点ID&gt;三元组表示它知道的最接近目标ID的k个节点。这些三元组可以来自单个k桶，也可以来自多个k桶（如果最近的k桶没有满的话）。在任何情况下，RPC接收方都必须返回k个条目(除非所有k个桶的组合中有少于k个节点，在这种情况下，它返回它所知道的每个节点)。 FIND VALUE的行为类似于FIND NODE，也返回&lt;IP地址;UDP端口;节点ID&gt;三元组，只有一个例外。如果RPC接收方收到了STORE的RPC，它只返回存储值。 在所有RPC中，接收者必须回显一个160位的随机RPC ID，这为地址伪造提供了一定的抵抗力。还可以在RPC应答上附加ping，以便RPC接收方获得对发送方网络地址,从而获得额外保证。 Kademlia参与者必须执行的最重要的过程是定位距离某个给定节点ID最近的k个节点。我们将此过程称为节点查找。Kademlia使用递归算法进行节点查找。查找发起者首先从最近的非空k桶中选择α个节点（如果已知节点数少于α，则选择全部节点）。。发起者发送并行或异步的rpc FIND NODE给α个节点。α是一个全系统的并发性参数，比如3 在递归步骤中，初始节点将FIND NODE重新发送到它从之前的rpc结果中了解到的节点（这个递归可以从先前的RPC返回后开始）。收到响应后，发起者向离目标更近的其中α个未被请求的节点发送FIND NODE。无法快速响应的节点将从考虑中删除，直到它们再次响应。如果一轮查找节点未能返回比已知的更近的节点，则初始节点将FIND NODE重新发送给它尚未查询的k个最近的节点。当初始节点查询并从它所知的k个最近的节点中获得响应时，查找将终止。当α= 1查找算法类似于Chord的信息消耗和延迟检测失败的节点。然而，Kademlia可以通过路由获得更低的延迟，因为它可以灵活地选择k个节点中的任意一个来转发请求。 大多数操作都是根据上面的查找过程实现的。要存储键值对，参与者需要找到距离键最近的k个节点，并向它们发送STORE rpc。此外，每个节点每小时重新发布它拥有的键值对，这确保键值对的持久性概率维持较高水平。通常，我们还需要键值对的原始发布者每24小时重新发布一次。否则，所有的键值对将在最初发布24小时后过期，从而限制系统中的陈旧信息。 最后，为了使键值对的发布-搜索在声明周期中保持一致，我们要求每当一个节点w观察到一个新的节点u时，这个新节点u更接近w的一些键值对时，w将这些对复制到u，而不从自己的数据库中删除。 要查找一个键值对，初始节点首先进行查找，查找id最接近的k个节点。不过，使用的rpc是FIND VALUE。此外，当任何节点返回值时，程序立即停止。出于缓存的目的，一旦查找成功，请求节点将键值对存储在它观察到的最接近目标但没有返回值的节点上。 由于拓扑的单向性，未来对相同键的搜索可能会在查询最近的节点之前命中缓存的条目。在某个键非常流行的时候，系统可能会在许多节点上缓存它。。为了避免“过度缓存”，我们将任何节点数据库中的键值对的过期时间设置为与当前节点和ID最接近的节点之间的节点数量成指数反比。虽然简单的LRU清除将导致类似的生存期分布，但是没有选择缓存大小的天生方法，因为节点不知道系统将存储多少值。 桶中内容经常会保持最新，这是由于通过节点传输的请求流量造成的。为了避免在没有通信量的情况下出现病态情况，每个节点需要在某个桶所在范围内一个小时没有执行节点查找时进行刷新。刷新意味着在桶的范围内随机选择一个ID，并对该ID执行节点搜索。 要加入网络，节点u必须与已经参与其中的节点w有联系。然后，u对自己的节点ID执行节点查找。最后，u刷新所有k桶。在刷新期间，u都填充自己的k桶，并根据需要将自己插入其他节点的k桶中。 路由表根据协议，Kademlia的基本路由表结构相当简单，不过在处理高度不平衡的树时需要稍作改进。路由表是一个二叉树，它的叶子是k桶。每个k桶包含一些节点，它们的id具有一些公共前缀。前缀是k桶在二叉树中的位置。因此每个k桶覆盖ID空间的某个范围，所有k桶一起覆盖整个160位ID空间，没有重叠。 路由树中的节点根据需要动态分配。图4说明了这个过程。最开始，一个节点u的路由树只有一个节点，一个k桶覆盖整个ID空间。当u获得一个新的连接时，他就会将其插入适当的k桶。如果该桶未满，只需简单插入。反之，如果k桶的范围包含u自己的ID，那么这个bucket就会被分成两个新桶，旧的内容被划分到这两个桶中，然后重复插入尝试。如果k桶已满，且不包含u的ID，则直接丢弃新的信息。 一个复杂的情况出现在高度不平衡的树中。假设节点u加入系统，并且是ID从000开始的惟一节点。进一步假设系统已经有超过k个前缀为001的节点。每个带001前缀的节点将有一个空的应该将u插入其中的k桶，但是u在对其k桶进行更新是只会通知到其中k个节点。为了避免这个问题，Kademlia节点将所有有效的联系人保存在至少k个节点大小的子树中，即使这需要分割桶，而节点本身的ID并不驻留在桶中。图5显示了这些额外的分割。当 u 更新这些分割过的 buckets 时，所有具有 001 前缀的节点都会得到通知。 高效的key重发布为了确保键值对的持久性，节点必须定期重新发布key。否则，有两种情况会导致对有效 key 的查询失败。首先，在发布时，最初获得键值对的k个节点中的一些会离开网络。其次，新加入节点的 ID 相比键值对的原始发布节点，可能距离该key更近一些。在这两种情况下，拥有键值对的节点必须要对其进行重新发布，这样就再次保证了从距离该 key 最近的 k 个节点上可以获取该 key 。 为了对节点离开造成的问题的弥补， Kademlia 每一小时就对每个键值对进行重新发布。这种实现会导致很多消息往来，存储键值对的k个节点每小时都会进行一次节点查询，饭后进行k-1出STORErpc调用。幸运的是，可以对这种过程进行优化。首先，当一个节点收到一个针对某个键值对的STORE rpc时，他可以认为该rpc也发送给了其他k-1个节点，因此他就不会重新发布键值对。这就保证了只要重新发布间隔不是精确同步的，对于任何一个键值对来说，每小时只会有一个节点对其进行重新发布。 第二个优化是避免在重新发布key之前进行节点查找。如2.4小节所示，为了解决不平衡树，节点在需要时可以分裂k桶以保持其具有关于一个节点个数超过k的边缘子树的全部知识。在重新发布键值对之前，如果节点u更新了该字数中k个节点的所有k桶，那么他将自动获取关于某个key值最近的k个节点信息。对于这些桶的更新代价可以分摊到许多key的重新发布上。 要想知道为何在对规模大于k的子树中的桶进行更新后，就无需再进行节点查询操作，就得考虑两种情况。如果要被重新发布的key位于该子树覆盖的ID区间内，那么由于该子树的规模至少为 k ，并且 u 具有关于该子树的全部知识，因此u一定知道距离该key最近的 k 个节点。另一方面，如果key位于子树范围之外，而u是距离该key最近的k个节点之一，那么按照 u 的k桶规则，所有距离该key比子树更近一些的区间中的元素都少于k。因此， u 将知道这些k桶中的所有节点，再加上关于子树的知识，就可以得到距离该 key 最近的 k 个节点。 当一个新节点加入系统时，对于每个 key-vaule 对来说，如果该节点为其 k 个最近节点之一，那么必须对其进行存储。系统中原有的节点同样可以通过其边缘子树的完整知识，知道哪些键值对需要存储在该新增节点上。每个了解到新节点的节点都会发起 STORE RPC 把相关的 key-value 对传送到新节点之上。为了避免重复的 STORE RPC ，只有那些自身 ID 比其他节点 ID 更接近 key 的节点才会进行 key-value 对的传送。 实现注意事项在本小节中，我们将介绍两个用来改进 Kademlia 实现性能的重要技术。 优化联系记录对于k桶最基本的属性是能够提供LRU检查，并且在不丢失任何有效信息的情况下删除无效信息。如2.2节所述，如果一个k桶已满，他会在收到该桶范围内的任何一个位置节点的消息时发送一条PING。这个PING用来检测最近最少使用的节点是否仍然有效。如果无效，新的节点为替代带旧的节点。不幸的是，这种行为会导致大量的ping消息充斥在网络中 为了减少这些流量，Kademlia会延迟这个探测行为，直到要发送一条有用的消息给他们时。当一个节点收到一个未知节点的消息时，如果所在的k桶已满，节点会把它放在一个置换缓存中，当节点下次查询是，对于无效的节点会被用缓存中的节点替换。缓存中的节点时按照时间排序的，最近的节点有最高的优先级。 有一个和Kademlia使用UDP相关的问题。当网络丢包时，会丢失一些有效节点的信息。通常丢包意味着网络阻塞，所以Kademlia会锁定那些未响应的节点，并在一个以指数增长的退避时间间隔内不向其发送任何消息。因为在Kademlia查询过程中，大部分情况下只需联系到 k 个节点中的一个，所以一般情况下，系统不会向同一节点重传被丢弃的 RPCs 如果连续五条消息都没有响应，则认为是过期的。如果k桶不满，或缓存为空，那么Kademlia只是将过期信息打上标记，而不是立即清除，这就保证了节点出现短暂的网络故障时，不会完全清除其k桶 加速查询另一个优化是用过增加路由表大小来减少查询的步数。从概念上讲，可以考虑每次使用b位ID而不是一位。和前面介绍一样，期望的步数是log2n。如果把路由表扩大到2^blog2^b n个k桶，我们可以减少步数到log2^b n 2.4小节较少了当Kademlia节点的k桶满且其区间包含了节点自己ID是，如何去分裂该k桶。然而，在实现中，也会把不包含节点自己ID的区间分裂成b-1层。比如，如果b=2，不包含节点ID的那一半会分类一次。如果b=3，会分裂两层，最多四个区间，以此类推。大致的分裂规则是，如果一个满的k桶包含了节点自身的ID或其在路由树中的深度d满足d=O(mod b)，就会被分裂，当前实现是b=5 虽然基于 XOR 的路由算法和 Pastry、 Tapestry以及 Plaxton 分布式搜素算法中第一阶段的路由算法很相似，但是当它们一般化到 b&gt;1 时就都变得非常复杂。如果没有基于XOR的拓扑，就需要另外使用一个算法结构来从具有相同前缀但是后 b 位又不同的节点中找出目标节点。这三个算法采用了不同的方法来解决这个问题，各具缺点；除了大小为O(2^b log2^b n)的主路由表外，它们都需要一个大小为O(2^b)的二级路由表。这增加了启动和维护的成本，也使协议变得复杂，并且对于Pastry和Tapestry来说，也使得对其进行正确性和一致性方面的规范分析变得困难或不可能。有一个针对Plaxton的证明，但是该系统难以适应像 P2P 这样的高故障概率环境。 题图来自unsplash: https://unsplash.com/photos/phIFdC6lA4E]]></content>
      <categories>
        <category>翻译</category>
      </categories>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非对称加密算法与数字签名]]></title>
    <url>%2F2019%2F03%2F31%2F%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%2F</url>
    <content type="text"><![CDATA[RSA算法背景RSA是一种非对称加密算法，该算法在1977年由Ron Rivest、Adi Shamir和Leonard Adleman三人提出，算法一起三人姓氏开头字母命名。 对极大整数做因数分解的难度决定了RSA算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA算法愈可靠。假如有人找到一种快速因数分解的算法的话，那么用RSA加密的信息的可靠性就肯定会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的RSA钥匙才可能被强力方式解破。到当前为止，世界上还没有任何可靠的攻击RSA算法的方式。只要其钥匙的长度足够长，用RSA加密的信息实际上是不能被解破的。 算法流程RSA算法本身比较简单，基本流程如下： 选择两个大素数p和q，p不等于q 计算N = p*q 令r=(p-1)(q-1) 寻找一个小于r的的整数e，使e与r互质 寻找一个整数d，使 (d*e) mod r = 1 (N,e)是公钥，(N,d)是私钥 加密时，若明文为P，则密文C = P^e mod N 解密时，P = C^d mod N 举例1234567取 p = 7，Q = 17n = p*q = 119r = 6 * 16 = 96取e = 5取d = 77假设明文为10，密文c = 10^e mod n = 40解密： 40^d mod n = 10 RSA安全性分析回顾整个算法。我们公开的是公钥e和n，保密的是私钥d，私钥是由e和r构成的。由于e是公开的，所以攻击者需要求得r。一个途径就是根据公开的n求得p和q就得到了r。但是p和q是很大的素数，导致n也很大，所以因数分解异常困难，有数学分析证明，如果n能达到100位数，那么正确求得q和p需要数十年的时间。 速度毫无疑问，由于涉及大量大数运算，RSA加密速度很慢。一种有效的方法是加密的一方使用一种可靠的对称加密算法加密明文，然后用RSA加密较短的秘钥，最后连同RSA加密的密文和对称加密算法加密的密文一同传输。 数字签名RSA加密算法分公钥秘钥和私钥密码。用RSA进行数字签名的步骤如下 发送方A对消息M进行摘要得到M1 A用自己的私钥对摘要进行加密，得到数字签名DS A将消息M和数字签名DS一同发送给B B对消息M进行摘要得到M2 B用A的公钥对数字签名解密得到M1 对比M2和M1是否相等来判断消息是否完整或被篡改 使用加解密这里用go语言进行演示（其后所有实例完整代码见这里），先看加解密，基本思想就是公钥加密私钥解密12345678910111213141516171819202122232425func main() &#123; read:=rand.Reader privKey,err:=rsa.GenerateKey(read,1024) if err != nil&#123; log.Fatalln(err.Error()) &#125; pubKey := privKey.PublicKey fmt.Println("N:",privKey.N) fmt.Println("公钥E:",privKey.E) fmt.Println("私钥D",privKey.D) plainText := "helloworld5645你好" ciphertext,err:=rsa.EncryptPKCS1v15(read,&amp;pubKey,[]byte(plainText)) if err != nil&#123; log.Fatalln(err.Error()) &#125; fmt.Println(hexToString(ciphertext)) result,err:=rsa.DecryptPKCS1v15(read,privKey,ciphertext) if err != nil&#123; log.Fatalln(err.Error()) &#125; fmt.Println(string(result))&#125; 上面代码中GenerateKey是随机生成一对秘钥，公钥是和私钥相对应的，通过查看源码可以知道公钥的结构体就是包含一个大整数N和一个整数E，私钥除了记录了公钥信息，还记录了一个大整数D就是私钥。代码中使用的加密方法是EncryptPKCS1v15，PKCS是公钥加密标准(Public-Key Cryptography Standards ),PKCS1就是一系列标准的第一个，常记做PKCS#1，也即是RSA加密标准。v15表示1.5版本，详见文档 除了EncryptPKCS1v15的一套加解密方法外，还有一套OAEP方法，是另外一种填充方式，详见文档,用法如下：12ciphertext,err:=rsa.EncryptOAEP(sha256.New(),read,&amp;pubKey,[]byte(plainText),[]byte("hi"))result,err:=rsa.DecryptOAEP(sha256.New(),read,privKey,ciphertext,[]byte("hi")) 值得一提的是在加密时可以指定一个标签，解密时不但要秘钥正确，标签也要对应，否则无法解密，标签可以为空 数字签名数字签名的签名与验证基本思路就是私钥签名，公钥验证123456789101112131415161718192021222324252627282930313233343536func main() &#123; read:=rand.Reader privKey,err:=rsa.GenerateKey(read,1024) if err != nil&#123; log.Fatalln(err.Error()) &#125; pubKey := privKey.PublicKey text := "helloworld5645你好" signature1,err:=rsa.SignPKCS1v15(read,privKey,crypto.Hash(0),[]byte(text)) if err != nil&#123; log.Fatalln(err.Error()) &#125; fmt.Println("signature1:",hex.EncodeToString(signature1)) hashed := sha256.Sum256([]byte(text)) signature2,err:=rsa.SignPKCS1v15(read,privKey,crypto.SHA256,hashed[:]) if err != nil&#123; log.Fatalln(err.Error()) &#125; fmt.Println("signature2:",hex.EncodeToString(signature2)) err=rsa.VerifyPKCS1v15(&amp;pubKey,crypto.Hash(0),[]byte(text),signature1) if err != nil &#123; fmt.Println("签名验证失败") &#125;else &#123; fmt.Println("签名验证成功") &#125; err=rsa.VerifyPKCS1v15(&amp;pubKey,crypto.SHA256,hashed[:],signature2) if err != nil &#123; fmt.Println("签名验证失败") &#125;else &#123; fmt.Println("签名验证成功") &#125;&#125; 首先还是用GenerateKey生成一对秘钥，然后使用SignPKCS1v15进行签名，由于非对称加密的效率问题，官方强烈建议对原文进行摘要后在进行签名，这是需要在第三个参数中指定所用的hash函数，如果不摘要，则用0表示。验证也是一样道理，使用VerifyPKCS1v15函数，传入要验证的内容即可。注意使用的签名和验证函数以一对PKCS1v15后缀的，和加解密一样这是用PKCS1v15标准的。还有一对使用PSS规范的方法，用法基本一样这里不再举例。 DSA算法先介绍一下DSA的一些基本变量123456p ：长度为L的素数，L是64的倍数q ：(p-1)的N位素数因子g ：h^((p-1)/q) mod p ,h是小于p-1的数，g需要大于1x ：小于q的数y ：g^x mod pH ：摘要算法 在以上变量中(p,q,g,y)是公开的，即公钥，x是私钥，签名过程如下（m是消息） 发送方A随机选择一个小于q的随机数k，作为临时秘钥 r=(g^k mod p) mod q s=((1/k)*(H(m)+xr)) mod q r与s作为数字签名连同信息m发送给接收方B B进行如下计算 w = (1/s) mod q u1 = (H(m) * w) mod q u2 = (rw) mod q v = ((g^u1 * y^u2) mod p) mod q 最后比较v与r是否相等验证数字签名 相比RSA可以用作加密，DSA只能用作签名，而且安全程度类似。 使用12345678910111213141516171819202122232425262728293031func main() &#123; read:=rand.Reader privKey:=new(dsa.PrivateKey) err:=dsa.GenerateParameters(&amp;privKey.Parameters,read,dsa.L1024N160) if err!=nil &#123; log.Fatalln(err.Error()) &#125; err=dsa.GenerateKey(privKey,read) if err!=nil &#123; log.Fatalln(err.Error()) &#125; fmt.Println("私钥：X =",privKey.X) fmt.Println("公钥：Y =",privKey.PublicKey.Y) fmt.Println("公共参数：") fmt.Println("p = ",privKey.PublicKey.P) fmt.Println("q = ",privKey.PublicKey.Q) fmt.Println("g = ",privKey.PublicKey.G) r,s,err:=dsa.Sign(read,privKey,[]byte("helloworld")) if err!=nil &#123; log.Fatalln(err.Error()) &#125; fmt.Println("签名结果：\nr=",r) fmt.Println("s=",s) b:=dsa.Verify(&amp;privKey.PublicKey,[]byte("helloworld"),r,s) if b &#123; fmt.Println("签名验证成功") &#125;else &#123; fmt.Println("签名验证失败") &#125;&#125; 首先是生成秘钥对，和rsa需要指定秘钥长度一样，这里要指定密钥对的参数长度，这里选用dsa.L1024N160，L表示p的长度，N表示q的长度。先用GenerateParameters生成参数，再用GenerateKey生成秘钥，然后用Sign签名得到r,s。最后用Verify验证。同样由于效率问题，签名时除非明文较短，否则不要直接对明文签名。注意Go语言中是按照FIPS 186-3标准实现的，详见文档 ElGamal算法和RSA类似，ElGamal是一种非对称加密算法，先介绍它的加密 秘钥生成 选取一个足够大的素数p 选取Zp的生成元E1 随机选取整数d，d小于p-2，计算E2 = E1^d mod p 私钥为d，公钥为(E1,E2,p) 加密 选取随机数r属于Zp-1 C1 = E1^r mod p C2 = M*E2^r mod p (M位明文) C1,C2就是密文 解密计算 (C2 * (C1^d)^-1) mod p = M 数字签名公钥为(E1,E2,p),私钥为d 发送方选择一个随机数r S1 = E1^r mod p S2 = ((M - dS1) r^-1) mod (p-1) S1,S2就是数字签名，M是原始消息，将三种发送给接收方 接收方进行如下计算 V1 = E1 ^ M mod p V2 = (E2^S1 * S1^S2) mod p 比较v1与v2是否相等来进行验证 ECC算法ECC即EllipseCurve Cryptography，全称椭圆曲线加密。是一种基于椭圆曲线数学的公钥密码。与传统的基于大质数因子分解困难性的加密方法不同，ECC 依赖于解决椭圆曲线离散对数问题的困难性。关于椭圆曲线的知识见这里：ECC椭圆曲线详解 加解密过程 发送方A选择一条曲线E，同时选择曲线上一点G作为基点，基点G的阶数为n A选择一个私钥d，d&lt;n。生成公钥K = dG A将E、K和G传给接收方B B收到信息后，将明文编码到一点M（编码方式可自由协商），并产生随机数r，r&lt;n B进行如下计算 C1 = M+rK C2 = rG C1与C2就是密文 A收到密文后进行如下解密：M = C1 - dC2 数字签名使用ECC进行的数字签名被称为ECDSA。基本过程如下， 依旧选择一条曲线E，同时选择曲线上一点G作为基点，基点G的阶数为n 选择一个私钥d，d&lt;n,计算公钥Q = dG 首先计算信息的摘要e 随机选择一个数k，k&lt;n 计算点(x1,y1) = kG 计算r = x1 mod n，如果r=0，回到第4步 计算s = k^-1(e + rd) mod n，如果s = 0，回到第4步 r和s就是签名值 验证如下： 收到消息m和签名值r，s后进行如下计算 先计算摘要e 计算w = s^-1 mod n 计算u1 = ew mod n 计算u2 = rw mod n 计算点(x1,y1) = u1G+u2Q 判断r是否等于x1 密钥协商之前我们讲过Diffie-Hellman密钥协商算法，基于的是大数分解难题，而基于ECC也有一种密钥协商算法，称为ECDH，思想是和Diffie-Hellman类似的，基本流程如下： A,B双方协商一条椭圆曲线及基点G，这些数据是可以明文传播的 A计算自己的公钥和私钥，即da与Da，其中Da=da*G B计算自己的公钥和私钥，即db与Db，其中Db=db*G 双方交换公钥 A计算密钥Sa=da*Db B计算密钥Sb=db*Da 可以证明Sa=Sb：Sa=da*Db=da*db*G，Sb=db*Da=db*da*G 使用下面例子是ecdsa1234567891011121314151617181920func main() &#123; read:=rand.Reader priv,err:=ecdsa.GenerateKey(elliptic.P256(),read) if err != nil &#123; log.Fatalln(err.Error()) &#125; r,s,err:=ecdsa.Sign(read,priv,[]byte("hello")) if err != nil &#123; log.Fatalln(err.Error()) &#125; fmt.Println("签名结果") fmt.Println("r = ",r) fmt.Println("s = ",s) b := ecdsa.Verify(&amp;priv.PublicKey,[]byte("hello"),r,s) if b &#123; fmt.Println("签名验证成功") &#125;else &#123; fmt.Println("签名验证失败") &#125;&#125; 虽然标准包中没有提供ecc的实现，但是有elliptic包，提供了椭圆曲线的一些基本运算，再参考ecdsa可以自行设计加解密算法。对于ecdh在以太坊的ecies有实现123456789101112131415161718func (prv *PrivateKey) GenerateShared(pub *PublicKey, skLen, macLen int) (sk []byte, err error) &#123; if prv.PublicKey.Curve != pub.Curve &#123; return nil, ErrInvalidCurve &#125; if skLen+macLen &gt; MaxSharedKeyLength(pub) &#123; return nil, ErrSharedKeyTooBig &#125; x, _ := pub.Curve.ScalarMult(pub.X, pub.Y, prv.D.Bytes()) if x == nil &#123; return nil, ErrSharedKeyIsPointAtInfinity &#125; sk = make([]byte, skLen+macLen) skBytes := x.Bytes() copy(sk[len(sk)-len(skBytes):], skBytes) return sk, nil&#125; 秘钥格式一些规范对RSA秘钥的格式也有一些要求，具体格式语法就不介绍了，go语言提供方便的转换接口 密钥编码12345678910111213141516171819202122func main() &#123; read:=rand.Reader privKey,err:=rsa.GenerateKey(read,1024) if err != nil&#123; log.Fatalln(err.Error()) &#125; pubKey := privKey.PublicKey encodePrivKey := x509.MarshalPKCS1PrivateKey(privKey) block1:=pem.Block&#123; Type: "RSA PRIVATE KEY", Bytes: encodePrivKey, &#125; pem.Encode(os.Stdout,&amp;block1) encodePubvKey := x509.MarshalPKCS1PublicKey(&amp;pubKey) block2:=pem.Block&#123; Type: "RSA PUBLIC KEY", Bytes: encodePubvKey, &#125; pem.Encode(os.Stdout,&amp;block2)&#125; 首先利用x509包中的MarshalPKCS1PrivateKey方法对秘钥进行序列化，然后利用pem包进行编码，编码前首先要用Block对秘钥进行包装，主要是指定Type，最后生成数据如下123456789101112131415-----BEGIN RSA PRIVATE KEY-----MIICXQIBAAKBgQDQ6x6qUOn6lct8npBizj9thh9RrPi35wez7EHmRLH9QYhJqtJVp/9B5ITgwXR1VBM4shJ3RvNUj+diT8ox0FUuw4+3EZqW5tSgoQGzV3Go+PX+4p21u874GOqYtFUDmhQjMuh4NtsBfnClGsf9pUmInjxsVKKfdUbYZxLKzGK2DwIDAQABAoGAMeyNtmuBjlUvfEcz/7iDpbuQTmdEREYcLB3AHbO6yOdZFymP+9IaiHeAXWk9WDBQK5M6IHC/Ay0kQPUKP18mi4hXKm4hRql3B3rJoV6qiP3/c5hYakhSSPouPmoC30a1ERWnKlH9YSMDOhYUY1c02onYsY9AxM18N27AOYLSMWECQQD75aGjjYY+lDKbUXsqSLgL4hbPTswKjYJU6ps6hkJKEklMI5rQk/J5yLuji7USJdmGJziZin41vGx/NSQlsUuRAkEA1FJGYeC4idHhYZ5NIKgSefWn9+lgIDzxjIAivcViTFLd9bz4UcSQU+FzEHEkA78C0y3g30NqAGkspVuxfO7XnwJBALO26DSM0xswlk5zuqC3Uv+/ZTCwciiRP0wgOXFuujqogzzcJibrdtJmYWDUWvJAqMnqj5oT0em6rdmv60MtE9ECQDvGqiAWV34dw9lq6wX9q64Adni6kKCi59KJpL5O2vzn+6uat0K2F3g2KeIAKIaReWchLIVPAoH5GmO3rAGjcLsCQQDMDtQxU3DTcrLyKgx+N3n4jqkDOsK/iiotvdHFrQvrdPJPsUtSsFa0ejvIO6Mf0d9h4fi4vNIIIIS1QjpAkOE4-----END RSA PRIVATE KEY----- 秘钥解码给出一段上文表示秘钥可以用下面方法解码123456789101112131415161718192021222324func main() &#123; read:=rand.Reader privKey,err:=rsa.GenerateKey(read,1024) if err != nil&#123; log.Fatalln(err.Error()) &#125; encodePrivKey := x509.MarshalPKCS1PrivateKey(privKey) block1:=pem.Block&#123; Type: "RSA PRIVATE KEY", Bytes: encodePrivKey, &#125; file, err := os.Create("priv.pem") pem.Encode(file,&amp;block1) key,err:=ioutil.ReadFile("priv.pem") block,_:=pem.Decode(key) if block ==nil &#123; log.Fatalln("nil") &#125; privkey2,err:=x509.ParsePKCS1PrivateKey(block.Bytes) fmt.Println(privKey.D.Cmp(privkey2.D)==0) fmt.Println(privKey.N.Cmp(privkey2.N)==0)&#125; 基本就是编码的逆过程，先decode再Parse。 其他除了可以编解码PKCS1规范的秘钥，还提供了MarshalPKCS8PrivateKey、MarshalECPrivateKey与 MarshalPKIXPublicKey等，用于支持不同的密钥或规范 题图来自unsplash：https://unsplash.com/photos/KidY3t8O4PE]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grpc学习]]></title>
    <url>%2F2019%2F03%2F31%2Fgrpc%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[背景gRPC是一个高性能、通用的开源RPC框架，其由Google主要面向移动应用开发并基于HTTP/2协议标准而设计，基于ProtoBuf序列化协议开发，且支持众多开发语言。关于ProtoBuf的详细内容可以参考我的这篇文章 根据官方页面显示，目前支持的语言如下： 也就是说在这些语言平台上，完全可以用grpc实现rpc通信，同时又由于protobuf的编码效率高，所以可以实现替代jsonrpc HelloWorld 国际惯例，我们先用go语言写一个grpc版本的hellworld。首先要安装grpc库1go get -u google.golang.org/grpc protobuf定义及编译首先定义protobuf文件如下：1234567891011121314151617181920syntax = &quot;proto3&quot;;option java_multiple_files = true;option java_package = &quot;io.grpc.examples.helloworld&quot;;option java_outer_classname = &quot;HelloWorldProto&quot;;package helloworld;service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;message HelloRequest &#123; string name = 1;&#125;message HelloReply &#123; string msg = 1;&#125; 几点需要注意的，首先protobuf版本为proto3，其中定义了两个message，分别用于请求和响应，又定义了一个service，其中有一个rpc方法，接受请求返回响应 然后执行下面命令生成pb.go文件1protoc ./helloworld/helloworld.proto --go_out=plugins=grpc:./ 我们看一下生成的go代码，首先定义的两个message各自成为一个struct123456789101112type HelloRequest struct &#123; Name string `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"` XXX_NoUnkeyedLiteral struct&#123;&#125; `json:"-"` XXX_unrecognized []byte `json:"-"` XXX_sizecache int32 `json:"-"`&#125;type HelloReply struct &#123; Msg string `protobuf:"bytes,1,opt,name=msg,proto3" json:"msg,omitempty"` XXX_NoUnkeyedLiteral struct&#123;&#125; `json:"-"` XXX_unrecognized []byte `json:"-"` XXX_sizecache int32 `json:"-"`&#125; 这两个struct中含有我们定义message时定义的成员变量。之后我们还定义了一个名为Greeter的服务，它变成了一个interface123type GreeterServer interface &#123; SayHello(context.Context, *HelloRequest) (*HelloReply, error)&#125; 这就是要我们写服务时实现这个接口才能正确定义grpc 服务端服务端代码如下1234567891011121314151617181920type server struct &#123;&#125;func (s *server)SayHello(ctx context.Context, in *helloworld.HelloRequest) (*helloworld.HelloReply, error)&#123; fmt.Println("received:",in.Name) return &amp;helloworld.HelloReply&#123;Msg:"hello " + in.Name&#125;,nil&#125;func main() &#123; lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; s:=grpc.NewServer() helloworld.RegisterGreeterServer(s,&amp;server&#123;&#125;) if err := s.Serve(lis); err != nil &#123; log.Fatalf("failed to serve: %v", err) &#125;&#125; 和写普通rpc代码类型，先定义一个服务类，不过这里要实现我们定义的接口。在main入口里可以发现grpc还是基于tcp传输的，这里的逻辑是定义tcp连接和grpc服务，然后将我们刚才写的服务类注册到grpc中，最后用grpc提供的方法去接管tcp连接即可 客户端客户端代码如下123456789101112131415161718func main() &#123; conn,err:=grpc.Dial("127.0.0.1:1234",grpc.WithInsecure()) if err!=nil &#123; log.Fatal("dial:",err.Error()) &#125; defer conn.Close() c:=helloworld.NewGreeterClient(conn) ctx,cancel:=context.WithTimeout(context.Background(),time.Second) defer cancel() r,err:=c.SayHello(ctx,&amp;helloworld.HelloRequest&#123;Name:"world"&#125;) if err!=nil &#123; log.Fatal("dial:",err.Error()) &#125; fmt.Println("greeting",r.Msg)&#125; 可能是为了降低大家学习成本，grpc的接口设置和go rpc标准包类似。首先利用grpc提供的接口去发起一个连接。接下来，grpc很方便的帮我们包装了一个client类，其中有我们可以调用的rpc方法，省去了之前用字符串表示的麻烦，随后就像函数调用一样去调用远程方法即可，返回一个响应，然后我们从响应中读数据。 有一个小问题需要注意的是，用grpc去发起连接时，目标地址如果是本机地址的话不能像go标准包那样简写为”:1234”，需要像上面代码那样写出全名。 最后先运行服务端代码再运行客户端代码，就成功实现利用grpc通信。该节示例代码见这里 grpc相关概念服务类型 grpc定义了四种服务 单项rpc就是最普通的请求响应模式12rpc SayHello(HelloRequest) returns (HelloResponse)&#123;&#125; 服务端流式rpc客户端向服务端发起一个请求，服务端返回一个数据流响应12rpc LotsOfReplies(HelloRequest) returns (stream HelloResponse)&#123;&#125; 客户端流式rpc客户端向服务端发送数据流请求，客户端仅返回一个响应12rpc LotsOfGreetings(stream HelloRequest) returns (HelloResponse) &#123;&#125; 双向流式rpc客户端与服务端都以数据流形式通信12rpc BidiHello(stream HelloRequest) returns (stream HelloResponse)&#123;&#125; RPC终止与取消在客户端与服务端，二者对调用的成功与否是独立，可能会出现不同的判断。客户端与服务端可在任何时间取消一个rpc，rpc会立即终止，但只影响之后状态，取消前完成的不会回滚。 超时客户端可以指定超时时间，超过这个时间没有响应测返回DEADLINE_EXCEEDED错误，服务端也可查询还有多久去完成响应。 详细内容实际上上面的helloworld已经可以说明grpc的基本使用，下面只是针对另外几种rpc服务类型进行介绍，这里引用官方的例子，完整代码见这里。 protobuf定义12345678910111213141516171819202122232425262728293031323334353637383940414243service RouteGuide &#123; rpc GetFeature(Point) returns (Feature) &#123;&#125; rpc ListFeatures(Rectangle) returns (stream Feature) &#123;&#125; rpc RecordRoute(stream Point) returns (RouteSummary) &#123;&#125; rpc RouteChat(stream RouteNote) returns (stream RouteNote) &#123;&#125;&#125;message Point &#123; int32 latitude = 1; int32 longitude = 2;&#125;message Rectangle &#123; Point lo = 1; Point hi = 2;&#125;message Feature &#123; string name = 1; Point location = 2;&#125;message RouteNote &#123; Point location = 1; string message = 2;&#125;message RouteSummary &#123; int32 point_count = 1; int32 feature_count = 2; int32 distance = 3; int32 elapsed_time = 4;&#125; 如上所述，我们对四种rpc分别定义了一个方法。编译命令如下1protoc --go_out=plugins=grpc:./ route/route.proto 创建服务端回看刚才生成的代码，有这样一个接口123456type RouteGuideServer interface &#123; GetFeature(context.Context, *Point) (*Feature, error) ListFeatures(*Rectangle, RouteGuide_ListFeaturesServer) error RecordRoute(RouteGuide_RecordRouteServer) error RouteChat(RouteGuide_RouteChatServer) error&#125; 我们的服务端首先要创建一个类实现这个接口 普通rpc12345678func (s *routeGuideServer)GetFeature(ctx context.Context, point *route.Point) (*route.Feature, error)&#123; for _,feature:=range s.savedFeatures&#123; if proto.Equal(feature.Location,point)&#123; return feature,nil &#125; &#125; return &amp;route.Feature&#123;Location:point&#125;,nil&#125; 很简单，参数中的Point和Feature都是我们定义的message，通过输入一个point，然后遍历feature集合，查找符合条件的feature。注意比较两个message可以使用proto包提供的equal方法 服务端流式rpc12345678910func (s *routeGuideServer)ListFeatures(rect *route.Rectangle, stream route.RouteGuide_ListFeaturesServer) error&#123; for _,feature := range s.savedFeatures&#123; if inRange(feature.Location,rect) &#123; if err:=stream.Send(feature);err!=nil&#123; return err &#125; &#125; &#125; return nil&#125; 形象的说，这种rpc就是向服务端发送一个请求，服务端以流的形式返回数据。如代码所示，我们指定一个区域，然后判断所有保存的feature是否在区域内，每判断一个，如果符合条件就以send形式发出。grpc为我们做了很形象的包装，对于输出流，我们只需send即可，不必考虑缓存，同步之类的问题，非常方便。唯一需要注意的是，每send一个数据，就需要判断是否报错，然后随时停止。 客户端流式rpc123456789101112131415161718192021222324252627282930func (s *routeGuideServer)RecordRoute(stream route.RouteGuide_RecordRouteServer) error&#123; var pointCount, featureCount, distance int32 var lastPoint *route.Point startTime := time.Now() for &#123; point,err:=stream.Recv() if err == io.EOF&#123; endTime := time.Now() return stream.SendAndClose(&amp;route.RouteSummary&#123; PointCount:pointCount, FeatureCount:featureCount, Distance:distance, ElapsedTime:int32(endTime.Sub(startTime).Seconds()), &#125;) &#125; if err!=nil&#123; return err &#125; pointCount++ for _,feature := range s.savedFeatures&#123; if proto.Equal(feature.Location,point)&#123; featureCount++ &#125; &#125; if lastPoint != nil&#123; distance += calcDistance(lastPoint,point) &#125; lastPoint = point &#125;&#125; 我们定义的是客户端给服务端发送流式数据，然后服务端返回一个响应。如代码所示，grpc也给我提供了一个形象的封装，对于输入流，我们只需要Recv即可，然后判断输入流是否结束，通过EOF标志位，如果结束返回一个响应。注意这里返回的方法是通过调用SendAndClose方法。通过查看SendAndClose实现，他和上面的send方法一样，都是调用了SendMsg方法。 这段实现的大概意思是，客户端发送一个流，流中包含多个point数据的路径，我们遍历这个流，判断每个point是否在已有的feature集合中，然后计算路径长度，最后返回一个RouteSummary信息。 双向流式rpc123456789101112131415161718192021222324func (s *routeGuideServer)RouteChat(stream route.RouteGuide_RouteChatServer) error&#123; for&#123; in,err:=stream.Recv() if err==io.EOF&#123; return nil &#125; if err!=nil&#123; return err &#125; key := serialize(in.Location) s.mu.Lock() s.routeNotes[key] = append(s.routeNotes[key],in) rn :=make([]*route.RouteNote,len(s.routeNotes[key])) copy(rn,s.routeNotes[key]) s.mu.Unlock() for _,note:=range rn&#123; if err:=stream.Send(note);err!=nil &#123; return err &#125; &#125; &#125;&#125; 既然是双向流，那么就是即能收也能发，如代码所示，每次循环通过Recv从客户端接受一个数据，经过一系列处理后通过send给客户端发送数据。最后知道客户端发送完毕或中间报错为止 最后服务端main方法如下123456789101112131415161718func newServer() *routeGuideServer &#123; s := &amp;routeGuideServer&#123;routeNotes: make(map[string][]*route.RouteNote)&#125; data := exampleData if err := json.Unmarshal(data, &amp;s.savedFeatures); err != nil &#123; log.Fatalf("Failed to load default features: %v", err) &#125; return s&#125;func main() &#123; lis,err:=net.Listen("tcp",":1234") if err!=nil&#123; log.Fatal("listen error:",err.Error()) &#125; server:=grpc.NewServer() route.RegisterRouteGuideServer(server,newServer()) server.Serve(lis)&#125; 和helloworld一样，显示创建grpc服务实例，然后注册服务，最后让grpc接管tcp连接 创建客户端首先创建连接部分还是和helloworld一样123456conn,err:=grpc.Dial("127.0.0.1:1234",grpc.WithInsecure())if err!=nil&#123; log.Fatal("dail error",err.Error())&#125;defer conn.Close()client:=pb.NewRouteGuideClient(conn) 我们接下来还是对四种服务进行调用 普通rpc123456789101112printFeature(client, &amp;pb.Point&#123;Latitude: 409146138, Longitude: -746188906&#125;)func printFeature(client pb.RouteGuideClient, point *pb.Point) &#123; log.Printf("Getting feature for point (%d, %d)", point.Latitude, point.Longitude) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() feature, err := client.GetFeature(ctx, point) if err != nil &#123; log.Fatalf("%v.GetFeatures(_) = _, %v: ", client, err) &#125; log.Println(feature)&#125; 对于普通的rpc我们当做函数调用即可，输入一个point返回一个feature 服务端流式rpc123456789101112131415161718192021222324printFeatures(client, &amp;pb.Rectangle&#123; Lo: &amp;pb.Point&#123;Latitude: 400000000, Longitude: -750000000&#125;, Hi: &amp;pb.Point&#123;Latitude: 420000000, Longitude: -730000000&#125;,&#125;)func printFeatures(client pb.RouteGuideClient, rect *pb.Rectangle) &#123; log.Printf("Looking for features within %v", rect) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.ListFeatures(ctx, rect) if err != nil &#123; log.Fatalf("%v.ListFeatures(_) = _, %v", client, err) &#125; for &#123; feature, err := stream.Recv() if err == io.EOF &#123; break &#125; if err != nil &#123; log.Fatalf("%v.ListFeatures(_) = _, %v", client, err) &#125; log.Println(feature) &#125;&#125; 前面说过，这种类型的rpc是客户端发送一个请求，服务端返回一个数据流。这里我们调用ListFeatures方法，给我们返回一个流，然后我们遍历这个流，通过Recv()一次接受一个数据，并通过EOF标志位判断流是否结束 客户端流式rpc123456789101112131415161718192021222324252627runRecordRoute(client)func runRecordRoute(client pb.RouteGuideClient) &#123; r := rand.New(rand.NewSource(time.Now().UnixNano())) pointCount := int(r.Int31n(100)) + 2 var points []*pb.Point for i := 0; i &lt; pointCount; i++ &#123; points = append(points, randomPoint(r)) &#125; log.Printf("Traversing %d points.", len(points)) ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.RecordRoute(ctx) if err != nil &#123; log.Fatalf("%v.RecordRoute(_) = _, %v", client, err) &#125; for _, point := range points &#123; if err := stream.Send(point); err != nil &#123; log.Fatalf("%v.Send(%v) = %v", stream, point, err) &#125; &#125; reply, err := stream.CloseAndRecv() if err != nil &#123; log.Fatalf("%v.CloseAndRecv() got error %v, want %v", stream, err, nil) &#125; log.Printf("Route summary: %v", reply)&#125; 对于这种类型，客户端是发送一系列数据，而服务端返回一个响应，如上面代码所述，我们先随机一些point，然后通过send方法一个一个发送给客户端，发送完后，调用CloseAndRecv关闭流然后等待服务端响应。CloseAndRecv和服务端使用的SendAndClose相对应。 双向流式rpc12345678910111213141516171819202122232425262728293031323334353637383940runRouteChat(client)func runRouteChat(client pb.RouteGuideClient) &#123; notes := []*pb.RouteNote&#123; &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 1&#125;, Message: "First message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 2&#125;, Message: "Second message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 3&#125;, Message: "Third message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 1&#125;, Message: "Fourth message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 2&#125;, Message: "Fifth message"&#125;, &#123;Location: &amp;pb.Point&#123;Latitude: 0, Longitude: 3&#125;, Message: "Sixth message"&#125;, &#125; ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() stream, err := client.RouteChat(ctx) if err != nil &#123; log.Fatalf("%v.RouteChat(_) = _, %v", client, err) &#125; waitc := make(chan struct&#123;&#125;) go func() &#123; for &#123; in, err := stream.Recv() if err == io.EOF &#123; // read done. close(waitc) return &#125; if err != nil &#123; log.Fatalf("Failed to receive a note : %v", err) &#125; log.Printf("Got message %s at point(%d, %d)", in.Message, in.Location.Latitude, in.Location.Longitude) &#125; &#125;() for _, note := range notes &#123; if err := stream.Send(note); err != nil &#123; log.Fatalf("Failed to send a note: %v", err) &#125; &#125; stream.CloseSend() &lt;-waitc&#125; 由于客户端与服务端都是收发流数据，在服务端是收到一个数据处理一个然后返回一个，所以我们在客户端不断的发送数据的同时，也启动一个goroutine去接受数据，在发送完数据后要关闭输出流。 总结 对于普通rpc，客户端就当做方法调用一样去调用某个远端的方法，服务端接受数据后按照返回参数返回值即可 对于服务端流式rpc，客户端通过调用方法发送一个数据，然后利用返回值stream去不断接受数据；而服务端在接受到请求后，不断用send发送数据。 对于客户端流式rpc，客户端通过调用方法获得一个stream后，不断的send发送数据，发送完毕后调用CloseAndRecv关闭输出流并等待响应；而服务端不断使用Recv去接受数据，接受完之后调用SendAndClose关闭输入流发送响应 对于双向流式rpc，客户端通过调用方法获得一个stream后，不断的send发送数据，并在发送的时候启动一个goroutine通过Recv接受数据；而服务端则不断的接受数据、处理数据、返回数据。客户端在发送完毕后注意通过CloseSend关闭输出流]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AES加密]]></title>
    <url>%2F2019%2F03%2F30%2FAES%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景全称Advanced Encryption Standard，即高级加密标准。又称Rijndael加密法。是一个用来替换DES的加密算法，在全世界已经广泛使用，官方文档。 算法简述AES算法支持的秘钥长度和明文块位128~256位（32位为步长），常用的组合是128位明文块和128位密文；128位明文块和256位密文。（严格地说，AES和Rijndael加密法并不完全一样，因为Rijndael加密法可以支持更大范围的区块和密钥长度：AES的区块长度固定为128比特，密钥长度则可以是128，192或256比特；而Rijndael使用的密钥和区块长度均可以是128，192或256比特。） AES密码使用了替换与置换思想，秘钥和明文块的长度决定了需要运行的轮数，最少是10轮，即秘钥和明文块都是128位。算法分为以下两个步骤 一次性初始化操作 轮次操作 本文以128位秘钥和128位明文块为标准介绍 一次性初始化操作扩展秘钥输入的秘钥长度为16字节，需要扩展到11个4*4的矩阵中。也就是说将16字节秘钥扩展为176字节。 秘钥扩展可以表示为下图 扩展出来的第一个矩阵就是输入矩阵，将输入矩阵每4字节记为一个字。以K0=a，k1=b，k2=c，k3=d为例，w0=abcd，依次类推。接着记w0，w1，w2，w3位w数组。用w数组扩展出剩余40个w。剩余40个w分别记为w4，w5，…，w43。其中每个wi都和w(i-1)以及w(i-4)有关，基本规则如下： 若i不是4的倍数，则wi = W(i-1) XOR w(i-4)。若i是4的倍数，wi = T(w(i-1)) XOR w(i-4).函数T流程如下图： T函数分为3部分：旋转，代换，常量异或： 旋转：将一个字中的四个字节循环左移1字节，如abcd变为bcda 代换：使用s盒代换，把每个字节的高四位作为行值，第四位作为列值在S盒寻找输出，S盒如下 常量异或：有10个常量，每轮取一个进行异或，这几个常量如下： 轮数 1 2 3 4 5 6 7 8 9 10 常量值 01 02 04 08 10 20 40 80 1B 36 简单示例12345678910111213141516假设初始秘钥分别为：00 01 02 ... 0F，则w0 = 00 01 02 03w1 = 04 05 06 07w2 = 08 09 0A 0Bw3 = 0C 0D 0E 0F为了计算w4，先计算T(w3):旋转得：0D 0E 0F 0CS盒替换得：D7 AB 76 FE常量异或得：D6 AB 76 FE将T函数输出再与w0异或得w4 = D6 AA 72 FDw5 = w4 XOR w1w6 = w5 XOR w2w7 = w6 XOR w3 明文初始化由于明文块也是128位，即16字节，左移也将这16个字节写位4*4的矩阵，列优先。之后与第一个秘钥对应字节进行异或运算。 轮次运算每一轮依次有以下几步 s盒替换就是将输入的矩阵每个元素进行s盒替换 旋转将矩阵第i行循环左移i个字节，如下列1234567891 5 9 132 6 10 143 7 11 154 8 12 16旋转后1 5 9 136 10 14 211 15 3 716 4 8 12 混合列操作将上一步的结果与常量矩阵相乘，运算规则如下1234567891011121314151617有常量矩阵 2 3 1 1A = 1 2 3 1 1 1 2 3 3 1 1 2有输入矩阵 b1 b5 b9 b13b = b2 b6 b10 b14 b3 b7 b11 b15 b4 b8 b12 b16则A*b结果的第一列如下c1 = (b1*2)XOR(b2*3)XOR(b3*1)XOR(b4*1)c1 = (b1*1)XOR(b2*2)XOR(b3*3)XOR(b4*1)c1 = (b1*1)XOR(b2*1)XOR(b3*2)XOR(b4*3)c1 = (b1*3)XOR(b2*1)XOR(b3*1)XOR(b4*2)实际上数学中的矩阵相乘类似，只不过相加改为了异或 结果还是一个4*4矩阵 秘钥异或将上步输出的矩阵与该轮对应的秘钥进行异或运算 总体流程如下（注意最后一轮没有列混合运算） 解密流程也如上图所示，就是反过来，其中s盒的逆如下 解密的逆列混淆用的是如下常数矩阵去乘以密文矩阵：12340E 0B 0D 0909 0E 0B 0D0D 09 0E 0B0B 0D 09 0E 题图来自unsplash：https://unsplash.com/photos/ARVFsI-32Uk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中rpc源码学习]]></title>
    <url>%2F2019%2F03%2F29%2Fgo-ethereum%E4%B8%ADrpc%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[背景RPC全称Remote Procedure Call，即远程过程调用是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。 运行时一次客户机对服务器的RPC调用，基本过程如下图： go语言中的rpcgo语言的标准包中以及有了对RPC的支持，分别在三个层面上即TCP、HTTP和JSONRPC上提供了支持。除了JSONRPC其余两种都只支持以go语言开发的客户端与服务器。 首先，在Go中一个正确的RPC函数应该满足下面要求 函数必须是可导出的（首字母大写） 必须有两个可导出类型的参数 第一个是接受的参数，第二个是返回参数 函数必须有一个error类型的返回值 例子如下：1func (t *T) MethodName(argType T1, replyType *T2) error HTTP RPC服务端代码123456789101112131415161718type HelloService struct &#123;&#125;func (p *HelloService)Hello(requset string,reply *string)error&#123; *reply = "hello " + requset return nil&#125;func main() &#123; rpc.Register(new(HelloService)) rpc.HandleHTTP() err:=http.ListenAndServe(":1234",nil) if err!=nil &#123; fmt.Println(err.Error()) &#125;&#125; 关键有两点，一个是定义供客户端调用的方法，另一个是注册服务，并使RPC托管http服务，最后正常启动http服务 客户端代码123456789func main() &#123; client,err:=rpc.DialHTTP("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; TPC RPC服务端代码12345678910111213func main() &#123; rpc.Register(new(HelloService)) lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; conn,err:=lis.Accept() if err!=nil &#123; log.Fatal("accept:",err.Error()) &#125; rpc.ServeConn(conn)&#125; 供远程调用的方法和前面的例子一样，不在重复，tcprpc和httprpc的不同点就是在于首先正常启动tcp监听，然后接收到的连接交给rpc即可 客户端代码123456789func main() &#123; client,err:=rpc.Dial("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; 和httprpc的唯一区别就是初始化客户端对象的方法不同 jsonRPC服务端代码12345678910111213func main() &#123; rpc.Register(new(HelloService)) lis,err:=net.Listen("tcp",":1234") if err!=nil &#123; log.Fatal("listen:",err.Error()) &#125; conn,err:=lis.Accept() if err!=nil &#123; log.Fatal("accept:",err.Error()) &#125; jsonrpc.ServeConn(conn)&#125; 相比较tcprpc只是在处理tcp连接时使用rpcjson提供的方法。 客户端代码123456789func main() &#123; client,err:=jsonrpc.Dial("tcp",":1234") if err!=nil &#123; log.Fatal("dial",err.Error()) &#125; var reply string err = client.Call("HelloService.Hello","world",&amp;reply) fmt.Println(reply)&#125; 唯一区别也只是在创建client实例时的不同，使用jsonrpc提供的方法 由于tcprpc和httprpc都采用gob编码，所以不能跨语言使用，而jsonrpc采用的json格式编码，可以很方便的跨语言，这里提供一个go语言和java语言交互的例子，其中服务端由go语言编写，如上面所示，java编写的客户端如下：1234567891011121314151617181920212223242526272829303132333435public class ClientRequest &#123; public String method; public String[] params; public int id;&#125;public class ServerResponse &#123; public int id; public String result; public String error;&#125;public static void main(String[] args)&#123; try(Socket client = new Socket("127.0.0.1",1234))&#123; OutputStream out = client.getOutputStream(); Gson gson = new Gson(); ClientRequest request = new ClientRequest(); request.id = 1; request.method = "HelloService.Hello"; request.params = new String[]&#123;"hello"&#125;; out.write(gson.toJson(request).getBytes()); client.shutdownOutput(); InputStream in = client.getInputStream(); int len; byte[] buffer = new byte[1024]; StringBuilder sb = new StringBuilder(); while ((len = in.read(buffer))!=-1) sb.append(new String(buffer,0,len)); ServerResponse response = gson.fromJson(sb.toString(),ServerResponse.class); client.shutdownInput(); System.out.println(response.result); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;&#125; 还是基于TCP通信的，由于是借助json传输的，所以需要有json序列化和反序列化操作，且json格式要符合go语言的规定。go语言中规定请求的格式如下：12345678910111213//客户端请求type clientRequest struct&#123; Method string `json:"method"` Params [1]interface&#123;&#125; `json:"params"` Id uint64 `json:"id"`&#125;//服务端请求type serverRequest struct&#123; Method string `json:"method"` Params *json.RawMessage `json:"params"` Id *json.RawMessage `json:"id"`&#125; 规定响应的格式如下123456789101112//客户端响应type clientResponse struct&#123; Id uint64 `json:"id"` Result *json.RawMessage `json:"result"` Error interface&#123;&#125; `json:"error"`&#125;//服务端响应type serverResponse struct&#123; Id uint64 `json:"id"` Result interface&#123;&#125; `json:"result"` Error interface&#123;&#125; `json:"error"`&#125; 在跨语言交互时，要根据上面的定义，编写对应的json文件 go-ethereum中的rpc主要集中在rpc目录下 server.go服务创建与注册首先从服务端开始看，server的结构体以及创建如下123456789101112131415161718// go-ethereum\rpc\server.gotype Server struct &#123; services serviceRegistry idgen func() ID run int32 codecs mapset.Set&#125;type serviceRegistry struct &#123; mu sync.Mutex services map[string]service&#125;func NewServer() *Server &#123; server := &amp;Server&#123;idgen: randomIDGenerator(), codecs: mapset.NewSet(), run: 1&#125; rpcService := &amp;RPCService&#123;server&#125; //MetadataApi = "rpc" server.RegisterName(MetadataApi, rpcService) return server&#125; 结构体中services的类型是serviceRegistry实际上就是记录了所有注册的服务。run用来控制server的运行。codecs是一个set类型，存储所有编解码器。 在创建server时，randomIDGenerator()是一个id的随机生成器。随后调用RegisterName把自己的实例注册进去（RPCService包装了server类）1234567891011121314151617181920212223242526272829303132333435363738func (s *Server) RegisterName(name string, receiver interface&#123;&#125;) error &#123; return s.services.registerName(name, receiver)&#125;// go-ethereum\rpc\service.gofunc (r *serviceRegistry) registerName(name string, rcvr interface&#123;&#125;) error &#123; rcvrVal := reflect.ValueOf(rcvr) if name == "" &#123; return fmt.Errorf("no service name for type %s", rcvrVal.Type().String()) &#125; callbacks := suitableCallbacks(rcvrVal) if len(callbacks) == 0 &#123; return fmt.Errorf("service %T doesn't have any suitable methods/subscriptions to expose", rcvr) &#125; r.mu.Lock() defer r.mu.Unlock() if r.services == nil &#123; r.services = make(map[string]service) &#125; svc, ok := r.services[name] if !ok &#123; svc = service&#123; name: name, callbacks: make(map[string]*callback), subscriptions: make(map[string]*callback), &#125; r.services[name] = svc &#125; for name, cb := range callbacks &#123; if cb.isSubscribe &#123; svc.subscriptions[name] = cb &#125; else &#123; svc.callbacks[name] = cb &#125; &#125; return nil&#125; suitableCallbacks方法如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// go-ethereum\rpc\service.gofunc suitableCallbacks(receiver reflect.Value) map[string]*callback &#123; typ := receiver.Type() callbacks := make(map[string]*callback) for m := 0; m &lt; typ.NumMethod(); m++ &#123; method := typ.Method(m) if method.PkgPath != "" &#123; continue // method not exported &#125; cb := newCallback(receiver, method.Func) if cb == nil &#123; continue // function invalid &#125; name := formatName(method.Name) callbacks[name] = cb &#125; return callbacks&#125;func newCallback(receiver, fn reflect.Value) *callback &#123; fntype := fn.Type() c := &amp;callback&#123;fn: fn, rcvr: receiver, errPos: -1, isSubscribe: isPubSub(fntype)&#125; c.makeArgTypes() if !allExportedOrBuiltin(c.argTypes) &#123; return nil &#125; outs := make([]reflect.Type, fntype.NumOut()) for i := 0; i &lt; fntype.NumOut(); i++ &#123; outs[i] = fntype.Out(i) &#125; if len(outs) &gt; 2 || !allExportedOrBuiltin(outs) &#123; return nil &#125; switch &#123; case len(outs) == 1 &amp;&amp; isErrorType(outs[0]): c.errPos = 0 case len(outs) == 2: if isErrorType(outs[0]) || !isErrorType(outs[1]) &#123; return nil &#125; c.errPos = 1 &#125; return c&#125;type callback struct &#123; fn reflect.Value rcvr reflect.Value argTypes []reflect.Type hasCtx bool errPos int isSubscribe bool &#125; 在suitableCallbacks内先遍历了server的所有方法，对于可导出的，利用newCallback方法创建一个callback对象。一个callback对象中的几个成员意义如下： fn表示对于的方法 rcvr表示方法所在的类 argtypes存储所有输入参数类型（context除外） hasCtx表示参数中是否有Context类型，. errPos表示error类型的返回值是第几个 isSubscribe表示该方法是否可订阅（满足三个条件：第二个输入参数是Context类型，第一个输出参数是Subscription类型，第二个输出参数是error类型） 最后suitableCallbacks返回一个map存储符合条件的callback。接下来初始化serviceRegistry的services，也是一个map。然后创建一个service，存入services。最后遍历刚才callbacks，将其中的可订阅的方法单独拿出来。 总结一下，所谓的serviceRegistry注册方法就是给一个类，然后遍历所有方法，根据方法的参数与返回值归类，最后以service的形式放到serviceRegistry的services中. 服务启动及rpc请求处理分析1234567891011121314// go-ethereum\rpc\ipc.gofunc (s *Server) ServeListener(l net.Listener) error &#123; for &#123; conn, err := l.Accept() if netutil.IsTemporaryError(err) &#123; log.Warn("RPC accept error", "err", err) continue &#125; else if err != nil &#123; return err &#125; log.Trace("Accepted RPC connection", "conn", conn.RemoteAddr()) go s.ServeCodec(NewJSONCodec(conn), OptionMethodInvocation|OptionSubscriptions) &#125;&#125; 整个是一个无限循环，每次循环接受一个连接，然后启动一个goroutine去调用ServeCodec处理，第一个参数是ServerCodec类型：12345678910111213141516171819func NewJSONCodec(conn Conn) ServerCodec &#123; enc := json.NewEncoder(conn) dec := json.NewDecoder(conn) dec.UseNumber() return NewCodec(conn, enc.Encode, dec.Decode)&#125;func NewCodec(conn Conn, encode, decode func(v interface&#123;&#125;) error) ServerCodec &#123; codec := &amp;jsonCodec&#123; closed: make(chan interface&#123;&#125;), encode: encode, decode: decode, conn: conn, &#125; if ra, ok := conn.(ConnRemoteAddr); ok &#123; codec.remoteAddr = ra.RemoteAddr() &#125; return codec&#125; 具体来说是一个jsonCodec对象，用于读写jsonrpc请求与响应的。ServeCodec的第二个参数是一个选项，但是新版本的go-ethereum不在支持该选项，所以弃用。总的来说codec类型对象就代表的是一个个连接请求 具体来说ServeCodec方法是读取一个请求，然后使用合适的callback去处理，最后返回，来看具体代码123456789101112131415// go-ethereum\rpc\server.gofunc (s *Server) ServeCodec(codec ServerCodec, options CodecOption) &#123; defer codec.Close() if atomic.LoadInt32(&amp;s.run) == 0 &#123; return &#125; s.codecs.Add(codec) defer s.codecs.Remove(codec) c := initClient(codec, s.idgen, &amp;s.services) &lt;-codec.Closed() c.Close()&#125; 前面说过run成员是控制运行的，如果等于0就不执行任何操作。然后将codec添加到set集合中，然后初始化一个Client去处理，最后等待codec关闭后，关闭Client。一个client就代表一个连接。初始化客户端代码如下1234567891011121314151617181920212223// go-ethereum\rpc\client.gofunc initClient(conn ServerCodec, idgen func() ID, services *serviceRegistry) *Client &#123; _, isHTTP := conn.(*httpConn) c := &amp;Client&#123; idgen: idgen, isHTTP: isHTTP, services: services, writeConn: conn, close: make(chan struct&#123;&#125;), closing: make(chan struct&#123;&#125;), didClose: make(chan struct&#123;&#125;), reconnected: make(chan ServerCodec), readOp: make(chan readOp), readErr: make(chan error), reqInit: make(chan *requestOp), reqSent: make(chan error, 1), reqTimeout: make(chan *requestOp), &#125; if !isHTTP &#123; go c.dispatch(conn) &#125; return c&#125; 就是简单的初始化，不过通过判断是否是http类型连接来决定是否分发。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// go-ethereum\rpc\client.gofunc (c *Client) dispatch(codec ServerCodec) &#123; var ( lastOp *requestOp reqInitLock = c.reqInit conn = c.newClientConn(codec) reading = true ) defer func() &#123; close(c.closing) if reading &#123; conn.close(ErrClientQuit, nil) c.drainRead() &#125; close(c.didClose) &#125;() go c.read(codec) for &#123; select &#123; case &lt;-c.close: return case op := &lt;-c.readOp: if op.batch &#123; conn.handler.handleBatch(op.msgs) &#125; else &#123; conn.handler.handleMsg(op.msgs[0]) &#125; case err := &lt;-c.readErr: conn.handler.log.Debug("RPC connection read error", "err", err) conn.close(err, lastOp) reading = false case newcodec := &lt;-c.reconnected: log.Debug("RPC client reconnected", "reading", reading, "conn", newcodec.RemoteAddr()) if reading &#123; conn.close(errClientReconnected, lastOp) c.drainRead() &#125; go c.read(newcodec) reading = true conn = c.newClientConn(newcodec) conn.handler.addRequestOp(lastOp) case op := &lt;-reqInitLock: reqInitLock = nil lastOp = op conn.handler.addRequestOp(op) case err := &lt;-c.reqSent: if err != nil &#123; conn.handler.removeRequestOp(lastOp) &#125; reqInitLock = c.reqInit lastOp = nil case op := &lt;-c.reqTimeout: conn.handler.removeRequestOp(op) &#125; &#125;&#125; 大体上来看dispatch方法是一个无限循环，每次循环都借助channel机制实现对不同的情况做不同处理，在循环阻塞时，启动了一个goroutine，去读取rpc请求12345678910111213func (c *Client) read(codec ServerCodec) &#123; for &#123; msgs, batch, err := codec.Read() if _, ok := err.(*json.SyntaxError); ok &#123; codec.Write(context.Background(), errorMessage(&amp;parseError&#123;err.Error()&#125;)) &#125; if err != nil &#123; c.readErr &lt;- err return &#125; c.readOp &lt;- readOp&#123;msgs, batch&#125; &#125;&#125; 这里就很清楚，直接调用ServerCodec的read方法，我们前面说过ServerCodec是一个个连接请求的包装，而这里的ServerCodec实际上是个jsonCodec类型，我们看看它的read方法123456789101112131415161718192021222324func (c *jsonCodec) Read() (msg []*jsonrpcMessage, batch bool, err error) &#123; var rawmsg json.RawMessage if err := c.decode(&amp;rawmsg); err != nil &#123; return nil, false, err &#125; msg, batch = parseMessage(rawmsg) return msg, batch, nil&#125;func parseMessage(raw json.RawMessage) ([]*jsonrpcMessage, bool) &#123; if !isBatch(raw) &#123; msgs := []*jsonrpcMessage&#123;&#123;&#125;&#125; json.Unmarshal(raw, &amp;msgs[0]) return msgs, false &#125; dec := json.NewDecoder(bytes.NewReader(raw)) dec.Token() // skip '[' var msgs []*jsonrpcMessage for dec.More() &#123; msgs = append(msgs, new(jsonrpcMessage)) dec.Decode(&amp;msgs[len(msgs)-1]) &#125; return msgs, true&#125; 这里的decode就是json.NewDecoder(conn)创建的，它将请求中的数据流转为一个json原始格式信息，为的是接下来反序列化。isBatch检查数据中第一个非空字符是否是“[”，如果是的话表示是一个json数据格式。总之最后解析为jsonrpcMessage对象，结构如下12345678type jsonrpcMessage struct &#123; Version string `json:"jsonrpc,omitempty"` ID json.RawMessage `json:"id,omitempty"` Method string `json:"method,omitempty"` Params json.RawMessage `json:"params,omitempty"` Error *jsonError `json:"error,omitempty"` Result json.RawMessage `json:"result,omitempty"`&#125; 我们继续回到read方法中，当正确解析请求的内容时，返回值打包为readOp类型，然后写入Client的readOp这个chan字段中，这时触发dispatch中的select，执行下面逻辑：12345if op.batch &#123; conn.handler.handleBatch(op.msgs)&#125; else &#123; conn.handler.handleMsg(op.msgs[0])&#125; op.batch代表是否有多个jsonrpcMessage，以此执行不同逻辑。这里的conn是一个clientConn类型，包装了ServerCodec以及一个handler。我们下面看一下只有一个message的处理逻辑1234567// go-ethereum\rpc\handler.gofunc (h *handler) handleMsg(msg *jsonrpcMessage) &#123; if ok := h.handleImmediate(msg); ok &#123; return &#125; h.startCallProc(....)&#125; 第一行中handleImmediate处理的是不需要回复的请求，如一个通知或一个响应。通过方法名，ID以及参数等综合判断。对于正常请求调用startCallProc开始处理。123456789func (h *handler) startCallProc(fn func(*callProc)) &#123; h.callWG.Add(1) go func() &#123; ctx, cancel := context.WithCancel(h.rootCtx) defer h.callWG.Done() defer cancel() fn(&amp;callProc&#123;ctx: ctx&#125;) &#125;()&#125; h.callWG是一个sync.WaitGroup类型，为的是线程同步，这里加一表示有一个goroutine在运行，后面启动一个goroutine，这里面的实际逻辑是先前传递进来的func，如下12345678910func(cp *callProc) &#123; answer := h.handleCallMsg(cp, msg) h.addSubscriptions(cp.notifiers) if answer != nil &#123; h.conn.Write(cp.ctx, answer) &#125; for _, n := range cp.notifiers &#123; n.activate() &#125; &#125; 这里调用handleCallMsg去处理message：123456789101112131415161718192021func (h *handler) handleCallMsg(ctx *callProc, msg *jsonrpcMessage) *jsonrpcMessage &#123; start := time.Now() switch &#123; case msg.isNotification(): h.handleCall(ctx, msg) h.log.Debug("Served "+msg.Method, "t", time.Since(start)) return nil case msg.isCall(): resp := h.handleCall(ctx, msg) if resp.Error != nil &#123; h.log.Info("Served "+msg.Method, "reqid", idForLog&#123;msg.ID&#125;, "t", time.Since(start), "err", resp.Error.Message) &#125; else &#123; h.log.Debug("Served "+msg.Method, "reqid", idForLog&#123;msg.ID&#125;, "t", time.Since(start)) &#125; return resp case msg.hasValidID(): return msg.errorResponse(&amp;invalidRequestError&#123;"invalid request"&#125;) default: return errorMessage(&amp;invalidRequestError&#123;"invalid request"&#125;) &#125;&#125; 不管是通知类型还是调用类型，都调用的是handleCall方法：1234567891011121314151617181920func (h *handler) handleCall(cp *callProc, msg *jsonrpcMessage) *jsonrpcMessage &#123; if msg.isSubscribe() &#123; return h.handleSubscribe(cp, msg) &#125; var callb *callback if msg.isUnsubscribe() &#123; callb = h.unsubscribeCb &#125; else &#123; callb = h.reg.callback(msg.Method) &#125; if callb == nil &#123; return msg.errorResponse(&amp;methodNotFoundError&#123;method: msg.Method&#125;) &#125; args, err := parsePositionalArguments(msg.Params, callb.argTypes) if err != nil &#123; return msg.errorResponse(&amp;invalidParamsError&#123;err.Error()&#125;) &#125; return h.runMethod(cp.ctx, msg, callb, args)&#125; 分了三种情况：订阅请求，取消订阅请求以及一般请求。我们先看一般请求：h.reg是serviceRegistry，handler的serviceRegistry是前面dispatch方法创建clientConn时创建handle时传入的，来自于client的services字段，而client的services字段是在server的ServeCodec方法中调用initClient传入的，实际上就是Server的services字段。我们上节了解到在server会有一个registerName动作，会解析rpcserver的所有可导出方法，并用callback包装，而在handleCall中，就调用了serviceRegistry方法123456789func (r *serviceRegistry) callback(method string) *callback &#123; elem := strings.SplitN(method, serviceMethodSeparator, 2) if len(elem) != 2 &#123; return nil &#125; r.mu.Lock() defer r.mu.Unlock() return r.services[elem[0]].callbacks[elem[1]]&#125; 首先解析方法名，然后从services中，这里保存了一系列注册的服务，在从各个服务的callbacks集合中寻找对应的callback。继续回到handleCall，若找的callback不为空，则尝试解析参数：1234567891011121314151617181920212223242526272829303132333435363738394041func parsePositionalArguments(rawArgs json.RawMessage, types []reflect.Type) ([]reflect.Value, error) &#123; dec := json.NewDecoder(bytes.NewReader(rawArgs)) var args []reflect.Value tok, err := dec.Token() switch &#123; case err == io.EOF || tok == nil &amp;&amp; err == nil: case err != nil: return nil, err case tok == json.Delim('['): if args, err = parseArgumentArray(dec, types); err != nil &#123; return nil, err &#125; default: return nil, errors.New("non-array args") &#125; for i := len(args); i &lt; len(types); i++ &#123; if types[i].Kind() != reflect.Ptr &#123; return nil, fmt.Errorf("missing value for required argument %d", i) &#125; args = append(args, reflect.Zero(types[i])) &#125; return args, nil&#125;func parseArgumentArray(dec *json.Decoder, types []reflect.Type) ([]reflect.Value, error) &#123; args := make([]reflect.Value, 0, len(types)) for i := 0; dec.More(); i++ &#123; if i &gt;= len(types) &#123; return args, fmt.Errorf("too many arguments, want at most %d", len(types)) &#125; argval := reflect.New(types[i]) if err := dec.Decode(argval.Interface()); err != nil &#123; return args, fmt.Errorf("invalid argument %d: %v", i, err) &#125; if argval.IsNil() &amp;&amp; types[i].Kind() != reflect.Ptr &#123; return args, fmt.Errorf("missing value for required argument %d", i) &#125; args = append(args, argval.Elem()) &#125; _, err := dec.Token() return args, err&#125; 主要逻辑是在parseArgumentArray中，根据方法的参数列表类型一个一个进行解析，对于没有的参数设为该类型的默认空值，最后返回一组参数。在handleCall的最后去执行方法：12345678910111213141516171819202122232425262728293031323334353637func (h *handler) runMethod(ctx context.Context, msg *jsonrpcMessage, callb *callback, args []reflect.Value) *jsonrpcMessage &#123; result, err := callb.call(ctx, msg.Method, args) if err != nil &#123; return msg.errorResponse(err) &#125; return msg.response(result)&#125;func (c *callback) call(ctx context.Context, method string, args []reflect.Value) (res interface&#123;&#125;, errRes error) &#123; fullargs := make([]reflect.Value, 0, 2+len(args)) if c.rcvr.IsValid() &#123; fullargs = append(fullargs, c.rcvr) &#125; if c.hasCtx &#123; fullargs = append(fullargs, reflect.ValueOf(ctx)) &#125; fullargs = append(fullargs, args...) defer func() &#123; if err := recover(); err != nil &#123; const size = 64 &lt;&lt; 10 buf := make([]byte, size) buf = buf[:runtime.Stack(buf, false)] log.Error("RPC method " + method + " crashed: " + fmt.Sprintf("%v\n%s", err, buf)) errRes = errors.New("method handler crashed") &#125; &#125;() results := c.fn.Call(fullargs) if len(results) == 0 &#123; return nil, nil &#125; if c.errPos &gt;= 0 &amp;&amp; !results[c.errPos].IsNil() &#123; err := results[c.errPos].Interface().(error) return reflect.Value&#123;&#125;, err &#125; return results[0].Interface(), nil&#125; 基本上就是补全参数，然后调用callback中保存的func去执行，然后进行错误处理，最后返回结果也就是响应。回到runMethod中，调用response去包装结果123456789// go-ethereum\rpc\json.gofunc (msg *jsonrpcMessage) response(result interface&#123;&#125;) *jsonrpcMessage &#123; enc, err := json.Marshal(result) if err != nil &#123; // TODO: wrap with 'internal server error' return msg.errorResponse(err) &#125; return &amp;jsonrpcMessage&#123;Version: vsn, ID: msg.ID, Result: enc&#125;&#125; 这一步是将结果序列化，最后包装成为一个jsonrpcMessage。到这里handleCall流程结束，回到handleCallMsg，直接返回响应，再往回调，来到startCallProc方法，如果响应不为空，则调用write写入响应，一次rpc普通调用完成！负责写的还是ServerCodec类型对象，具体就是jsonCodec，最后写入响应流中。 总结一下，大致流程就是当接收到一个网络请求时，就启动一个goroutine，同时创建一个ServerCodec去包装过来的连接，在这个goroutine中会初始化一个client对象，代表一个连接，在初始化之后会进行连接的分发，分发就是有一个无限循环，同时再启动一个goroutine去解析请求信息，根据信息去开始注册的服务中查找合适的callback然后传入请求体重的参数执行响应逻辑，最后在利用ServerCodec去写会响应。 服务的关闭123456789func (s *Server) Stop() &#123; if atomic.CompareAndSwapInt32(&amp;s.run, 1, 0) &#123; log.Debug("RPC server shutting down") s.codecs.Each(func(c interface&#123;&#125;) bool &#123; c.(ServerCodec).Close() return true &#125;) &#125;&#125; 首先将标志位run置0，这样后续新的连接就被放弃（参见ServeCodec方法），然后遍历set，对每个ServerCodec执行close方法。123456func (c *jsonCodec) Close() &#123; c.closer.Do(func() &#123; close(c.closed) c.conn.Close() &#125;)&#125; 主要就是关闭channel和连接。channel关闭后影响ServeCodec方法，原来阻塞地方开始执行，然后关闭client12345678910func (c *Client) Close() &#123; if c.isHTTP &#123; return &#125; select &#123; case c.close &lt;- struct&#123;&#125;&#123;&#125;: &lt;-c.didClose case &lt;-c.didClose: &#125;&#125; 这里首先close这个channel获得值，在dispatch的那个无限循环中的到触发，跳出循环，执行defer逻辑，12345678defer func() &#123; close(c.closing) if reading &#123; conn.close(ErrClientQuit, nil) c.drainRead() &#125; close(c.didClose) &#125;() 这里进行最后善后处理，关闭完didClose后，上面Close()方法中最后阻塞得到解除，方法正常执行完毕。 题图来自unsplash：https://unsplash.com/photos/zNNPSqKRR2c]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC5加密]]></title>
    <url>%2F2019%2F03%2F28%2FRC5%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景RC5全称Rivest Cipher5，,是1994年Ron Rivest设计的（原始论文）。AES的候选算法之一RC6就是基于RC5开发的。这种算法具有块可变，秘钥长度可变，加密轮数可变的特点，非常灵活。并且，操作简单，仅需加法、移位、异或即可完成，而且内存占用极少 基本原理首先加密前要确定块长，轮数和秘钥长度，确定后不可改变。其中块长可选16,32或64位。轮数介于1-255之间，秘钥长度介于0-255字节。为了便于记忆，我们定义RC5-w/r/b表示一个实例，w/r/b分别表示一个字的长度（算法以两个字位一单位），轮数和秘钥长。推荐的最低安全标准为RC5-32/16/16 加密时都先将明文块分两部分，用这两部分开始若干轮计算，每轮都涉及相加、移位和异或，最后输出密文 详细流程初始化操作首相将明文分为A,B两部分。然后A与子秘钥S[0]相加，B与子秘钥S[1]相加，结果分别用2^w求模，得到C,D 每一轮细节 C和D异或得E E循环左移D位 E与子秘钥S[2i]相加得F。同样也要模2^w，i表示第几轮 D与F异或得G G循环左移F位 G与子秘钥S[2i+1]相加得H。同样也要模2^w，i表示第几轮 若还有轮数则C=F，D=H 基本可以写成下列形式12345A = A + S[0]B = B + S[1]for i = 1 to r: A = ((A XOR B) &lt;&lt;&lt; B) + S[2i] B = ((B XOR A) &lt;&lt;&lt; A) + S[2i+1] 秘钥计算子秘钥生成首先取两个常亮P、Q。P与Q在不同的w也就是字长下有不同值： W P Q 16 0xB7E1 0x9E37 32 0xB7E15163 0x9E3779B9 64 0xB7E151628AED2A6B 0x9E3779B97F4A7C15 P、Q计算公式分别如下： 第一个公式中的e表示自然常数，即2.71828… 第二个公式中的φ表示黄金比例，即1.618….。odd表示取最接近给定输入的奇数。P、Q都是魔法数字，没有任何来源根据. 得到两个常数后，令S[0] = P，从i=1开始循环，i每个循环递增1，每次循环计算A = S[i-1]+Q，B = A mod 2^w，S[i] = B。一直循环2(r+1)-1次。表示如下123s[0] = Pfor i = 1 to 2(r+1)-1: s[i] = (s[i-1]+Q) mod 2^w 子秘钥混合该阶段将子秘钥S与秘钥L进行混合1234567i = j = 0A = B = 0do 3 * max(2(r+1), (b*8)/w) times: A = S[i] = (S[i] + A + B) &lt;&lt;&lt; 3 B = L[j] = (L[j] + A + B) &lt;&lt;&lt; (A + B) i = (i + 1) mod 2(r+1) j = (j + 1) mod (b*8)/w 解密解密就是将加密过程颠倒123456for i = r to 1: A = ((B - S[2i+1])&gt;&gt;&gt;A) XOR A B = ((A - S[2i])&gt;&gt;&gt;B) XOR BB = B - S[1]A = A - S[0] 安全性12轮RC5(64位块)容易受到使用了2^44的选定的明文的差分攻击。18–20轮加密则被认为可以提供足够的保护。更大的安全性可以通过增加轮数获得，其代价是减少密码的吞吐量。 实现论文附录中作者给出了详细实现，这里不再列出。 题图来自unsplash：https://unsplash.com/photos/WhRsHmFtFXQ]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中ethdb源码学习]]></title>
    <url>%2F2019%2F03%2F27%2Fgo-ethereum%E4%B8%ADethdb%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[前面学习了ethereum的编码和数据结构，这里学习一些ethereum的持久化存储也就是数据相关的源码。 背景go-ethereum的数据存储时借助于leveldb数据库，它是Google开发的一种键值对类型的数据库，另外Facebook又基于其开发了RocksDB数据库。简单来说，leveldb具有轻量以及高性能的特点。 原生的leveldb是用c++写的，并不方便直接用到go项目中，好在leveldb的开发者用go重新实现了leveldb，我们可以直接使用(github地址)。 go版本的leveldb需要go1.5以上版本，安装很简单，执行下面命令1go get github.com/syndtr/goleveldb/leveldb go-leveldb使用由于是键值对类型的数据库，所以使用比较简单，下面简单介绍一下基本操作，更高级的操作参见API文档。下面操作示例代码见这里 打开数据库12345db, err := leveldb.OpenFile("db", nil)if(err!=nil)&#123; log.Fatalln(err.Error())&#125;defer db.Close() OpenFile会创建或打开一个数据库。 增删改查123err = db.Put([]byte("key"), []byte("value"), nil)err = db.Delete([]byte("key"), nil)data, err := db.Get([]byte("key"), nil) 基本上就对于put，get，delete几个方法，其中更改一个记录的话也是用put。 普通迭代123456iter := db.NewIterator(nil, nil)for iter.Next() &#123; key := iter.Key() value := iter.Value()&#125;iter.Release() 就是迭代数据库全部键值对 指定起点的迭代首先需要明白的是，leveldb的存储是按key的顺序存储的，所以可以指定一个key，从该key开始遍历1234567iter:=db.NewIterator(nil,nil)for ok:=iter.Seek(key);ok;ok=iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 子集迭代可以指定区间进行迭代1234567iter:=db.NewIterator(&amp;util.Range&#123;Start:[]byte("key2"),Limit:[]byte("key6")&#125;,nil)for iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 前缀迭代只迭代有指定前缀的1234567iter:=db.NewIterator(util.BytesPrefix([]byte(prefix)),nil)for iter.Next()&#123; fmt.Println(string(iter.Key()),"---",string(iter.Value()))&#125;iter.Release()err := iter.Error()fmt.Println(err) 批量写入12345678batch:=new(leveldb.Batch)for i:=0; i&lt;10; i++ &#123; batch.Put([]byte("batch"+strconv.Itoa(i)),[]byte("batch"+strconv.Itoa(i)))&#125;err:=db.Write(batch,nil)if err!=nil &#123; fmt.Println(err)&#125; 源码分析源码集中在ethdb目录内，主要是对leveldb的封装。 interface.go顾名思义就是定义了一些接口，如数据库接口：12345678type Database interface &#123; Putter Deleter Get(key []byte) ([]byte, error) Has(key []byte) (bool, error) Close() NewBatch() Batch&#125; Batch接口。用于批量操作，不能用于并发1234567type Batch interface &#123; Putter Deleter ValueSize() int Write() error Reset()&#125; 上面两个结构又包含了Putter和Deleter接口123456type Putter interface &#123; Put(key []byte, value []byte) error&#125;type Deleter interface &#123; Delete(key []byte) error&#125; database.go构造这就是ethereum所使用的代码，先看结构体1234567891011121314151617type LDBDatabase struct &#123; fn string // filename for reporting db *leveldb.DB // LevelDB instance compTimeMeter metrics.Meter // Meter for measuring the total time spent in database compaction compReadMeter metrics.Meter // Meter for measuring the data read during compaction compWriteMeter metrics.Meter // Meter for measuring the data written during compaction writeDelayNMeter metrics.Meter // Meter for measuring the write delay number due to database compaction writeDelayMeter metrics.Meter // Meter for measuring the write delay duration due to database compaction diskReadMeter metrics.Meter // Meter for measuring the effective amount of data read diskWriteMeter metrics.Meter // Meter for measuring the effective amount of data written quitLock sync.Mutex // Mutex protecting the quit channel access quitChan chan chan error // Quit channel to stop the metrics collection before closing the database log log.Logger // Contextual logger tracking the database path&#125; NewLDBDatabase成员很多，关键的就是一个leveldb.DB对象和几个同步操作的成员。接下来看新建数据库的方法12345678910111213141516171819202122232425262728293031func NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) &#123; logger := log.New("database", file) //从init调用过来时，cache和handles都为0 //默认启动节点，cache为512，handles为0，在node.DefaultConfig配置 if cache &lt; 16 &#123; cache = 16 &#125; if handles &lt; 16 &#123; handles = 16 &#125; logger.Info("Allocated cache and file handles", "cache", common.StorageSize(cache*1024*1024), "handles", handles) db, err := leveldb.OpenFile(file, &amp;opt.Options&#123; OpenFilesCacheCapacity: handles, BlockCacheCapacity: cache / 2 * opt.MiB, WriteBuffer: cache / 4 * opt.MiB, Filter: filter.NewBloomFilter(10), &#125;) if _, corrupted := err.(*errors.ErrCorrupted); corrupted &#123; db, err = leveldb.RecoverFile(file, nil) &#125; if err != nil &#123; return nil, err &#125; return &amp;LDBDatabase&#123; fn: file, db: db, log: logger, &#125;, nil&#125; 逻辑很简单，创建了一个levelDB对象，主要看一下options的内容： OpenFilesCacheCapacity：定义打开的文件缓存大小，默认是500，设为-1或0时表示不缓存 BlockCacheCapacity：定义了一个名为sorted table的缓存容量，默认是8MB，设为-1或0时表示不缓存 WriteBuffer：定义memdb的大小，它是一个内存数据库，默认是4MB. Filter：定义过滤器，优化读性能。这是使用了一个布隆过滤器 put，has，get，delete12345678910111213141516func (db *LDBDatabase) Put(key []byte, value []byte) error &#123; return db.db.Put(key, value, nil)&#125;func (db *LDBDatabase) Has(key []byte) (bool, error) &#123; return db.db.Has(key, nil)&#125;func (db *LDBDatabase) Get(key []byte) ([]byte, error) &#123; dat, err := db.db.Get(key, nil) if err != nil &#123; return nil, err &#125; return dat, nil&#125;func (db *LDBDatabase) Delete(key []byte) error &#123; return db.db.Delete(key, nil)&#125; 都是对leveldb做了封装而已。 Batch及其操作批量读写的封装12345type ldbBatch struct &#123; db *leveldb.DB b *leveldb.Batch size int&#125; put、delete、write、reset1234567891011121314151617181920func (b *ldbBatch) Put(key, value []byte) error &#123; b.b.Put(key, value) b.size += len(value) return nil&#125;func (b *ldbBatch) Delete(key []byte) error &#123; b.b.Delete(key) b.size += 1 return nil&#125;func (b *ldbBatch) Write() error &#123; return b.db.Write(b.b, nil)&#125;func (b *ldbBatch) Reset() &#123; b.b.Reset() b.size = 0&#125; Meter这是用于初始化LDBDatabase的一系列Meter成员用的123456789101112131415func (db *LDBDatabase) Meter(prefix string) &#123; db.compTimeMeter = metrics.NewRegisteredMeter(prefix+"compact/time", nil) db.compReadMeter = metrics.NewRegisteredMeter(prefix+"compact/input", nil) db.compWriteMeter = metrics.NewRegisteredMeter(prefix+"compact/output", nil) db.diskReadMeter = metrics.NewRegisteredMeter(prefix+"disk/read", nil) db.diskWriteMeter = metrics.NewRegisteredMeter(prefix+"disk/write", nil) db.writeDelayMeter = metrics.NewRegisteredMeter(prefix+"compact/writedelay/duration", nil) db.writeDelayNMeter = metrics.NewRegisteredMeter(prefix+"compact/writedelay/counter", nil) db.quitLock.Lock() db.quitChan = make(chan chan error) db.quitLock.Unlock() go db.meter(3 * time.Second)&#125; 这个方法内先初始化各种Meter，然后创建了一个chan，最后启动一个goroutine运行meter，之后每3秒收集一次信息并反馈到Meter。这一段代码比较长，就不贴出来了。主要是利用db.db.GetProperty(“leveldb.stats”)获取信息，信息格式如下：123456// Level | Tables | Size(MB) | Time(sec) | Read(MB) | Write(MB)// -------+------------+---------------+---------------+---------------+---------------// 0 | 0 | 0.00000 | 1.27969 | 0.00000 | 12.31098// 1 | 85 | 109.27913 | 28.09293 | 213.92493 | 214.26294// 2 | 523 | 1000.37159 | 7.26059 | 66.86342 | 66.77884// 3 | 570 | 1113.18458 | 0.00000 | 0.00000 | 0.00000 下面就是解析这个字符串并写入Meter。另外一点这段代周期循环的关键代码如下1234567for i := 1; errc == nil &amp;&amp; merr == nil; i++ &#123; //.... select &#123; case errc = &lt;-db.quitChan: case &lt;-time.After(refresh): &#125;&#125; 到select出会阻塞，3秒后进行下一次循环，退出时向Meter方法中初始化的chan发送信息，导致errc不为nil，就自然退出循环 close12345678910111213141516171819func (db *LDBDatabase) Close() &#123; db.quitLock.Lock() defer db.quitLock.Unlock() if db.quitChan != nil &#123; errc := make(chan error) db.quitChan &lt;- errc if err := &lt;-errc; err != nil &#123; db.log.Error("Metrics collection failed", "err", err) &#125; db.quitChan = nil &#125; err := db.db.Close() if err == nil &#123; db.log.Info("Database closed") &#125; else &#123; db.log.Error("Failed to close database", "err", err) &#125;&#125; 退出代码也很简单，主要就是在加锁环境下，向quitChan写入信息，停止meter，然后等待反馈（在meter发出反馈），最后关闭数据库。 memory_database.go这是一个用于测试的基于内存的数据库。在源码中主要是在geth初始化时，如果最后创建数据库时依旧没有有效的datadir则使用这个数据库代替 构造12345678910type MemDatabase struct &#123; db map[string][]byte lock sync.RWMutex&#125;func NewMemDatabase() *MemDatabase &#123; return &amp;MemDatabase&#123; db: make(map[string][]byte), &#125;&#125; 可见就是基于map的封装。 基础操作123456789101112131415161718192021222324252627282930313233func (db *MemDatabase) Put(key []byte, value []byte) error &#123; db.lock.Lock() defer db.lock.Unlock() db.db[string(key)] = common.CopyBytes(value) return nil&#125;func (db *MemDatabase) Has(key []byte) (bool, error) &#123; db.lock.RLock() defer db.lock.RUnlock() _, ok := db.db[string(key)] return ok, nil&#125;func (db *MemDatabase) Get(key []byte) ([]byte, error) &#123; db.lock.RLock() defer db.lock.RUnlock() if entry, ok := db.db[string(key)]; ok &#123; return common.CopyBytes(entry), nil &#125; return nil, errors.New("not found")&#125;func (db *MemDatabase) Delete(key []byte) error &#123; db.lock.Lock() defer db.lock.Unlock() delete(db.db, string(key)) return nil&#125; 全是基于map操作，只不过进行了加锁 Batch1234567891011121314151617181920212223242526272829303132333435363738394041type memBatch struct &#123; db *MemDatabase writes []kv size int&#125;type kv struct &#123; k, v []byte del bool&#125;func (db *MemDatabase) NewBatch() Batch &#123; return &amp;memBatch&#123;db: db&#125;&#125;func (b *memBatch) Put(key, value []byte) error &#123; b.writes = append(b.writes, kv&#123;common.CopyBytes(key), common.CopyBytes(value), false&#125;) b.size += len(value) return nil&#125;func (b *memBatch) Delete(key []byte) error &#123; b.writes = append(b.writes, kv&#123;common.CopyBytes(key), nil, true&#125;) b.size += 1 return nil&#125;func (b *memBatch) Write() error &#123; b.db.lock.Lock() defer b.db.lock.Unlock() for _, kv := range b.writes &#123; if kv.del &#123; delete(b.db.db, string(kv.k)) continue &#125; b.db.db[string(kv.k)] = kv.v &#125; return nil&#125;func (b *memBatch) Reset() &#123; b.writes = b.writes[:0] b.size = 0&#125; 批量操作先存储在一个KV类型的数组内，等到写入时遍历那个数组，依次存入数据库 table.go与table_batch.go这两个也是对数据的封装，之所以叫table是因为实例化一个table时要指定一个前缀，之后利用table的基本操作都会给key添加指定的前缀。table_batch也类似，直接看一下table.go的源码12345678910111213141516171819202122func NewTable(db Database, prefix string) Database &#123; return &amp;table&#123; db: db, prefix: prefix, &#125;&#125;func (dt *table) Put(key []byte, value []byte) error &#123; return dt.db.Put(append([]byte(dt.prefix), key...), value)&#125;func (dt *table) Has(key []byte) (bool, error) &#123; return dt.db.Has(append([]byte(dt.prefix), key...))&#125;func (dt *table) Get(key []byte) ([]byte, error) &#123; return dt.db.Get(append([]byte(dt.prefix), key...))&#125;func (dt *table) Delete(key []byte) error &#123; return dt.db.Delete(append([]byte(dt.prefix), key...))&#125;]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RC4加密与实现]]></title>
    <url>%2F2019%2F03%2F27%2FRC4%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景RC4全名Rivest Cipher 4，是1987年Ron Rivest设计的一种流加密法，属于对称加密算法，曾经是WEP、TLS等使用的加密算法，它速度较快，且设计简单，所以使用较广 基本原理首先RC4的秘钥是可变的，长度在1~256个字节之间，开始前我们需要一个初始化状态向量，在进行初始置换后生产流秘钥进行加密。对于解密则是和加密一样的算法。 详细流程S的初始化 首先定义一个长度为1~256个字节的秘钥K。 初始化一个向量S，S[0] = 0,S[1] = 1, … ,S[255] = 255 创建临时数组T，T的长度是256，T用K填充，填不满的循环用K填充，直到T被填满 S的初始置换T数组的作用是对S进行初始置换，置换规则如下：将S[i]与S[j]交换，其中j = (j + S[i] + T[i]) mod 256。j的初始值是0 流秘钥生成根据如下计算：i = (i+1) mod 256，i初始值为0；j = (j + s[i]) mod 256,j初始值位0。然后交换s[i]和S[j]。令t = (S[i] + S[j]) mod 256。输出S[t]作为秘钥通明文进行一字节一字节的加密（异或运算） 简单实现java代码简单实现如下123456789101112131415161718192021222324252627282930313233public class RC4 &#123; private int[] S = new int[256]; RC4(byte[] keys) throws Exception &#123; int keyLen = keys.length; if (keyLen &lt;1 || keyLen &gt; 256) throw new Exception("秘钥长度错误"); int[] T = new int[256]; for (int i = 0;i&lt;256;i++)&#123; S[i] = i; &#125; int j = 0; for (int i = 0;i&lt;256;i++)&#123; j = (j + S[i] + keys[i % keyLen]) % 256; int temp = S[i]; S[i] = S[j]; S[j] = temp; &#125; &#125; public byte[] encrypt(byte[] msgs)&#123; int i = 0,j = 0; byte[] out = new byte[msgs.length]; for (int k = 0;k&lt;msgs.length;k++)&#123; i = (i+1)%256; j = (j+S[i])%256; int temp = S[i]; S[i] = S[j]; S[j] = temp; out[k] = (byte) (msgs[k] ^ S[(S[i] + S[j])%256]); &#125; return out; &#125;&#125; 验证123456public static void main(String[] args) throws Exception &#123; RC4 rc4 = new RC4("123".getBytes()); byte[] out = rc4.encrypt("abcdefg".getBytes()); Base64.Encoder encoder = Base64.getEncoder(); System.out.println(new String(encoder.encode(out))); &#125; 最后输出：MpLc5oASYw== 使用第三方RC4加密验证： 解密验证，由于说解密算法和加密算法一致，所以我们不必做任何修改，直接如下：1234567public static void main(String[] args) throws Exception &#123; RC4 rc4 = new RC4("123".getBytes()); byte[] out = rc4.encrypt("abcdefg".getBytes()); RC4 rc41 = new RC4("123".getBytes()); System.out.println(new String(rc41.encrypt(out))); &#125; 需要注意的一点是，解密时要新建一个RC4对象，原来的对象在加密时S数组已经发生交换，不能使用。 总结RC4算法通过上面实现来看非常简单，没有什么复杂计算，只有简单的交换和异或运算，秘钥也足够长，是一种比较理想的算法。但是弱密钥会导致算法不安全，另外由于更好的算法出现，RC4目前已经很少使用。 题图来自unsplash：https://unsplash.com/photos/B9j-xgMVf90]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum中trie源码学习]]></title>
    <url>%2F2019%2F03%2F26%2Fgo-ethereum%E4%B8%ADtrie%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[MPT（Merkle Patricia Tree），是以太坊实现中广泛使用的一种数据结构，如在区块头中就保存了状态树，交易树和收据树这三棵树的根的hash，而这三棵树就是MPT。MPT是Trie树、Patricia Trie树和Merkle树的变形，下面我们就来详细了解一下 背景Trie树Trie树又称前缀树或字典树。顾名思义一个节点的所有孩子都具有同样的前缀，就像字典一样把单词按前缀分类排序。 在Trie树中，根节点不保存信息，每个节点的最大孩子数量相同（若是保存英文字母，不区分大小写，则最多有26个孩子）。 从根节点开始，到某一节点，路径上的字符组合起来就是该节点对应的字符串 没有重复的节点 语言说起来比较抽象，看一张图就很清楚了 如上图所示，这棵树可能保存了:A,to,tea,ted,ten,i,in,inn这8个字符串（具体某个节点表示的仅仅是前缀还是字符串还要根据节点参数判断）。java实现见这里 Trie树具有查找效率高的特点，但是稀疏现象比较严重，空间利用率低。Trie树常用于搜索提示，如输入前几个字母，就可以很快的提示一些可能匹配的字符串。 Patricia Trie实际上是基数树，或压缩前缀树。根据名字可知，是对前缀进行一定的压缩，为了是缓解Trie树空间利用率不高的问题。如下图 从图中我们可以知道，如果以Trie树存储romane和romanus，对于他们的公共前缀roman我们要创建5个先后依赖的节点，在第5层处分叉，对于us又需要两层节点。而对于基数树，可以把roman合并为一个节点，us也合并为一个节点，这样原本至少7层才能表示的现在2层即可。 关于这种树的实现我们会在后面源码分析提到 Merkle树Merkle Tree，通常也被称作Hash Tree。这种树的的主要作用是验证。它结构上大多情况是一颗二叉树，叶子结点都以数据库的hash值作为标签，其他结点都是其子节点的标签拼接后再做hash。他可以高效的安全的验证大型数据结构的内容。 如上图，数据的每一块都对应一个叶子，叶子内存储该块的hash，之后层层做hash运算，最后得到根节点的一个hash值。我们只需要验证根节点的hash是否相同，就能判断整个文件是否完整或者是否被人恶意篡改。另外，通过重建整个树，可以很快的知道具体哪一部分出错。具体在区块链中，无论比特币还是以太坊，都是只在区块头中存储根节点，从而来判断是否一致。 以太坊的MPT一般而言MPT的存储借鉴的是Patricia Trie。与一般的存储英文字符串不同，MPT存储的是hash值，每一位有0-f共16种可能，不过MPT又对其进行了扩展。 首先，定义了三种节点： branch：分支节点，一个长度为17的list，分别是0-f共16位，再加一个value。最后的value代表该节点可能对某个key是终点，用于存取值 leaf：叶子节点，和Trie树的叶子结点类型 extension：扩展节点，纯粹的路径节点，其中的值时其它节点hash，可以理解为一个指向其他节点的指针 看一张经典的图会比较容易理解： 在图中，右上角四对键值就是图中树所存储的内容。首先他们都有前缀a7，所以根节点就是一个扩展节点，它的指针指向一个分支节点，分支节点用到了1、7、f三个值，1、f分别指向两个叶子节点，因为没有其他key和他们有除a7外的公共前缀，分支节点7指向一个扩展节点，因为右上角第二和第四个还有公共前缀d3，随后在指向一个分支节点，再找值分为两个叶子节点。叶子结点的value就存着每个键值对中的value. 源码分析ethereum关于这部分的源码集中在trie目录下 结点定义见代码：1234567891011121314151617181920// go-ethereum\trie\node.gotype node interface &#123; fstring(string) string cache() (hashNode, bool) canUnload(cachegen, cachelimit uint16) bool&#125;type ( fullNode struct &#123; Children [17]node // Actual trie node data to encode/decode (needs custom encoder) flags nodeFlag &#125; shortNode struct &#123; Key []byte Val node flags nodeFlag &#125; hashNode []byte valueNode []byte) 虽说黄皮书中定义了3种结点，但这里只有两种节点，分别是fullnode和shortnode。fullnode就是分支节点，可见其有一个长度为17的数组。shortnode可以代表扩展节点或叶子节点，因为二者结构是一样的，区分两种节点主要看val的值。另外还有两种节点，虽然是字节数组类型的，但是他们都实现了node接口的全部方法，所以也是节点类型。 树的构造先看一下树的结构：12345type Trie struct &#123; db *Database root node cachegen, cachelimit uint16&#125; root就是根节点，db就是数据库，树的结构最后要存到数据库中，启动时再加载出来。对于cachegen，每次提交其值都会增加，新节点会标记cachegen，如果当前的cachegen - cachelimit大于node的cache时代，那么node会从cache里面卸载，以便节约内存。 创建一棵树12345678910111213141516func New(root common.Hash, db *Database) (*Trie, error) &#123; if db == nil &#123; panic("trie.New called without a database") &#125; trie := &amp;Trie&#123; db: db, &#125; if root != (common.Hash&#123;&#125;) &amp;&amp; root != emptyRoot &#123; rootnode, err := trie.resolveHash(root[:], nil) if err != nil &#123; return nil, err &#125; trie.root = rootnode &#125; return trie, nil&#125; new方法接受一个hash和一个数据库指针，首席确保指针不为空，然后初始化树，之后再判断传入的hash是否为空值，若不是则从数据库加载，否则返回一个空树。 插入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960func (t *Trie) insert(n node, prefix, key []byte, value node) (bool, node, error) &#123; if len(key) == 0 &#123; if v, ok := n.(valueNode); ok &#123; return !bytes.Equal(v, value.(valueNode)), value, nil &#125; return true, value, nil &#125; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) if matchlen == len(n.Key) &#123; dirty, nn, err := t.insert(n.Val, append(prefix, key[:matchlen]...), key[matchlen:], value) if !dirty || err != nil &#123; return false, n, err &#125; return true, &amp;shortNode&#123;n.Key, nn, t.newFlag()&#125;, nil &#125; branch := &amp;fullNode&#123;flags: t.newFlag()&#125; var err error _, branch.Children[n.Key[matchlen]], err = t.insert(nil, append(prefix, n.Key[:matchlen+1]...), n.Key[matchlen+1:], n.Val) if err != nil &#123; return false, nil, err &#125; _, branch.Children[key[matchlen]], err = t.insert(nil, append(prefix, key[:matchlen+1]...), key[matchlen+1:], value) if err != nil &#123; return false, nil, err &#125; if matchlen == 0 &#123; return true, branch, nil &#125; return true, &amp;shortNode&#123;key[:matchlen], branch, t.newFlag()&#125;, nil case *fullNode: dirty, nn, err := t.insert(n.Children[key[0]], append(prefix, key[0]), key[1:], value) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn return true, n, nil case nil: return true, &amp;shortNode&#123;key, value, t.newFlag()&#125;, nil case hashNode: rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.insert(rn, prefix, key, value) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf("%T: invalid node: %v", n, n)) &#125;&#125; 几个参数分别是：n代表当前的结点。prefix代表已经搜索过的前缀，key表示尚未处理的部分，二者拼接到一起就是完整的key。value表示要插入的值。返回值中bool表示是否改变了树，node表示插入后子树的根节点。通过参数可以猜到这是通过递归进行操作的。 代码的第一个if判断中，若key的长度为0，表示key已经遍历完了，同时也找到了一个节点。判断这个节点是否是valueNode类型节点，若是的话，判断要插入的值和结点的值是否相等，来判断是否改变了树。若不是valueNode类型节点，就直接更新value，同时指明树已经改变了。 若还在变量key的途中，则根据当前节点的类型进行判断： 若是shortNode节点，表示是一个叶子节点或扩展节点，则调用prefixLen方法计算公共前缀长度。若公共前缀长度就等于key的长度，说明二者的可以是一样的，则按照需要更新value。若只有部分公共前缀，则需要构造一个分支节点，将原来的节点和要插入的作为新分支节点的孩子插入。最后对刚才的公共前缀进行判断，若为0，表示没有公共前缀，则用新的分支节点替换掉原来的节点，若不为零，则将新的分支节点作为原节点的孩子，并改变原节点的可以。注意给分支节点添加孩子时，也是调用的insert，只不过n为nil，这对应后面的一种情况，稍后分析。 若是fullNode，也就是分支节点，则直接寻找对应的位置尝试插入，注意分支节点对于位置的孩子可能为空，为shortNode或者fullnode，不管为什么，最终继续递归，并按需更新孩子即可 若是nil，这种情况可能会一棵空树时候出现，这是新建一个shortNode节点作为根节点，返回即可。同时，在上文向分支节点插入孩子时也会出现，同样也是新建shortNode结点作为分支节点孩子即可。 若是hashNode，可以理解为一个指针，但是数据都在数据库，需要取数据库取值插入 最后不满足定义的四种节点，报错 最后总结一点，对于shortNode节点，要么进行更新，要么新建扩展节点进行插入，对于fullNode，要么成为其某个孩子，要么更新其值，要么为其添加扩展节点，进行扩展。总之新的叶子节点插入操作都是在扩展节点上完成的。 删除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778func (t *Trie) delete(n node, prefix, key []byte) (bool, node, error) &#123; switch n := n.(type) &#123; case *shortNode: matchlen := prefixLen(key, n.Key) if matchlen &lt; len(n.Key) &#123; return false, n, nil // don't replace n on mismatch &#125; if matchlen == len(key) &#123; return true, nil, nil // remove n entirely for whole matches &#125; dirty, child, err := t.delete(n.Val, append(prefix, key[:len(n.Key)]...), key[len(n.Key):]) if !dirty || err != nil &#123; return false, n, err &#125; switch child := child.(type) &#123; case *shortNode: return true, &amp;shortNode&#123;concat(n.Key, child.Key...), child.Val, t.newFlag()&#125;, nil default: return true, &amp;shortNode&#123;n.Key, child, t.newFlag()&#125;, nil &#125; case *fullNode: dirty, nn, err := t.delete(n.Children[key[0]], append(prefix, key[0]), key[1:]) if !dirty || err != nil &#123; return false, n, err &#125; n = n.copy() n.flags = t.newFlag() n.Children[key[0]] = nn pos := -1 //遍历后，若pos大于等于0，表示只有一个孩子 //若pos等于-2则孩子数量大于一个 for i, cld := range &amp;n.Children &#123; if cld != nil &#123; if pos == -1 &#123; pos = i &#125; else &#123; pos = -2 break &#125; &#125; &#125; if pos &gt;= 0 &#123; if pos != 16 &#123; cnode, err := t.resolve(n.Children[pos], prefix) if err != nil &#123; return false, nil, err &#125; if cnode, ok := cnode.(*shortNode); ok &#123; k := append([]byte&#123;byte(pos)&#125;, cnode.Key...) return true, &amp;shortNode&#123;k, cnode.Val, t.newFlag()&#125;, nil &#125; &#125; return true, &amp;shortNode&#123;[]byte&#123;byte(pos)&#125;, n.Children[pos], t.newFlag()&#125;, nil &#125; return true, n, nil case valueNode: return true, nil, nil case nil: return false, nil, nil case hashNode: rn, err := t.resolveHash(n, prefix) if err != nil &#123; return false, nil, err &#125; dirty, nn, err := t.delete(rn, prefix, key) if !dirty || err != nil &#123; return false, rn, err &#125; return true, nn, nil default: panic(fmt.Sprintf("%T: invalid node: %v (%v)", n, n, key)) &#125;&#125; 参数和返回值和插入操作类似，不在赘述。依旧是判断当前节点类型： 若为shortNode结点，首先也是计算公共前缀。若公共前缀的长度小于当前节点key的长度，表示没有匹配到。若公共前缀的长度等于要删除的key的长度，表示匹配到子树，直接删除该节点为根的子树。若公共前缀的长度等于当前节点key的长度，也就是当前节点的key是要删除key的一部分，说明还要向下查找。但是删除完后要对节点做处理，若子节点fullnode节点删除孩子后孩子数量大于1个，则只改变当前节点的flag。若删除后孩子数量小于等于一个，则要对节点进行合并，也就是对前缀进行合并 若为fullnode结点，则直接根据key的第一个字符取尝试删除某个孩子。然后遍历孩子，判断非空的数量，若大于两个则不做处理，若只有一个，进行节点的合并。 若为valueNode节点，直接删除，返回 若为nil，一般在阐述fullnode的孩子时遇到，表示没有匹配，不做处理 若为hashNode，表示还在数据库中，则先加载，在尝试删除 查询也就是Get方法，见代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func (t *Trie) Get(key []byte) []byte &#123; res, err := t.TryGet(key) if err != nil &#123; log.Error(fmt.Sprintf("Unhandled trie error: %v", err)) &#125; return res&#125;func (t *Trie) TryGet(key []byte) ([]byte, error) &#123; key = keybytesToHex(key) //转为16进制半字节 value, newroot, didResolve, err := t.tryGet(t.root, key, 0) if err == nil &amp;&amp; didResolve &#123; t.root = newroot &#125; return value, err&#125;func (t *Trie) tryGet(origNode node, key []byte, pos int) (value []byte, newnode node, didResolve bool, err error) &#123; switch n := (origNode).(type) &#123; case nil: return nil, nil, false, nil case valueNode: return n, n, false, nil case *shortNode: if len(key)-pos &lt; len(n.Key) || !bytes.Equal(n.Key, key[pos:pos+len(n.Key)]) &#123; // key not found in trie return nil, n, false, nil &#125; value, newnode, didResolve, err = t.tryGet(n.Val, key, pos+len(n.Key)) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.Val = newnode n.flags.gen = t.cachegen &#125; return value, n, didResolve, err case *fullNode: value, newnode, didResolve, err = t.tryGet(n.Children[key[pos]], key, pos+1) if err == nil &amp;&amp; didResolve &#123; n = n.copy() n.flags.gen = t.cachegen n.Children[key[pos]] = newnode &#125; return value, n, didResolve, err case hashNode: child, err := t.resolveHash(n, key[:pos]) if err != nil &#123; return nil, n, true, err &#125; value, newnode, _, err := t.tryGet(child, key, pos) return value, newnode, true, err default: panic(fmt.Sprintf("%T: invalid node: %v", origNode, origNode)) &#125;&#125; 查找的逻辑也很简单，首先要把byte数组转为16进制半字节的数组形式，使用keybytesToHex方法（后面会讲）。之后从根节点开始，调用tryGet递归查询，也分一下几种情况： 若为空，表示没有找到 若为valueNode节点，直接返回即可 若为shortNode，如果当前节点的key长度大于本次递归要查找的或即使长度相等但内容不一样的，则表示没有匹配的，否则继续递归查找 若为fullNode结点，则递归到孩子中寻找 若为hashNode结点，则先从数据库中加载，在尝试递归查询 编码主要是encoding.go，处理树的三种编码格式的互相转换。 keybytes：原始字节数组，大部分trie的函数都用这种格式 hex：hex编码，将一个字节用两个字节表示，编码时，将8位二进制码重新分组成两个4位的字节，其中一个字节的低4位是原字节的高四位，另一个字节的低4位是原数据的低4位，高4位都补0。编码后再在尾部跟上一个标志位0x10，标识是叶子节点或者扩展节点 compact：compact编码，就是Hex-Prefix Encoding，在黄皮书中的附录C有说明。是hex编码的变体。第一个字节的高位存储标志位，低位存储0（长度为偶数）或hex编码的第一个半字节（长度为奇数）。总之最后长度是偶数。数学描述如下（f(t)表示hex编码的标志位是否存在）： 下面具体看源码： hexToCompacthex编码转compact编码12345678910111213141516func hexToCompact(hex []byte) []byte &#123; terminator := byte(0) if hasTerm(hex) &#123; terminator = 1 hex = hex[:len(hex)-1] &#125; buf := make([]byte, len(hex)/2+1) buf[0] = terminator &lt;&lt; 5 // the flag byte if len(hex)&amp;1 == 1 &#123; buf[0] |= 1 &lt;&lt; 4 // odd flag buf[0] |= hex[0] // first nibble is contained in the first byte hex = hex[1:] &#125; decodeNibbles(hex, buf[1:]) return buf&#125; hasTerm判断最后一字节是否是16，也就是有没有标志位，若是则terminator标记为1，并去除hex编码的标志位。接下来写入compat编码的标志位，首先terminator右移5位，再判断hex编码长度的奇偶性，并根据情况改下标志位。然后解码hex编码改为compat编码，流程和黄皮书一致。 compactToHexcompact编码转hex编码12345678910111213func compactToHex(compact []byte) []byte &#123; if len(compact) == 0 &#123; return compact &#125; base := keybytesToHex(compact) // delete terminator flag if base[0] &lt; 2 &#123; base = base[:len(base)-1] &#125; // apply odd flag chop := 2 - base[0]&amp;1 return base[chop:]&#125; 可见先看做一般字节数组，然后转为hex编码。然后判断是否有标志位。首先根据黄皮书规定，compact编码的第一字节的高四位有这几种情况：12340000 hex编码没有标志位，且长度为偶数0001 hex编码没有标志位，且长度为奇数0010 hex编码有标志位，且长度为偶数0011 hex编码有标志位，且长度为奇数 根据上面四种情况，删除最后的标志位。然后在根据第一位的值，决定是删除前两位还是第一位 keybytesToHex原始数组转hex编码12345678910func keybytesToHex(str []byte) []byte &#123; l := len(str)*2 + 1 var nibbles = make([]byte, l) for i, b := range str &#123; nibbles[i*2] = b / 16 nibbles[i*2+1] = b % 16 &#125; nibbles[l-1] = 16 return nibbles&#125; 很简单，就是一个字节拆为两个字节，利用整除和取余，最后加一个标志位。 hexToKeybyteshex编码还原12345678910111213141516func hexToKeybytes(hex []byte) []byte &#123; if hasTerm(hex) &#123; hex = hex[:len(hex)-1] &#125; if len(hex)&amp;1 != 0 &#123; panic("can't convert hex key of odd length") &#125; key := make([]byte, len(hex)/2) decodeNibbles(hex, key) return key&#125;func decodeNibbles(nibbles []byte, bytes []byte) &#123; for bi, ni := 0, 0; ni &lt; len(nibbles); bi, ni = bi+1, ni+2 &#123; bytes[bi] = nibbles[ni]&lt;&lt;4 | nibbles[ni+1] &#125;&#125; 先根据需求去除标志位，再具体转换。可见将两字节还原为一字节时就是利用移位和或逻辑。 序列化序列化就是将一课树存储到数据库中123456789101112131415161718192021// go-ethereum\trie\trie.gofunc (t *Trie) Commit(onleaf LeafCallback) (root common.Hash, err error) &#123; if t.db == nil &#123; panic("commit called on trie with nil database") &#125; hash, cached, err := t.hashRoot(t.db, onleaf) if err != nil &#123; return common.Hash&#123;&#125;, err &#125; t.root = cached t.cachegen++ return common.BytesToHash(hash.(hashNode)), nil&#125;func (t *Trie) hashRoot(db *Database, onleaf LeafCallback) (node, node, error) &#123; if t.root == nil &#123; return hashNode(emptyRoot.Bytes()), nil, nil &#125; h := newHasher(t.cachegen, t.cachelimit, onleaf) defer returnHasherToPool(h) return h.hash(t.root, db, true)&#125; 这一部分主要是创建了hasher，然后利用hash方法去实现。进入hasher的代码123456// go-ethereum\trie\hasher.gofunc newHasher(cachegen, cachelimit uint16, onleaf LeafCallback) *hasher &#123; h := hasherPool.Get().(*hasher) h.cachegen, h.cachelimit, h.onleaf = cachegen, cachelimit, onleaf return h&#125; hasherPool是一个对象池，newHasher方法主要是从中尝试取或者创建一个hasher对象。下面看hash方法：123456789101112131415161718192021222324252627282930313233343536func (h *hasher) hash(n node, db *Database, force bool) (node, node, error) &#123; if hash, dirty := n.cache(); hash != nil &#123; if db == nil &#123; return hash, n, nil &#125; if n.canUnload(h.cachegen, h.cachelimit) &#123; cacheUnloadCounter.Inc(1) return hash, hash, nil &#125; if !dirty &#123; return hash, n, nil &#125; &#125; collapsed, cached, err := h.hashChildren(n, db) if err != nil &#123; return hashNode&#123;&#125;, n, err &#125; hashed, err := h.store(collapsed, db, force) if err != nil &#123; return hashNode&#123;&#125;, n, err &#125; cachedHash, _ := hashed.(hashNode) switch cn := cached.(type) &#123; case *shortNode: cn.flags.hash = cachedHash if db != nil &#123; cn.flags.dirty = false &#125; case *fullNode: cn.flags.hash = cachedHash if db != nil &#123; cn.flags.dirty = false &#125; &#125; return hashed, cached, nil&#125; 第一个if我们后面再解释，接下来的hashChildren是一个关键点，它将所有的子节点换为他们的hash1234567891011121314151617181920212223242526272829303132333435func (h *hasher) hashChildren(original node, db *Database) (node, node, error) &#123; var err error switch n := original.(type) &#123; case *shortNode: collapsed, cached := n.copy(), n.copy() collapsed.Key = hexToCompact(n.Key) cached.Key = common.CopyBytes(n.Key) if _, ok := n.Val.(valueNode); !ok &#123; collapsed.Val, cached.Val, err = h.hash(n.Val, db, false) if err != nil &#123; return original, original, err &#125; &#125; return collapsed, cached, nil case *fullNode: subtrees collapsed, cached := n.copy(), n.copy() for i := 0; i &lt; 16; i++ &#123; if n.Children[i] != nil &#123; collapsed.Children[i], cached.Children[i], err = h.hash(n.Children[i], db, false) if err != nil &#123; return original, original, err &#125; &#125; &#125; cached.Children[16] = n.Children[16] return collapsed, cached, nil default: return n, original, nil &#125;&#125; 主要也是根据结点类型进行操作。 对于shortNode节点，先对key从hex编码转为compact编码，然后递归调用hash把子节点也改为hash 对于fullNode结点，遍历所有孩子，递归调用hash方法 对于其他类型节点原样返回 再回到hash方法，接下来调用store方法。12345678910111213141516171819202122232425262728293031323334353637383940func (h *hasher) store(n node, db *Database, force bool) (node, error) &#123; if _, isHash := n.(hashNode); n == nil || isHash &#123; return n, nil &#125; h.tmp.Reset() if err := rlp.Encode(&amp;h.tmp, n); err != nil &#123; panic("encode error: " + err.Error()) &#125; if len(h.tmp) &lt; 32 &amp;&amp; !force &#123; return n, nil // Nodes smaller than 32 bytes are stored inside their parent &#125; database. hash, _ := n.cache() if hash == nil &#123; hash = h.makeHashNode(h.tmp) &#125; if db != nil &#123; cache hash := common.BytesToHash(hash) db.lock.Lock() db.insert(hash, h.tmp, n) db.lock.Unlock() if h.onleaf != nil &#123; switch n := n.(type) &#123; case *shortNode: if child, ok := n.Val.(valueNode); ok &#123; h.onleaf(child, hash) &#125; case *fullNode: for i := 0; i &lt; 16; i++ &#123; if child, ok := n.Children[i].(valueNode); ok &#123; h.onleaf(child, hash) &#125; &#125; &#125; &#125; &#125; return hash, nil&#125; 首先判断节点类型，若本身就是hashNode或为空不存储。然后对节点编码。详细流程不在赘述，参考RLP编码学习。编码之后的结果存在tmp这个字节数组中。接下来判断是否强制存储，然后计算根节点编码后结果hash，最后存储到数据库，键就是刚才计算的hash。 再次回到hash方法，存储成功后。将存储的键转为hashNode类，然后判断cached（实际是跟节点的copy）的类型，对于是shortNode和fullNode类型，将其flags成员的hash值进行修改，然后返回hash值和cached。 反序列化不同于序列化，反序列化在trie的源码中就多次出现，主要是下面方法123456789func (t *Trie) resolveHash(n hashNode, prefix []byte) (node, error) &#123; cacheMissCounter.Inc(1) hash := common.BytesToHash(n) if node := t.db.node(hash, t.cachegen); node != nil &#123; return node, nil &#125; return nil, &amp;MissingNodeError&#123;NodeHash: hash, Path: prefix&#125;&#125; 主要逻辑在node方法中123456789101112131415161718192021222324252627// go-ethereum\trie\database.gofunc (db *Database) node(hash common.Hash, cachegen uint16) node &#123; if db.cleans != nil &#123; if enc, err := db.cleans.Get(string(hash[:])); err == nil &amp;&amp; enc != nil &#123; memcacheCleanHitMeter.Mark(1) memcacheCleanReadMeter.Mark(int64(len(enc))) return mustDecodeNode(hash[:], enc, cachegen) &#125; &#125; db.lock.RLock() dirty := db.dirties[hash] db.lock.RUnlock() if dirty != nil &#123; return dirty.obj(hash, cachegen) &#125; enc, err := db.diskdb.Get(hash[:]) if err != nil || enc == nil &#123; return nil &#125; if db.cleans != nil &#123; db.cleans.Set(string(hash[:]), enc) memcacheCleanMissMeter.Mark(1) memcacheCleanWriteMeter.Mark(int64(len(enc))) &#125; return mustDecodeNode(hash[:], enc, cachegen)&#125; 这也是一个典型的二级缓存的例子，首先尝试从内存缓存中获取，若没有，则从磁盘的数据库中获取，最后实际反序列化操作都在mustDecodeNode方法中123456789101112131415161718192021222324252627// go-ethereum\trie\node.gofunc mustDecodeNode(hash, buf []byte, cachegen uint16) node &#123; n, err := decodeNode(hash, buf, cachegen) if err != nil &#123; panic(fmt.Sprintf("node %x: %v", hash, err)) &#125; return n&#125;func decodeNode(hash, buf []byte, cachegen uint16) (node, error) &#123; if len(buf) == 0 &#123; return nil, io.ErrUnexpectedEOF &#125; elems, _, err := rlp.SplitList(buf) if err != nil &#123; return nil, fmt.Errorf("decode error: %v", err) &#125; switch c, _ := rlp.CountValues(elems); c &#123; case 2: n, err := decodeShort(hash, elems, cachegen) return n, wrapError(err, "short") case 17: n, err := decodeFull(hash, elems, cachegen) return n, wrapError(err, "full") default: return nil, fmt.Errorf("invalid number of list elements: %v", c) &#125;&#125; 首先解释一下涉及到的几个rlp方法，通过学习rlp编码我们知道，rlp编码一般由一个标志位+前缀+内容组成，SplitList方法返回的就是内容以及剩余内容（未被解析的）。对于复合类型，也就是编码中的第二种数据来源–多维数组类型，它的rlp编码内容部分是由多个单独的子类型rlp编码组合而成的，CountValues就是统计有多少个子部分。 接下来一个switch就是根据有多少子内容区分节点的类型，如代码中所述，2个子内容的就是shortNode，17个的就是fullNode，注意这点可能会有些人有疑问，我们定义节点的时候，这两类节点可不止这几个成员变量，这是因为在存储时节点都被转化为rawShortNode和rawFullNode两种简单类型（ go-ethereum\trie\database.go），只保留关键信息。我们接下来再看具体的反序列化方法123456789101112131415161718192021222324252627282930313233343536373839404142func decodeShort(hash, elems []byte, cachegen uint16) (node, error) &#123; kbuf, rest, err := rlp.SplitString(elems) if err != nil &#123; return nil, err &#125; flag := nodeFlag&#123;hash: hash, gen: cachegen&#125; key := compactToHex(kbuf) if hasTerm(key) &#123; val, _, err := rlp.SplitString(rest) if err != nil &#123; return nil, fmt.Errorf("invalid value node: %v", err) &#125; return &amp;shortNode&#123;key, append(valueNode&#123;&#125;, val...), flag&#125;, nil &#125; r, _, err := decodeRef(rest, cachegen) if err != nil &#123; return nil, wrapError(err, "val") &#125; return &amp;shortNode&#123;key, r, flag&#125;, nil&#125;func decodeRef(buf []byte, cachegen uint16) (node, []byte, error) &#123; kind, val, rest, err := rlp.Split(buf) if err != nil &#123; return nil, buf, err &#125; switch &#123; case kind == rlp.List: if size := len(buf) - len(rest); size &gt; hashLen &#123; err := fmt.Errorf("oversized embedded node (size is %d bytes, want size &lt; %d)", size, hashLen) return nil, buf, err &#125; n, err := decodeNode(nil, buf, cachegen) return n, rest, err case kind == rlp.String &amp;&amp; len(val) == 0: return nil, rest, nil case kind == rlp.String &amp;&amp; len(val) == 32: return append(hashNode&#123;&#125;, val...), rest, nil default: return nil, nil, fmt.Errorf("invalid RLP string size %d (want 0 or 32)", len(val)) &#125;&#125; 逻辑还是很清晰的，首先使用SplitString，分理处内容和剩余数据，然后将内容转为hex编码，再判断value是否有标志位来决定是否是叶子节点，若是叶子节点，则解析剩余的内容。若不是，则使用decodeRef来解析剩余内容。decodeRef首先也是分离出rlp编码各部分，先判断类型，再根据类型生成具体的节点。最后回到decodeShort构造出一个完整的节点。另外decodeFull流程也类似，不在赘述。主要思想就是一层一层剥开rlp编码，根据具体类型生成具体节点。 trie的cachetrie除了有数据库和根节点这两个成员变量，还有cachegen, cachelimit用于缓存管理的变量。trie树在每次commit时都会将cachegen加1（见上面序列化部分源码），然后在每次插入节点时都会把cachegen写入新节点，利用的是newFlag方法123func (t *Trie) newFlag() nodeFlag &#123; return nodeFlag&#123;dirty: true, gen: t.cachegen&#125;&#125; 当trie.cachegen - node.cachegen &gt; cachelimit时，就会把节点从内存中卸载（删除），用的是canUnload方法判断，每个继承node接口的类都实现了该方法：1234func (n *fullNode) canUnload(gen, limit uint16) bool &#123; return n.flags.canUnload(gen, limit) &#125;func (n *shortNode) canUnload(gen, limit uint16) bool &#123; return n.flags.canUnload(gen, limit) &#125;func (n hashNode) canUnload(uint16, uint16) bool &#123; return false &#125;func (n valueNode) canUnload(uint16, uint16) bool &#123; return false &#125; 卸载的作用是节省内存，所以说经过几次commit后，就会有节点被从内存中删除，删除是在hash方法中，也就是那个方法的第一个if1234567891011121314func (h *hasher) hash(n node, db *Database, force bool) (node, node, error) &#123; if hash, dirty := n.cache(); hash != nil &#123; if db == nil &#123; return hash, n, nil &#125; if n.canUnload(h.cachegen, h.cachelimit) &#123; cacheUnloadCounter.Inc(1) return hash, hash, nil &#125; if !dirty &#123; return hash, n, nil &#125; &#125; .... 获取hash是首先从节点的cache中获取，若存在的话，先不急着返回，首先判断是否可卸载，若可以，则卸载，注意卸载方式很有意思，不返回节点实例，而是返回一个hash表示节点，然后需要的时候在反序列化即可。注意若节点没有缓存hash值，则一定不进行卸载。 SecureTrie最后还有一个SecureTrie，是为了避免使用很长的key导致性能下降。SecureTrie包装了trie，所有的key都转化为keccak256计算的hash，但在数据库中存储原始key123456type SecureTrie struct &#123; trie Trie hashKeyBuf [common.HashLength]byte secKeyCache map[string][]byte //hash值和key值的映射 secKeyCacheOwner *SecureTrie &#125; 题图来自unsplash：https://unsplash.com/photos/hnw3Al47-KE]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA加密与实现]]></title>
    <url>%2F2019%2F03%2F26%2FIDEA%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[背景IDEA全称International Data Encryption Algorithm，即国际数据加密算法。也是一种强大的加密算法，原本目的是取代DES，但是由于专利的存在，IDEA并没有DES使用广泛，但是如PGP加密程序就是用的IDEA。 IDEA和DES一样，都是可逆的，加解密算法相同，也利用了扩展和混淆思想 基本原理加密前明文进行分块，每块64位，秘钥位128位。加密时，首先将明文分为4组，每组16位，作为第一轮的输入，总共需要8轮。在每一轮中，从128位的秘钥中产生6组子秘钥，每组16位，用这6组子秘钥对输入的4组明文进行一系列操作，产生一轮的输出，并作为下一轮输入。8轮结束后进行一次变换，这次变换需要4个子秘钥，组合起来得到64位密文。 轮次每一轮有14步，基本流程如下（我们将4组输入定义为P1-P4，6组秘钥定义为k1-K6）： P1与K1相乘 P2与K2相加 P3与K3相加 P4与K4相乘 第1步结果与第2步结果异或 第2步结果与第4步结果异或 第5步结果与K5相乘 第6步结果和第7步结果相乘 第8步与K6相乘 第7步与第9步相加 第1步结果与第9步结果异或 第3步结果与第9步结果异或 第2步结果与第10步结果异或 第4步结果与第10步结果异或 第11，13，12，14分别为输出的第1-4组，示意图如下（图中红圈代表相乘运算，篮圈代表异或运算，绿圈代表相加运算： 注意步骤中的加或乘并不是简单的加与乘。对于加法，加之后用2^16(即65536)求模。对于乘法，乘之后用2^16 + 1(即65537)求模。求模主要是为了保证输出为16位。 子秘钥生成总体来看，前8轮每轮需要8个子秘钥，最后一个输出变换需要4个子秘钥 第一轮第一轮开始前我们有一组128位的原始秘钥，第一轮用前96位，每16位一组，公6组 第二轮第二轮先使用没有用的32位，共两组，还差4组64位秘钥。然后将原始秘钥循环左移25位，再取前64位，作为后四组秘钥。 第三轮上一轮还剩64位，作为该轮的前四组秘钥，然后再左移25位，选前32位作为剩下两组子秘钥。 后面几轮一次类推，每次都先使用上一轮未使用的，对于不够的先循环左移，再取秘钥 输出变换第8轮之后，有四组输出，然后进行输出变换，具体过程如下(将4组输出定义为R1-R4，4组秘钥定义为K1-K4)： R1与K1相乘 R2与K2相加 R3与K3相加 R4与K4相乘 注意，相加相乘还是和之前8轮里的加和乘一样操作。对于子秘钥，第8轮是刚好把128位的后96位用完。这一次，依旧先左移25位，然后取前64位作为4组秘钥 解密解密算法和加密算法是一样的，只是秘钥有所不同。 第i(1-9)轮的解密秘钥的前4四个子秘钥由加密过程中第10-i轮的前四个子秘钥得出 其中第1与第4个子秘钥为对应子秘钥关于2^16 + 1的乘法逆元 第 2 个和第 3 个子密钥的取法为：1.当轮数为 2，…，8 时，取相应的第 3 个和第 2 个的子密钥的2^16加法逆元 2.当轮数为 1 或 9 时，取相应的第 2 个和第 3 个子密钥对应的2^16加法逆元 第 5 和第 6 个密钥不变 简单实现java代码见这里 题图来自unsplash：https://unsplash.com/photos/WDOJ5256Cvk]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DES加密与实现]]></title>
    <url>%2F2019%2F03%2F25%2FDES%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[DES加密基本上属于学习加密算法的必修内容，这里也来梳理一下整个算法 背景DES全称Data Encryption Standard，也就是数据加密标准，也被称作Data Encryption ALgorithm，DEA，数据加密算法。分类上，它属于对称秘钥加密块密码。1976年被被美国联邦政府的国家标准局确定为联邦资料处理标准，随后再全世界广泛应用，成为一种通用加密算法。虽然现在这种算法已经不安全了，但是它使用的一些思想和理念深深影响可后来许多加密算法。这个算法的官方文档见这里 基本原理首先这是一种块加密算法，以64位为一块，输出的密文也是64位，加解密使用相同的秘钥，秘钥的长度是56位。对于秘钥，最初是64位的，不过在算法开始前会丢弃8位（第8,16,24,32,40,48,56,64位）。 之后算法的主要思想是对明文进行替换和变换（也称混淆和扩散），这是香农提出的思想，对后世的密码算法有重要影响。混淆是为了保证密文中不会出现明文线索，扩散则是增加明文的冗余度。 DES主要步骤如下： 将明文进行初始置换（IP） 将置换后的块分为左右两部分 对每一部分进行16轮加密 将加密后的两部分拼接起来，进行最终置换（FP），得到密文 如下图： 详细过程初始置换在加密前需要进行一次初始置换，称为IP，结束后有一个最终置换，FP，这两个操作在密码学上几乎没有任何意义，只是在最初设计时，为了简化输入输出数据库的过程而被纳入加密流程。 初始置换借助的是一个置换表，如下表： 表中数字代表明文中该位的位置，如第一个是58，则代表将明文中的第58位放到置换后的第一位，依次类推 DES的一轮每一轮包含秘钥变换，扩展置换，S盒替换，P盒替换和异或交换这几步。也被统称为费斯妥函数，也就是开始那张图中的F函数 秘钥变换首先秘钥有56位，这一步是从这56位中选取48位，作为这一轮的子秘钥。变换的基本规则是，将56位分为两部分，各28位，每一轮循环左移一位或两位，具体情况如下表： 移位后，具体如何挑选48位，是根据下表挑选： 和初始置换类似，表中数字也是表示的该位在原秘钥中的位置，如第一位14表示将秘钥的第14位写在这里，后面依次类推 由于是将56位变为48位，这一步也称为压缩置换 扩展置换经过初始置换后，得到两个32位的明文部分，称为左右明文，而这一步就是将右明文扩展到48位。具体过程如下 将32位明文分为8组，每组4位 将每组的4位扩展为6位，实际上是重复每组的第一和第4位，但不是简单的重复，每组之间是有依赖的，简单描述就是，原来每位右移移位，第一位由上一组的第四位填充（第一组由最后一组填充），第六位由下一组的第一位填充（最后一组由第一组填充） 由于这一步极有规律，可以表示为下面的变换表： 这个表使用和前面的一样，不在赘述 S盒替换前一步将32位明文变为48位，这样就可以和秘钥进行异或操作，最后得到48位的输出，S盒的作用就是将这48位变为32位，总共有8个S盒，每个盒接受6位输入，产生4位输出，随后将48位变为32位。 8个S盒如下 关于S盒的使用如下，首先把一个S和看做4行16列的表格，首先输入有6位，将其中间四位看做列号，首尾两位看做行号。如输入101101，则行号就是11=3，列号就是0110=6，则就取s盒第3行第6位（行列都从0开始计数），如使用第二个S盒就输出2，转为4位二进制就是0010 P盒替换经s盒替换后，输出32位结果，之后进行一次简单的P和置换，置换表如下： 异或与交换P和置换不改变位数，输出还是32位，之后将输出的32位与左明文进行异或（前面一系列步骤都是再对右明文处理），运算结果成为下一轮的右明文，而原来的有明文变成下一轮的左明文，这就是所谓的交换 最后一张图总结这几步： 最终置换这样重复16轮之后，得到一个64位的密文。然后在进行最终置换，置换表如下： 解密通过前文可知，加密过程是极其繁琐和复杂的，许多替换不深入研究是不能了解其意义的，但是对于解密而言，就体现了DES算法的强大之处，它的加密算法和解密算法是一样的，唯一区别就是那16轮中用的秘钥要反过来，如第1轮解密要用第16轮加密秘钥。不过由于秘钥是独立运算的，所以可以事先计算好16轮加密所使用的全部秘钥。 DES变体双重DES从字面意思很好理解，就是使用两个秘钥，进行两次加密。解密时反向操作两次即可。如果说单一DES加密破解需要搜索2^56个秘钥，则双重DES就需要搜索2^112个秘钥 双重DES的中间人攻击这是一种理论上的攻击，我们假设攻击者知道明文和密文，需要找到加密的两个秘钥。首先创建两张表，第一张表存储所有可能的密码对明文块加密后的结果，第二张表存储所有可能的密码对密文块解密后的结果，比对两张表的结果，相同的那两行所用的秘钥就是加密过程中用的秘钥。 三重DES三个秘钥的三重DES比较简单，就是用三个秘钥，加密三次 两个秘钥的三重DES使用两个秘钥，首先用秘钥K1执行加密，再用K2解密，再用K1加密，这种模式成为加解加模式（EDE） DES的实现我们这里用java实现一下DES，完整源码见这里 注意在下面移位操作中，对于二进制字符串，我们认为最左边为第1位。 构造函数和构造密钥组对于构造函数要求出入一个字节数组作为密钥，长度必须是8字节，然后准备两个long类型数组存储加密和解密子密钥，由于子密钥是48位，所以用64位的long类型存储1234567891011121314151617181920212223242526private long[] encryptKeys = new long[16];private long[] decryptKeys = new long[16];MyDES(byte[] bytes) throws Exception &#123; if (bytes.length!=8) throw new Exception("密钥长度错误"); generateSubKey(bytes);&#125;private void generateSubKey(byte[] keyBytes) &#123; long key = bytesToLong(keyBytes); //64位密钥转为64位long类型表示 long pc1Result = permute(PC1,key,64); //从64位中选56位 int l = (int) (pc1Result &gt;&gt;&gt; 28); //密钥左半部分 int r = (int) (pc1Result &amp; 0xfffffff); //密钥右半部分 for (int i = 0; i&lt;16;i++)&#123; //左右部分分别循环左移 l = (l &lt;&lt; KEY_ROTATE[i]) | (l &gt;&gt;&gt; (28-KEY_ROTATE[i])); r = (r &lt;&lt; KEY_ROTATE[i]) | (r &gt;&gt;&gt; (28-KEY_ROTATE[i])); //拼接密钥 long temp = ((l &amp; 0xfffffffL) &lt;&lt; 28) | (r &amp; 0xfffffffL); //从56位密钥中选择48位 encryptKeys[i] = permute(PC2,temp,56); //解密密钥组是加密密钥组的倒序 decryptKeys[15-i] = encryptKeys[i]; &#125;&#125; 轮次操作详细代码如下，关键步骤见注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private byte[] des(byte[] bytes,long[] subkeys)&#123; long msg = bytesToLong(bytes); //将64位明文块用long类型表示 long IPResult = permute(IP,msg,64); //初始置换 //明文块分为左右两部分 int l = (int) (IPResult &gt;&gt;&gt; 32); int r = (int) (IPResult &amp; 0xffffffff); int temp = 0; for (int i = 0;i&lt;16;i++)&#123; temp = r; //暂存右半部分，作为下一轮的左半部分输入 r = l ^ f(r, subkeys[i]); //左半部分和右半部分经费斯妥函数运算后异或 l = temp; //新一轮的左半部分为该轮输入的右半部分 &#125; //最终置换，注意由于最后一轮不需要左右交换， //而我们上面代码进行了左右交换，所以这里要在进行一次左右交换 long FPResult = permute(FP,((r &amp; 0xffffffffL) &lt;&lt; 32) | (l &amp; 0xffffffffL),64); //将long类型转换为64位字节数组 return longTobytes(FPResult);&#125;//费斯妥函数private int f(int src, long subkey) &#123; //32位扩展为48位 long rExpand = permute(EXPAND,src&amp;0xffffffffL,32); //与子密钥异或 long sIn = rExpand ^ subkey; //s盒置换 long sOut = sBox(sIn); //P盒置换 int pResult = (int) permute(P,sOut,32); return pResult;&#125;//S盒置换private long sBox(long sIn) &#123; long result = 0; int r = 0,c = 0; for (int i = 0; i&lt; 8;i++)&#123; //取低6位 byte input = (byte) (sIn &amp; 0x3f); //取6位输入的首位两位计算行数 r = ((input &amp; 0x20)&gt;&gt;&gt;4) | (input &amp;0x1); //取6位输入的中间4位计算列数 c = (input &amp; 0x1e) &gt;&gt;&gt; 1; //生成的4位输出进行适当移位 result |= (S[7-i][r][c] &amp; 0xffL) &lt;&lt; (i*4); //输出右移6位，一般下一次循环取低6位 sIn &gt;&gt;&gt;= 6; &#125; return result;&#125; 测试与验证1234567public static void main(String[] args) throws Exception &#123; MyDES myDES = new MyDES("12345678".getBytes()); byte[] enc = myDES.encrypt("abcdefgh".getBytes()); System.out.println(byteToHexString(enc)); byte[] dec = myDES.decrypt(enc); System.out.println(new String(dec));&#125; 上面加密结果转为16进制字符串之后为94d4436bc3b5b693，与网上在线加密（注意比对时要选择ECB模式，而且大多数都会默认填充，即使明文已经达到了64位，所以要将网上结果去除尾部16个十六进制字符）测试结果一致，解密也可以正常得出原文。 题图来自unsplash：https://unsplash.com/photos/E7PlRr9ZfoM]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分组密码中的算法模式]]></title>
    <url>%2F2019%2F03%2F24%2F%E5%88%86%E7%BB%84%E5%AF%86%E7%A0%81%E4%B8%AD%E7%9A%84%E7%AE%97%E6%B3%95%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[算法模式是块加密中一系列步骤中基本，同一种加密方法采用不同的模式会产生不同的密文，安全性也不尽相同 电子密码薄（ECB）模式这是块加密中最简单的模式，如定义每块为64位，则将明文每64位分一组，之后对每组使用相同的秘钥和加密算法进行单独加密。解密时也是按64位分组，用同样的秘钥和加密方法进行解密即可。这种方法只适合于短消息，因为如果有重复信息，密文也会产生重复，易被攻击。加解密示意图如下： 加密块链接（CBC）模式这种模式的特点是对前一个块加密的结果会影响当前块的加密，确保了每条消息的唯一性。基本过程如下： 首先随机出一个与分组等长的初始文本块，然后用该文本块和第一个要加密的块做异或运算，并对运算结果进行加密 加密第二个块时，用第一个块加密之后的密文与第二个块进行异或运算，并对运算结果使用和第一块相同的算法和秘钥进行加密 依次类推，关键点是，在加密前使用上一块的密文与当前块做异或运算，之后再加密 可以抽象为下面数学表达(Ek表示加密函数，Ci表示明文的第几块)： 示意图如下： 对于解密，首先要了解一下异或运算的一个重要性质，就是连用两次异或后能恢复原值，即 A = A XOR B XOR B。由于这个性质异或就天然的有隐藏和还原信息的功能，所以解密算法如下 首先对密文块1进行解密，解密后再和加密时使用的初始文本块做异或运算就得到了原文. 对其他密文块也是一样，先解密，再与前一个密文块做异或，就得到原文 可以抽象为下面数学表达(Dk表示解密函数，Ci表示明文的第几块)： 示意图如下： 这种模式虽然很好的隐藏了信息，但是由于加密时都要依赖前面的信息，所以只能串行加密。不能并行运算。但是解密时可以并行运算 加密反馈（CFB）模式首先并不是所有程序都能处理数据库，如一个输入系统，需要以安全方式在信道中立即传输信息，这就要求数据用更小的单元进行加密（如8位，以byte长度）。所以出现了CFB模式。基本流程如下： 首先也需要一个64位的初始化向量，并将其放在移位寄存器中，并对该初始化向量进行加密，得到64位的初始密文 将加密过的初始化向量前j位和明文前j为进行异或，作为密文输出 将寄存器中的初始化向量左移j位，并将刚才加密的j位拼接到初始化向量尾部 然后重复上面步骤，即再对寄存器中的新初始化向量加密，随后再加密明文前j位，再进行左移个补充操作，最后再循环 示意图如下： 解密也很简单，由于明文是和移位寄存器中加密过的内容做异或后得到的密文，所以根据异或的性质，只需把密文和移位寄存器（初始内容还是加密时选定初始内容）中加密过的内容再做一次异或就得到明文（注意解密之后，寄存器中内容也要同步移位）示意图如下： 这种模式虽然和CBC很像，但是有一个优点，就是明文是不需要填充为分组的整数倍数长度的，明文和密文有相等长度，且较为灵活。 输出反馈（OFB）模式这种模式和CFB模型类似，但是没有CFB那么复杂，直接看一下示意图比较清晰： 可见主要区别是移位寄存器中的内容不再受密文的影响，而是每次独立进行加密。这样做的一大好处是某一位出错后，仅影响该位的密文，而和后面无关，前面CBC和CFB每次加密都会用到前面的信息，某一位出错将会影响后面所有输出。 解密过程也就相对较简单，将密文和初始向量加密后的信息做异或处理即可，随后也同步更新移位寄存器中内容。示意图如下 计数器(CTR)模式这种模式也被成为ICM(Integer Counter Mode)或SIC模式(Segmented Integer Counter) 这种模式类似于OFB模式，只不过将寄存器中的值换做一个计数器，计数器在任意时间产生不同的输出，之后对该输出进行加密，并用加密过的结果和明文异或，得到的结果作为密文。示意图（注意图中计数器的输出采用的是一个初始化向量和整数拼接的方式）如下： 解密方法和OFB类似，不在赘述，直接看示意图 这种方式的一大特点是可以并行加密，由于不同块的计数器输出是可以事先预测的，所以可以实现并行加密。 题图来自unsplash: https://unsplash.com/photos/pdRsf77OBoo]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Protobuf学习及编码深入]]></title>
    <url>%2F2019%2F03%2F22%2FProtobuf%E5%AD%A6%E4%B9%A0%E5%8F%8A%E7%BC%96%E7%A0%81%E6%B7%B1%E5%85%A5%2F</url>
    <content type="text"><![CDATA[简介按照官方的介绍，Protocol buffers是一种与具体平台或者编程语言无关的可扩展的序列化语言，类似于XML或者JSON，由其对比XML而言，具有更小更快更简单的特点。接下来我们就来了解一下这个东西。 简单使用一般而言，使用步骤有三步。首先定义Protobuf模板文件，以.proto为后缀；然后生成特定语言的接口代码；最后利用接口代码进行序列化或者反序列操作。整体步骤和我们利用一些第三方库如Gson去操作json文件类似，下面就具体看一下这几个过程： 定义Protobuf文件下面这个例子是官方文档给出，定义了一个地址簿的数据结构：12345678910111213141516syntax = &quot;proto2&quot;;package tutorial;option java_package = &quot;code.protobuf&quot;;option java_outer_classname = &quot;AddressBookProtos&quot;;message Person &#123; required string name = 1; required int32 id = 2; optional string email = 3;&#125;message AddressBook &#123; repeated Person people = 1;&#125; 具体语法我们稍后再介绍，首先可以看到，Protobuf文件的格式很像一些面向对象语言中类的定义，上面例子一个message就像一个类定义，类之间可以嵌套。AddressBook中有Person对象，Person中又有PhoneNumber对象。Person中也有一些基本类型如string和int。用过Gson之类的库解析json的应该感觉这和解析json时定义的类很像。 编译写好Protobuf文件后，就相当于写好一个模板文件，在不同平台或者不同语言间交互时都以这个文件为标准，但是还不能直接，根据具体的编程语言，我们还要有接口文件，我们可以利用官方给的编译工具生成我们需要的接口代码，以java语言为例：1protoc --java_out=src\ src\code\protobuf\addressbook.proto –java_out表示生成的接口文件路径，由于我们在Protobuf文件文件中定义了java_package，所以只需指定包所在目录即可，生成的文件会自动放在具体包下，最后指定Protobuf文件具体路径。生成的文件名在Protobuf文件中java_outer_classname字段定义。 接口操作执行完命令后，在code.protobuf包下生成了AddressBookProtos.java文件(要使用这个代码还需要导入相关库)。代码还是很长的，我们仅仅定义了一个简单的地址簿数据结构，就生成了近2000行代码，但是对于我们所使用的接口而言，生成的这个代码其实就是一个JavaBean类，它使用了建造者模式，当我们要构造一个Person对象时，如下：12345678AddressBookProtos.Person john = AddressBookProtos.Person.newBuilder().setId(1234) .setName("John") .setEmail("john@163.com") .addPhones(AddressBookProtos.Person.PhoneNumber.newBuilder() .setNumber("15463") .setType(AddressBookProtos.Person.PhoneType.HOME) .build()) .build(); 除了常用的get与set方法，还提供了：toString()方法用于转为有意义的字符串形式；isInitialized()方法用于检测所有必需字段是否设置；clear()方法用于清空所有字段；mergeFrom(Message other)用于合并两个对象。 当然作为序列化工具，生成的对象也提供了序列化和反序列化相关的方法：toByteArray()和parseFrom(byte[] data)。另外还可以直接操作流：writeTo(OutputStream output)和parseFrom(InputStream input)。 简单示例这里演示一个简单的跨语言的传输数据的例子。使用Go语言编写服务端，java编写客户端，从客户端向服务端发送数据。protobuf文件还使用上面的例子，这里在使用编译工具编译go语言的接口文件，protobuf文件不用做任何修改：1protoc --go_out=.\ src\code\protobuf\addressbook.proto java的客户端代码如下：123456789101112131415161718public static void main(String[] args) &#123; AddressBookProtos.Person person = AddressBookProtos.Person.newBuilder() .setName("jack") .setId(1) .setEmail("jack@163.com") .build(); AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .addPeople(person) .build(); try (Socket socket = new Socket("127.0.0.1",1234))&#123; OutputStream out = socket.getOutputStream(); out.write(book.toByteArray()); socket.shutdownOutput(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; go的服务端代码如下12345678910111213141516171819func main() &#123; listener,err:=net.Listen("tcp",":1234") if err!=nil&#123; log.Fatalln("Listen：",err.Error()) &#125; con,err:=listener.Accept() if err!=nil&#123; log.Fatalln("Accept：",err.Error()) &#125; result,err:=ioutil.ReadAll(con) if err!=nil&#123; log.Fatalln("ReadAll：",err.Error()) &#125; book := &amp;tutorial.AddressBook&#123;&#125; if err := proto.Unmarshal(result, book); err != nil &#123; log.Fatalln("Failed to parse address book:", err) &#125; fmt.Println(*book.People[0].Email)&#125; 详细语法首先在文件第一行在指定语法版本，如：syntax = “proto2”; 基本字段类型message中每个字段都要指定数据类型。如下表： 分配字段编号如例子中所示，每个字段都要分配一个独一无二编号，编号范围在1~536,870,911，主要是为了标记字段，并且不能改变，需要注意的是19000到19999是不能使用的。关于编号，官方文档建议，对于频繁使用的元素应当使用1到15的编号，因为这些序号被编码为1byte，而16到2047被编码为2byte。 字段约束有以下几个修饰词:123required：使用时必须被指定的字段optional：可以不被指定，但是最多只能指定一个repeated：可以出现次的，也可以不出现，相当于数组的概念。官方建议使用[packed=true]选项提高编码效率：repeated int32 samples = 4 [packed=true]; 了解完字段类型，编号，约束词以后，我们可以得到message中一个字段的完整定义:12字段约束 类型 名称 = 字段编号;required string query = 1; 注释类似于java等语言的注释风格：使用// 或/**/ 保留字对于以删除的字段，若是后面再被使用，可能会导致问题，所以可以用reserved标记出来，若被使用编译器将报错。reserved使用方法如下：1234message Foo &#123; reserved 2, 15, 9 to 11; reserved &quot;foo&quot;, &quot;bar&quot;;&#125; 注意字段和编号不能混合在一起用reserved标记 可选字段的默认值对于optional修饰的字段，若未定义，会有一个与字段类型对应的默认值，如string为空，bool为false等，我们也可以指定默认值如下所示：1optional int32 result_per_page = 3 [default = 10]; 枚举类型定义如下：123456789enum Corpus &#123; UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; &#125; 在一个枚举中，可以指定一些相同值的成员，这样会被解析为别名，同时需要加上option allow_alias = true123456enum EnumAllowingAlias &#123; option allow_alias = true; UNKNOWN = 0; STARTED = 1; RUNNING = 1;&#125; 若在一个message中使用另一个message的enum可以以MessageType.EnumType的形式调用 导包protobuf也有导包的概念，如果要从一个proto文件中引用另一个proto文件中的一个message，需要使用import关键字进行导包。注意在编译时使用-I指定搜索包的路径，否则只会默认搜索当前目录下的文件 嵌套定义12345678message SearchResponse &#123; message Result &#123; required string url = 1; optional string title = 2; repeated string snippets = 3; &#125; repeated Result result = 1;&#125; 上面例子在一个message中定义了另一个message，使用时利用SearchResponse.Result引用内部定义的message Extensions扩展实际上是一个占位符，它代表未在原始文件中定义的字段123message Foo &#123; extensions 100 to 199;&#125; 其他用户可以使用extensions指定的字段为原来的message添加新字段123extend Foo &#123; optional int32 bar = 126;&#125; 访问extension也有特殊的api，示例：123456789101112//序列化AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .setExtension(AddressBookProtos.bar,10) .build();byte[] out = book.toByteArray();//反序列化ExtensionRegistry registry = ExtensionRegistry.newInstance();registry.add(AddressBookProtos.bar);AddressBookProtos.AddressBook ob = AddressBookProtos.AddressBook.parseFrom(out,registry);System.out.println(ob.hasExtension(AddressBookProtos.bar)); 注意在反序列化时候要注册需要解析的extension，并作为参数传入parseFrom Oneofoneof的出现是为了实现这样的需求：一个message中有多个成员，但同一时间只能有一个成员被赋值。12345oneof test&#123; string a = 4; string b = 5; string c = 6; &#125; 1234567891011121314AddressBookProtos.Person p2 = AddressBookProtos.Person.newBuilder() .setName("tom") .setId(2) .setEmail("tom@163.com") .setA("hello") .setB("world") .build();AddressBookProtos.AddressBook book = AddressBookProtos.AddressBook.newBuilder() .addPeople(p2) .build(); byte[] out = book.toByteArray();AddressBookProtos.AddressBook ob = AddressBookProtos.AddressBook.parseFrom(out);System.out.println(ob.getPeople(0).hasA());System.out.println(ob.getPeople(0).hasB()); 可见我们虽然同时对A，B都进行了赋值，但是只有B被赋值成功，也就是同时只有一个成员可以被赋值需要有以下几点注意： 对一个成员赋值，会自动清除其他已赋值的成员 extension不支持oneof oneof不能被修饰为repeated 实际上对于oneof修饰的一组成员，完全可以把它们当做普通的optional成员看待，只不过这几个成员之间又互相依赖关系 另外，oneof： 安全的移除或添加字段，但会可能会导致数据丢失 可以删除一个oneof，也可能会导致数据丢失 可以分割或合并oneof，效果类似移除或添加字段 maps一般意义上的映射数据类型。1map&lt;string, Project&gt; projects = 3; key可以使任何整数或string（也就是浮点和字节类型除外），枚举也不能做为key。value可以是除map外的任何类型。注意事项： extension不支持map map不能有repeated, optional, 或 required修饰 map是无序的 map等效于下面的实现：123456message MapFieldEntry &#123; optional key_type key = 1; optional value_type value = 2;&#125;repeated MapFieldEntry map_field = N; Message更新更新需要遵循以下规则 不要改变已有字段的编号 新字段只能使用optional或repeated修饰。这样也很好理解，旧的代码序列化的数据仍然可以被新代码解析，否则会由于缺少required而报错 非required修饰的字段可以被移除，但是注意被删除的字段所使用的编号不能再次使用 只要类型或者编号不便，非required字段可以转为extension int32, uint32, int64, uint64 和 bool 是可以互相兼容的，也就是可以互相转换 sint32和sint64彼此兼容，但不和其他整数类型兼容 string和bytes互相兼容，前提是使用UTF-8编码 fixed32和sfixed32、fixed64、sfixed64是兼容的 optional与repeated是兼容的，若输入的是repeated，在解析为optional时，以最后一个输入为主，或合并输入 可以改变默认值，但要注意不同版本的protobuf文件的默认不同时会在带来潜在的冲突 enum 和 int32, uint32, int64, uint64是兼容的 将optional改为oneof是安全的 packages在proto文件中指定package字段来防止名字冲突。在java中，除非指定java_package字段，否则会以package作为包名 自定义选项 java_package ：指定生成的java文件所在的包 java_outer_classname ：指定生成的java文件名 optimize_for ：优化选项，有SPEED, CODE_SIZE, 和 LITE_RUNTIME三种选择。SPEED是默认选项，对代码进行优化。CODE_SIZE可以减小生成代码量，但解析速度会下降，LITE_RUNTIME生成的代码最少，但会失去一些特性4.deprecated：被标记为true的字段表示不再使用：optional int32 old_field = 6 [deprecated=true]; proto3语法proto3的语法和2有很多相似之处，所以这里只介绍一些不同点 版本号当然版本号要更改为proto31syntax = &quot;proto3&quot;; 修饰词移除了required修饰词；所有字段默认都是singular，也就是原来的optional，但是不能显式的指定为singularrepeated被保留了 正常情况下一个message书写如下：1234567syntax = &quot;proto3&quot;;message SearchRequest &#123; string query = 1; int32 page_number = 2; int32 result_per_page = 3;&#125; 默认值取消了default选项，也就是说默认值只能有系统默认指定，如字符串为空串，bool型为false，数字为0等。还有对于枚举类，默认是编号为0的成员。 枚举类型必须有一个编号为0的成员来作为其第一个成员。 未知字段在3.5版本之前，不能被解析的字段会被直接抛弃，但是在3.5版本之后，这种特性又回归到proto2上，即不能被解析的字段仍然会保留到下次序列化的输出中 any用于替代extensions，不过尚在开发中 编码Varints规则protobuf的编码基础是Varints，它是将整数序列化为一个或多个byte的方法。 Varints规则是用每byte的第7位存储值，第8位为标志位，若标志位为1，表示后面还有数据，若为0，表示该byte为最后一个。最后Varints采用小端存储。下面举一个例子：123456以整数300为例，300的二进制表示如下： 100101100按小端存储并每7位一组： 0101100 0000010再加上标志位，最终表示如下： 10101100 00000010 Varints的优点是，由于标志位存在，省去了编码长度的表示，其次越小的数编码越短，但是由于标志位的存在，也牺牲了容量，如4byte实际可用表示数值的只有28位 基本编码规则我们首先看一下message中每个成员变量的定义1int32 a = 1; 有三部分组成，变量类型，变量名和变量序号。其中变量名只是为了帮助我们做识别，在编码时不会写入，仅仅用变量序号作为标识，所以也就有了在更新message时序号不能复用的规则，以及可以安全地添加新成员（没有被识别的会直接跳过）。 在编码中，成员变量是以键值对形式出现的，键有两部分组成：成员序号加上成员类型代码，具体代码如下 总共有6种代码，其中group使用的两个代码已被弃用，但是依旧保留。这6个代码需要3位二进制表示，所以键的组成是：字段编号+类型代码（加好表示拼接，并不是运算），示例如下：123456789当我们有一个inst32类型的成员a，编号为1，被赋值为150时由于是int32类型，根据上图采用varint规则，首先对150进行Varints规则编码（过程略）： 10010110 00000001由于是int32类型，类型代码为0，编号为1，类型代码采用三位二进制表示为000，二者拼接之后如下： 0001000所以a的最终编码为 0001000 10010110 00000001改用16进制表示如下 08 96 01 其他类型规则sint32, sint64对于Varints规则不适用与存储负数，负数最高位为1，造成编码极大的浪费，为了节省空间，引入了ZigZag编码格式，基本思想就是将有符号整数转为无符号整数。转换规则如下：12(n &lt;&lt; 1) ^ (n &gt;&gt; 31) #sint32(n &lt;&lt; 1) ^ (n &gt;&gt; 63) #sint64 示例如下： 转为无符号的整数后，再用varints编码即可。 64-bit 和 32-bit 类型这两种分有不同的类型代码，而且编码时不进行其他转换，直接以64位或32位原始存储（注意也是小端存储），读取时根据类型代码直接读取64位或32位 Strings类型代码2表示一类Length-delimited数据。这种编码类型还附带有长度信息，就是在键值之间附加一个用varints编码的长度编码，例子如下：123456789我们有一个string类型的变量b，编号为2，赋值为testing首先testing的utf-8编码如下： 74 65 73 74 69 6e 67长度为7，varints格式编码如下： 00000111编号加类型代码拼接后如下： 00010010最后组合在一起用十六进制表示如下： 12 07 74 65 73 74 69 6e 67 除了表示字符串这种简单信息，还可以表示其他message，如下：123456789101112message Test3 &#123; optional Test1 c = 3;&#125;其中Test1：message Test1 &#123; optional int32 a = 1;&#125;我们对Test1中a赋值为150，上面已经计算过，最后编码为 08 96 01对于Test1类型的变量c表示如下：首先原始数据就是08 96 01，长度为3，编号为3，类型代码为2，组合起来就是 1a 03 08 96 01 packed在proto3中packed为默认的，在proto2中需要手动指定。使用proto3 模式将会使编码更加紧凑（主要针对repeated 类型）。设想，对于一个repeated类型的成员，他们有多个值时，虽然值不同，前键都是相同的，我们可以减少键的数量，如下例：12345假设有一个int32类型的变量d，序号为4，是一个repeated类型，我们赋了4个值，分别是3,270,86942.使用packed模式后，如下22 06 03 8E 02 9E A7 05注意22是编号加类型代码（为2，指packed repeated fields），06表示数据长度后面实际数据，都是varints编码，但是互有区分 顺序编解码顺序和字段顺序无关，由键值对保证即可。未知字段会写在已知字段后。]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Playfair密码与实现]]></title>
    <url>%2F2019%2F03%2F20%2FPlayfair%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[背景这种加密方法是1854年Charles Wheatstone发明的，由Lord Playfair推广，所以命名为Playfair密码。它在一战和二战中都有使用，虽然在一战中就被破译，但是由于使用简单，可以用来保护一些敏感但不很关键的信息，即使被破译，信息也已经过时。 详细流程创建矩阵这种密码使用一个5*5的矩阵作为一个密码表，用作加密解密时的秘钥。这个矩阵由一个关键词生成，首先将关键词从左到右，从上到下填入矩阵，遇到重复元素则省略，写完之后按照字母表顺序，将未出现的字母填充到剩余位置，知道整个矩阵被填满。 如以PLAYFAIREXAMPLE为关键词，生成的矩阵如下： 你可能注意到，密码表中缺少J，由于只有25个空位，对于字母大于25的语言，可以将某两个合并，或者省去出现频率少的，这里把i和j进行了合并 加密加密之前首先将明文两两分组），对每一组分别进行以下处理 在密码表中找到每组中两个字母的位置 若果两个字母相同或组中只有一个字母，则插入一个字母，如X或Q（如果最后一个字母或者重复的字母是X，可以添加Q，替换方法可自定义） 如果两个字母在密码表的同一行，则用这两个字母右边的字母进行替换，如(I,E)替换为(R,X)。我们定义第一列是最后一列的右边 如果两个字母在密码表的同一列，则用这两个字母的下方字母进行替换，如(E,O)替换为(D,V)。我们定义第一行是最后一行的下边 如果两个字母不在同一行同一列，则用对角线上的字母进行替换，至于是行替换或列替换可以自行定义。如(M,Y)替换为(X,F)，使用的是行替换 解密解密就很简单了，基本就是加密的逆过程，还是利用密码表，如在同一行的话，用左边替换，同一列用上面的替换，在对角线上的还是不变。具体过程见后面实现。 示例如还以PLAYFAIREXAMPLE为关键词，明文为MYNAMEISTOM，加密过程如下： 生成矩阵，如上图 分组：MY NA ME IS TO MX (最后一个单独字母补X) 根据密码表替换 XF OL IX MK VK IM 最后密文为： XFOLIXMKVKIM 简单实现这里只是简单实现了Playfair密码原理，有些地方如包含标点符号，非英文字母的情况并没有处理，有兴趣的可以自行修改123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125public class PlayFair &#123; char[][] table = new char[5][5]; //密码表 PlayFair(String key)&#123; generateTable(key);//根据关键字生成密码表 &#125; private void generateTable(String key)&#123; key = key.replaceAll(" ","").toUpperCase(); char[] keys = key.toCharArray(); int count = 0; char alphabet = 'A'; ArrayList&lt;Character&gt; list = new ArrayList&lt;&gt;(); for (int i = 0;i&lt;5;i++)&#123; for (int j = 0;j&lt;5;j++)&#123; while(count &lt; keys.length &amp;&amp; list.contains(keys[count]))&#123; //寻找关键字中不重复的字母 count++; &#125; if (count &lt; keys.length)&#123; table[i][j] = keys[count]; list.add(keys[count]); count++; &#125;else&#123; while (alphabet &lt;= 'Z' &amp;&amp; (list.contains(alphabet) || alphabet == 'J'))&#123; //按顺序从字母表中填充 alphabet++; &#125; table[i][j] = alphabet; alphabet++; &#125; &#125; &#125; &#125; public String encryption(String msg)&#123; //加密算法 msg = msg.replaceAll(" ","").toUpperCase(); char[] msgs = msg.toCharArray(); StringBuffer result = new StringBuffer(); for (int i = 0;i&lt;msgs.length;i++)&#123; char a = msgs[i];//获取分组第一个字母 i++; char b; if (i&lt;msgs.length)&#123; //判读是否越界 if (msgs[i] == a)&#123; //是否重复 if (a == 'X')&#123; //若是X重复，添加Q b = 'Q'; &#125;else&#123; b = 'X'; &#125; i--; &#125;else&#123; b = msgs[i]; &#125; &#125;else&#123; //越界，就是最后只剩一个字母 if (a == 'X')&#123; //若最后一个是X，补Q b = 'Q'; &#125;else&#123; b = 'X'; &#125; &#125; int[] locA = find(a); //寻找分组第一个字母位置 int[] locB = find(b); //寻找分组第二个字母位置 if(locA[0] == locB[0])&#123; //若在同一行 a = locA[1]+1&lt;5?table[locA[0]][locA[1]+1]:table[locA[0]][0]; b = locB[1]+1&lt;5?table[locB[0]][locB[1]+1]:table[locB[0]][0]; &#125;else if(locA[1] == locB[1])&#123; //若在同一列 a = locA[0]+1&lt;5?table[locA[0]+1][locA[1]]:table[0][locA[1]]; b = locB[0]+1&lt;5?table[locB[0]+1][locB[1]]:table[0][locB[1]]; &#125;else&#123; //不在同一行同一列，行替换 a = table[locA[0]][locB[1]]; b = table[locB[0]][locA[1]]; &#125; result.append(a); result.append(b); &#125; return result.toString(); &#125; public String decrypt(String msg)&#123; //解密算法 msg = msg.replaceAll(" ","").toUpperCase(); char[] msgs = msg.toCharArray(); if (msgs.length%2!=0)&#123; //密文不是偶数个，报错 return "error: The length of ciphertext is odd"; &#125; StringBuffer result = new StringBuffer(); for (int i = 0;i&lt;msgs.length;i++)&#123; char a = msgs[i]; i++; char b = msgs[i]; int[] locA = find(a);//寻找分组第一个字母位置 int[] locB = find(b);//寻找分组第二个字母位置 if(locA[0] == locB[0])&#123; //若在同一行 a = locA[1]-1&gt;-1?table[locA[0]][locA[1]-1]:table[locA[0]][4]; b = locB[1]-1&gt;-1?table[locB[0]][locB[1]-1]:table[locB[0]][4]; &#125;else if(locA[1] == locB[1])&#123; //若在同一列 a = locA[0]-1&gt;-1?table[locA[0]-1][locA[1]]:table[4][locA[1]]; b = locB[0]-1&gt;-1?table[locB[0]-1][locB[1]]:table[4][locB[1]]; &#125;else&#123; //不在同一行同一列 a = table[locA[0]][locB[1]]; b = table[locB[0]][locA[1]]; &#125; result.append(a); result.append(b); &#125; return result.toString(); &#125; private int[] find(char c)&#123; //寻找字母在表中位置 if (c == 'J')//对于J当做I处理 c = 'I'; for (int i = 0;i&lt;5;i++)&#123; for (int j = 0;j&lt;5;j++)&#123; if (table[i][j] == c) return new int[]&#123;i,j&#125;; &#125; &#125; return new int[]&#123;-1,-1&#125;; &#125; public static void main(String[] args) &#123;//测试代码 PlayFair p = new PlayFair("PLAYFAIREXAMPLE"); String msg = p.encryption("MYNAMEISTOM"); System.out.println("ciphertext：" + msg); System.out.println("plaintext：" + p.decrypt(msg)); &#125;&#125; 小结本质上Playfair密码仍然是替换型的密码算法。与一般的替换算法相比，他的替换不固定，每个字母都有可能替换为任意一个其他字母。另外实现简单，一个不同秘钥生成不同密码表，产生不同的替换可能。但是它依然可以被破解，首先它是按照顺序读取的，密文与明文基本上一一对应，从而也暴露的密文结构；其次，密码表最后填充时是按照字母表顺序填充，可借助字母出现频率构造密码表，一旦一部分被构造出来，剩下的很容易破解；]]></content>
      <categories>
        <category>密码学</category>
      </categories>
      <tags>
        <tag>密码学</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rlp编码学习]]></title>
    <url>%2F2019%2F03%2F19%2Frlp%E7%BC%96%E7%A0%81%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[RLP的全称是Recursive Length Prefix，是以太坊实现中普遍使用的一种序列化方法，在黄皮书的附录B中有详细的定义，我们这里也简要学习一下 源数据RLP定义了两种源数据，一种是一维的字节数组；另外一种是多维字节数组，也就是一维数组的嵌套。所有要序列化的数据类型，都要有一定的方法转为上述两种格式，转换的方法可以根据不同的实现自己定义。在黄皮书中给出了源数据的定义： RLP定义函数定义如下： 可见分别定义了两个函数，对应了上一节中的两种源数据，分别解释一下这两个函数 源数据为一维字节数组当数据为简单的一维字节数组时，有以下三种序列化规则: 当只含有一个字节时，而且这个字节又小于128，则不做任何处理，直接输出，对应上图第一种情况 当字节数组的长度小于56时，则加上一个前缀，这个前缀等于128+字节数组长度，对应上图第二种情况 若不符合上述两种情况，则加上这样两个前缀，第一个前缀等于183+字节数组长度在大端表示时的长度，第二个前缀为字节数组长度的大端表示，对应上图第三种情况（所谓大端表示就是将高位字节排放在内存的低地址端，0x1234表示为00 00 12 34，BE函数就是去除前面的零，也可以理解为实际长度） 源数据为嵌套的多维字节数组当数据为嵌套的多维数组形式时，有以下两种序列化规则： 首先对数组中每一个子元素都递归使用上一小节中的规则序列化，注意序列化时对象都要为一维字节数组，若子元素也是嵌套格式，则递归调用，之后将每个子元素序列化结果拼接起来。对于拼接后的长度： 若长度小于56，则加上这样一个前缀，这个前缀等于192+拼接后的长度，对应上图第一种情况 若长度大于等于56，则加上这样两个前缀，第一个前缀等于247+拼接后字节数组长度在大端表示时的长度，第二个前缀为拼接后的长度的大端表示，对应上图第二种情况 源数据是标量数据首先RLP只能用于处理正整数，处理是要先用BE函数处理，去掉前导0后，当做字节数组处理，如下图： 解码实际上了解到编码规则后，解码就很简单，关键就是第一个字节，这个字节标识使用哪种情况编码 当位于[0,128)区间时，对应源数据是一维字节数组的第一种情况，就是单一字节 当位于[128,184)区间时，对应源数据是一维字节数组的第二种情况，就是长度小于56的一维字节数组 当位于[184,192)区间时，对应源数据是一维字节数组的第三种情况，这时观察第二个前缀，第二个前缀长度等于第一个字节减去183，然后计算原始数据的真正长度 当位于[192,247)区间时，对于源数据是多维字节数组的第一种情况，就是拼接长度小于56，递归解析其后数据 当位于[247,256)区间时，对于源数据是多维字节数组的第二种情况，类似于第三条规则，先实际计算出第二个前缀的长度，在解析数原始数据长度，在递归解析出原始数据 源码解析源码主要集中在go-ethereum\rlp目录下，再去除一些测试代码，实际功能代码并不多，关键如下：1234decode.go //解码器，就是反序列化encode.go //编码器，就是序列化raw.go //未解码的RLP数据typecache.go //类型缓存， 类型缓存记录了类型-&gt;(编码器|解码器)的内容。 typecache由于go-ethereum是用go语言实现的，而go语言没有方法重载，所以对于不同类型的数据要手动指定需要的编解码器。这个类主要功能是给我们返回一个typeinfo类型的对象，这个对象保存在对应数据类型的编解码方法1234type typeinfo struct &#123; decoder writer&#125; 去创建一个typeinfo需要从cachedTypeInfo方法开始：1234567891011121314151617181920212223242526272829303132333435363738// go-ethereum\rlp\typecache.gofunc cachedTypeInfo(typ reflect.Type, tags tags) (*typeinfo, error) &#123; typeCacheMutex.RLock() info := typeCache[typekey&#123;typ, tags&#125;] //尝试从缓存中国区 typeCacheMutex.RUnlock() if info != nil &#123; //获取成功 return info, nil &#125; typeCacheMutex.Lock() //加锁，避免多线程多次创建 defer typeCacheMutex.Unlock() return cachedTypeInfo1(typ, tags)&#125;func cachedTypeInfo1(typ reflect.Type, tags tags) (*typeinfo, error) &#123; key := typekey&#123;typ, tags&#125; info := typeCache[key]//再次尝试获取，确保只创建一次 if info != nil &#123; //获取成功 return info, nil &#125; typeCache[key] = new(typeinfo) //创建一个空对象 info, err := genTypeInfo(typ, tags) //实际创建对象 if err != nil &#123; //创建失败 delete(typeCache, key) return nil, err &#125; *typeCache[key] = *info //存储到map中 return typeCache[key], err&#125;func genTypeInfo(typ reflect.Type, tags tags) (info *typeinfo, err error) &#123; info = new(typeinfo) if info.decoder, err = makeDecoder(typ, tags); err != nil &#123; return nil, err &#125; if info.writer, err = makeWriter(typ, tags); err != nil &#123; return nil, err &#125; return info, nil&#125; 可见对每种类型，都是单例模式。上述代码中实际创建编解码器的方法是makeDecoder和makeWriter。这两个方法详见下文 encode对于编码器的使用，一般调用Encode函数：123456789101112func Encode(w io.Writer, val interface&#123;&#125;) error &#123; if outer, ok := w.(*encbuf); ok &#123;//判断是否是encbuf类型的writer return outer.encode(val) &#125; eb := encbufPool.Get().(*encbuf) //从并发变量池中获取一个encbuf对象 defer encbufPool.Put(eb) eb.reset() //清空原有数据 if err := eb.encode(val); err != nil &#123; //编码 return err &#125; return eb.toWriter(w)&#125; 编码的核心操作在encbuf的encode方法：12345678func (w *encbuf) encode(val interface&#123;&#125;) error &#123; rval := reflect.ValueOf(val) ti, err := cachedTypeInfo(rval.Type(), tags&#123;&#125;) if err != nil &#123; return err &#125; return ti.writer(rval, w)&#125; 这里就接上了上一节typecache中的方法，这里通过makeWriter确定编码器1234567891011121314151617181920212223242526272829303132333435func makeWriter(typ reflect.Type, ts tags) (writer, error) &#123; kind := typ.Kind() switch &#123; case typ == rawValueType: return writeRawValue, nil case typ.Implements(encoderInterface): return writeEncoder, nil case kind != reflect.Ptr &amp;&amp; reflect.PtrTo(typ).Implements(encoderInterface): return writeEncoderNoPtr, nil case kind == reflect.Interface: return writeInterface, nil case typ.AssignableTo(reflect.PtrTo(bigInt)): return writeBigIntPtr, nil case typ.AssignableTo(bigInt): return writeBigIntNoPtr, nil case isUint(kind): return writeUint, nil case kind == reflect.Bool: return writeBool, nil case kind == reflect.String: return writeString, nil case kind == reflect.Slice &amp;&amp; isByte(typ.Elem()): return writeBytes, nil case kind == reflect.Array &amp;&amp; isByte(typ.Elem()): return writeByteArray, nil case kind == reflect.Slice || kind == reflect.Array: return makeSliceWriter(typ, ts) case kind == reflect.Struct: return makeStructWriter(typ) case kind == reflect.Ptr: return makePtrWriter(typ) default: return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ) &#125;&#125; 就是简单的根据不同的类型创建不同的编码方法，以string为例：1234567891011121314151617181920func writeString(val reflect.Value, w *encbuf) error &#123; s := val.String() if len(s) == 1 &amp;&amp; s[0] &lt;= 0x7f &#123;//只有一个字符，且小于128 w.str = append(w.str, s[0]) &#125; else &#123; w.encodeStringHeader(len(s))//添加前缀 w.str = append(w.str, s...) &#125; return nil&#125;func (w *encbuf) encodeStringHeader(size int) &#123; if size &lt; 56 &#123; //长度小于56 w.str = append(w.str, 0x80+byte(size))//前缀是128+长度 &#125; else &#123; //其他情况 sizesize := putint(w.sizebuf[1:], uint64(size)) //将长度的大端表示写入sizebuf w.sizebuf[0] = 0xB7 + byte(sizesize) //第一个前缀183+字符串长度在大端表示后的长度 w.str = append(w.str, w.sizebuf[:sizesize+1]...)//拼接第二个前缀，字符串长度的大端表示 &#125;&#125; 详细过程见注释，基本过程和RLP定义的一样。对于结构体可能有些特殊：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func makeStructWriter(typ reflect.Type) (writer, error) &#123; fields, err := structFields(typ) //分析结构体每个字段，根据情况指定每个字段的编码方法 if err != nil &#123; return nil, err &#125; writer := func(val reflect.Value, w *encbuf) error &#123; //编码器具体方法 lh := w.list() for _, f := range fields &#123; if err := f.info.writer(val.Field(f.index), w); err != nil &#123; return err &#125; &#125; w.listEnd(lh) return nil &#125; return writer, nil&#125;// go-ethereum\rlp\typecache.gofunc structFields(typ reflect.Type) (fields []field, err error) &#123; for i := 0; i &lt; typ.NumField(); i++ &#123; if f := typ.Field(i); f.PkgPath == "" &#123; // 若果是可导出的，也就是首字母大写，PkgPath为空，不可导出会返回包名 tags, err := parseStructTag(typ, i)//解析每个字段的标签，就是字段后``中定义的 if err != nil &#123; return nil, err &#125; if tags.ignored &#123; continue &#125; info, err := cachedTypeInfo1(f.Type, tags)//根据类型获取cachedTypeInfo，包含编解码器 if err != nil &#123; return nil, err &#125; fields = append(fields, field&#123;i, info&#125;) &#125; &#125; return fields, nil&#125;func parseStructTag(typ reflect.Type, fi int) (tags, error) &#123; f := typ.Field(fi) var ts tags for _, t := range strings.Split(f.Tag.Get("rlp"), ",") &#123; switch t = strings.TrimSpace(t); t &#123; case "": case "-": ts.ignored = true case "nil": ts.nilOK = true case "tail": ts.tail = true if fi != typ.NumField()-1 &#123; return ts, fmt.Errorf(`rlp: invalid struct tag "tail" for %v.%s (must be on last field)`, typ, f.Name) &#125; if f.Type.Kind() != reflect.Slice &#123; return ts, fmt.Errorf(`rlp: invalid struct tag "tail" for %v.%s (field type is not slice)`, typ, f.Name) &#125; default: return ts, fmt.Errorf("rlp: unknown struct tag %q on %v.%s", t, typ, f.Name) &#125; &#125; return ts, nil&#125; 结构体类型的虽然复杂，但也是具体到每个字段执行不同的序列化方法，最后进行拼接。 decode对于解码器一般调用Decode函数：1234567891011121314151617181920212223242526func Decode(r io.Reader, val interface&#123;&#125;) error &#123; return NewStream(r, 0).Decode(val)&#125;func (s *Stream) Decode(val interface&#123;&#125;) error &#123; if val == nil &#123; return errDecodeIntoNil &#125; rval := reflect.ValueOf(val) rtyp := rval.Type() if rtyp.Kind() != reflect.Ptr &#123; //判断是否为指针类型 return errNoPointer &#125; if rval.IsNil() &#123; return errDecodeIntoNil &#125; info, err := cachedTypeInfo(rtyp.Elem(), tags&#123;&#125;) //获取编解码方法 if err != nil &#123; return err &#125; err = info.decoder(s, rval.Elem())//解码 if decErr, ok := err.(*decodeError); ok &amp;&amp; len(decErr.ctx) &gt; 0 &#123; decErr.ctx = append(decErr.ctx, fmt.Sprint("(", rtyp.Elem(), ")")) &#125; return err&#125; 注意decode的逻辑是从Stream中获取源数据，最后解析到val中，所以需要val是一个指针类型，接下来又回到typecache中，通过判断val的类型获取所需的解码器。12345678910111213141516171819202122232425262728293031323334func makeDecoder(typ reflect.Type, tags tags) (dec decoder, err error) &#123; kind := typ.Kind() switch &#123; case typ == rawValueType: return decodeRawValue, nil case typ.Implements(decoderInterface): return decodeDecoder, nil case kind != reflect.Ptr &amp;&amp; reflect.PtrTo(typ).Implements(decoderInterface): return decodeDecoderNoPtr, nil case typ.AssignableTo(reflect.PtrTo(bigInt)): return decodeBigInt, nil case typ.AssignableTo(bigInt): return decodeBigIntNoPtr, nil case isUint(kind): return decodeUint, nil case kind == reflect.Bool: return decodeBool, nil case kind == reflect.String: return decodeString, nil case kind == reflect.Slice || kind == reflect.Array: return makeListDecoder(typ, tags) case kind == reflect.Struct: return makeStructDecoder(typ) case kind == reflect.Ptr: if tags.nilOK &#123; return makeOptionalPtrDecoder(typ) &#125; return makePtrDecoder(typ) case kind == reflect.Interface: return decodeInterface, nil default: return nil, fmt.Errorf("rlp: type %v is not RLP-serializable", typ) &#125;&#125; 以string为例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192func decodeString(s *Stream, val reflect.Value) error &#123; b, err := s.Bytes() if err != nil &#123; return wrapStreamError(err, val.Type()) &#125; val.SetString(string(b)) //还原为string return nil&#125;func (s *Stream) Bytes() ([]byte, error) &#123; kind, size, err := s.Kind() if err != nil &#123; return nil, err &#125; switch kind &#123; case Byte: s.kind = -1 return []byte&#123;s.byteval&#125;, nil case String: b := make([]byte, size) //根据数据长度指定byte数组 if err = s.readFull(b); err != nil &#123; //读取原始数据 return nil, err &#125; if size == 1 &amp;&amp; b[0] &lt; 128 &#123; return nil, ErrCanonSize &#125; return b, nil default: return nil, ErrExpectedString &#125;&#125;func (s *Stream) Kind() (kind Kind, size uint64, err error) &#123; var tos *listpos if len(s.stack) &gt; 0 &#123; tos = &amp;s.stack[len(s.stack)-1] &#125; if s.kind &lt; 0 &#123; s.kinderr = nil if tos != nil &amp;&amp; tos.pos == tos.size &#123; return 0, 0, EOL &#125; s.kind, s.size, s.kinderr = s.readKind() //读取原始数据类型以及长度 if s.kinderr == nil &#123; if tos == nil &#123; if s.limited &amp;&amp; s.size &gt; s.remaining &#123; s.kinderr = ErrValueTooLarge &#125; &#125; else &#123; if s.size &gt; tos.size-tos.pos &#123; s.kinderr = ErrElemTooLarge &#125; &#125; &#125; &#125; return s.kind, s.size, s.kinderr&#125;func (s *Stream) readKind() (kind Kind, size uint64, err error) &#123; b, err := s.readByte() //读第一个byte if err != nil &#123; if len(s.stack) == 0 &#123; switch err &#123; case io.ErrUnexpectedEOF: err = io.EOF case ErrValueTooLarge: err = io.EOF &#125; &#125; return 0, 0, err &#125; s.byteval = 0 switch &#123; //根据第一字节的只判断原始数据类型 case b &lt; 0x80: //原始数据只有一个byte，且小于128 s.byteval = b return Byte, 0, nil case b &lt; 0xB8: //原始数据长度小于56 //返回的第二个数据获得原始数据长度 return String, uint64(b - 0x80), nil case b &lt; 0xC0: size, err = s.readUint(b - 0xB7) if err == nil &amp;&amp; size &lt; 56 &#123; err = ErrCanonSize &#125; return String, size, err case b &lt; 0xF8: return List, uint64(b - 0xC0), nil default: size, err = s.readUint(b - 0xF7) if err == nil &amp;&amp; size &lt; 56 &#123; err = ErrCanonSize &#125; return List, size, err &#125;&#125; 可见流程就是rlp编码的逆向过程，和我们之前讲的解码方法一样，关键是通过第一个字节获取原始数据的类型，然后推算出原始数据的长度，最后解析即可 小结最后，go-ethereum源码中rlp实现部分还是很完整的，并且没有什么其他依赖，都使用的是go标准包，所以可以单独拿出来做一个库，以后遇到需要用rlp编码的地方，可以直接拿来使用。还有这一部分源码大量的使用了反射，对于学习go语言反射也是很好的一个素材]]></content>
      <categories>
        <category>编码</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言signal包使用指南]]></title>
    <url>%2F2019%2F02%2F27%2FGo%E8%AF%AD%E8%A8%80signal%E5%8C%85%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[go语言学习笔记：signal包 os/signal主要用于实现对信号的处理(官方文档) 信号类型首先关于linux信号机制课自行查找资料，这里不再赘述。linux中的全部信号如下图： 在go中预定义了几种信号：1234567891011121314151617//"syscall"const ( // More invented values for signals SIGHUP = Signal(0x1) SIGINT = Signal(0x2) SIGQUIT = Signal(0x3) SIGILL = Signal(0x4) SIGTRAP = Signal(0x5) SIGABRT = Signal(0x6) SIGBUS = Signal(0x7) SIGFPE = Signal(0x8) SIGKILL = Signal(0x9) SIGSEGV = Signal(0xb) SIGPIPE = Signal(0xd) SIGALRM = Signal(0xe) SIGTERM = Signal(0xf)) 首先在这么多信号中，SIGKILL和SIGSTOP是无法被程序捕获的，其中SIGKILL就是我们常用的kill -9 pid方法锁触发的。其次一些有程序执行中的错误所触发的同步信号如SIGBUS，SIGFPE和SIGSEGV，go会将其转为panic，不过若是我们通过kill方式触发也是可以被捕获的。 除了那些同步信号，其余都是异步信号，是由内核或其他程序发送的，我们都可以捕获。 在异步信号中，当程序丢失终端时收到SIGHUP，在终端按下中断字符(一般为ctrl+c)时收到SIGINT，在终端按下退出字符(一般为^\)时收到SIGQUIT。 正常的，信号都是有默认动作的，最常见的如按下ctrl+c退出程序。其余的SIGHUP，SIGINT或SIGTERM信号导致程序退出。SIGQUIT，SIGILL，SIGTRAP，SIGABRT，SIGSTKFLT，SIGEMT或SIGSYS信号导致程序以堆栈转储退出。SIGTSTP，SIGTTIN或SIGTTOU信号获取系统默认行为（shell使用这些信号进行作业控制）。SIGPROF会被go运行时捕获实现runtime.CPUProfile. 捕获信号signal包中提供了Notify方法，用于注册所要监听的信号。1func Notify(c chan&lt;- os.Signal, sig ...os.Signal) 该方法需要提供一个Signal类型的channel，以及要监听的信号(当不指定时会监听所有信号)。当有信号到来时，会被写入所传入的channel中，之后拿出来即可。下例是一个监听ctrl+c退出的程序：1234567func main() &#123; c := make(chan os.Signal, 1) signal.Notify(c, syscall.SIGINT) s := &lt;-c fmt.Println("Got signal:", s)&#125; 上述程序会在第五行阻塞，直到有一个信号过来。运行结果如下： 其余apifunc Stop(c chan&lt;- os.Signal)这个方法用于停止监听信号，之后不会再往所指定的channel中写入任何内容。搭配Notify使用如下：12345678go func() &#123; sigc := make(chan os.Signal, 1) signal.Notify(sigc, syscall.SIGINT, syscall.SIGTERM) //监听信号 defer signal.Stop(sigc) //确保关闭 &lt;-sigc //线程阻塞 log.Info("Got interrupt, shutting down...") go Stop() //执行程序停止逻辑 &#125;() func Ignore(sig …os.Signal)忽略指定的信号，同理，若是未指定，忽略所有信号 func Ignored(sig os.Signal) bool检查某个信号是否被忽略 func Reset(sig …os.Signal)重置之前调用Notify时的处理。也就是不在捕获信号，进行默认操作。注意和Ignore的区别，Ignore是不对信号做任何操作，Reset是恢复默认操作。 附录部分信号说明(图片来源于网络)：]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[geth的init流程分析]]></title>
    <url>%2F2019%2F02%2F26%2Fgeth%E7%9A%84init%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[go-ethereum源码学习：init流程 geth总览首先看一下geth这个程序的总体设计，其主要代码位于go-ethereum\cmd\geth里面，先看main.go,这是一个利用urfave/cli开发的命令行程序，关于这个库的简单介绍见这里。在开头var代码块中中实例化了cli的app对象:1234567891011121314app = utils.NewApp(gitCommit, "the go-ethereum command line interface")func NewApp(gitCommit, usage string) *cli.App &#123; app := cli.NewApp() app.Name = filepath.Base(os.Args[0]) app.Author = "" //app.Authors = nil app.Email = "" app.Version = params.VersionWithMeta //见go-ethereum\params\version.go 生成版本号 if len(gitCommit) &gt;= 8 &#123; app.Version += "-" + gitCommit[:8] //gitCommit之前在编译时定义 &#125; app.Usage = usage return app&#125; 实例化之后，定义了大量flag，详细信息可以输入geth -h或到官方文档查看。接下来，在init()方法中进行进一步初始化，添加了大量command及先前定义的flag。并定义了geth的action：1234567891011app.Action = gethfunc geth(ctx *cli.Context) error &#123; if args := ctx.Args(); len(args) &gt; 0 &#123; //仅执行geth时，不能有任何附加参数 return fmt.Errorf("invalid command: %q", args[0]) &#125; node := makeFullNode(ctx) //创建默认节点 defer node.Close() startNode(ctx, node) node.Wait() return nil&#125; 在init中还定义了app.Before用于初始化工作：123456789101112131415161718192021222324252627282930313233app.Before = func(ctx *cli.Context) error &#123; logdir := "" if ctx.GlobalBool(utils.DashboardEnabledFlag.Name) &#123; logdir = (&amp;node.Config&#123;DataDir: utils.MakeDataDir(ctx)&#125;).ResolvePath("logs") &#125; if err := debug.Setup(ctx, logdir); err != nil &#123; //见\go-ethereum\internal\debug\flags.go return err &#125; // Cap the cache allowance and tune the garbage collector var mem gosigar.Mem //见\go-ethereum\vendor\github.com\elastic\gosigar\sigar_interface.go //获取系统内存信息 if err := mem.Get(); err == nil &#123; //配置缓存 allowance := int(mem.Total / 1024 / 1024 / 3) if cache := ctx.GlobalInt(utils.CacheFlag.Name); cache &gt; allowance &#123; log.Warn("Sanitizing cache to Go's GC limits", "provided", cache, "updated", allowance) ctx.GlobalSet(utils.CacheFlag.Name, strconv.Itoa(allowance)) &#125; &#125; // Ensure Go's GC ignores the database cache for trigger percentage cache := ctx.GlobalInt(utils.CacheFlag.Name) gogc := math.Max(20, math.Min(100, 100/(float64(cache)/1024))) log.Debug("Sanitizing Go's GC trigger", "percent", int(gogc)) godebug.SetGCPercent(int(gogc)) //设置垃圾收集目标百分比 // Start metrics export if enabled utils.SetupMetrics(ctx) //默认是关闭的，开关在\go-ethereum\metrics\metrics.go // Start system runtime metrics collection go metrics.CollectProcessMetrics(3 * time.Second) //默认不会启动 return nil &#125; 随后也定义了app.After逻辑12345app.After = func(ctx *cli.Context) error &#123; debug.Exit() console.Stdin.Close() // 重置终端模式 return nil &#125; 接下来进入main函数123456func main() &#123; if err := app.Run(os.Args); err != nil &#123; //运行处理程序 fmt.Fprintln(os.Stderr, err) os.Exit(1) &#125;&#125; 到这里，geth大致轮廓就看完了，随后会根据用户输入的命令执行相应的逻辑。 init这是初始化函数。源码中描述如下 The init command initializes a new genesis block and definition for the network.This is a destructive action and changes the network in which you will beparticipating.It expects the genesis file as argument. 一般使用如下1geth init gen.json --datadir ./mychain/ 需要指定一个json文件，可选择指定数据存储路径。在源码定义如下：123456789101112// go-ethereum\cmd\geth\chaincmd.goinitCommand = cli.Command&#123; Action: utils.MigrateFlags(initGenesis), Name: "init", Usage: "Bootstrap and initialize a new genesis block", ArgsUsage: "&lt;genesisPath&gt;", Flags: []cli.Flag&#123; utils.DataDirFlag, &#125;, Category: "BLOCKCHAIN COMMANDS", Description: `.....`, &#125; 可见子命令名就是init，没有别名，只有一个flag，定义如下1234567// go-ethereum\cmd\utils\flags.goDataDirFlag = DirectoryFlag&#123; Name: "datadir", Usage: "Data directory for the databases and keystore", Value: DirectoryString&#123;node.DefaultDataDir()&#125;, //获取默认目录，见go-ethereum\node\defaults.go //linux下为/home/&lt;user&gt;/.ethereum &#125; DirectoryString定义如下123456789101112131415161718192021// go-ethereum\cmd\utils\customflags.gotype DirectoryString struct &#123; Value string&#125;func (self *DirectoryString) String() string &#123; return self.Value&#125;func (self *DirectoryString) Set(value string) error &#123; self.Value = expandPath(value) return nil&#125;func expandPath(p string) string &#123; if strings.HasPrefix(p, &quot;~/&quot;) || strings.HasPrefix(p, &quot;~\\&quot;) &#123; if home := homeDir(); home != &quot;&quot; &#123; p = home + p[1:] &#125; &#125; return path.Clean(os.ExpandEnv(p))&#125; DataDirFlag作用主要就是定义初始化生成数据的存储路径，之后我们看initCommand的action，这个是关键：1Action: utils.MigrateFlags(initGenesis), 调用了utils.MigrateFlags，定义如下1234567891011// \go-ethereum\cmd\utils\flags.gofunc MigrateFlags(action func(ctx *cli.Context) error) func(*cli.Context) error &#123; return func(ctx *cli.Context) error &#123; for _, name := range ctx.FlagNames() &#123; if ctx.IsSet(name) &#123; ctx.GlobalSet(name, ctx.String(name)) &#125; &#125; return action(ctx) &#125;&#125; 这个方法并没有什么实际意义，只是将所有用户指定的flag以GlobalSet的形式存了起来，主要逻辑在传递进来的action，我们这里传递的action如下：12345678910111213141516171819202122232425262728293031323334// go-ethereum\cmd\geth\chaincmd.gofunc initGenesis(ctx *cli.Context) error &#123; // Make sure we have a valid genesis JSON genesisPath := ctx.Args().First() //获取genesis.json if len(genesisPath) == 0 &#123; utils.Fatalf("Must supply path to genesis JSON file") &#125; file, err := os.Open(genesisPath) if err != nil &#123; utils.Fatalf("Failed to read genesis file: %v", err) &#125; defer file.Close() genesis := new(core.Genesis) //Genesis结构体见 go-ethereum\core\genesis.go if err := json.NewDecoder(file).Decode(genesis); err != nil &#123; //解析json文件，遇到错误就退出 utils.Fatalf("invalid genesis file: %v", err) &#125; // Open an initialise both full and light databases stack := makeFullNode(ctx) //建立默认节点 defer stack.Close() for _, name := range []string&#123;"chaindata", "lightchaindata"&#125; &#123; chaindb, err := stack.OpenDatabase(name, 0, 0) //创建数据库 if err != nil &#123; utils.Fatalf("Failed to open database: %v", err) &#125; _, hash, err := core.SetupGenesisBlock(chaindb, genesis) //写创世区块内容 if err != nil &#123; utils.Fatalf("Failed to write genesis block: %v", err) &#125; log.Info("Successfully wrote genesis state", "database", name, "hash", hash) &#125; return nil&#125; 刚开始，获取了子命令参数，也就是我们指定的genesis.json的文件，然后尝试打开并解析其中内容，任何一步出错的就终止程序，之后调用了stack := makeFullNode(ctx)，这一部分比较繁琐，实现如下1234567891011121314151617181920212223242526272829303132333435363738394041424344// go-ethereum\cmd\geth\config.gofunc makeFullNode(ctx *cli.Context) *node.Node &#123; stack, cfg := makeConfigNode(ctx) if ctx.GlobalIsSet(utils.ConstantinopleOverrideFlag.Name) &#123; cfg.Eth.ConstantinopleOverride = new(big.Int).SetUint64(ctx.GlobalUint64(utils.ConstantinopleOverrideFlag.Name)) &#125; utils.RegisterEthService(stack, &amp;cfg.Eth) //注册eth服务， eth服务是以太坊的主要的服务。是以太坊功能的提供者。 if ctx.GlobalBool(utils.DashboardEnabledFlag.Name) &#123; //默认是false utils.RegisterDashboardService(stack, &amp;cfg.Dashboard, gitCommit) &#125; // Whisper must be explicitly enabled by specifying at least 1 whisper flag or in dev mode //Whisper是一个独立模块，用来进行加密通讯的功能。 需要显式的提供参数来启用，或者是处于开发模式。 shhEnabled := enableWhisper(ctx) //自动启动的条件没有手动配置Whisper并且处于开发者模式 shhAutoEnabled := !ctx.GlobalIsSet(utils.WhisperEnabledFlag.Name) &amp;&amp; ctx.GlobalIsSet(utils.DeveloperFlag.Name) //二者满足一个就启动（注册shh服务）,一般都不满足 if shhEnabled || shhAutoEnabled &#123; if ctx.GlobalIsSet(utils.WhisperMaxMessageSizeFlag.Name) &#123; cfg.Shh.MaxMessageSize = uint32(ctx.Int(utils.WhisperMaxMessageSizeFlag.Name)) &#125; if ctx.GlobalIsSet(utils.WhisperMinPOWFlag.Name) &#123; cfg.Shh.MinimumAcceptedPOW = ctx.Float64(utils.WhisperMinPOWFlag.Name) &#125; if ctx.GlobalIsSet(utils.WhisperRestrictConnectionBetweenLightClientsFlag.Name) &#123; cfg.Shh.RestrictConnectionBetweenLightClients = true &#125; utils.RegisterShhService(stack, &amp;cfg.Shh) &#125; // Configure GraphQL if required if ctx.GlobalIsSet(utils.GraphQLEnabledFlag.Name) &#123; if err := graphql.RegisterGraphQLService(stack, cfg.Node.GraphQLEndpoint(), cfg.Node.GraphQLCors, cfg.Node.GraphQLVirtualHosts, cfg.Node.HTTPTimeouts); err != nil &#123; utils.Fatalf("Failed to register the Ethereum service: %v", err) &#125; &#125; // Add the Ethereum Stats daemon if requested. if cfg.Ethstats.URL != "" &#123; utils.RegisterEthStatsService(stack, cfg.Ethstats.URL) &#125; return stack&#125; 第一行调用了makeConfigNode，实现如下1234567891011121314151617181920212223242526272829303132333435363738// go-ethereum\cmd\geth\config.gofunc makeConfigNode(ctx *cli.Context) (*node.Node, gethConfig) &#123; // Load defaults. //加载各个模块的默认配置 cfg := gethConfig&#123; Eth: eth.DefaultConfig, // go-ethereum\eth\config.go //Ethereum主网的默认配置，如NetworkId，SyncMode等 Shh: whisper.DefaultConfig, // go-ethereum\whisper\whisperv6\config.go Node: defaultNodeConfig(), //见defaultNodeConfig()，默认节点配置 Dashboard: dashboard.DefaultConfig, //一个独立模块，见go-ethereum\dashboard\README &#125; // Load config file. //加载配置文件，一般未指定配置文件，此处为空 if file := ctx.GlobalString(configFileFlag.Name); file != "" &#123; if err := loadConfig(file, &amp;cfg); err != nil &#123; utils.Fatalf("%v", err) &#125; &#125; // Apply flags. //从flag加载配置 utils.SetULC(ctx, &amp;cfg.Eth) //ULC:Ultra Light client go-ethereum\cmd\utils\flags.go utils.SetNodeConfig(ctx, &amp;cfg.Node) stack, err := node.New(&amp;cfg.Node) //实例化node对象 go-ethereum\node\node.go //stack就是Node对象 if err != nil &#123; utils.Fatalf("Failed to create the protocol stack: %v", err) &#125; utils.SetEthConfig(ctx, stack, &amp;cfg.Eth) if ctx.GlobalIsSet(utils.EthStatsURLFlag.Name) &#123; cfg.Ethstats.URL = ctx.GlobalString(utils.EthStatsURLFlag.Name) &#125; utils.SetShhConfig(ctx, stack, &amp;cfg.Shh) utils.SetDashboardConfig(ctx, &amp;cfg.Dashboard) return stack, cfg&#125; 这个方法首先加载代码中的默认配置，之后加载配置文件配置，随后加载用户在命令行指定的配置，由于我们分析的是init流程，所以大部分配置都是默认配置，相关代码注释见这里代码注释 经过makeConfigNode之后，我们获得stack, cfg，stack是一个node对象，cfg是配置信息。回到makeFullNode，初始化node后，又调用了utils.RegisterEthService(stack, &amp;cfg.Eth)取注册eth服务，eth服务是以太坊功能的主要服务提供者：12345678910111213141516171819202122// go-ethereum\cmd\utils\flags.gofunc RegisterEthService(stack *node.Node, cfg *eth.Config) &#123; var err error //默认是FastSync if cfg.SyncMode == downloader.LightSync &#123; err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) &#123; return les.New(ctx, cfg) &#125;) &#125; else &#123; err = stack.Register(func(ctx *node.ServiceContext) (node.Service, error) &#123; fullNode, err := eth.New(ctx, cfg) if fullNode != nil &amp;&amp; cfg.LightServ &gt; 0 &#123; ls, _ := les.NewLesServer(fullNode, cfg) fullNode.AddLesServer(ls) &#125; return fullNode, err &#125;) &#125; if err != nil &#123; Fatalf("Failed to register the Ethereum service: %v", err) &#125;&#125; 我们看一下Register的实现：12345678910111213// go-ethereum\node\node.gofunc (n *Node) Register(constructor ServiceConstructor) error &#123; n.lock.Lock() //同步操作 defer n.lock.Unlock() if n.server != nil &#123; return ErrNodeRunning &#125; //将ServiceConstructor添加到serviceFuncs这个切片中,ServiceConstructor定义如下 //type ServiceConstructor func(ctx *ServiceContext) (Service, error) n.serviceFuncs = append(n.serviceFuncs, constructor) return nil&#125; 逻辑很简单，就是将要注册的东西存起来。我们再来看注册的eth服务的内容。我们分析的是init的流程，默认的同步模式是FastSync，调用eth.New(ctx, cfg)，创建了一个Ethereum对象，这里我们暂不分析创建过程，只需知道这里实例化了了一个Ethereum对象，也就是变量fullNode。在回到makeConfigNode，后面就是根据具体情况去注册各种服务，如DashboardService，ShhService等，套路和eth注册是一样的。需要注意的是，这里面除了eth服务是必须的，其他的都是可选的。最后返回stack，也就是node对象 实际上，在我们分析的流程中，initGenesis调用的makeFullNode方法都是在做初始化。回到initGenesis，makeFullNode之后有一个遍历，遍历了两个字符串：”chaindata”, “lightchaindata”。他们的用处是用来创建数据库：12345678910// go-ethereum\node\node.gochaindb, err := stack.OpenDatabase(name, 0, 0)func (n *Node) OpenDatabase(name string, cache, handles int) (ethdb.Database, error) &#123; if n.config.DataDir == "" &#123; return ethdb.NewMemDatabase(), nil //如果路径为空，创建内存数据库，实际上就是放在内存中的一个map // go-ethereum\ethdb\memory_database.go &#125; return ethdb.NewLDBDatabase(n.config.ResolvePath(name), cache, handles)&#125; 1234567891011121314151617181920212223242526272829303132333435// go-ethereum\ethdb\database.gofunc NewLDBDatabase(file string, cache int, handles int) (*LDBDatabase, error) &#123; logger := log.New("database", file) //从init调用过来时，cache和handles都为0 //默认启动节点，cache为512，handles为0，在node.DefaultConfig配置 // Ensure we have some minimal caching and file guarantees if cache &lt; 16 &#123; cache = 16 &#125; if handles &lt; 16 &#123; handles = 16 &#125; logger.Info("Allocated cache and file handles", "cache", common.StorageSize(cache*1024*1024), "handles", handles) // Open the db and recover any potential corruptions db, err := leveldb.OpenFile(file, &amp;opt.Options&#123; OpenFilesCacheCapacity: handles, BlockCacheCapacity: cache / 2 * opt.MiB, WriteBuffer: cache / 4 * opt.MiB, // Two of these are used internally Filter: filter.NewBloomFilter(10), &#125;) if _, corrupted := err.(*errors.ErrCorrupted); corrupted &#123; db, err = leveldb.RecoverFile(file, nil) &#125; // (Re)check for errors and abort if opening of the db failed if err != nil &#123; return nil, err &#125; return &amp;LDBDatabase&#123; fn: file, db: db, log: logger, &#125;, nil&#125; 这里使用的levelDB数据库，关于这个数据库的介绍与使用见这里。逻辑很简单就是在指定位置创建levelDB数据库。数据库创建完成后，回到initGenesis，接下来开始写内容：123456789101112131415161718192021222324252627_, hash, err := core.SetupGenesisBlock(chaindb, genesis)// go-ethereum\core\genesis.gofunc SetupGenesisBlock(db ethdb.Database, genesis *Genesis) (*params.ChainConfig, common.Hash, error) &#123; return SetupGenesisBlockWithOverride(db, genesis, nil)&#125;func SetupGenesisBlockWithOverride(db ethdb.Database, genesis *Genesis, constantinopleOverride *big.Int) (*params.ChainConfig, common.Hash, error) &#123; if genesis != nil &amp;&amp; genesis.Config == nil &#123; //如果json，没有配置config部分，则退出 return params.AllEthashProtocolChanges, common.Hash&#123;&#125;, errGenesisNoConfig &#125; // Just commit the new block if there is no stored genesis block. stored := rawdb.ReadCanonicalHash(db, 0) // go-ethereum\core\rawdb\accessors_chain.go //从数据库中获取创世区块的hash if (stored == common.Hash&#123;&#125;) &#123; //如果为空，init会进入这个分支 if genesis == nil &#123; log.Info("Writing default main-net genesis block") genesis = DefaultGenesisBlock() &#125; else &#123; log.Info("Writing custom genesis block") &#125; // 写入数据库 block, err := genesis.Commit(db) return genesis.Config, block.Hash(), err &#125; .....&#125; 首先利用rawdb.ReadCanonicalHash(db, 0)或取genesis区块，由于是初始化，自然获取不到，进入下面的if分枝，首先调用了Commit(db)：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// go-ethereum\core\genesis.gofunc (g *Genesis) Commit(db ethdb.Database) (*types.Block, error) &#123; block := g.ToBlock(db) if block.Number().Sign() != 0 &#123; return nil, fmt.Errorf("can't commit genesis block with number &gt; 0") &#125; // go-ethereum\core\rawdb\accessors_chain.go 写入各种信息 rawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty) rawdb.WriteBlock(db, block) rawdb.WriteReceipts(db, block.Hash(), block.NumberU64(), nil) rawdb.WriteCanonicalHash(db, block.Hash(), block.NumberU64()) rawdb.WriteHeadBlockHash(db, block.Hash()) rawdb.WriteHeadHeaderHash(db, block.Hash()) config := g.Config if config == nil &#123; config = params.AllEthashProtocolChanges &#125; rawdb.WriteChainConfig(db, block.Hash(), config) return block, nil&#125;func (g *Genesis) ToBlock(db ethdb.Database) *types.Block &#123; if db == nil &#123; //如果数据库为nil，建立一个内存数据库 db = ethdb.NewMemDatabase() &#125; statedb, _ := state.New(common.Hash&#123;&#125;, state.NewDatabase(db)) // go-ethereum\core\state\statedb.go // go-ethereum\core\state\database.go //state.New：根据给定的Tried创建一个新的状态() //state.NewDatabase：创建一个内存数据库 for addr, account := range g.Alloc &#123; //遍历json文件中的alloc配置 statedb.AddBalance(addr, account.Balance) statedb.SetCode(addr, account.Code) statedb.SetNonce(addr, account.Nonce) for key, value := range account.Storage &#123; statedb.SetState(addr, key, value) &#125; &#125; root := statedb.IntermediateRoot(false) head := &amp;types.Header&#123; //go-ethereum\core\types\block.go 创建区块头 Number: new(big.Int).SetUint64(g.Number), Nonce: types.EncodeNonce(g.Nonce), Time: new(big.Int).SetUint64(g.Timestamp), ParentHash: g.ParentHash, Extra: g.ExtraData, GasLimit: g.GasLimit, GasUsed: g.GasUsed, Difficulty: g.Difficulty, MixDigest: g.Mixhash, Coinbase: g.Coinbase, Root: root, &#125; if g.GasLimit == 0 &#123; head.GasLimit = params.GenesisGasLimit //默认为4712388 go-ethereum\params\protocol_params.go &#125; if g.Difficulty == nil &#123; head.Difficulty = params.GenesisDifficulty //默认为131072 &#125; statedb.Commit(false) statedb.Database().TrieDB().Commit(root, true) return types.NewBlock(head, nil, nil, nil)//创建一个新的区块 go-ethereum\core\types\block.go //每个区块有四部分内容，区块头，交易列表，叔块，收据&#125; Commit方法中首先调用了ToBlock，在这里创建了一个实例化的区块对象并返回，之后再Commit中写入各种信息到数据库中，我们以总难度为例，看它是如何写入的：1234567891011rawdb.WriteTd(db, block.Hash(), block.NumberU64(), g.Difficulty)func WriteTd(db DatabaseWriter, hash common.Hash, number uint64, td *big.Int) &#123; data, err := rlp.EncodeToBytes(td) if err != nil &#123; log.Crit("Failed to RLP encode block total difficulty", "err", err) &#125; if err := db.Put(headerTDKey(number, hash), data); err != nil &#123; log.Crit("Failed to store block total difficulty", "err", err) &#125;&#125; 首先WriteTd接收四个参数，分别是数据库的实例，区块hash，区块编号，难度值。之后将难度值进行RLP编码，然后调用db.Put()写入数据库，写入的键是headerTDKey(number, hash)，值就是编码过得数据。在commit的最后，写入所有数据后，返回了区块实例，然后回到initGenesis方法，最终返回了错误信息和区块hash。到此init的流程就结束了。创世区块的内容也被写入了数据库。]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go-ethereum编译流程简单学习]]></title>
    <url>%2F2019%2F02%2F21%2Fgo-ethereum%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B%E7%AE%80%E5%8D%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[go-ethereum源码学习：源码编译流程 一般，在根目录下执行make geth 或者 make all编译go-ethereum。前者仅编译go-ethereum主程序，后者编译所有模块。详见go-ethereum的README 以make geth为例，进入go-ethereum根目录下，打开Makefile文件，执行的逻辑是1234geth: build/env.sh go run build/ci.go install ./cmd/geth @echo "Done building." @echo "Run \"$(GOBIN)/geth\" to launch geth." 可见直接执行了build/env.sh脚本，传入的参数为go run build/ci.go install ./cmd/geth 进入这个脚本文件，签名若干行都是在进行目录和环境设置，只有最后一行起到编译作用1exec "$@" exec指执行后面的跟的命令，$@是一个变量，存储着传给这个脚本的所有参数，这里的参数就是上面说的go run build/ci.go install ./cmd/geth ./cmd/geth，这就是go的编译命令，他编译运行的是build/ci.go文件，顺便还传入了参数install ./cmd/geth 首先在这个文件开头，我们可以知道这也是一个CLI程序，和我们编译生成的geth类似，在开头列出了一些命令的格式，如第一行就是我们流程中将要执行的1234Available commands are: install [ -arch architecture ] [ -cc compiler ] [ packages... ] ... 我们所要执行的就是 install ./cmd/geth，没有任何附加参数。 先从main函数开始，在这里的switch结构中，判断了第一个参数，我们这里为install，执行doInstall(os.Args[2:])，传入的参数自然为./cmd/geth。doInstall这个方法也比较简单，首先，利用flag进行参数解析，然后判断了go的版本后，最后根据需求拼凑编译指令。这一部分关键步骤注释见这里]]></content>
      <categories>
        <category>go-ethereum源码学习</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>go-ethereum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go的CLI程序开发]]></title>
    <url>%2F2019%2F02%2F21%2Fgo%E7%9A%84CLI%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[go语言学习笔记：CLI程序开发 CLI(command-line interface)就是命令行界面，我们在linux命令行中输入的一个个指令都是CLI程序，典型如tar命令，一般使用go开发一个命令行程序有以下几种方法 Arguments这个算是最基本的方法，但也是最繁琐的。主要借助os.Args，查看源码，介绍如下 12// Args hold the command-line arguments, starting with the program name.var Args []string 这里告诉我们这个数组切片保存了命令行的参数，且第一个参数程序名。这里需要注意的一点是，就算一个参数不附加，os.Args这个数组也是有一个值的，就是当前的程序，所以我们在通过len(os.Args)判断是否有额外参数时，len(os.Args)&gt;1才能说明有额外参数 既然我们可以通过这个数组获取所有参数，那么就可以通过一系列参数判断，开发出一个命令行程序，但无疑是很繁琐的，所以go标准库中提供了一个简单的库来帮助我们 flag我们先引入一个小例子 12345func main() &#123; dir := flag.String("dir","/home/user","data directory") flag.Parse() fmt.Println(*dir)&#125; 之后再命令行输入下面命令去运行，123456789101112131415161718go run example.go 输出/home/usergo run example.go -dir /etc/opt 输出/etc/optgo run in.go -h输出：Usage of .../example.exe -dir string data directory (default &quot;/home/user&quot;) go run example.go -dirs /etc输出：flag provided but not defined: -dirsUsage of .../example.exe -dir string data directory (default &quot;/home/user&quot;) 可以看出这已经是一个比较完善的命令程序，我们指定了参数名：dir，默认值：”/home/user”，以及参数解释：”data directory”。之后flag包自动帮我们解析参数，并附带了-h帮助信息，以及未定义参数的提示信息 通过上面的例子基本可以了解flag大体使用方法，首先定义一些参数，之后flag.Parse()进行解析，最后使用解析到的数据即可，关于Parse()源码如下 123func Parse() &#123; CommandLine.Parse(os.Args[1:])&#125; 可见也是用的os.Args[1:]作为输入，只不过这个包帮我们做好了匹配及错误处理而已。接下来详细学习一下用法 flag定义基本上分三大类： flag.Xxx(name,value,usage) *Xxx Xxx表示相应的数据类型，如Bool，Float64，Int，String等等，参数都是三个：名称，默认值，用法介绍。返回值1是相应类型的一个指针变量。例子如下： 1dir := flag.String("dir","/home/user","data directory") flag.XxxVar(p,name,value,usage) Xxx也是表示相应的数据类型，和上面那个一样，区别是多了一个参数，需要传入一个变量的引用，然后解析时会把值赋给这个变量，没有返回值，例子如下 12var dir stringflag.StringVar(&amp;dir,"dir","/home/user","data directory") flag.Var(value,name,usage) 当包中预定义的数据类型不能满足要求时，就需要这个方法了，第一个参数是一个引用，其类是实现flag.Value 接口，剩下的两个参数意义和上边的一样。先看一下这个接口 1234type Value interface &#123; String() string Set(string) error&#125; 基本上就是要定义存取方法，只不过存取的值都必须是string类型，举一个简单的例子 1234567891011121314151617181920212223242526272829303132type student struct &#123; name string age int64&#125;func (s *student) String()string&#123; return s.name+string(s.age)&#125;func (s *student) Set(str string)error&#123; slice:=strings.Split(str,",") if len(slice)!=2 &#123; return errors.New("bad format") &#125; i,err:=strconv.ParseInt(slice[1],10,64) if err!=nil &#123; return err &#125; s.name = slice[0] s.age = i return nil&#125;func main() &#123; var dir student flag.Var(&amp;dir,"stu","student info") flag.Parse() fmt.Println(dir.name,"+++",dir.age)&#125;//用法//go run example.go -stu wang,21 flag格式一般形式如下： 123-flag-flag = x-flag x //仅适用于非boolean类型flag 其中-和–都是允许的 flag解析会在遇到第一个非flag参数或单独的–之后停止，例 123456func main() &#123; n := flag.Int("n",0,"number") flag.Parse() fmt.Println(*n) fmt.Println(flag.NArg())&#125; 下面的命令都会由于提前停止解析得不到所要的值 123go run example.go 45 -n 1 //flag.NArg()会返回3go run example.go - -n 1 //flag.NArg()会返回3go run example.go -- -n 1 //flag.NArg()会返回2，--被当做终止符 其他方法 Arg(i int)string ， Args()[]string ， NArg()int ， NFlag()int Arg(i int)返回的是在被flag解析后，第i个剩余的参数，没有的话返回空字符串 Args()返回的是被flag解析后，剩余参数数组切片 NArg()返回的是被flag解析后，剩余参数的个数 NFlag()返回的是接收到的flag参数个数（并不是定义的个数） 12345678910111213n := flag.Int("n",0,"number")flag.Parse()fmt.Println(n)fmt.Println(flag.Arg(1))//输入&gt;go run example.go -n 1 454 555，返回555 //输入&gt;go run example.go -n 1 454 ，返回空 fmt.Println(flag.Args())//输入&gt;go run example.go -n 1 454 555，返回[454,555]fmt.Println(flag.NArg())//输入&gt;go run example.go -n 1 454 555,返回2fmt.Println(flag.NFlag())//输入&gt;go run example.go -n 1 454 555，返回1 //输入&gt;go run example.go 454 555，返回0 flag.Parsed()bool 判断参数是否解析过 Set(name, value string) error 给指定的flag赋值 flag.Usage 库里已经帮我们自动生成了一套帮助信息，可以使用-h或-help查看，另外我们也可以自己定制，重写Usage例 123 flag.Usage = func() &#123; fmt.Println("hello world")&#125; 另外我们也可以看一下源码，原来的帮助信息是怎么生成的 1234var Usage = func() &#123; fmt.Fprintf(CommandLine.Output(), "Usage of %s:\n", os.Args[0]) PrintDefaults()&#125; 可见，先是打印了os.Args[0]，也就是程序信息，之后调用了PrintDefaults()，打印了所有flag的信息 urfave/cli其实官方给出的flag已能满足大部分要求，如果有更复杂的需要，可以借助这个强大的第三方包urfave/cli 安装与导包1go get github.com/urfave/cli 123import ( "gopkg.in/urfave/cli.v1") 简单使用该包的github主页有详细的使用说明，这里就不一一赘述了，只简单说一下常用的使用流程 实例化App对象 1app := cli.NewApp() 配置App信息 123456789101112131415161718192021222324252627282930313233343536//这个包可以配置丰富的App描述信息，如名称，版本号，作者，版权信息，程序简介等app.Name = "HelloWorld"app.Version = "1.0.0"app.Authors = []cli.Author&#123; cli.Author&#123; Name: "Tom", Email: "Tom@example.com", &#125;,&#125;app.Copyright = "(c) 1999 Serious Enterprise"app.Usage = "greet"app.UsageText = "Example program"//输入go run example.go -h后显示如下/*NAME: HelloWorld - greetUSAGE: Example programVERSION: 1.0.0AUTHOR: Tom &lt;Tom@example.com&gt;COMMANDS: help, h Shows a list of commands or help for one commandGLOBAL OPTIONS: --help, -h show help --version, -v print the versionCOPYRIGHT: (c) 1999 Serious Enterprise*/ 定义程序执行逻辑 这里是指程序运行的逻辑。主要是配置app.Action，例：12345app.Action = func(c *cli.Context) &#123; fmt.Println("hello world") &#125;//go run example.go //输出hello world 当然我们也可以不在这里定义主程序逻辑，在这里定义的一个好处是cli.Context携带了许多有用的上下文环境变量供我们使用，后面可以见到。 app.Action是执行程序时执行的逻辑，我们也可以定义在程序执行前后所要插入的逻辑，定义app.Before与app.After即可，例123456789101112131415161718192021222324func main() &#123; app := cli.NewApp() app.Before = func(context *cli.Context) error &#123; fmt.Println("before hello world") return nil; &#125; app.Action = func(c *cli.Context) &#123; fmt.Println("hello world") &#125; app.After = func(context *cli.Context) error &#123; fmt.Println("after hello world") return nil; &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal(err) &#125;&#125;//执行go run example.go/* 输出：before hello worldhello worldafter hello world*/ 注意：如果app.Before返回的error不为空，app.Action的内容将不会执行，而不管app.Action与app.Before中是否有错误发生，app.After的内容都会执行，app.After可用于收尾工作。 定义flag 这里的flag概念和上文中go的标准包中flag类似，直接看一个例子：12345678910111213141516171819202122func main() &#123; app := cli.NewApp() app.Flags = []cli.Flag&#123; cli.StringFlag&#123; Name:"path", Value:"/home/", Usage:"setting path", &#125;, &#125; app.Action = func(c *cli.Context) &#123; fmt.Println(c.String("path")) &#125; err := app.Run(os.Args) if err != nil &#123; log.Fatal("aaa",err) &#125;&#125;//输入go run example.go -path /home/base//输出：/home/base//输入go run example.go//输出：/home/ 定义起来很简单，关键几个要素就是Name和Value，取值时使用cli.Context提供的对应取值方法即可。包内预定义了许多种类型的flag，基本涵盖了所有基本类型，详见这里 另外在取值时，除了调用如c.Int(),c.String()之类的方法，还可以在定义flag时直接绑定到某些变量上，如：123456var age intcli.IntFlag&#123; Name:"age", Value:100, Destination:&amp;age,&#125; 另外，还可以配置flag的简写或别名，只需在定义Name时定义多个名称，中间用逗号隔开即可，例：123456cli.IntFlag&#123; Name:"age,a,ege", Value:100, Destination:&amp;age,&#125;,//-age -a -ege 都是有效的 配置子命令 如git push …中push就是一个子命令，这个包为我们提供了便捷定义子命令及其动作的方法12345678910111213app.Commands = []cli.Command&#123; &#123; Name: "push", Aliases: []string&#123;"p"&#125;, Usage: "push a file to the server", Action: func(c *cli.Context) error &#123; fmt.Println("push flie: ", c.Args().First())//c.Args().First()取命令后的第一个参数 return nil &#125;, &#125;, &#125;//执行go run example.go push test.txt//输出：push flie: test.txt 用法很简单，指定命名名，别名用法，以及相应动作即可。另外子命令可以像它的一个程序一样，有自己flag，Before，After，甚至是自己的子命令，使用Subcommands定义 注意，如果即定义了app的action，又定义了子命令的action，同一时间只能执行一个，如调用子命令时，app的action就不会执行 启动程序 所有配置都配置完成后，就需要启动程序，不然是不会生效的1234err := app.Run(os.Args)if err != nil &#123; log.Fatal("aaa",err)&#125; 最后给出一个详细例子，这是给出的，基本上涵盖了所有配置要点:例子]]></content>
      <categories>
        <category>go语言学习笔记</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F12%2F20%2Fhello-world%2F</url>
    <content type="text"><![CDATA[一切都从Hello World开始！ Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
